Issue Number,Issue Title,Issue Body
29608,Cannot `import tensorflow.summary` since 2019-06-08 nightly,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): gLinux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `('v1.12.1-3679-g3040de1372', '2.0.0-dev20190608')`
- Python version: 2.7 or 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

Importing `tensorflow.summary` raises `ModuleNotFoundError`:

```
$ python -c 'import tensorflow.summary'; echo $?
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow.summary'
```

**Describe the expected behavior**

Importing that module should succeed:

```
$ python -c 'import tensorflow.summary'; echo $?
0
```

**Code to reproduce the issue**

```
$ activate ~/virtualenv/tf-nightly-2.0-preview-20190606-py2.7
$ python -c 'import tensorflow.summary'; echo $?
0
$ activate ~/virtualenv/tf-nightly-2.0-preview-20190607-py2.7
$ python -c 'import tensorflow.summary'; echo $?
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/buildtools/current/sitecustomize/sitecustomize.py"", line 152, in SetupPathsAndImport
    return real_import(name, globals, locals, fromlist, level)
  File ""/HOMEDIR/virtualenv/tf-nightly-2.0-preview-20190607-py2.7/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 93, in <module>
    from tensorflow_core import *
AttributeError: 'module' object has no attribute 'compiler'
1
$ activate ~/virtualenv/tf-nightly-2.0-preview-20190608-py2.7
$ python -c 'import tensorflow.summary'; echo $?
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/buildtools/current/sitecustomize/sitecustomize.py"", line 152, in SetupPathsAndImport
    return real_import(name, globals, locals, fromlist, level)
ImportError: No module named summary
1
```

**Other info / logs**

cc @mihaimaruseac; is this related to recent Pip changes?
"
29607,"How do I extract information (consistently) such as Accuracy etc,.. from the distributed example/context ?","I was using your distribute example: https://www.tensorflow.org/tutorials/distribute/training_loops

I wanted to know how to properly extract some properties such as accuracy in this custom training loop example.

I have tried a couple of things but the documentation regarding this is not too specific.

Something I was initially looking at was:
  - passing in or returning a tf.Keras.metrics object, taking the logits and labels within the step_fn and getting predictions and then accuracy. But I am running into issues of tensor parsing. Should I be using tf.Summary.scalar in some way then?

A concrete reply would help."
29599,model.fit_generator(verbose=0/2) prints multiple lines per epoch during validation.,"Custom code: Yes (included below)
OS Platform: Debian GNU/Linux 9.8 (stretch) (GNU/Linux 4.9.0-8-amd64 x86_64)
TensorFlow installed from: conda install -c anaconda tensorflow-gpu
TensorFlow version: 1.13.1
Python version: 3.7.1
CUDA/cuDNN version: 10.0
GPU model and memory: Tesla P4 7611MiB

**Describe the current behavior**
When verbose=0, it should be silent, but it prints out multiple lines during validation. It's same for verbose=2.

**Describe the expected behavior**
It should be ""0 = silent, 1 = progress bar, 2 = one line per epoch.""

**Code to reproduce the issue**
```
import numpy as np
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Input, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.utils import Sequence

class CustomCallback(Callback):
	def __init__(self, patience=10, restore_best=True, dir=""weights""):
		super().__init__()
		self.best_score = 0.0
		self.best_epoch = 0
		self.best_weights = None
		self.patience = patience
		self.restore_best = restore_best

	def on_epoch_end(self, epoch, logs={}):
		score = logs[""val_acc""]
		if score>self.best_score:
			self.best_score = score
			self.best_epoch = epoch
			self.best_weights = self.model.get_weights()
			print(f""\nBest Score: {self.best_score*100:.2f}"")
		else: print(f""\nBest Epoch: {self.best_epoch+1}, Best Score: {self.best_score*100:.2f}"")

		if self.patience>0 and epoch-self.best_epoch >= self.patience:
			print(f""\nStopping... Best Epoch: {self.best_epoch+1}, Best Score: {self.best_score*100:.2f}"")
			self.stopped_epoch = epoch
			self.model.stop_training = True
			if self.restore_best: 		self.model.set_weights(self.best_weights)
    
class DataGenerator(Sequence):
	def __init__(self,x, y, batch_size=32):
		self.x = x
		self.y = y
		self.batch_size = batch_size
		self.on_epoch_end()

	def __len__(self):
		return int(np.ceil(len(self.x) / float(self.batch_size)))

	def on_epoch_end(self):
		self.indexes = np.arange(len(self.x))
		np.random.shuffle(self.indexes)
	
	def __getitem__(self, index):
		indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
		x_batch = self.x[indexes]
		y_batch = self.y[indexes]
		return x_batch, y_batch

def dense_model(input_shape, output_shape):
	inputs = Input(input_shape)
	x = Flatten()(inputs)
	x = Dense(300, activation='relu')(x)
	x = Dense(100, activation=""relu"")(x)
	outputs = Dense(output_shape, activation='softmax')(x)
	model = Model(inputs=inputs, outputs=outputs)
	model.compile(loss=""categorical_crossentropy"", optimizer=""adam"", metrics=[""accuracy""])
	return model

(x_train, y_train), (x_test, y_test) = mnist.load_data()
height, width = 28, 28
input_shape = (height, width)
output_shape = 10
x_train = x_train/255
x_test = x_test/255
y_train = to_categorical(y_train, output_shape)
y_test = to_categorical(y_test, output_shape)
model = dense_model(input_shape, output_shape)
history = model.fit_generator(DataGenerator(x_train, y_train), epochs=12, validation_data=DataGenerator(x_test, y_test), verbose=0)
```

**Other info / logs**
``
Epoch 1/12
1/313 [..............................] - ETA: 17s - loss: 0.1513 - acc: 0.9688
25/313 [=>............................] - ETA: 1s - loss: 0.1436 - acc: 0.9525
48/313 [===>..........................] - ETA: 0s - loss: 0.1517 - acc: 0.9479
...
``
"
29597,"Compiling from source, can't find any working combination","GPU 1080Ti
cuda 10.1
cuDNN 7.6.0
nccl 2.4.7
Ubuntu 18.04.2
Python 3.6
Tensorflow r1.12, r1.13, r1.14
Bazel 0.17.2, 0.18.0, 0.25.2, 0.26.1

r1.14 + 0.26.1
downgrade bazle to 0.25.2

r1.14 + 0.25.2
This error:
`Traceback (most recent call last):
  File ""third_party/gpus/find_cuda_config.py"", line 497, in <module>
    main()
  File ""third_party/gpus/find_cuda_config.py"", line 489, in main
    for key, value in sorted(find_cuda_config().items()):
  File ""third_party/gpus/find_cuda_config.py"", line 448, in find_cuda_config
    _get_default_cuda_paths(cuda_version))
  File ""third_party/gpus/find_cuda_config.py"", line 164, in _get_default_cuda_paths
    ] + _get_ld_config_paths()
  File ""third_party/gpus/find_cuda_config.py"", line 144, in _get_ld_config_paths
    match = pattern.match(line.decode(""ascii""))
UnicodeDecodeError: 'ascii' codec can't decode byte 0xc2 in position 27: ordinal not in range(128)
Asking for detailed CUDA configuration...
`
I try any other combination of tensorflow ans bazel but I always get errors in different places.

r1.13 + 0.25.2
downgrate to 0.21.0

./configure work

Error at compiling:

`bazel build --config=opt --config=mkl --config=cuda //tensorflow/tools/pip_package:build_pip_package`

`ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': in /home/thomasd/tensorflow/tensorflow/tensorflow.bzl: Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/thomasd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1556
		_create_local_cuda_repository(repository_ctx)
	File ""/home/thomasd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1302, in _create_local_cuda_repository
		_find_libs(repository_ctx, cuda_config)
	File ""/home/thomasd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 840, in _find_libs
		_find_cuda_lib(""cublas"", repository_ctx, cpu_value, c..., ...)
	File ""/home/thomasd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 752, in _find_cuda_lib
		auto_configure_fail((""Cannot find cuda library %s"" %...))
	File ""/home/thomasd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 342, in auto_configure_fail
		fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: Cannot find cuda library libcublas.so.10.1
WARNING: Target pattern parsing failed.
ERROR: error loading package 'tensorflow/tools/pip_package': in /home/thomasd/tensorflow/tensorflow/tensorflow.bzl: Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/thomasd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1556
		_create_local_cuda_repository(repository_ctx)
	File ""/home/thomasd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1302, in _create_local_cuda_repository
		_find_libs(repository_ctx, cuda_config)
	File ""/home/thomasd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 840, in _find_libs
		_find_cuda_lib(""cublas"", repository_ctx, cpu_value, c..., ...)
	File ""/home/thomasd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 752, in _find_cuda_lib
		auto_configure_fail((""Cannot find cuda library %s"" %...))
	File ""/home/thomasd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 342, in auto_configure_fail
		fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: Cannot find cuda library libcublas.so.10.1
INFO: Elapsed time: 5.369s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/tools/pip_package
    Fetching @local_config_cuda; fetching
`

r1.12 + 0.21.0

.configure work

Error at compiling:

`ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': The native http_archive rule is deprecated. load(""@bazel_tools//tools/build_defs/repo:http.bzl"", ""http_archive"") for a drop-in replacement.
Use --incompatible_remove_native_http_archive=false to temporarily continue using the native rule.
ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': The native http_archive rule is deprecated. load(""@bazel_tools//tools/build_defs/repo:http.bzl"", ""http_archive"") for a drop-in replacement.
Use --incompatible_remove_native_http_archive=false to temporarily continue using the native rule.
INFO: Elapsed time: 1.986s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    Fetching @io_bazel_rules_closure; fetching`

I try any other combination of tensorflow and bazel but I always get errors in different places.
"
29596,Post Training Quantization slower in latest tf-nightly vs tf 1.10,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04.2 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): tensorflow==1.10.0 vs tf-nightly==1.14.1.dev20190606
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I have converted the mobilenetv2_1.0_224_frozen.pb model to tflite and performed post training quantization in two virtual environments - one with tf-nightly==1.14.1.dev20190606 (following the instructions from here: https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/lite/tutorials/post_training_quant.ipynb) and one with tensorflow==1.10.0.

During inference, I have observed that the model converted with the latest tensorflow version is ~2x slower

**Describe the expected behavior**
I expect that the latest post training quantization should remain as fast as the one in version 1.10.
 
**Code to reproduce the issue**
The scripts used for conversion:
[conversion_scripts.zip](https://github.com/tensorflow/tensorflow/files/3272376/conversion_scripts.zip)

For inference I have used tflite 1.10 and tflite 2.0.

I have used the profiling functionality of tflite and observed that:
   - in tf 1.10 there are 49 DEQUANTIZE Nodes vs 15 DEQUANTIZE Nodes for tf 1.14.1.dev20190606
   - CONV_2D is ~3x slower for the converted model in tf 1.14.1.dev20190606 (when running a float model CONV_2D seems similar in both tf versions)
   - by looking at the run order of the nodes it seems that only the depthwise nodes are quantized in tf 1.14.1.dev20190606 but in tf 1.10 expand, project and depthwise are quantized.

Here is the Summary by node type for tf 1.10:
```
Number of nodes executed: 115
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]     [times called]
	       DEPTHWISE_CONV_2D	       17	   151.612	   68
	                 CONV_2D	       36	   125.676	    144
	              DEQUANTIZE	       49	     7.872	     	      196
	                     ADD	       10	     0.288	            40
	         AVERAGE_POOL_2D	        1	     0.056	    	   4
	                 SOFTMAX	        1	     0.028	     	        4
	                 RESHAPE	        1	     0.004	     	        4

```

And the Summary by node type for tf 1.14.1.dev20190606:
```

Number of nodes executed: 81
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	   [times called]
	                 CONV_2D	       36	   380.280	        144
	       DEPTHWISE_CONV_2D	       17	   160.624	   68
	                     ADD	       10	     0.428	     	       40
	         AVERAGE_POOL_2D	        1	     0.056	    	        4
	                 SOFTMAX	        1	     0.028	     	        4
	              DEQUANTIZE	       15	     0.016	     	       60
	                 RESHAPE	        1	     0.004	               4
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29595,Installation of Tensorflow 2.0.0.dev20190607 on Ubuntu  :AttributeError: module 'tensorflow_core' has no attribute 'compiler',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): GCP ""Ubuntu""VERSION=""18.04.2 LTS (Bionic Beaver)""
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version: TF 2.0 nightly tf-nightly-2.0-preview==2.0.0.dev20190607
- Python version: 3.6.6 
- Installed using virtualenv? pip? conda?: conda virtual env
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the problem**
Installation of TF is fine but it crashes during the import of Tensorflow 2.0.0.dev20190607 on GCP Ubuntu. The exact same works on Mac OS.

```
Python 3.6.6 |Anaconda, Inc.| (default, Oct  9 2018, 12:34:16)
[GCC 7.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/root/miniconda3/envs/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow/__init__.py"", line 93, in <module>
    from tensorflow_core import *
AttributeError: module 'tensorflow_core' has no attribute 'compiler'
```
packages related to TF after the installation:

> 
> tb-nightly                1.14.0a20190610          pypi_0    pypi
> tensorflow-estimator-2-0-preview 1.14.0.dev2019060900          pypi_0    pypi
> tensorflow-metadata       0.13.0                   pypi_0    pypi
> tf-nightly-2-0-preview    2.0.0.dev20190607          pypi_0    pypi
> tfds-nightly              1.0.2.dev201906050105          pypi_0    pypi

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
more environment_2_0.yml
channels:
- defaults
- conda-forge
dependencies:
- python=3.6.6
- numpy=1.14.5
- scipy=1.1.0
- scikit-learn=0.20.1
- tornado=4.5.3
- jupyter=1.0.0
- jupyterlab=0.34.9
- jupyter_contrib_nbextensions=0.5.0
- jupyter_nbextensions_configurator=0.4.0
- pandas=0.24.2
- matplotlib
- nomkl # Only for Mac user
- notebook=5.6.0
- ipykernel=4.10.0
- ipywidgets=7.4.1
- nbconvert=5.4.0
- watermark
- pytest=3.6.2
- autopep8
- pylint
- pep8=1.7.1
- pylama=7.4.3
- nbdime
- google-auth
- pillow
- scikit-image=0.14.0
- seaborn=0.9.0
- lime
- google-cloud-storage
- google-cloud-bigquery
- psutil
- pip=19.1
- pip:
  - tfds-nightly==1.0.2.dev201906050105
  - tf-nightly-2.0-preview==2.0.0.dev20190607
```

```
conda env create -f environment_2_0.yml -n env_gcp_dl_2_0_nightly
conda activate env_gcp_dl_2_0_nightly
```
"
29594,sparse.to_dense don't work when used to dataset element,"`def _parse_function(example_proto):

  features = {""feature0"":tf.io.VarLenFeature(tf.int64),
              ""feature1"": tf.io.FixedLenFeature([1], tf.int64)}
  parsed_features = tf.io.parse_single_example(example_proto, features)
  print(parsed_features['feature0'])
  return tf.sparse.to_dense(parsed_features['feature0']), parsed_features['feature1']

dataset = tf.data.TFRecordDataset(filename)
dataset = dataset.map(_parse_function)`

error like below
`  File ""/home/yi/bin/Miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py"", line 68, in _convert_to_sparse_tensor
    raise TypeError(""Input must be a SparseTensor."")
TypeError: Input must be a SparseTensor.`
"
29593,tf.estimator.train_and_evaluate fails to print anything (loss/ accuracy) when used with  tf.keras.estimator.model_to_estimator [tf2.0 beta],"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below): 2.0.0-beta0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0/ 7.5
- GPU model and memory: 11gb GTX 1080ti

**Describe the current behavior**
When training an estimator which is got from a tf.keras.Model instance, the tf.estimator.train_and_evaluate method fails to log anything on the stdout.
```
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)
```
However, if set the above flag, i can loss being logged (similar to that of API v1)

```
I0610 16:24:54.069874 140233725445952 basic_session_run_hooks.py:260] loss = 0.9756932, step = 600 (4.162 sec)
```
**Describe the expected behavior**
log the metrics and loss as described in the official docs
[https://www.tensorflow.org/beta/guide/migration_guide]()
```
W0608 04:37:53.280840 139724414916352 estimator.py:1811] Using temporary folder as model directory: /tmp/tmp4rht4njh W0608 04:37:54.037474 139724414916352 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version. Instructions for updating: Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts. W0608 04:37:58.233872 139724414916352 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating: Use standard file APIs to check for files with this prefix. 
({'accuracy': 0.678125, 'global_step': 25, 'loss': 1.4507575}, [])
```
**Code to reproduce the issue**
```
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
import tensorflow_datasets as tfds
import tensorflow as tf
import numpy as np
print('Tensorflow version', tf.__version__)

def input_fn(training=False):
    batch_size = 8
    def preprocess_map_func(image, label):
        image = tf.image.resize(image, size=[299, 299])
        image.set_shape([None, None, 3])
        image /=  127.5
        image -= 1
        return image, label
    
    def input_():
        if training:
            dataset = tfds.load(name='cats_vs_dogs', as_supervised=True, split=[""train""])[0]
            train_dataset = dataset.skip(3000)
            train_dataset = train_dataset.map(preprocess_map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)
            train_dataset = train_dataset.shuffle(1024).batch(batch_size).repeat().prefetch(tf.data.experimental.AUTOTUNE)
            return train_dataset
        else:
            dataset = tfds.load(name='cats_vs_dogs', as_supervised=True, split=[""train""])[0]
            test_dataset = dataset.take(3000)
            test_dataset = test_dataset.map(preprocess_map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)
            test_dataset = test_dataset.shuffle(1024).batch(batch_size).repeat().prefetch(tf.data.experimental.AUTOTUNE)
            return test_dataset
    return input_

epochs = 10
samples = 23000
batch_size = 8

base_model = Xception(input_shape=(299, 299, 3), include_top=False, weights='imagenet')
y = GlobalAveragePooling2D()(base_model.output)
y = Dense(units=1, activation='linear', kernel_initializer='he_normal')(y)
base_model.trainable = False
model = tf.keras.Model(base_model.input, y)
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

estimator = tf.keras.estimator.model_to_estimator(model)
train_spec = tf.estimator.TrainSpec(input_fn(training=True), max_steps=epochs * samples//batch_size)
eval_spec = tf.estimator.EvalSpec(input_fn(training=False), steps=3000//batch_size)
tf.estimator.train_and_evaluate(estimator, 
                                train_spec=train_spec, 
                                eval_spec=eval_spec)

```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29592,Custom Op Placement on TPUs,"Hello,

I'd like to place one portion of my model on a single core of a TPU and another portion on another core (as opposed to the usual full-model replica method).

What is the correct way to do this? I understand that I'll need to do away with TPUEstimator and use a tpu.rewrite() along with tf.Sessions, but I'm not sure the correct way to specify placement for a TPU core.

Is it as simple as `with tf.device(""TPU:<core_id>""):`?"
29591,Broken Link,"https://www.tensorflow.org/images/models/pose_estimation.gif


this Link is broken"
29590,"Does tFlite support input shape=[1,32,None,3]","**System information**
 Linux Ubuntu 16.04
tf-cpu-1.13.1

I use tensorflow train a crnn+ctc OCR  model,the width of textline is Variable,but when I convert pb to tflite,ValueError: None is only supported in the 1st dimension Tensor 'input_images' has invalid shape [1, 32, None, 3]。

"
29588,Segmentation fault model_from_json,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Linux Ubuntu 16.04 LTS:
- TensorFlow installed with pip install:
- TensorFlow version 1.13.1
- Python version: 3.5
- CUDA/cuDNN version: 10.0/?
- GPU model and memory: Tesla K80 11GB (even after disconnecting the card from VM app still crashed)

Tensorflow loads fine, yet program crashes with segmentation error at load_from_json action.


**Code to reproduce the issue**
```
import numpy.core.multiarray
import numpy as np
import tensorflow as tf
from keras.models import load_model, model_from_json

json_file = open(os.path.join('/'.join(FLAGS.model_path.split('/')[0:-1]), 'model.json'), 'r')
loaded_model_json = json_file.read()
json_file.close()
model = model_from_json(loaded_model_json, custom_objects={'tf': tf, 'RESIZE_FACTOR': RESIZE_FACTOR})    <<<<<  This line crashes
model.load_weights(FLAGS.model_path)
```

Exactly the same code runs smoothly on my laptop with only CPU, windows 10 and python 3.7.
"
29587,"when i install tensorflow2.0 ,I run it it told me that:","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.0
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\heyx\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\heyx\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\heyx\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\heyx\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\heyx\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 找不到指定的模块。

"
29586,"when i install tensorflow2.0 ,I run it it told me that:","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29584,TF 2.0 beta0: Can't use tf.keras.layers.LSTM on GPU.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (Linux d8cb89680c63 4.14.79)
- TensorFlow installed from (source or binary): binary (using pip)
- TensorFlow version (use command below): tensorflow-gpu-2.0.0b0
- Python version: 3.6.7
- CUDA/cuDNN version: V10.0.130
- GPU model and memory: Tesla T4  15079MiB

**Describe the current behavior**
After `!pip install tensorflow-gpu==2.0.0-beta0`, and restart Google colab runtime. Try to fit the model, got the following log, then it just stay there 5 minutes plus, then start logging the train steps. Besides the training is very slow, so I suspect it is trained on CPU.
But it **can** train on GPU when I `!pip install tensorflow-gpu==2.0.0-alpha0`
```
2019-06-10 03:10:39.688276: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-06-10 03:10:39.775107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-10 03:10:39.775558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
2019-06-10 03:10:39.798707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-10 03:10:39.958916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-10 03:10:40.032897: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-10 03:10:40.050421: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-10 03:10:40.183197: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-10 03:10:40.286011: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-10 03:10:40.620983: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-10 03:10:40.621231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-10 03:10:40.621760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-10 03:10:40.622122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-06-10 03:10:40.628272: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-10 03:10:40.800975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-10 03:10:40.804767: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29ac300 executing computations on platform CUDA. Devices:
2019-06-10 03:10:40.804807: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2019-06-10 03:10:40.888533: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-06-10 03:10:40.888737: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29acbc0 executing computations on platform Host. Devices:
2019-06-10 03:10:40.888768: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-10 03:10:40.889062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-10 03:10:40.889477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
2019-06-10 03:10:40.889555: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-10 03:10:40.889580: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-10 03:10:40.889601: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-10 03:10:40.889623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-10 03:10:40.889641: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-10 03:10:40.889659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-10 03:10:40.889679: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-10 03:10:40.889776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-10 03:10:40.890166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-10 03:10:40.890578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-06-10 03:10:40.893860: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-10 03:10:40.895061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-10 03:10:40.895092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-06-10 03:10:40.895105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-06-10 03:10:40.902720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-10 03:10:40.903146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-10 03:10:40.903526: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2019-06-10 03:10:40.903571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
2019-06-10 03:10:40.928132: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 388579200 exceeds 10% of system memory.
2019-06-10 03:10:41.602882: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 388579200 exceeds 10% of system memory.
2019-06-10 03:10:41.835533: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 388579200 exceeds 10% of system memory.
I0610 03:10:42.373863 139896129251200 lstm.py:580] LSTM, act is tanh
I0610 03:10:47.659146 139896129251200 lstm.py:716] build model -> done
W0610 03:10:47.744854 139896129251200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where

Epoch 00001: LearningRateScheduler reducing learning rate to 0.000625.
Epoch 1/4
2019-06-10 03:10:50.361292: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-06-10 03:10:50.708566: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-06-10 03:10:51.075378: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-06-10 03:10:51.252533: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-10 03:10:52.298371: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 55296000 exceeds 10% of system memory.
2019-06-10 03:10:57.025235: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 388579200 exceeds 10% of system memory.
```
**Describe the expected behavior**
Model fitting should run successfully in GPU.

**Code to reproduce the issue**
```
from tensorflow.keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, PReLU
...
...
    def build_lstm_model_customed(self, num_aux_targets, with_aux=False, loss='binary_crossentropy', metrics=None,
                                  hidden_act='relu', with_BN=False):
        logger.debug(f'model detail: loss {loss}, hidden_act {hidden_act}, with_BN {with_BN}')
        words = Input(shape=(d.MAX_LEN,))  # (None, 180)
        x = Embedding(*self.embedding_matrix.shape, weights=[self.embedding_matrix], trainable=False)(words)

        x = SpatialDropout1D(0.2)(x)
        logger.debug(""LSTM, act is tanh"")
        x = Bidirectional(LSTM(LSTM_UNITS, activation='tanh', return_sequences=True))(x)
        x = Bidirectional(LSTM(LSTM_UNITS, activation='tanh', return_sequences=True))(x)

        hidden = concatenate([
            AttentionRaffel(d.MAX_LEN, name=""attention_after_lstm"")(x),
            GlobalMaxPooling1D()(x),
            #GlobalAveragePooling1D()(x),
        ])

        activate_type = hidden_act
        if activate_type == 'prelu':  # found it not working
            hidden = add([hidden, PReLU()(Dense(DENSE_HIDDEN_UNITS, activation=None)(hidden))])
            if with_BN: hidden = BatchNormalization()(hidden)
            hidden = add([hidden, PReLU()(Dense(DENSE_HIDDEN_UNITS, activation=None)(hidden))])
        else:
            hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation=activate_type)(hidden)])
            if with_BN: hidden = BatchNormalization()(hidden)
            hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation=activate_type)(hidden)])

        logit = Dense(1, activation=None)(hidden)
        result = Activation('sigmoid')(logit)

        if with_aux:
            aux_result = Dense(num_aux_targets, activation='sigmoid')(hidden)
            model = Model(inputs=words, outputs=[result, aux_result])
        else:
            model = Model(inputs=words, outputs=result)

        model.compile(loss=loss, optimizer='adam', metrics=metrics)

        return model

    model = build_lstm_model_customed(0)
    model.fit(X,y)
```

**Other info / logs**
```
== check os platform ===============================================
os: Linux
os kernel version: #1 SMP Wed Dec 19 21:19:13 PST 2018
os release version: 4.14.79+
os platform: Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic
linux distribution: ('Ubuntu', '18.04', 'bionic')
linux os distribution: ('Ubuntu', '18.04', 'bionic')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='d8cb89680c63', release='4.14.79+', version='#1 SMP Wed Dec 19 21:19:13 PST 2018', machine='x86_64', processor='x86_64')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 7.4.0-1ubuntu1~18.04) 7.4.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
mesh-tensorflow          0.0.5                
msgpack-numpy            0.4.3.2              
numpy                    1.16.4               
protobuf                 3.7.1                
tensorflow               1.13.1               
tensorflow-estimator     1.13.0               
tensorflow-gpu           2.0.0b0              
tensorflow-hub           0.4.0                
tensorflow-metadata      0.13.0               
tensorflow-probability   0.6.0                

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.0.0-beta0
tf.version.GIT_VERSION = v1.12.1-3259-gf59745a381
tf.version.COMPILER_VERSION = 4.8.5
```"
29583,bulid form source 1.13.1 no such package '@org_sqlite//,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):centos7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:1.13.1
- Python version:3.6
- Installed using virtualenv? pip? conda?:virtualenv
- Bazel version (if compiling from source):0.25.3
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.0
- GPU model and memory:

when i build tf  from source and run this command:
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

there is a error :no such package '@org_sqlite//:
`ERROR: /tmp/tf/tensorflow/tensorflow/contrib/summary/BUILD:65:1: no such package '@org_sqlite//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/www.sqlite.org/2019/sqlite-amalgamation-3280000.zip, https://www.sqlite.org/2019/sqlite-amalgamation-3280000.zip] to /home/tico/.cache/bazel/_bazel_tico/111e4735042cad380f0b87cff4bce3f6/external/org_sqlite/sqlite-amalgamation-3280000.zip: All mirrors are down: [GET returned 404 Not Found, sun.security.validator.ValidatorException: PKIX path bu`

i think the  download url is wrong , when i open this url:
 http://mirror.tensorflow.org/www.sqlite.org/2019/sqlite-amalgamation-3280000.zip
the page can not open, and in the  http://mirror.tensorflow.org/ page ,for www.sqlite.org key,there only have this:

```
<Contents>
<Key>
www.sqlite.org/2018/sqlite-amalgamation-3240000.zip
</Key>
<Generation>1553535068786424</Generation>
<MetaGeneration>2</MetaGeneration>
<LastModified>2019-03-25T17:31:08.786Z</LastModified>
<ETag>""4ea1e0c6e7e82cb0490d4753d6878698""</ETag>
<Size>2206612</Size>
</Contents>
```

so , i  vi  the workspace.bzl  file  and  change the  sqlite download url http://mirror.tensorflow.org/www.sqlite.org/2019/sqlite-amalgamation-3280000.zip to  https://mirror.bazel.build/www.sqlite.org/2018/sqlite-amalgamation-3240000.zip
,then it works!
"
29582,TFLite build failed in 7348ee578693bb5aacdb45a1be746f0c933fc65f,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version:7348ee578693bb5aacdb45a1be746f0c933fc65f
- Python version:2.7
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I use tensorflow/tensorflow/lite/java/demo in Android studio.
Android studio version:3.1.2 Andoird_NDK=r16b
run build, it comes error:
<img width=""1351"" alt=""image"" src=""https://user-images.githubusercontent.com/38650344/59168984-dbaf3e00-8b6a-11e9-98d5-c69cd43a6c2c.png"">

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
The log info is:
Could not download tensorflow-lite-gpu.aar (org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly)
   > Could not get resource 'https://jcenter.bintray.com/org/tensorflow/tensorflow-lite-gpu/0.0.0-nightly/tensorflow-lite-gpu-0.0.0-nightly.aar'.
      > Could not GET 'https://jcenter.bintray.com/org/tensorflow/tensorflow-lite-gpu/0.0.0-nightly/tensorflow-lite-gpu-0.0.0-nightly.aar'.
         > Connect to d29vzk4ow07wi7.cloudfront.net:443 [d29vzk4ow07wi7.cloudfront.net/13.224.42.66, d29vzk4ow07wi7.cloudfront.net/13.224.42.221, d29vzk4ow07wi7.cloudfront.net/13.224.42.134, d29vzk4ow07wi7.cloudfront.net/13.224.42.149] failed: Read timed out

"
29581,Inconsistency in Input Pipeline code block for test_dataset,"## URL(s) with the issue:

https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/generative/pix2pix.ipynb

## Description of issue (what needs changing):

The code block below appears under the heading `Input Pipeline`.
It appears to be an almost, but not quite, semantic copy of the code block above it for the 
`train_dataset`, except that, in this code block for the `test_dataset` we are shuffling the
`train_dataset` again.

```
test_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')
# shuffling so that for every epoch a different image is generated
# to predict and display the progress of our model.
train_dataset = train_dataset.shuffle(BUFFER_SIZE)
test_dataset = test_dataset.map(load_image_test)
test_dataset = test_dataset.batch(1)
```

So, I think that this code block should be:

```
test_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')
# shuffling so that for every epoch a different image is generated
# to predict and display the progress of our model.
test_dataset = test_dataset.shuffle(BUFFER_SIZE)
test_dataset = test_dataset.map(load_image_test)
test_dataset = test_dataset.batch(1)
```

Also note that the code block for the `train_dataset` has:

```
train_dataset = train_dataset.map(load_image_train,
                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)
```

But the code block for the `test_dataset` only has:
```
test_dataset = test_dataset.map(load_image_test)
```

The `AUTOTUNE ` is noted here, but not explained, so I can't easily comment on what its use,
or lack of, actually means:

https://www.tensorflow.org/api_docs/python/tf/data/experimental#AUTOTUNE

### Submit a pull request?

I can if this is actually incorrect."
29578,Tensorflow 2.0 graph slower than eager for dynamic batch sizes,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, Linux, Colaboratory
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): unknown 2.0.0-beta0
- Python version: 3.6.7
- CUDA/cuDNN version: 10
- GPU model and memory: Quadro M1000M, Colaboratory, ...

**Describe the current behavior**
Passing data with variable batch sizes to a training graph (as created by `tf.function`) causes the graph execution to be significantly slower than just executing the training in eager mode. It's also significantly slower than executing the same inputs with graph mode in TF1.x

While passing data with variable batch sizes is uncommon on most DL tasks, it is required for tasks on Geometric Learning. For example, if your data is graphs, even if you fix the same number of graphs per batch, you can still get a varying number of nodes or edges.

**Describe the expected behavior**
Graph mode should always be faster than eager mode.
Graph mode in TF2.0 should be at least approximately as fast as graph mode in TF 1.x.

**Code to reproduce the issue**
[Colab notebook available here](https://colab.research.google.com/drive/1xUVb0NAeOdefofgjKQhL_MB-XPILdSo_). Running with GPU makes eager mode significantly faster and the time difference more noticeable.
"
29576,Different variable names in keras layers depending on how layer is used,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary (conda defaults channel)
- TensorFlow version (use command below):
tf.version.VERSION = 1.13.1
tf.version.GIT_VERSION = b'unknown'
- Python version: 3.6.8
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
I am getting two different variable names from keras layers when variables are built.
If I create a layer and call it on some input, everything works as expected.
However, if I create a layer and call  `layer.build(input_shape)`, the variable names are different.
**Describe the expected behavior**
I expect to get the same variable names in a layer no matter how layer is used.

**Code to reproduce the issue**
Calling Keras layers on some input results in different variable names compared to calling layer.build:
```python
In [1]: import tensorflow as tf                                                                                                                                

In [2]: layer1 = tf.keras.layers.Dense(3, name=""dense_1"")                                                                                                      

In [3]: layer1.variables                                                                                                                                       
Out[3]: []

In [4]: layer1.build((None, 3))                                                                                                                                

In [5]: layer1.variables                                                                                                                                       
Out[5]: 
[<tf.Variable 'kernel:0' shape=(3, 3) dtype=float32>,
 <tf.Variable 'bias:0' shape=(3,) dtype=float32>]

In [6]: layer2 = tf.keras.layers.Dense(3, name=""dense_2"")                                                                                                      

In [7]: layer2.variables                                                                                                                                       
Out[7]: []

In [8]: layer2(tf.zeros((32, 3)))                                                                                                                              
Out[8]: <tf.Tensor 'dense_2/BiasAdd:0' shape=(32, 3) dtype=float32>

In [9]: layer2.variables                                                                                                                                       
Out[9]: 
[<tf.Variable 'dense_2/kernel:0' shape=(3, 3) dtype=float32>,
 <tf.Variable 'dense_2/bias:0' shape=(3,) dtype=float32>]
```
In the first case, variable names are:
```
[<tf.Variable 'kernel:0' shape=(3, 3) dtype=float32>,
 <tf.Variable 'bias:0' shape=(3,) dtype=float32>]
```
while in the second case, they are:
```
[<tf.Variable 'dense_2/kernel:0' shape=(3, 3) dtype=float32>,
 <tf.Variable 'dense_2/bias:0' shape=(3,) dtype=float32>]
```

I expect the variables in the first layer to be prefixed with `dense_1/`.

**Other info / logs**
None
"
29575, DLL load failed: The specified module could not be found,"when running code with keras library 
it ran at the first time , but when running it at the second time this exception appeared


C:\ProgramData\Anaconda3\envs\tf-1-9-36\python.exe ""C:/Users/TOSHIBA/PycharmProjects/omnia text detection/CNN.py""
Traceback (most recent call last):
  File ""C:/Users/TOSHIBA/PycharmProjects/omnia text detection/CNN.py"", line 4, in <module>
    import numpy as np
  File ""C:\ProgramData\Anaconda3\envs\tf-1-9-36\lib\site-packages\numpy\__init__.py"", line 140, in <module>
    from . import _distributor_init
  File ""C:\ProgramData\Anaconda3\envs\tf-1-9-36\lib\site-packages\numpy\_distributor_init.py"", line 34, in <module>
    from . import _mklinit
ImportError: DLL load failed: The specified module could not be found.
"
29574,Op type not registered 'swish_f32' in binary running,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-9-a62a8332a64b> in <module>
     10       verbose=1,
     11     use_multiprocessing=True,
---> 12     workers=4)

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1513         shuffle=shuffle,
   1514         initial_epoch=initial_epoch,
-> 1515         steps_name='steps_per_epoch')
   1516 
   1517   def evaluate_generator(self,

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)
    255 
    256       is_deferred = not model._is_compiled
--> 257       batch_outs = batch_function(*batch_data)
    258       if not isinstance(batch_outs, list):
    259         batch_outs = [batch_outs]

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)
   1256         outputs = self.train_function(ins)  # pylint: disable=not-callable
   1257       else:
-> 1258         self._make_fit_function()
   1259         outputs = self._fit_function(ins)  # pylint: disable=not-callable
   1260 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py in _make_fit_function(self)
   2175     ]
   2176     self._make_train_function_helper(
-> 2177         '_fit_function', [self.total_loss] + metrics_tensors)
   2178 
   2179   def _make_test_function_helper(self, fn_name, outputs):

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py in _make_train_function_helper(self, fn_name, outputs)
   2160             updates=updates,
   2161             name='train_function',
-> 2162             **self._function_kwargs)
   2163         setattr(self, fn_name, fn)
   2164 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py in function(inputs, outputs, updates, name, **kwargs)
   3241       raise ValueError('Session keyword arguments are not support during '
   3242                        'eager execution. You passed: %s' % (kwargs,))
-> 3243     return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)
   3244 
   3245   if kwargs:

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py in __init__(self, inputs, outputs, updates, name)
   3162         lifted_map = lift_to_graph.lift_to_graph(
   3163             init_tensors=init_tensors, graph=exec_graph, sources=inputs,
-> 3164             add_sources=True, handle_captures=True, base_graph=source_graph)
   3165 
   3166         inputs = [lifted_map[i] for i in inputs]

/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/lift_to_graph.py in lift_to_graph(init_tensors, graph, sources, disallowed_placeholders, add_sources, handle_captures, base_graph)
    313         continue
    314 
--> 315       _copy_non_source(op=op, graph=graph, op_map=op_map)
    316 
    317     return op_map

/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/lift_to_graph.py in _copy_non_source(op, graph, op_map)
    158         dtypes=[x.dtype for x in op.outputs],
    159         attrs=op.node_def.attr,
--> 160         name=op.name)
    161   op_map[op] = copied_op
    162   for i, o in enumerate(op.outputs):

/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/func_graph.py in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)
    450     return super(FuncGraph, self).create_op(
    451         op_type, inputs, dtypes, input_types, name, attrs, op_def,
--> 452         compute_device=compute_device)
    453 
    454   def capture(self, tensor, name=None):

/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    505                 'in a future version' if date is None else ('after %s' % date),
    506                 instructions)
--> 507       return func(*args, **kwargs)
    508 
    509     doc = _add_deprecated_arg_notice_to_docstring(

/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py in create_op(***failed resolving arguments***)
   3477           input_types=input_types,
   3478           original_op=self._default_original_op,
-> 3479           op_def=op_def)
   3480       self._create_op_helper(ret, compute_device=compute_device)
   3481     return ret

/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)
   1975     else:
   1976       if op_def is None:
-> 1977         op_def = self._graph._get_op_def(node_def.op)
   1978       # TODO(skyewm): op_def_library.apply_op() flattens the incoming inputs.
   1979       # Refactor so we don't have to do this here.

/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py in _get_op_def(self, type)
   3864     with c_api_util.tf_buffer() as buf:
   3865       # pylint: disable=protected-access
-> 3866       c_api.TF_GraphGetOpDef(self._c_graph, compat.as_bytes(type), buf)
   3867       # pylint: enable=protected-access
   3868       data = c_api.TF_GetBuffer(buf)

NotFoundError: Op type not registered 'swish_f32' in binary running on tensorflow-20190607-122214. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

My running environment:
Tensorflow 2.0 alpha,
Python 3.5.3
on Google Cloud Platform.

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29573,Tensorflow 2 eager execution is off by default,"This code:
```python
import tensorflow as tf
print(tf.__version__)
print(tf.executing_eagerly())
```
Produces this output:
```
2.0.0-beta0
False
```

I build it from source.
"
29572,Initialize Layer with weights loaded from files,"```python
embedding = tf.keras.layers.Embedding(1000, 64, 
    initializer=tf.keras.initializer.FileInitializer(""weights.npy"", verify_shape=True))
```


**System information**
- TensorFlow version (you are using): 1.13.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Presently there is no way to directly tell Tensorflow to initialize the weights of a layer from a file without loading them up first and passing them. This is not required and can be done at the target device itself using the callback.
**Will this change the current api? How?**
The current API remains unchanged.
**Who will benefit with this feature?**
Anyone doing NLP, Vision, who might want to specificly load the weights of a layer from a file. This could also help in sharing weights of a few layers of a complicated neural network. It is definitely beneficial when working with word2vec like embedding layers. 

If it's fine, I would like to get assigned to this. "
29571,tflite: Slicing isn't compatible with quantisation ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): v1.12.1-3185-g1a4a0aee1f 1.13.1
- Python version: 3.6.7
- CUDA/cuDNN version: -
- GPU model and memory: -

I'm trying to implement shufflenet v2 in Tensorflow 2.0 with tflite, which requires slicing.  This works fine with float precision, however when I turn on quantization I get an error. 

```
import numpy as np
import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION)

channels = 64
# Slicing & quantization together results in an error
use_slice = True
quantize = True

input = tf.keras.layers.Input(shape=(channels))
x = input
x *= x
if use_slice:
    x = x[:, ::2]

model = tf.keras.Model(inputs=[input], outputs=[x])
model.summary()


def _gen_input(channels):
    return tf.constant(np.random.uniform(0, 1, size=(1, channels,)), dtype=tf.float32)

# Test normal tensorflow forward pass
model(_gen_input(channels))

converter = tf.lite.TFLiteConverter.from_keras_model(model)
if quantize:
    converter.optimizations = [tf.lite.Optimize.DEFAULT]

def representative_data_gen():
    for _ in range(100):
        yield [_gen_input(channels)]

converter.representative_dataset = representative_data_gen
tflite_model = converter.convert()

interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.set_tensor(input_details[0]['index'], _gen_input(channels))
interpreter.invoke()
tflite_results = interpreter.get_tensor(output_details[0]['index'])
```

If I turn off either 'use_slice' or 'quantise', it works fine - however with both on I get the following error:

RuntimeError: tensorflow/lite/kernels/dequantize.cc:67 op_context.input->type == kTfLiteUInt8 || op_context.input->type == kTfLiteInt8 || op_context.input->type == kTfLiteFloat16 was not true.Node number 3 (DEQUANTIZE) failed to prepare.
"
29570,"hi, anyone know how to fix this?","

>>> import tensorflow as tf
Traceback (most recent call last):
  File ""D:\Deep_Learning\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Deep_Learning\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Deep_Learning\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\Deep_Learning\envs\tensorflow\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""D:\Deep_Learning\envs\tensorflow\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 找不到指定的模块。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Deep_Learning\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""D:\Deep_Learning\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\Deep_Learning\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\Deep_Learning\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Deep_Learning\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\Deep_Learning\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\Deep_Learning\envs\tensorflow\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""D:\Deep_Learning\envs\tensorflow\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 找不到指定的模块。


Failed to load the native TensorFlow runtime.
"
29569,"when i tried ''import tensorflow as tf' this came up, Can anyone help me with this, I am a newbie  ","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29568, about bottleneck_input = tf.placeholder_with_default ? ,"In the original retrain.py:
bottleneck_input = tf.placeholder_with_default(
bottleneck_tensor, shape=[batch_size, bottleneck_tensor_size],
name='BottleneckInputPlaceholder')
Changed to:
bottleneck_input = tf.placeholder(
tf.float32, shape=[batch_size, bottleneck_tensor_size], name='BottleneckInputPlaceholder')

After training, check the parameters in retrained_graph.pb.
Utilize:
import tensorflow as tf
import os

model_name = 'retrained_graph.pb'
def create_graph():
with tf.gfile.FastGFile(os.path.join(model_name), 'rb') as f:
graph_def = tf.GraphDef()
graph_def.ParseFromString(f.read())
create_graph()

tensor_name_list = [tensor.name for tensor in tf.get_default_graph().as_graph_def().node]
for tensor_name in tensor_name_list:
print(tensor_name,'\n')

Before BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape:0' was discovered, all the parameters were missing. Why?"
29566,The `Load CSV with tf.data` tutorial creates confusion about categorical data,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/beta/tutorials/load_data/csv#categorical_data
Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

The new `Load CSV with tf.data` tutorial is very nice. The tutorial shows users how to load a csv file into a tf.data Dataset. However, there are a couple of issues in the tutorial. First, the tutorial shows a very inconsistent and un-scalable way to encode categorical data using Regex expressions. A simpler way would be to use the already developed Feature Columns API, which is more consistent with the existing Tensorflow API. Second, the name of the tutorial is improper English. The tutorial is about loading tf.data with a CSV, not loading a CSV file with tf.data. So that should be fixed. 

### Clear description
1. Overly complicated and unscalable explanation of how to encode categorical features.

The tutorial takes the user through loading a CSV file into a tf.data Dataset using the experimental `make_csv_dataset` function in TF-2.0.0-beta. That is all very well done. But the problem arises in the ""Data Preprocessing"" section. 

The section on categorical data says that data must be converted from text to numerical encodings before passing the data to the model. However, the method described looks like this:

```
CATEGORIES = {
    'sex': ['male', 'female'],
    'class' : ['First', 'Second', 'Third'],
    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],
    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],
    'alone' : ['y', 'n']
}
``` 
Then using this dictionary, the user is asked to:

```
def process_categorical_data(data, categories):
  """"""Returns a one-hot encoded tensor representing categorical values.""""""
  
  # Remove leading ' '.
  data = tf.strings.regex_replace(data, '^ ', '')
  # Remove trailing '.'.
  data = tf.strings.regex_replace(data, r'\.$', '')
  
  # ONE HOT ENCODE
  # Reshape data from 1d (a list) to a 2d (a list of one-element lists)
  data = tf.reshape(data, [-1, 1])
  # For each element, create a new list of boolean values the length of categories,
  # where the truth value is element == category label
  data = tf.equal(categories, data)
  # Cast booleans to floats.
  data = tf.cast(data, tf.float32)
  
  # The entire encoding can fit on one line:
  # data = tf.cast(tf.equal(categories, tf.reshape(data, [-1, 1])), tf.float32)
  return data
```

Now this approach will work, but there are a couple of really big problems. First, Tensorflow has a Feature Column API already developed to handle this type of conversion. If the user simply did something like creating a feature column with vocabulary list, and then wrapping that column in an indicator column, this same code could be resolved in 2 lines instead of 14 lines. This change would also make the code easier to read, and provide more insight into how to use the Feature API.  
```
col_sex = tf.feature_column.categorical_column_with_vocabulary_list(key=""Sex"", vocabulary_list=[""male"", ""female""])

fc_sex =  tf.feature_column.indicator_column(col_sex)
```
2. Correct the name of the tutorial

The name of the tutorial is ""Load CSV with tf.data."" This name is actually improper English and a bit confusing. The current name makes it sound like you are loaded a tf.data dataset into a CSV, which is the opposite of the intent. The tutorial is about taking a CSV file and loading the data into a tf.data Dataset. So the proper name of the tutorial should be ""Load a CSV file into a tf.data Dataset,"" or ""Populate a tf.data Dataset with CSV file."" This change might help reduce confusion about what the tutorial is trying to demonstrate. 


### Correct links

Is the link to the source code correct?
Yes
### Parameters defined

Are all parameters defined and formatted correctly?
Yes
### Returns defined

Are return values defined?
Yes
### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

Errors are not clearly defined. 
### Usage example

Is there a usage example?
There is a usage example, but the usage example is very poorly designed. Hence I submitted the issue.
### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?
Visuals are okay. 
### Submit a pull request?
I am happy to submit a pull request. I guess let me see the response to this issue. If the development team agrees, then I can work on a pull request to update the documentation. 
Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29562,Custom Layer in tensorflow v2.0.0beta throws object has no attribute '_expects_mask_arg' error ,"I am trying to reconsturct an image based on three inputs of previous layers normal (None,128,128,3),albedo(None,128,128,3) and lighting(27) . But here the code still says object has no attribute '_expects_mask_arg' error .I have presented my code here in which I have implemented a custom layer using Tensorflow v2 beta using the high level API.
The code begins here .


class Reconstruction_Layer(tf.keras.layers.Layer):


        def __init__(self,input_shape):
       # super(Reconstruction_Layer, self).__init__()
        #self.num_outputs = num_outputs
        #self.pixel=np.zeros((9),dtype=int)
        
        self.sphar=np.zeros((9),dtype=float)
        self.y=np.zeros((9),dtype=float)
        self.reconstructed_img=np.zeros((128,128,3),dtype=float)
        #self.y=tf.zeros([128,128,9])
        self.normal_light=np.zeros((128,128,9),dtype=float)
        self.y_temp=np.zeros((9),dtype=float)
        w_init = tf.random_normal_initializer()
        self.r_img = tf.Variable(initial_value=w_init(shape=input_shape),dtype='float32',trainable=True)
    
       

    def build(self, input_shape):
        print(input_shape)
        super(Reconstruction_Layer, self).build(input_shape)
            
    
    
    def call(self,input_layer,*args,**kwargs):
        self.normal,self.albedo = input_layer
        super().__call__(self,*args,**kwargs)
            
        
        """"""
        self.normal=np.array(self.normal)
        self.albedo=np.array(self.albedo)
        self.light=np.array(self.light)
        """"""
        for i in range(128):
            for j in range(128):
                #self.y=spherical_harmonic_calc(self.normal(i,j))
                
                self.pixel=self.normal[i,j,:]
                
                np.reshape(self.pixel,(3))
                
                #self.normal_light(i,j)= self.y
                self.sphar[0]=(1/((4*math.pi)**0.5))
                self.sphar[1]=((3/(4*math.pi))**0.5)*self.pixel[2]
                self.sphar[3]=(((3/(4*math.pi))**0.5)*self.pixel[1])
                self.sphar[4]=((1/2)*((5/(4*math.pi))**0.5)*(3*(self.pixel[2]**2) - 1))
                self.sphar[5]=(3*((5/(12*math.pi))**0.5)*self.pixel[2]*self.pixel[0])
                self.sphar[6]=(3*((5/(12*math.pi))**0.5)*self.pixel[2]*self.pixel[1])
                self.sphar[7]=((3/2)*((5/(12*math.pi))**0.5)*((self.pixel[0]**2)-(self.pixel[1]**2)))
                self.sphar[8]=(3*((5/(12*math.pi))**0.5)*self.pixel[0]*self.pixel[1])
                
                self.normal_light[i,j,:]=self.sphar
        
        for j in range(128):
            for k in range(128):
                for i in range(3):
                    #self.y_temp=self.normal_light(j,k)
                    """"""
                    print('self.normal_light[j,k]',self.normal_light[j,k])
                    print('self.normal_light[j,k].shape',self.normal_light[j,k].shape)
                    print('self.light[i*9:(i+1)*9 - 1]',self.light[i*9:(i+1)*9 - 1])
                    print('self.light[i*9:(i+1)*9 - 1]',self.light[i*9:(i+1)*9 - 1].shape)
                    """"""
                    self.reconstructed_img[j,k,i]=self.albedo[j,k,i]* tf.tensordot(self.normal_light[j,k],self.light[i*9:(i+1)*9 ],axes=1)
        
        self.reconstructed_img=tf.convert_to_tensor(self.reconstructed_img)
        self.r_img=self.reconstructed_img
        
        def compute_output_shape(self):
            return shape(self.r_img)
     
        return self.r_img

![Screenshot from 2019-06-08 23-50-31](https://user-images.githubusercontent.com/20143249/59150910-4a47ab00-8a48-11e9-9dbf-5f9fa24153dc.png)
"
29559,TF2 Nightly-20190608 unable to link to core framework,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04+
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf_nightly_2.0_preview==2.0.0.dev20190608
- Python version: Python2 / 3
- Bazel version (if compiling from source): 0.24.1

**Describe the current behavior**
TF Addons is failing to link to the tensorflow core framework for our python 2 build:
```
tensorflow_addons/custom_ops/text/cc/kernels/skip_gram_kernels.cc:20:49: fatal error: tensorflow/core/framework/op_kernel.h: No such file or directory
 #include ""tensorflow/core/framework/op_kernel.h""

tensorflow_addons/custom_ops/text/cc/ops/skip_gram_ops.cc:16:42: fatal error: tensorflow/core/framework/op.h: No such file or directory
 #include ""tensorflow/core/framework/op.h""

./tensorflow_addons/custom_ops/image/cc/kernels/euclidean_distance_transform_op.h:23:52: fatal error: tensorflow/core/framework/tensor_types.h: No such file or directory
 #include ""tensorflow/core/framework/tensor_types.h""

....
```

Strangely this is only affecting our python2 builds. See the build logs in https://github.com/tensorflow/addons/pull/273

**Describe the expected behavior**
Able to correctly link to the framework.

**Other info / logs**
Assuming this is related to the virtual pip package. Should these be looking in `tensorflow_core/...`?

cc @mihaimaruseac @perfinion 
"
29558,model.fit() does not reshuffle the dataset between epochs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
MacOSX 10.13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
VERSION='2.0.0-dev20190606'
GIT_VERSION='v1.12.1-3447-g5a0f1bbfb7'
- Python version:
3.6.8
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A

**Describe the current behavior**
When calling `model.fit(dataset, epochs=2)` with a finite shuffled dataset, the model is trained on the same dataset order at each epoch.

**Describe the expected behavior**
I expect the dataset to be reshuffled after each epoch. Right now, it's not, even when I use `reshuffle_each_iteration=True` in the dataset's `shuffle()` method. This argument seems to only shuffle between iterations within one epoch.

**Code to reproduce the issue**

```python
import tensorflow as tf
from tensorflow import keras
import numpy as np

X = np.arange(6).astype(np.float32).reshape(-1, 1)
y = X**2
dataset = tf.data.Dataset.from_tensor_slices((X,y))
dataset = dataset.shuffle(100, reshuffle_each_iteration=True)
dataset = dataset.repeat(2)
dataset = dataset.batch(2)

@tf.function
def log_inputs(inputs):
    tf.print(inputs)
    return inputs

model = keras.models.Sequential([
    keras.layers.Lambda(log_inputs),
    keras.layers.Dense(1)
])
model.compile(loss=""mse"", optimizer=""sgd"")
model.fit(dataset, epochs=2, verbose=0)
```

**Other info / logs**
The output is as follows (I've added comments):

```python
[[5]   # first epoch, first iteration, first batch
 [2]]
[[3]      # second batch
 [1]]
[[0]      # third batch
 [4]]
[[0]   # first epoch, second iteration, first batch
 [3]]
[[1]      # second batch
 [5]]
[[4]      # third batch
 [2]]
[[5]   # second epoch, first iteration, first batch
 [2]]
[[3]
 [1]]
[[0]
 [4]]
[[0]   # second epoch, second iteration, first batch
 [3]]
[[1]
 [5]]
[[4]
 [2]]
```

As you can see the order of the data is perfectly identical during the 1st and 2nd epochs. It is only reshuffled at each iteration within the same epoch.

So the only way to ensure that the data will be reshuffled at each epoch is to use `dataset.repeat(n_epochs)`, then `model.fit(dataset, steps_per_epoch=..., epochs=n_epochs)`. It feels like unnecessary complexity."
29557,Reopen #26098,Please see https://github.com/tensorflow/tensorflow/issues/26098#issuecomment-489175950. That issue needs to be reopened since it is **not** fixed. It's been over a month since I pointed that out so I'm creating this new issue to bring the necessary attention to it. When https://github.com/tensorflow/tensorflow/issues/26098 is reopened you may close this. Thanks.
29556,Tensorflow Keras: all Keras optimizers throw an error when training in eager mode,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.8

**Describe the current behavior**

When creating a model with SGD optimizer in eager mode and setting its `run_eagerly` attribute to true when I fit the model using some tf.Dataset (created using [tf.data.experimental.CsvDataset](https://www.tensorflow.org/api_docs/python/tf/contrib/data/CsvDataset) if that matters) as an input, I get the following error:

```
AttributeError: 'SGD' object has no attribute 'apply_gradients'
```



**Describe the expected behavior**

I'd like to set Keras model's run_eagerly property to true so that I'd be able to step into custom-defined loss functions when being in eager mode when using SGD as an optimiser.

**Code to reproduce the issue**

```
import tensorflow as tf

tf.enable_eager_execution()

sgd = tf.keras.optimizers.SGD()

inputs = tf.keras.Input(shape=(3,))

# First layer
x = tf.keras.layers.Dense(5, kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)
x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)

# Second layer
x = tf.keras.layers.Dense(5, kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)
x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)

# Output
outputs = tf.keras.layers.Dense(
	1,
	kernel_regularizer=tf.keras.regularizers.l2(0.01),
	activation='sigmoid'
)(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)

model.compile(optimizer=sgd, loss='mean_squared_error')

model.run_eagerly = True

# Define some dummy dataset
x = [[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]]
y = [0, 1, 0]

model.fit(x, y)
```

**Other info / logs**

Full traceback:

```
Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm\helpers\pydev\pydevd.py"", line 1758, in <module>
    main()
  File ""C:\Program Files\JetBrains\PyCharm\helpers\pydev\pydevd.py"", line 1752, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm\helpers\pydev\pydevd.py"", line 1147, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/QMUL/user-state-recognition/src/train_MLP.py"", line 331, in <module>
    main()
  File ""C:/QMUL/user-state-recognition/src/train_MLP.py"", line 171, in main
    validation_steps=steps_per_epoch_val, callbacks=[tb_callback], verbose=1)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 851, in fit
    initial_epoch=initial_epoch)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training_generator.py"", line 191, in model_iteration
    batch_outs = batch_function(*batch_data)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1179, in train_on_batch
    self, x, y, sample_weights=sample_weights)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training_eager.py"", line 260, in train_on_batch
    model, inputs, targets, sample_weights=sample_weights, training=True)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training_eager.py"", line 225, in _process_single_batch
    model.optimizer.apply_gradients(zip(grads,
AttributeError: 'SGD' object has no attribute 'apply_gradients'
```

Regarding `run_eagerly` attribute: I need to step into my custom loss and metric functions. The code takes the decision in [Model.train_on_batch() function](https://github.com/tensorflow/tensorflow/blob/6612da89516247503f03ef76e974b51a434fb52e/tensorflow/python/keras/engine/training.py#L1123) in [this](https://github.com/tensorflow/tensorflow/blob/6612da89516247503f03ef76e974b51a434fb52e/tensorflow/python/keras/engine/training.py#L1177) line. If run_eagerly parameter will not be set explicitly to `True` before calling model.fit function, the modell will take [this](https://github.com/tensorflow/tensorflow/blob/6612da89516247503f03ef76e974b51a434fb52e/tensorflow/python/keras/engine/training.py#L1180) path instead, which will make it impossible to step into custom loss function nor custom metric function. When `run_eagerly` is set to true the code will eventually get to [this](https://github.com/tensorflow/tensorflow/blob/6612da89516247503f03ef76e974b51a434fb52e/tensorflow/python/keras/engine/training_eager.py#L225) line and that's where the code fails, as Keras's optimizer interface doesn't have `apply_gradients` method defined."
29555,[TF 2.0 alpha] Erratic metric behaviour with MAE and MSE,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below):2.0.0a0
- Python version:3.6.6
- Bazel version (if compiling from source):-
- GCC/Compiler version (if compiling from source):-
- CUDA/cuDNN version: Using CPU
- GPU model and memory: Using CPU

**Describe the current behavior**
The MAE and the MSE should be correlated but the MSE value used in the metric is not correlated [see this minimal log for instance](https://gist.github.com/roya0045/5e4c2950da48092af266c945dc69e0a1)

**Describe the expected behavior**
I assume that the MSE should be equivalent to the MAE squared but I may be wrong.

**Code to reproduce the issue**
Build a small LSTM with keras for sequence prediction.

Loss: 'mae'
metrics: ['mse','acc']
optimizer: kr.optimizers.Adam

**Other info / logs**
See link in the described behaviour."
29554,def call() should be def __call__(),"[https://www.tensorflow.org/beta/tutorials/quickstart/advanced](url)
[https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/quickstart/advanced.ipynb](url)

Correct your mistakes, please.

```
class MyModel(Model):
  def __init__(self):
    super(MyModel, self).__init__()
    self.conv1 = Conv2D(32, 3, activation='relu')
    self.flatten = Flatten()
    self.d1 = Dense(128, activation='relu')
    self.d2 = Dense(10, activation='softmax')

  def call(self, x):  #!!! should be  __call__  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    x = self.conv1(x)
    x = self.flatten(x)
    x = self.d1(x)
    return self.d2(x)
```"
29553,ModuleNotFoundError: No module named 'tensorflow.python.ops.cond_v2',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow version (use command below): tensorflow-gpu 2.0.0-beta and any tf 2.0 nightly build
- Python version: Python 3.6.7
- GPU model and memory: Tesla K80 (12GB RAM)

**Describe the current behavior**
Initilalizing a Keras model raises following error: ModuleNotFoundError: No module named 'tensorflow.python.ops.cond_v2' when using Google Colab

Code was working fine until yesterday's build. The error doesn't go away in other tf 2.0 versions.

**Code to reproduce the issue**
base_model = tf.keras.applications.MobileNetV2(input_shape=(128,128,3),
                                                   include_top=False,
                                                   weights='imagenet')
or

base_model = tf.keras.applications.MobileNetV2(input_shape=(128,128,3))
"
29550,TF 2.0 Beta TPUStrategy,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v1.12.1-3259-gf59745a381 2.0.0-beta0
- Python version: 3.6.7
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Running the following code to setup TPUStrategy results in NotFoundError: No registered 'ConfigureDistributedTPU' OpKernel for TPU_SYSTEM devices compatible with node {{node ConfigureDistributedTPU}}

`import tensorflow as tf
cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_host(cluster_resolver.master())
tf.tpu.experimental.initialize_tpu_system(cluster_resolver)
tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)`

**Describe the expected behavior**
TPUStrategy setup completes without error.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
https://colab.research.google.com/drive/1trrM2E-x912TiP0CeHtAi8jxZaA5y_SL

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
With reference to the [Distributed Training docs](https://www.tensorflow.org/beta/guide/distribute_strategy), I understand that TPUStrategy does not support all APIs in Tensorflow 2.0 Beta:
![image](https://user-images.githubusercontent.com/29782952/59141572-00c47500-89e2-11e9-82a4-9e045187db00.png)
However, given that some APIs are supported, it would follow that the TPUStrategy initialization in Tensorflow 2.0 Beta is expected to be functional. Hence, this bug report. Thank you!

"
29549,Tensorflow 2.0 alpha/beta performance,"**System information**
Google Colab system (GPU mode) with TensorFlow 2.0 and Python 3.

**Describe the current behavior**
Using TensorFlow 2.0 beta (pip install) on a CNN-RNN (two bidirecional lstm), is taking about 25 minutes to complete a single epoch (training).

**Describe the expected behavior**
The curious thing is that when using the same code, same file/platform (google colab) but with the Alpha version of the TF 2.0 (pip install), the same epoch takes around only 70 seconds.

**Other info / logs**
Everything is the same in both scenarios and also the identification of the GPU:
> Found GPU at: / device: GPU: 0

Another thing I noticed is that the alpha warning disappeared:

> W0608 02:52:12.500632 140219739858816 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f86d4231da0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.

Maybe it has something related?"
29545,Subclassing tf.keras.models.Model save_model saves h5py but not h5/hdf5 file types,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): Pip
- TensorFlow version (use command below): 2.0.0b
- Python version: 3.6.7
- GPU model and memory: Tesla T4

**Describe the current behavior**
-Using tf 2.0.0b-gpu on google colab.

While using the subclassing API for a subclassed layer and model, I was unable to use the model.save_model() function for h5 or hdf5 file types, but I could successfully save and load the model if it was saved as h5py file type. In the toy example being used it worked correctly, although this may not be the case. Note that the get_config method was implemented in the custom layer and custom model.

**Describe the expected behavior**
Either the save_model should always work (I believe this is a feature goal) and the documentation should reflect this, or if the save is likely to produce incorrect results it should raise an error and the documentation should continue to suggest that custom models can only be saved with the save_weights feature. 

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras

class resblock(keras.layers.Layer):
    def __init__(self, n_layers, n_neurons, **kwargs):
        super().__init__(**kwargs)
        self.hidden = [keras.layers.Dense(n_neurons,
                                          activation='elu',
                                          kernel_initializer='he_normal')
                       for _ in range(n_layers)]
        
    def call(self, inputs):
        z = inputs
        for layer in self.hidden:
            z = layer(z)
        return inputs + z
    
    def get_config(self):
        base_config = super().get_config()
        return {**base_config}

class res_mod(keras.models.Model):
    def __init__(self, output_dim, activation=None, **kwargs):
        super().__init__(**kwargs)
        self.f1 = keras.layers.Flatten()
        self.hidden1 = keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal')
        self.b1 = resblock(2, 100)
        self.b2 = resblock(2, 100)
        self.output1 = keras.layers.Dense(output_dim, activation=keras.activations.get(activation))
        
    def call(self, inputs):
        z = self.f1(inputs)
        z = self.hidden1(z)
        for _ in range(4):
            z = self.b1(z)
        z = self.b2(z)
        return self.output1(z)
    
    def get_config(self):
        base_config = super().get_config()
        return{**base_config, ""output_dim"" : output_dim, ""activation"": activation}
    

model = res_mod(10, activation='softmax')
model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])

model.fit(train, epochs=25, validation_data=test)
```
```
# This is able to save and works correctly, returning the trained model
model.save('custom_model.h5py')
del model
model = keras.models.load_model('custom_model.h5py', custom_objects={'resblock': resblock})
```


**Other info / logs**
This will raise an error that only sequential or functional models can be saved
```model.save('custom_model.h5')```
"
29543,Docs should describe how to add a MetaGraphDef to an existing graph,"## URL(s) with the issue:

https://www.tensorflow.org/guide/saved_model#save_and_restore_models

## Description of issue (what needs changing):

### Clear description and Usage Example

I've already created several models, trained over several days each, that we're ready to move from local testing to a serving environment.

The models were saved using the function

```python
def save_graph_to_file(sess, graph, graph_file_name):
    """"""Saves an graph to file, creating a valid quantized one if necessary.""""""
    output_graph_def = graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [final_tensor_name])
    with gfile.FastGFile(graph_file_name, 'wb') as f:
        f.write(output_graph_def.SerializeToString())
```

via the [image retraining sample script](https://github.com/tensorflow/tensorflow/blob/v1.6.0/tensorflow/examples/image_retraining/retrain.py#L853-L859).

Now, I'm ready to move this to a serving environment (via Sagemaker, but that just implements `tensorflow.serving`).

The error is clear enough:

```
2019-06-04 22:38:53.794056: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }
2019-06-04 22:38:53.798096: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:259] SavedModel load for tags { serve }; Status: fail. Took 83297 microseconds.
2019-06-04 22:38:53.798132: E tensorflow_serving/util/retrier.cc:37] Loading servable: {name: model version: 1} failed: Not found: Could not find meta graph def matching supplied tags: { serve }. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`
```

Loading up the graph by [adapting the loader from the retrain script](https://github.com/tensorflow/tensorflow/blob/v1.6.0/tensorflow/examples/image_retraining/retrain.py#L270-L293), I try to just append the serving tag to the graph

```python
def load_graph(model_file):
    """"""
    Code from v1.6.0 of Tensorflow's label_image.py example
    """"""
    graph = tf.Graph()
    graph_def = tf.GraphDef()
    with open(model_file, ""rb"") as f:
        graph_def.ParseFromString(f.read())
    with graph.as_default():
        tf.import_graph_def(graph_def)
    return graph
# Load the graph
graph = load_graph(modelPath)
import shutil
if os.path.exists(exportDir):
    shutil.rmtree(exportDir)
# Add the serving metagraph tag
builder = tf.saved_model.builder.SavedModelBuilder(exportDir)
from tensorflow.saved_model import tag_constants
with tf.Session(graph= graph) as sess:
    builder.add_meta_graph_and_variables(sess, [tag_constants.SERVING, tag_constants.GPU], strip_default_attrs= True)
builder.save()
print(""Built a SavedModel"")
```

which doesn't work (still has the same error). I'm not giving up on this, but given that the code was written out with a Tensorflow example, this seems like an obvious use case to cover.


### Submit a pull request?

If I'm able to solve this in a timely way, I'll submit a PR for the docs; at the moment it's a few steps away from me being there, however.
"
29542,Loss of shape information when using dilation_rate != 1 in Conv layers,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-beta0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0, 7.5
- GPU model and memory: 11gb, GTX1080Ti

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I was using the code below with 1.12, 1.13.1 and tf2.0 alpha. But it fails to run in the latest tf2.0 beta. As you can see there is nothing fancy going on in the code. This is the block of code that produces this error
```
def ASPP(tensor):
    '''atrous spatial pyramid pooling'''
    dims = K.int_shape(tensor)

    y_pool = AveragePooling2D(pool_size=(
        dims[1], dims[2]), name='average_pooling')(tensor)
    y_pool = Conv2D(filters=256, kernel_size=1, padding='same',
                    kernel_initializer='he_normal', name='pool_1x1conv2d', use_bias=False)(y_pool)
    y_pool = BatchNormalization(name=f'bn_1')(y_pool)
    y_pool = Activation('relu', name=f'relu_1')(y_pool)

    y_pool = Upsample(tensor=y_pool, size=[dims[1], dims[2]])

    y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same',
                 kernel_initializer='he_normal', name='ASPP_conv2d_d1', use_bias=False)(tensor)
    y_1 = BatchNormalization(name=f'bn_2')(y_1)
    y_1 = Activation('relu', name=f'relu_2')(y_1)

    y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same',
                 kernel_initializer='he_normal', name='ASPP_conv2d_d6', use_bias=False)(tensor)
    y_6 = BatchNormalization(name=f'bn_3')(y_6)
    y_6 = Activation('relu', name=f'relu_3')(y_6)

    y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same',
                  kernel_initializer='he_normal', name='ASPP_conv2d_d12', use_bias=False)(tensor)
    y_12 = BatchNormalization(name=f'bn_4')(y_12)
    y_12 = Activation('relu', name=f'relu_4')(y_12)

    y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same',
                  kernel_initializer='he_normal', name='ASPP_conv2d_d18', use_bias=False)(tensor)
    y_18 = BatchNormalization(name=f'bn_5')(y_18)
    y_18 = Activation('relu', name=f'relu_5')(y_18)

    y = concatenate([y_pool, y_1, y_6, y_12, y_18], name='ASPP_concat')

    y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same',
               kernel_initializer='he_normal', name='ASPP_conv2d_final', use_bias=False)(y)
    y = BatchNormalization(name=f'bn_final')(y)
    y = Activation('relu', name=f'relu_final')(y)
    return y
```
Strangely shapes of  y_pool, y_1 are correctly inferred , complete code to reproduce the issue available below
``` 
y = concatenate([y_pool, y_1, y_6, y_12, y_18], name='ASPP_concat')
```
**Describe the expected behavior**
The code should work as it did in the earlier release ie tf2.0 alpha
**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.models import Model
from tensorflow.keras.layers import AveragePooling2D, Lambda, Conv2D, Conv2DTranspose, Activation, Reshape, concatenate, Concatenate, BatchNormalization, ZeroPadding2D
from tensorflow.keras.applications.resnet50 import ResNet50


def Upsample(tensor, size):
    '''bilinear upsampling'''
    name = tensor.name.split('/')[0] + '_upsample'

    def bilinear_upsample(x, size):
        resized = tf.image.resize(
            images=x, size=size)
        return resized
    y = Lambda(lambda x: bilinear_upsample(x, size),
               output_shape=size, name=name)(tensor)
    return y


def ASPP(tensor):
    '''atrous spatial pyramid pooling'''
    dims = K.int_shape(tensor)

    y_pool = AveragePooling2D(pool_size=(
        dims[1], dims[2]), name='average_pooling')(tensor)
    y_pool = Conv2D(filters=256, kernel_size=1, padding='same',
                    kernel_initializer='he_normal', name='pool_1x1conv2d', use_bias=False)(y_pool)
    y_pool = BatchNormalization(name=f'bn_1')(y_pool)
    y_pool = Activation('relu', name=f'relu_1')(y_pool)

    y_pool = Upsample(tensor=y_pool, size=[dims[1], dims[2]])

    y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same',
                 kernel_initializer='he_normal', name='ASPP_conv2d_d1', use_bias=False)(tensor)
    y_1 = BatchNormalization(name=f'bn_2')(y_1)
    y_1 = Activation('relu', name=f'relu_2')(y_1)

    y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same',
                 kernel_initializer='he_normal', name='ASPP_conv2d_d6', use_bias=False)(tensor)
    y_6 = BatchNormalization(name=f'bn_3')(y_6)
    y_6 = Activation('relu', name=f'relu_3')(y_6)

    y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same',
                  kernel_initializer='he_normal', name='ASPP_conv2d_d12', use_bias=False)(tensor)
    y_12 = BatchNormalization(name=f'bn_4')(y_12)
    y_12 = Activation('relu', name=f'relu_4')(y_12)

    y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same',
                  kernel_initializer='he_normal', name='ASPP_conv2d_d18', use_bias=False)(tensor)
    y_18 = BatchNormalization(name=f'bn_5')(y_18)
    y_18 = Activation('relu', name=f'relu_5')(y_18)

    y = concatenate([y_pool, y_1, y_6, y_12, y_18], name='ASPP_concat')

    y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same',
               kernel_initializer='he_normal', name='ASPP_conv2d_final', use_bias=False)(y)
    y = BatchNormalization(name=f'bn_final')(y)
    y = Activation('relu', name=f'relu_final')(y)
    return y


def DeepLabV3Plus(img_height, img_width):
    base_model = ResNet50(input_shape=(
        img_height, img_width, 3), weights='imagenet', include_top=False)

    image_features = base_model.get_layer('activation_39').output
    x_a = ASPP(image_features)
    x_a = Upsample(tensor=x_a, size=[img_height // 4, img_width // 4])

    x_b = base_model.get_layer('activation_9').output
    x_b = Conv2D(filters=48, kernel_size=1, padding='same',
                 kernel_initializer='he_normal', name='low_level_projection', use_bias=False)(x_b)
    x_b = BatchNormalization(name=f'bn_low_level_projection')(x_b)
    x_b = Activation('relu', name='low_level_activation')(x_b)

    x = concatenate([x_a, x_b], name='decoder_concat')

    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',
               kernel_initializer='he_normal', name='decoder_conv2d_1', use_bias=False)(x)
    x = BatchNormalization(name=f'bn_decoder_1')(x)
    x = Activation('relu', name='activation_decoder_1')(x)

    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',
               kernel_initializer='he_normal', name='decoder_conv2d_2', use_bias=False)(x)
    x = BatchNormalization(name=f'bn_decoder_2')(x)
    x = Activation('relu', name='activation_decoder_2')(x)
    x = Upsample(x, [img_height, img_width])

    x = Conv2D(1, (1, 1), name='output_layer')(x)
    x = Activation('sigmoid')(x)
    model = Model(inputs=base_model.input, outputs=x, name='DeepLabV3_Plus')
    return model
```
**Other info / logs**
```
ValueError                                Traceback (most recent call last)
<ipython-input-20-0876af914f24> in <module>()
----> 1 DeepLabV3Plus(512, 512)

6 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py in build(self, input_shape)
    389                        'inputs with matching shapes '
    390                        'except for the concat axis. '
--> 391                        'Got inputs shapes: %s' % (input_shape))
    392 
    393   def _merge_function(self, inputs):

ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 32, 32, 256), (None, 32, 32, 256), (None, None, None, 256), (None, None, None, 256), (None, None, None, 256)]
```
"
29541,tf.train.Saver fails on AutoTrackable,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): public colab instance
- TensorFlow installed from (source or binary): tf-nightly-1.14.1.dev20190607
- TensorFlow version (use command below): 1.14.1.dev20190607
- Python version: 3.6.7

**Describe the current behavior**
Manually specifying an instance of AutoTrackable (e.g., tf.Module) causes `tf.train.Saver` to fail with a somewhat cryptic error:

`ValueError: Attr 'dtypes' of 'SaveV2' Op passed list of length 0 less than minimum 1.`

The issue seems to come from a call to `Trackable._gather_saveables_for_checkpoint` which is not overridden by `tf.Module` or `AutoTrackable`. 

**Describe the expected behavior**
I'm not sure if this is intended to work (so maybe this should be a feature request?) but at the least I think the issue should be caught earlier and return a more informative error message. 

The docs for `tf.train.Saver` call for a list/dict of `SaveableObject`, which `AutoTrackable` is not, but it seems odd that it isn't. It is possible that I am misunderstanding the `SaveableObject`/`Saver` API, but I do feel like `AutoTrackable` should be compatible `tf.train.Saver`.

**Code to reproduce the issue**
```python
import tensorflow as tf

class MyModel(tf.Module):
  
  def __init__(self):
    super(MyModel, self).__init__()
    self._var = tf.Variable(1.)
    
model = MyModel()
saver = tf.train.Saver({""model"": model})
```

**Other info / logs**
@tomhennigan 
"
29540,TF2-beta has mismatch between libtensorflow_framework and link flag,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0.b0

**Describe the current behavior**
There is a mismatch in the name of `libtensorflow_framework` and the `tf.sysconfig.get_link_flag` name. As an [example TF-Addons uses this to link](https://github.com/tensorflow/addons/blob/master/configure.sh#L46) with tensorflow core. 
```
$ python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
('v1.12.1-3259-gf59745a381', '2.0.0-beta0')

$ python -c ""import tensorflow as tf; print(tf.sysconfig.get_link_flags())""
['-L/usr/local/lib/python2.7/dist-packages/tensorflow', '-l:libtensorflow_framework.so.2

$ ll /usr/local/lib/python2.7/dist-packages/tensorflow
total 34128
drwxr-sr-x 10 root staff     4096 Jun  7 17:24 ./
drwxrwsr-x  1 root staff     4096 Jun  7 17:24 ../
...
drwxr-sr-x  9 root staff     4096 Jun  7 17:24 include/
-rwxr-xr-x  1 root staff 34858656 Jun  7 17:24 libtensorflow_framework.so.1*
drwxr-sr-x  5 root staff     4096 Jun  7 17:24 lite/
drwxr-sr-x 29 root staff     4096 Jun  7 17:24 python/
drwxr-sr-x  6 root staff     4096 Jun  7 17:24 tools/


```
**Describe the expected behavior**
The framework should be named `libtensorflow_framework.so.2`

**Code to reproduce the issue**
```
pip install tensorflow==2.0.0.b0
```

cc @yifeif @perfinion "
29536,TF2 Nightly-20190607 broken import,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf_nightly_2.0_preview-2.0.0.dev20190607
- Python version:  Python2 / Python3

**Describe the current behavior**
TF2 nightly breaks with this error:
```
File ""/usr/lib/python2.7/site-packages/tensorflow/__init__.py"", line 93, in <module>
    from tensorflow_core import *
AttributeError: 'module' object has no attribute 'compiler
```

**Code to reproduce the issue**
```
pip install tf-nightly-2.0-preview
python -c ""import tensorflow as tf""
```
**Other info / logs**
Probably related to the commit mentioned in https://github.com/tensorflow/tensorflow/issues/29532 but not positive."
29535,model.trainable=False does nothing in tensorflow keras,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below):1.13
- Python version:2.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1.105
- GPU model and memory:m60,8gb


It seems setting `model.trainable=False` in tensorflow keras does nothing except for to print a wrong model.summary(). Here is the code to reproduce the issue:


```
import tensorflow as tf
import numpy as np
IMG_SHAPE = (160, 160, 3)

# Create the base model from the pre-trained model MobileNet V2
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False, 
                                               weights='imagenet')
base_model.trainable = False
# for layer in base_model.layers:
#     layer.trainable=False
bc=[] #before compile
ac=[] #after compile
for layer in base_model.layers:
    bc.append(layer.trainable)
print(np.all(bc)) #True
print(base_model.summary()) ##this changes to show no trainable parameters but that  is wrong given the output to previous np.all(bc)
base_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])
for layer in base_model.layers:
    ac.append(layer.trainable)
print(np.all(ac)) #True
print(base_model.summary()) #this changes to show no trainable parameters but that  is wrong given the output to previous np.all(ac)
```
"
29534,1.11 and above: optimizers function incorrectly with datasets with unbalanced labels,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.10 (16.04 has the same issue)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `('v1.11.0-0-gc19e29306c', '1.11.0')`, `('v1.12.0-0-ga6d8ffae09', '1.12.0')`, `('v1.13.1-0-g6612da8951', '1.13.1')`
- Python version: 2.7, 3.5, 3.6, 3.7
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: - (reproducable with GPU explicitly disabled)

**Describe the current behavior**
- Reference version: `('v1.10.0-0-g656e7a2b34', '1.10.0')`

We are experiencing the issue on our models, that used to be trained using Tensorflow 1.10, where there was no issue, but since we upgraded to 1.13, it appeared.
I have constructed an artificial, as simple as possible example, showcasing the issue.

The example in the attached Zip file is using `imports85` data. The ""True"" label is `price < PRICE_CUTOFF`, with `PRICE_CUTOFF` set so that the resulting label mean is `0.0146`, making it significantly unbalanced.

The FTRL optimizer in the example code has bizarre coefficients set to demonstrate the issue more graphically. In our models we have them in reasonable range and still get the wrong behavior.

If the model is trained and evaluated using *1.10*, the results (given all the constants as set in the code) are the following:
```
Resulting means:
  Label: 0.0146341463415
  Prediction (no optimizer): 0.023864556
  Prediction (optimizer): 0.026022965
```

Now, the results above are pretty bad, but it's due to really small dataset, used to train the model, but it's not significant from the standpoint of showcasing wrong behavior: in our models, the predictions, done with 1.10-trained model are pretty on-point.

When the model is trained and evaluated using *1.13*, the model *WITH* optimizer applied starts to show unreasonably high predictions:
```
Resulting means:
  Label: 0.0146341463415
  Prediction (no optimizer): 0.02390607
  Prediction (optimizer): 0.044271074
``` 
These results above are consistent with what we see in our models, where predictions became overwhelmingly positive once 1.13 was used for the model training (since we do use optimizers).

This does not seem to be an issue with FTRL optimizer itself, since we have tried several of them, all showing significant skewing of predicted results towards one or other end, if the label in the dataset is not balanced.

The example code should allow easy reproduction of the issue. Zip file also contains two requirements files: `requirements_1.10.txt` and `requirements_1.13.txt` to streamline setting up the virtual environments to test the issue.

**Code to reproduce the issue**
See attached Zip
[optimizers_unbalanced_label_bug.zip](https://github.com/tensorflow/tensorflow/files/3266358/optimizers_unbalanced_label_bug.zip)
"
29532,Virtual TF package breaks tf.sysconfig based include path,"As f1ffa0225ae19870c1473b1d70faf0ceaeea9862 landed yesterday, the framework library is now moved from `tensorflow` to `tensorflow_core` and the include path also changed to `tensorflow_core/include`.

`tf.sysconfig.get_include` and `tf.sysconfig.get_lib` should be changed accordingly but they are not. This breaks downstream packages such as horovod and tensorflow_io that build custom ops and link to TF. It also means any binary distributions of these packages will break binary backward compatibility with this change.

See https://github.com/horovod/horovod/issues/1129 for a reproducing procedure.

Ping @mihaimaruseac @yifeif "
29531,model.trainable=False and layer.trainable=False for each layer giving very different performance,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below):1.3
- Python version:2.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1.105
- GPU model and memory:m60, 8gb

`for layer in base_model_seq.layers:`
 `    layer.trainable=False` 
and 
`base_model_seq.trainable=False` 
are giving very different results. To my understanding both are the ways to achieve same behavior

Data pipeline: This remains exactly same in both the cases. Providing the code for reference
```
import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
img_height = 224
img_width = 224
from random_eraser import get_random_eraser
IMAGE_DIR = ""./data/images""
traincsv = pd.read_csv('./data/train.csv')
testcsv = pd.read_csv('./data/test_ApKoW4T.csv')
traincsv['category'] = traincsv['category'].astype(str)
train_batch_size=32
val_batch_size = 32
test_batch_size = 32
seed = 43
traincsv = pd.read_csv('./data/train.csv')
testcsv = pd.read_csv('./data/test_ApKoW4T.csv')
traincsv['category'] = traincsv['category'].astype(str)
df_train,df_val = train_test_split(traincsv, stratify = traincsv.category, random_state=42, test_size=.1, shuffle=True)
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,width_shift_range=0.3, height_shift_range=0.3, 
                                                            rescale=1./255, shear_range=0.0,zoom_range=0.3, horizontal_flip=True, fill_mode='nearest',
                                                            preprocessing_function=get_random_eraser(pixel_level=True,s_h=0.4))

val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_dataframe(df_train,directory = IMAGE_DIR,x_col='image',y_col='category',
           class_mode=""categorical"", target_size=(img_height, img_width), batch_size=train_batch_size,shuffle=True)

validation_generator = val_datagen.flow_from_dataframe(df_val,directory=IMAGE_DIR,x_col='image',y_col='category',
           class_mode=""categorical"", target_size=(img_height, img_width),batch_size=val_batch_size,shuffle=True)

steps_per_epoch = train_generator.n // 32
validation_steps =  validation_generator.n //32
```
Now the piece followed by ######... is the only part i change in running the two experiments but i get drastically different results
```
import tensorflow as tf

from __future__ import absolute_import, division, print_function

import os

import tensorflow as tf
from tensorflow import keras
print(""TensorFlow version is "", tf.__version__)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from tensorflow.keras.applications import MobileNet, InceptionResNetV2
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.python.keras.applications import densenet_rootexposed
import tensorflow as tf

IMAGE_DIR = ""./data/images""
img_height =224
img_width = 224
IMG_SHAPE = (img_height,img_width, 3)
def step_decay(epoch, lr):
    print(lr)
    drop = 0.96
    return lr*drop
lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)
callbacks = [lrate]
base_model_seq = keras.applications.densenet.DenseNet201(input_shape=IMG_SHAPE,
                                              include_top=False, 
                                                weights='imagenet')
#######################################This is the only part i change while training the models
base_model_seq.trainable=False
# for layer in base_model_seq.layers:
#     layer.trainable=False
#######################################
model_seq = tf.keras.Sequential([
  base_model_seq,
  keras.layers.Flatten(),
  keras.layers.Dropout(0.5),
  keras.layers.Dense(2048, activation='relu'),
  keras.layers.Dropout(0.5),
  keras.layers.BatchNormalization(),
  keras.layers.Dense(5, activation='softmax')
])


for layer in base_model_seq.layers:
    layer._name = layer._name + str(""_1729"")
print(len(model_seq.trainable_variables))


model_seq.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

print('************************')
print(model_seq.summary())
epochs = 100

```

when i run it by freezing the model with `base_model_seq.trainable=False` the model starts with .8 val accuracy and rises up to .91 in first 20 epochs but when i run it by freezing the model with
` for layer in base_model_seq.layers:
     layer.trainable=False` 
The validation accuracy starts with .72 and reaches .82 in 20 epochs and then stalls there. I have repeated the experiment enough number of times to ensure this cannot be attributed to chance initialization. Please point me to the source of inconsistency in the approaches i have describes"
29530,tf.keras.Model serialization in tf1.14.0rc0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip 
- TensorFlow version (use command below):  1.14.0rc0
- Python version: 3.6.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

I am encountering serialization issues when trying to dump the `config` from a `tf.keras.Model` object without complex things like custom layers (or even Lambdas...)

The code worked well with tf 1.13.1 however in tf 1.1.4, json/yaml serialization fails, and `to_yaml` and `model_from_yaml` fails as well

**Describe the expected behavior**

We should be able to serialize the config from a `tf.keras.Model` into json/yaml and load it back, especially without using custom layers

I checked the changelog for 1.14 and did not see any documented changes on model serialization for tf 1.14

Is serializing just the config file something that should not be done in 1.14 / 2.0 ?

**Code to reproduce the issue**

```python
# %%
import tensorflow as tf
import json
from ruamel import yaml


# %%
def mini_cnn(input_shape, num_classes):
    inputs = tf.keras.layers.Input(shape=input_shape)

    x = tf.keras.layers.Conv2D(16, (3, 3), padding=""same"", use_bias=False)(inputs)
    x = tf.keras.layers.BatchNormalization(axis=-1)(x)
    x = tf.keras.layers.Activation(""relu"")(x)
    x = tf.keras.layers.MaxPooling2D((2, 2), strides=2)(x)
    x = tf.keras.layers.Conv2D(32, (3, 3), padding=""same"", use_bias=False)(x)
    x = tf.keras.layers.BatchNormalization(axis=-1)(x)
    x = tf.keras.layers.Activation(""relu"")(x)
    x = tf.keras.layers.MaxPooling2D((2, 2), strides=2)(x)
    x = tf.keras.layers.Conv2D(64, (3, 3), padding=""same"", use_bias=False)(x)
    x = tf.keras.layers.BatchNormalization(axis=-1)(x)
    x = tf.keras.layers.Activation(""relu"")(x)
    x = tf.keras.layers.MaxPooling2D((2, 2), strides=2)(x)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(64, use_bias=False)(x)
    x = tf.keras.layers.BatchNormalization(axis=-1)(x)
    x = tf.keras.layers.Activation(""relu"")(x)
    x = tf.keras.layers.Dropout(0.25)(x)

    logits = tf.keras.layers.Dense(num_classes, use_bias=True, name=""logits"")(x)
    probas = tf.keras.layers.Activation(activation=""softmax"", name=""probas"")(logits)

    model = tf.keras.Model(inputs=inputs, outputs=probas, name=""model"")

    return model


# %%
m = mini_cnn((64, 64, 3), 2)

## %%
try:
    c = m.get_config()
    m2 = tf.keras.models.model_from_config(c)
except:
    print(""c error"")

try:
    y = m.to_yaml()
    m2 = tf.keras.models.model_from_yaml(y)
except:
    print(""y error"")

try:
    j = m.to_json()
    m2 = tf.keras.models.model_from_json(j)
except:
    print(""j error"")
```

**Other info / logs**

YAML traceback (seems to come from batchnorm)
```
Traceback (most recent call last):
  File ""run.py"", line 49, in <module>
    m2 = tf.keras.models.model_from_yaml(y)
  File ""/my-env/lib/python3.6/site-packages/tensorflow/python/keras/saving/model_config.py"", line 78, in model_from_yaml
    return deserialize(config, custom_objects=custom_objects)
  File ""/my-env/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py"", line 89, in deserialize
    printable_module_name='layer')
  File ""/my-env/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 192, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/my-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1131, in from_config
    process_node(layer, node_data)
  File ""/my-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1087, in process_node
    layer(flat_input_tensors[0], **kwargs)
  File ""/my-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 591, in __call__
    self._maybe_build(inputs)
  File ""/my-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1881, in _maybe_build
    self.build(input_shapes)
  File ""/my-env/lib/python3.6/site-packages/tensorflow/python/keras/layers/normalization.py"", line 286, in build
    raise ValueError('Duplicate axis: %s' % self.axis)
ValueError: Duplicate axis: ListWrapper([3, 3])
None
```

config error
```
Traceback (most recent call last):
  File ""run.py"", line 42, in <module>
    m2 = tf.keras.models.model_from_config(c)
  File ""/my-env/lib/python3.6/site-packages/tensorflow/python/keras/saving/model_config.py"", line 55, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/my-env/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py"", line 81, in deserialize
    layer_class_name = config['class_name']
KeyError: 'class_name'
None

```

here is the yaml file that was generated:

```yaml
backend: tensorflow
class_name: Model
config:
  input_layers:
  - [input_1, 0, 0]
  layers:
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 64, 64, 3]
      dtype: float32
      name: input_1
      sparse: false
    inbound_nodes: []
    name: input_1
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {dtype: float32}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: &id001 !!python/tuple [1, 1]
      dtype: float32
      filters: 16
      kernel_constraint: null
      kernel_initializer:
        class_name: GlorotUniform
        config: {dtype: float32, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [3, 3]
      name: conv2d
      padding: same
      strides: &id002 !!python/tuple [1, 1]
      trainable: true
      use_bias: false
    inbound_nodes:
    - - - input_1
        - 0
        - 0
        - {}
    name: conv2d
  - class_name: BatchNormalization
    config:
      axis: !!python/object/new:tensorflow.python.training.tracking.data_structures._ListWrapper
        listitems: [3]
        state:
          _external_modification: false
          _last_wrapped_list_snapshot: [3]
          _non_append_mutation: false
          _self_extra_variables: []
          _self_trainable: true
          _storage: [3]
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {dtype: float32}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {dtype: float32}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {dtype: float32}
      moving_variance_initializer:
        class_name: Ones
        config: {dtype: float32}
      name: batch_normalization
      scale: true
      trainable: true
    inbound_nodes:
    - - - conv2d
        - 0
        - 0
        - {}
    name: batch_normalization
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation, trainable: true}
    inbound_nodes:
    - - - batch_normalization
        - 0
        - 0
        - {}
    name: activation
  - class_name: MaxPooling2D
    config:
      data_format: channels_last
      dtype: float32
      name: max_pooling2d
      padding: valid
      pool_size: !!python/tuple [2, 2]
      strides: !!python/tuple [2, 2]
      trainable: true
    inbound_nodes:
    - - - activation
        - 0
        - 0
        - {}
    name: max_pooling2d
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {dtype: float32}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: *id001
      dtype: float32
      filters: 32
      kernel_constraint: null
      kernel_initializer:
        class_name: GlorotUniform
        config: {dtype: float32, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [3, 3]
      name: conv2d_1
      padding: same
      strides: *id002
      trainable: true
      use_bias: false
    inbound_nodes:
    - - - max_pooling2d
        - 0
        - 0
        - {}
    name: conv2d_1
  - class_name: BatchNormalization
    config:
      axis: !!python/object/new:tensorflow.python.training.tracking.data_structures._ListWrapper
        listitems: [3]
        state:
          _external_modification: false
          _last_wrapped_list_snapshot: [3]
          _non_append_mutation: false
          _self_extra_variables: []
          _self_trainable: true
          _storage: [3]
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {dtype: float32}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {dtype: float32}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {dtype: float32}
      moving_variance_initializer:
        class_name: Ones
        config: {dtype: float32}
      name: batch_normalization_1
      scale: true
      trainable: true
    inbound_nodes:
    - - - conv2d_1
        - 0
        - 0
        - {}
    name: batch_normalization_1
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_1, trainable: true}
    inbound_nodes:
    - - - batch_normalization_1
        - 0
        - 0
        - {}
    name: activation_1
  - class_name: MaxPooling2D
    config:
      data_format: channels_last
      dtype: float32
      name: max_pooling2d_1
      padding: valid
      pool_size: !!python/tuple [2, 2]
      strides: !!python/tuple [2, 2]
      trainable: true
    inbound_nodes:
    - - - activation_1
        - 0
        - 0
        - {}
    name: max_pooling2d_1
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {dtype: float32}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: *id001
      dtype: float32
      filters: 64
      kernel_constraint: null
      kernel_initializer:
        class_name: GlorotUniform
        config: {dtype: float32, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [3, 3]
      name: conv2d_2
      padding: same
      strides: *id002
      trainable: true
      use_bias: false
    inbound_nodes:
    - - - max_pooling2d_1
        - 0
        - 0
        - {}
    name: conv2d_2
  - class_name: BatchNormalization
    config:
      axis: !!python/object/new:tensorflow.python.training.tracking.data_structures._ListWrapper
        listitems: [3]
        state:
          _external_modification: false
          _last_wrapped_list_snapshot: [3]
          _non_append_mutation: false
          _self_extra_variables: []
          _self_trainable: true
          _storage: [3]
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {dtype: float32}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {dtype: float32}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {dtype: float32}
      moving_variance_initializer:
        class_name: Ones
        config: {dtype: float32}
      name: batch_normalization_2
      scale: true
      trainable: true
    inbound_nodes:
    - - - conv2d_2
        - 0
        - 0
        - {}
    name: batch_normalization_2
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_2, trainable: true}
    inbound_nodes:
    - - - batch_normalization_2
        - 0
        - 0
        - {}
    name: activation_2
  - class_name: MaxPooling2D
    config:
      data_format: channels_last
      dtype: float32
      name: max_pooling2d_2
      padding: valid
      pool_size: !!python/tuple [2, 2]
      strides: !!python/tuple [2, 2]
      trainable: true
    inbound_nodes:
    - - - activation_2
        - 0
        - 0
        - {}
    name: max_pooling2d_2
  - class_name: Flatten
    config: {data_format: channels_last, dtype: float32, name: flatten, trainable: true}
    inbound_nodes:
    - - - max_pooling2d_2
        - 0
        - 0
        - {}
    name: flatten
  - class_name: Dense
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {dtype: float32}
      bias_regularizer: null
      dtype: float32
      kernel_constraint: null
      kernel_initializer:
        class_name: GlorotUniform
        config: {dtype: float32, seed: null}
      kernel_regularizer: null
      name: dense
      trainable: true
      units: 64
      use_bias: false
    inbound_nodes:
    - - - flatten
        - 0
        - 0
        - {}
    name: dense
  - class_name: BatchNormalization
    config:
      axis: !!python/object/new:tensorflow.python.training.tracking.data_structures._ListWrapper
        listitems: [1]
        state:
          _external_modification: false
          _last_wrapped_list_snapshot: [1]
          _non_append_mutation: false
          _self_extra_variables: []
          _self_trainable: true
          _storage: [1]
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {dtype: float32}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {dtype: float32}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {dtype: float32}
      moving_variance_initializer:
        class_name: Ones
        config: {dtype: float32}
      name: batch_normalization_3
      scale: true
      trainable: true
    inbound_nodes:
    - - - dense
        - 0
        - 0
        - {}
    name: batch_normalization_3
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_3, trainable: true}
    inbound_nodes:
    - - - batch_normalization_3
        - 0
        - 0
        - {}
    name: activation_3
  - class_name: Dropout
    config: {dtype: float32, name: dropout, noise_shape: null, rate: 0.25, seed: null,
      trainable: true}
    inbound_nodes:
    - - - activation_3
        - 0
        - 0
        - {}
    name: dropout
  - class_name: Dense
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {dtype: float32}
      bias_regularizer: null
      dtype: float32
      kernel_constraint: null
      kernel_initializer:
        class_name: GlorotUniform
        config: {dtype: float32, seed: null}
      kernel_regularizer: null
      name: logits
      trainable: true
      units: 2
      use_bias: true
    inbound_nodes:
    - - - dropout
        - 0
        - 0
        - {}
    name: logits
  - class_name: Activation
    config: {activation: softmax, dtype: float32, name: probas, trainable: true}
    inbound_nodes:
    - - - logits
        - 0
        - 0
        - {}
    name: probas
  name: model
  output_layers:
  - [probas, 0, 0]
keras_version: 2.2.4-tf
```

One can see the error with ListWrapper

Note:

Lambda layers serialization seem to fail, whereas they worked in tf1.13 as well"
29529,Support RaggedTensor in table lookups,"**System information**
- TensorFlow version (you are using): 2.0.0-alpha0 
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Make Table lookups (`tf.lookup.StaticHashTable` for example) support Ragged Tensor. Currently it only supports Tensor & Sparse Tensor.

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Pretty much any NLP practitioner using this awesome library :)

**Any Other info.**
"
29526,tf.scatter_add does not throw an error,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The documentation of [tf.scatter_add](https://www.tensorflow.org/api_docs/python/tf/scatter_add) states that it requires the following:
```
updates.shape = indices.shape + ref.shape[1:]
```
However, no exception is thrown when I run the code below. In this code, the terms in the condition above have below values.
```
updates.shape = (204671, 100)
indices.shape = (204671, 2)
ref.shape[1:] = (80, 100)
```
This makes it harder to understand the behavior of the function ```tf.scatter_add``` in case ```indices``` is a matrix. Specifically, what is the difference between ```tf.scatter_add``` and ```tf.scatter_nd``` when ```indices``` is a matrix.

**Describe the expected behavior**
An exception should be thrown when the condition in ```tf.scatter_add``` is not met.

**Code to reproduce the issue**

```
import tensorflow as tf
from tensorflow_probability.python.distributions import Bernoulli, Normal

if __name__ == '__main__':
    tf.enable_eager_execution()

    event_dist = Bernoulli(probs=0.2)
    kernel_dist = Normal(loc=0, scale=1)

    events = event_dist.sample(sample_shape=(128, 80, 100), seed=0)
    kernel = kernel_dist.sample(sample_shape=(100, 100), seed=0)

    event_idx = tf.where(events)
    event_effect = tf.gather(kernel, event_idx[:, 2])  # PSP due to each spike
    comp = tf.get_variable(name='v1', shape=(128, 80, 100), initializer=tf.zeros_initializer())
    tf.scatter_add(comp, event_idx[:, :2], event_effect)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29525,[TF 2.0] constant folding failed: invalid argument: unsupported type: 21,"**System information**
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly-gpu-2.0-preview 2.0.0.dev20190606

- Python version: 3.6.5

**Code to reproduce the issue**
<pre>
import numpy as np
import tensorflow as tf


class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.dense = tf.keras.layers.Dense(10)

    def call(self, inputs):
        return self.dense(inputs)


model = Model()


def forward(x):
    batch_size = x.shape[0]
    ys = tf.TensorArray(tf.float32, size=batch_size)
    for i in tf.range(batch_size):
        y = model(x[i][tf.newaxis, :])
        ys = ys.write(i, y)
    return ys.stack()


def train(x, forward_func):
    with tf.GradientTape() as tape:
        ys = forward_func(x)
        loss = tf.reduce_mean(ys)
    grads = tape.gradient(loss, model.trainable_weights)
    return grads


def big_train(x):
    with tf.GradientTape() as tape:
        batch_size = x.shape[0]
        ys = tf.TensorArray(tf.float32, size=batch_size)
        for i in tf.range(batch_size):
            y = model(x[i][tf.newaxis, :])
            ys = ys.write(i, y)
        ys = ys.stack()
        loss = tf.reduce_mean(ys)
    grads = tape.gradient(loss, model.trainable_weights)
    return grads


x = np.random.rand(10, 5).astype(np.float32)

codes_buggy = [
    ""tf.function(train)(x, forward)"",
    ""tf.function(big_train)(x)""
]

codes_normal = [
    ""tf.function(train)(x, tf.function(forward))"",
    ""train(x, tf.function(forward))"",
    ""train(x, forward)"",
    ""big_train(x)""
]


def test(code):
    tf.print(""=========================="")
    tf.print(f""{code}:"")
    exec(code)


test(codes_buggy[0])
test(codes_buggy[1])

test(codes_normal[0])
test(codes_normal[1])
test(codes_normal[2])
test(codes_normal[3])
</pre>

**Other info / logs**
Print:
<pre>
==========================
tf.function(train)(x, forward):
2019-06-07 16:46:23.314712: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-06-07 16:46:23.357137: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-06-07 16:46:23.460568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
==========================
tf.function(big_train)(x):
2019-06-07 16:46:24.139754: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-06-07 16:46:24.180814: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
==========================
tf.function(train)(x, tf.function(forward)):
==========================
train(x, tf.function(forward)):
==========================
train(x, forward):
==========================
big_train(x):
</pre>

Related to #28626 ."
29524,Error when running make for Tensorflow Lite Micro,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: bfc8733ffb
- GCC/Compiler version (if compiling from source): arm-none-eabi-g++ 8.2.1



**Describe the problem**
When running

$ make -f tensorflow/lite/experimental/micro/tools/Makefile generate_projects

it results in the following error:

tensorflow/lite/experimental/micro/examples/micro_vision/Makefile.inc:22: *** missing separator.  Stop.

Reverting commit d77ccda7569 removes that error, but leads to the following error:

make: *** No rule to make target 'tensorflow/lite/experimental/micro/tools/make/gen/linux_x86_64/prj/micro_vision_test/make/tensorflow/lite/experimental/micro/examples/micro_vision/no_person_image_data.cc', needed by 'generate_micro_vision_test_make_project'.  Stop."
29516,"""Failed to load the native TensorFlow runtime"" Win7-x64","**System information**
- OS Platform and Distribution: Microsoft Windows 7 x64
- Mobile device: N/A
- TensorFlow installed from: Binary
- TensorFlow version: 1.13
- Python version: 3.7.3
- Installed using: PIP
- Bazel version: N/A
- GCC/Compiler version: N/A
- CUDA/cuDNN version: CUDA 10.1.1 / cuDNN 7.6
- GPU model and memory: NVIDIA GT 720 2GB

**Describe the problem**
I have installed everything as outlined by the installation instructions and have not gotten any errors, but I get this error at run. I have updated my environment variables and tried many solutions already posted.

**Logs**
File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\imp.py"",
 line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\imp.py"",
 line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

E:\Videowelder\Desktop\srgan-master>python train.py
Traceback (most recent call last):
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\site-pac
kages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\site-pac
kages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\site-pac
kages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_
helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript
ion)
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\imp.py"",
 line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\imp.py"",
 line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""train.py"", line 7, in <module>
    from time import localtime, strftime
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\site-pac
kages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-im
port
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\site-pac
kages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\site-pac
kages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\site-pac
kages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\site-pac
kages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\site-pac
kages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_
helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript
ion)
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\imp.py"",
 line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Videowelder\AppData\Local\Programs\Python\Python37\lib\imp.py"",
 line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found."
29513,Failed to convert object of type <class 'dict'> to Tensor,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I'm writing some code to create a tf.estimator.BoostedTreeRegressor. I'm loading my data through pandas, so both my features and labels are pd frames. Due to this, my training function for the estimator is 
```python
tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,shuffle= True, batch_size = batch_size)
```
and the testing function is 
```python
tf.estimator.inputs.pandas_input_fn(x=X_test,y=y_test, shuffle = False, batch_size = batch_size)
```
Whenever I run the train function, I get the following error:
```python
TypeError: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'PP': <tf.Tensor 'random_shuffle_queue_DequeueUpTo:11' shape=(None,) dtype=float64>}. Consider casting elements to a supported type.
```

**Other info / logs**
```python
WARNING: Logging before flag parsing goes to stderr.
W0606 15:20:02.134926 11092 estimator.py:1799] Using temporary folder as model directory: C:\Users\CRISTI~1\AppData\Local\Temp\tmpeez4al44
W0606 15:20:02.150548 11092 deprecation.py:323] From C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\training\training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0606 15:20:02.166169 11092 deprecation.py:323] From C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow_estimator\python\estimator\inputs\queues\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0606 15:20:02.166169 11092 deprecation.py:323] From C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow_estimator\python\estimator\inputs\queues\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0606 15:20:02.181790 11092 deprecation.py:323] From C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\feature_column\feature_column.py:2121: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
W0606 15:20:02.181790 11092 deprecation.py:323] From C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py:2758: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
Traceback (most recent call last):
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 559, in make_tensor_proto
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 559, in <listcomp>
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\util\compat.py"", line 61, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got {'PP': <tf.Tensor 'random_shuffle_queue_DequeueUpTo:11' shape=(None,) dtype=float64>}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/CristianVives/Documents/translation/scratch/driver.py"", line 51, in <module>
    model.train(train_fun)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 359, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1139, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1169, in _train_model_default
    features, labels, ModeKeys.TRAIN, self.config)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1127, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow_estimator\python\estimator\canned\boosted_trees.py"", line 1924, in _model_fn
    train_in_memory=train_in_memory)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow_estimator\python\estimator\canned\boosted_trees.py"", line 1087, in _bt_model_fn
    batch_size = array_ops.shape(labels)[0]
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 313, in shape
    return shape_internal(input, name, optimize=True, out_type=out_type)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 337, in shape_internal
    input_tensor = ops.convert_to_tensor(input)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\framework\ops.py"", line 1050, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\framework\ops.py"", line 1108, in convert_to_tensor_v2
    as_ref=False)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\framework\ops.py"", line 1186, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 304, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 245, in constant
    allow_broadcast=True)
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 283, in _constant_impl
    allow_broadcast=allow_broadcast))
  File ""C:\Users\CristianVives\.conda\envs\ml\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 563, in make_tensor_proto
    ""supported type."" % (type(values), values))
TypeError: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'PP': <tf.Tensor 'random_shuffle_queue_DequeueUpTo:11' shape=(None,) dtype=float64>}. Consider casting elements to a supported type.
```"
29511,[TF 2.0 API Docs] tf.io.decode_image,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/decode_image
https://github.com/tensorflow/tensorflow/edit/master/tensorflow/python/ops/image_ops_impl.py

## Description of issue (what needs changing):

### Usage example

No usage example given

### Submit a pull request?

Yes
https://github.com/tensorflow/tensorflow/pull/29512"
29510,ImportError on Pycharm,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: extracted from tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl and placed in python path 
- TensorFlow version: 1.13
- Python version: 3.6
- Installed using virtualenv? pip? conda?: venv
- Bazel version (if compiling from source): na
- GCC/Compiler version (if compiling from source): na
- CUDA/cuDNN version: CUDA Version 10.0.166
- GPU model: 128-core NVIDIA Maxwell @ 921MHz  
- Memory: 4GB 64-bit LPDDR4 @ 1600MHz | with swapfile and SD card with 64GB


**Describe the problem**

When attempting to import tensorflow (`import tensorflow`) on pycharm the following error occurs: 
```
Traceback (most recent call last):
  File ""/usr/local/lib/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: /usr/local/lib/tensorflow/python/_pywrap_tensorflow_internal.so: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/ihub/Documents/PycharmProjects/first/HelloWorld.py"", line 15, in <module>
    import tensorflow
  File ""/usr/local/lib/tensorflow/__init__.py"", line 27, in <module>
    from tensorflow._api.v2 import audio
  File ""/usr/local/lib/tensorflow/_api/v2/audio/__init__.py"", line 8, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""/usr/local/lib/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: /usr/local/lib/tensorflow/python/_pywrap_tensorflow_internal.so: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

Process finished with exit code 1
```

the part that confuses me most is that the main error is about `_pywrap_tensorflow_internal.so` ""not existing"" yet it is in the same place as the rest of the fils, the exact path where it says it isnt't"
29509,How to convert a tensorlfow SpaceToBatchND-Conv2D-BatchToSpaceND to a single Conv2D in tflite,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA
- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below):1.13.1
- Python version: 2.7
- Bazel version (if compiling from source): 0.22.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm trying to train my own deeplab model using this [code](https://github.com/tensorflow/models/tree/master/research/deeplab) and convert it to tflite.
My target is to get a model similar to [this](https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/deeplabv3_257_mv_gpu.tflite)

However, the model is obtained contains operations like:
![image](https://user-images.githubusercontent.com/43549654/59057361-135a7500-884f-11e9-9546-e2bd20e69c95.png)
SpaceToBatchND and BatchToSpaceND operations are not supported by tflite + opengles backend, they reduced the model's performance on my device.

In your hosted deeplab model, those three ops are replaced by DEPTHWISE_CONV_2D v2, which has options to set dilation factor. This would be the best solution for me but I'm not sure how to convert SpaceToBatchND-Conv2D-BatchToSpaceND into a singe DEPTHWISE_CONV_2D v2(dilation=2).

FYI, I have tried the graph_transforms tool under tensorflow/tools/graph_transforms to flatten the atrous conv. It upsampled the kernels instead of Space_To_Batch + Batch_To_Space. But this transform leads to much more computations that I cannot afford.

**Describe the expected behavior**

convert SpaceToBatchND-Conv2D-BatchToSpaceND into a singe DEPTHWISE_CONV_2D v2(dilation=2)

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

You can try any model under deeplab model zoo for example [http://download.tensorflow.org/models/deeplabv3_mnv2_ade20k_train_2018_12_03.tar.gz](url)

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29507,[TF 2.0 API Docs] tf.image.crop_and_resize,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/crop_and_resize
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not defined

### Usage example

No usage example is given

### Submit a pull request?

Yes
https://github.com/tensorflow/tensorflow/pull/29508"
29506,[TF2.0-nightly] GRU/LSTM layers don't use cuDNN properly ,"**System information**
- Have I written custom code : Yes
- OS Platform and Distribution :
     - Ubuntu 16.04 + Docker 18.09.6-ce
     - Arch Linux 5.1.5
- TensorFlow installed from : pip install tf-nightly-gpu-2.0-preview
- TensorFlow version : 2.0.0-dev20190606, but every nightly since 2.0.0-dev20190319 presents the same behaviour.
- Python version: 3.6.8
- CUDA/cuDNN version: CUDA V10.0.130 / cuDNN 7.5.0.56
- GPU model and memory:
     - Nvidia GTX 980Ti (6GB)
     - Nivida GTX 1070 (8GB)


**Describe the current behavior**

GRU/LSTM layers don't use the cuDNN implementation properly, resulting in much worse performance.  Let's take for example this toy network :

```
# Imports
import numpy as np
import tensorflow as tf
tf.executing_eagerly()
print('TensorFlow version: ' + str(tf.__version__))

# Print checks
from tensorflow.python.eager import context
print('Executing eagerly? : ' + str(context.executing_eagerly()))
print('Number of GPUs: ' + str(context.num_gpus()))

# Generate random data
X = np.random.rand(6720,700,3)
y = X[:,1,1]
print('Shapes: ', X.shape, y.shape)

# Define toy network
input_shape = X.shape[2]
rnn_state_size = 1
timesteps = X.shape[1]

inputs = tf.keras.layers.Input(shape=[timesteps, input_shape], dtype=np.float32)
output = tf.keras.layers.LSTM(rnn_state_size)(inputs)
model = tf.keras.Model(inputs, output)
model.compile('rmsprop', 'mse')
print(model.summary())

# Fit
model.fit(X,y)
```

With the last nightly this is what we obtain:

```
TensorFlow version: 2.0.0-dev20190606
Executing eagerly? : True
2019-06-06 12:52:23.635654: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-06-06 12:52:23.660930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1658] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7845
pciBusID: 0000:42:00.0
2019-06-06 12:52:23.661142: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-06 12:52:23.661983: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-06 12:52:23.662749: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-06 12:52:23.662937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-06 12:52:23.663896: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-06 12:52:23.664621: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-06 12:52:23.667023: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-06 12:52:23.667936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1781] Adding visible gpu devices: 0
2019-06-06 12:52:23.668222: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-06 12:52:23.756255: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b18abf73d0 executing computations on platform CUDA. Devices:
2019-06-06 12:52:23.756289: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2019-06-06 12:52:23.758641: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3494060000 Hz
2019-06-06 12:52:23.759820: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b18aff2990 executing computations on platform Host. Devices:
2019-06-06 12:52:23.759845: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-06 12:52:23.760484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1658] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7845
pciBusID: 0000:42:00.0
2019-06-06 12:52:23.760515: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-06 12:52:23.760527: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-06 12:52:23.760537: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-06 12:52:23.760547: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-06 12:52:23.760557: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-06 12:52:23.760567: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-06 12:52:23.760577: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-06 12:52:23.761521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1781] Adding visible gpu devices: 0
2019-06-06 12:52:23.761549: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-06 12:52:23.762256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-06 12:52:23.762272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1205]      0 
2019-06-06 12:52:23.762280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1218] 0:   N 
2019-06-06 12:52:23.763253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6407 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:42:00.0, compute capability: 6.1)
Number of GPUs: 1
Shapes:  (6720, 700, 3) (6720,)
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 700, 3)]          0         
_________________________________________________________________
lstm (LSTM)                  (None, 1)                 20        
=================================================================
Total params: 20
Trainable params: 20
Non-trainable params: 0
_________________________________________________________________
None
Train on 6720 samples
2019-06-06 12:52:26.219667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
6720/6720 [==============================] - 114s 17ms/sample - loss: 0.1441
```


Which is much slower than what we obtained with version 2.0.0-dev20190319 and previous (including version 2.0-alpha) :

```
TensorFlow version: 2.0.0-dev20190319
Executing eagerly? : True
2019-06-06 13:23:14.360714: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-06 13:23:14.379231: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-06-06 13:23:14.500580: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558a01550ac0 executing computations on platform CUDA. Devices:
2019-06-06 13:23:14.500637: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2019-06-06 13:23:14.525050: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3494060000 Hz
2019-06-06 13:23:14.526497: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558a01662bb0 executing computations on platform Host. Devices:
2019-06-06 13:23:14.526541: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-06 13:23:14.526816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1551] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7845
pciBusID: 0000:42:00.0
totalMemory: 7.92GiB freeMemory: 6.59GiB
2019-06-06 13:23:14.526860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1674] Adding visible gpu devices: 0
2019-06-06 13:23:14.526931: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-06 13:23:14.527880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1082] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-06 13:23:14.527903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1088]      0 
2019-06-06 13:23:14.527925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1101] 0:   N 
2019-06-06 13:23:14.528098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1222] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6407 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:42:00.0, compute capability: 6.1)
Number of GPUs: 1
Shapes:  (6720, 700, 3) (6720,)
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 700, 3)]          0         
_________________________________________________________________
lstm (LSTM)                  (None, 1)                 20        
=================================================================
Total params: 20
Trainable params: 20
Non-trainable params: 0
_________________________________________________________________
None
2019-06-06 13:23:16.864613: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
6720/6720 [==============================] - 6s 884us/sample - loss: 0.1065
```

**Other info / logs**

I have tried in different computers and I am able to reproduce the issue.
With the modifications from [this pull request](https://github.com/tensorflow/tensorflow/pull/29424), I obtain the same performance in the last nightly as in 2.0.0-dev20190319, but with the advantage of being able to use cuDNN with masking, which was added by @qlzh727 in [this commit](https://github.com/tensorflow/tensorflow/commit/ac04087f7fb9d535d33b800d6e2bfb82c7df7077#diff-a9f256601f2626075300a37eeb4cea5f).

I am willing to contribute to solve this issue in a better way if you would like me to.
Thanks!"
29504,tf.function fails to parse for-loop in some circumstances,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): gLinux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0
- Python version: 3.6
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
```python
@tf.function
def tf_function_with_loop(num_iter):
  digit_list = []
  for i in tf.range(num_iter):
    digit_list.append(i)
  return tf.add_n(digit_list)

tf_function_with_loop(5)
fails with log posted in log section.

def function_with_loop(num_iter):
  digit_list = []
  for i in tf.range(num_iter):
    digit_list.append(i)
  return tf.add_n(digit_list)

function_with_loop(5)  # samething without @tf.function
returns tf.Tensor(10, shape=(), dtype=int32)
```
**Describe the expected behavior**
tf_function_with_loop(5) should return tf.Tensor(10, shape=(), dtype=int32)


**Code to reproduce the issue**
written above.

**Other info / logs**

ValueError: Trying to capture a tensor from an inner function. This can be caused by accessing a tensor defined inside a loop or conditional body, or a subfunction, from a calling function, without going through the proper return value mechanism. Consider using TensorFlow mechanisms such as TensorArrays to return tensors from inner functions or loop / conditional bodies. Tensor: Tensor(""TensorArrayV2Read/TensorListGetItem:0"", shape=(), dtype=int32); tensor graph: FuncGraph(name=while_body_40, id=139946430861008); this graph: FuncGraph(name=tf_function_with_loop, id=139946437179024)
"
29501,tensorflow debugger `run -t` fails on keras,"See the description at https://stackoverflow.com/questions/56452641/tensorflow-debugger-run-t-failed-running-keras-model

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

Exception thrown

**Describe the expected behavior**

Run the number of iteration as specified in the `run -t` command

**Code to reproduce the issue**

See  https://stackoverflow.com/questions/56452641/tensorflow-debugger-run-t-failed-running-keras-model

**Other info / logs**
"
29495,Estimator API - Unexpected behaviour for Validation Loss during early training steps,"**System information**
- Have I written custom code : Yes
- OS Platform and Distribution : Linux Ubuntu 18.04.2 LTS
- TensorFlow installed from : binary
- TensorFlow version : 1.12.0
- Python version: 2.7.15
- CUDA/cuDNN version: 10.1/7
- GPU model and memory: GeForce GTX 1080Ti 11Gb

I am trying the TF Estimator API for monitoring validation metrics during training. To debug my code I have set up some runs with the following:

- train and val sets are the same, both consisting of 1 sample
- batch size is set to 1 both for training and validation
- learning rate is set to 0.0 so that no changes happen to the network

**Describe the expected behavior**
I would expect training and validation loss to be constant throughout training and equal to each other

**Describe the current behavior**
However, what is observed in Tensorboard is:
- training loss behaves as expected
- validation loss is different in the beginning, slowly converging towards the constant value of the training loss
- increasing the learn rate seems to reduce this effect significantly. In the plots below all is the same apart from the learn rates which are 0.001 and 0.1

My question is if this is a bug or this behaviour is expected and if so what is the underlying mechanism driving this? 

lear_rate = 0.0
![image](https://user-images.githubusercontent.com/18511714/59041124-ea96a780-886f-11e9-94d5-1e3db786902e.png)

learn_rate = 0.001
![image](https://user-images.githubusercontent.com/18511714/59041183-0b5efd00-8870-11e9-9061-bff53435292a.png)

learn_rate = 0.1
![image](https://user-images.githubusercontent.com/18511714/59041217-174abf00-8870-11e9-8ad2-eed13161450e.png)

**Code to reproduce the issue**
```
import tensorflow as tf

data_paths = ""/home/user/Desktop/test_csv_files/1sample.csv""
batch_size = 1

def get_batch(paths, options):
    ....
    return {""images"": image_features_tensor}, labels_tensor
    
def fully_connected_network(features, sizes, is_training):
    inputs = features['images']
    if sizes == [0]:
        return inputs
    for i, size in enumerate(sizes):
        inputs = tf.layers.dense(inputs=inputs, units=size)
        inputs = tf.nn.relu(inputs)
        inputs = tf.layers.batch_normalization(
            inputs, momentum=0.99, axis=-1, epsilon=0.001, training=is_training, 
            reuse=None, fused=USE_FUSED_BN)
    return inputs
    
def model_fn(features, labels, mode, params):
    if mode == tf.estimator.ModeKeys.TRAIN:
        is_training = True
    else:
        is_training = False
    print(""IS TRAINING: "", is_training)

    features = fully_connected_network(features, 1, is_training)
    logits = tf.layers.dense(inputs=features, units=3)
    softmax = tf.nn.softmax(logits, name=""softmax_out"")
    predicted_classes = tf.reshape(tf.math.argmax(softmax, axis=1, output_type=tf.int32), (-1, 1))

    predictions = {""classes"": predicted_classes, ""probabilities"": softmax}

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

    one_hot_labels = tf.one_hot(labels, depth=3)
    loss = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_labels, logits=logits))

    batch_accuracy = batch_multiclass_metrics(labels, predicted_classes)

    tf.summary.scalar('accuracy', batch_accuracy)

    if mode == tf.estimator.ModeKeys.TRAIN:
        initial_learn_rate = tf.constant(learn_rate, tf.float32)
        learn_rate = tf.train.exponential_decay(learning_rate=0.001,
            global_step=tf.train.get_global_step(), decay_steps=1000,
            decay_rate=0.95,staircase=True)
        optimizer = tf.train.AdamOptimizer(learning_rate=learn_rate)
        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
        train_op = optimizer.minimize(
            loss=loss, global_step=tf.train.get_global_step())
        train_op = tf.group([train_op, update_ops])
        return tf.estimator.EstimatorSpec(
            mode=mode, loss=loss, train_op=train_op)  # ,
    if mode == tf.estimator.ModeKeys.EVAL:
        eval_metric_ops = {
            ""accuracy"": tf.metrics.accuracy(labels=labels, 
                                            predictions=predicted_classes)}
        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          predictions=predictions,  # test
                                          eval_metric_ops=eval_metric_ops)
                                          
checkpoint_config = tf.estimator.RunConfig(
        save_checkpoints_steps=1000,
        save_summary_steps=200,
        keep_checkpoint_max=10)

estimator = tf.estimator.Estimator(
    model_fn=model_fn,
    params=config_model_options,
    model_dir=savedir,
    config=checkpoint_config,
    warm_start_from=None)

train_input_fn = lambda paths: get_batch(data_paths, options=config_train_options)
eval_input_fn = lambda paths: get_batch(data_paths, options=config_val_options)

train_spec = tf.estimator.TrainSpec(input_fn=lambda: train_input_fn(data__paths),
                                    max_steps=None)

eval_spec = tf.estimator.EvalSpec(input_fn=lambda: eval_input_fn(data_paths),
                                  steps=1,
                                  start_delay_secs=20,
                                  throttle_secs=20)

tf.estimator.train_and_evaluate(estimator=estimator,
                                train_spec=train_spec,
                                eval_spec=eval_spec)  
```

**Other info / logs**
The question was originally asked in stack overflow https://stackoverflow.com/questions/56188656/tensorflow-estimator-api-validation-loss-during-early-training-steps

Many thanks,
Michael
"
29494,"Slow model training in Tensorflow 1.11, 1.12, 1.13","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Docker
- TensorFlow version (use command below): 1.11, 1.12, 1.13.1,
- Python version: Version supplied in docker container
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory:

**Describe the current behavior**
I have a fairly large, complicated estimator-based model that I want to train using a Tesla P100. Previously, performance has been okay:

```
INFO:tensorflow:loss = 5.1591277, step = 400 (5.961 sec)
INFO:tensorflow:global_step/sec: 16.6121
INFO:tensorflow:loss = 2.3208628, step = 500 (6.020 sec)
INFO:tensorflow:global_step/sec: 16.8526
```

But starting from TF 1.11 and up (as of writing newest is 1.13.1), performance has been much worse:

```
INFO:tensorflow:global_step/sec: 6.49846
INFO:tensorflow:loss = 0.115654044, step = 2300 (15.389 sec)
INFO:tensorflow:global_step/sec: 6.56155
INFO:tensorflow:loss = 0.002102174, step = 2400 (15.240 sec)
INFO:tensorflow:global_step/sec: 6.45419
INFO:tensorflow:loss = 0.6258155, step = 2500 (15.494 sec)
```

Using `tf.train.ProfilerHook`, I have generated the following performance profile for Tensorflow 1.13.1: ![profile](https://user-images.githubusercontent.com/448023/59034033-71e11c80-886a-11e9-9fd6-d590a61b82eb.PNG). The last part of the profile is several applications of `ApplyAdam` and the operations they depend on (reshapes, sums, mul, etc). It seems that these Adam applications and intermediate operations are completely serial with no parallelism. Is this expected? I would imagine it to be as parallel as the model itself is (i.e. a model with many sequential dependencies would have many sequential dependencies when computing the gradients).

Unfortunately, as `tf.train.ProfilerHook` is a fairly new addition I have no execution profiles for tensorflow versions older than 1.13.1.

There are a few differences in optimizer error/warnings that might explain why this difference in training speed happens:

- [ArithmeticOptimizer fails in 1.11 and up](https://github.com/tensorflow/tensorflow/issues/29052). The warning disappears if I use the nightly tensorflow docker images, but model training is still slow. A similar warning is logged in 1.10, but with a slightly different wording.
- Dependency optimizer fails in 1.11 and up, but not in 1.10:
    ```
    2019-06-06 11:46:25.390684: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 0, topological sort failed with message: The graph     couldn't be sorted in topological order.
    2019-06-06 11:46:25.563595: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:704] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
    ```

[This issue](https://github.com/tensorflow/tensorflow/issues/20843) mentions a slowdown caused by additional graph optimization in 1.9. I do not think that this is the case here, as it is the steps of the model itself that is slow.

**Describe the expected behavior**
I would expect TF 1.11 to be as fast or faster as TF 1.10."
29493,TFLite_Convert error,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10(10.0.17763.379)
- TensorFlow installed from (source or binary): https://anaconda.org/anaconda/tensorflow-gpu
- TensorFlow version (or github SHA if from source): 1.13.1

Converting with next command
toco --graph_def_file=tflite_graph.pb --output_file=ssd_ocr.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_decv_values=128  --alow_custom_ops=True

```
2019-06-06 16:57:31.348601: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX
2019-06-06 16:57:31.708229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
totalMemory: 8.00GiB freeMemory: 6.61GiB
2019-06-06 16:57:31.718843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-06-06 16:57:32.934642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-06 16:57:32.939220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-06-06 16:57:32.941782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-06-06 16:57:32.946998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\Scripts\toco-script.py"", line 10, in <module>
    sys.exit(main())
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 442, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 438, in run_main
    _convert_model(tflite_flags)
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 191, in _convert_model
    output_data = converter.convert()
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\lite\python\lite.py"", line 461, in convert
    **converter_kwargs)
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\lite\python\convert.py"", line 411, in toco_convert_graph_def
    input_data.SerializeToString())
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\lite\python\convert.py"", line 205, in toco_convert_protos
    ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
2019-06-06 16:57:37.302686: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TFLite_Detection_PostProcess
2019-06-06 16:57:37.303745: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-06-06 16:57:37.304168: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-06-06 16:57:37.304742: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-06-06 16:57:37.305160: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-06-06 16:57:37.305829: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TFLite_Detection_PostProcess
2019-06-06 16:57:37.388054: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 900 operators, 1355 arrays (0 quantized)
2019-06-06 16:57:37.484883: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 900 operators, 1355 arrays (0 quantized)
2019-06-06 16:57:39.390818: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 112 operators, 224 arrays (1 quantized)
2019-06-06 16:57:39.397064: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 112 operators, 224 arrays (1 quantized)
2019-06-06 16:57:39.399525: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 65 operators, 177 arrays (1 quantized)
2019-06-06 16:57:39.402192: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 65 operators, 177 arrays (1 quantized)
2019-06-06 16:57:39.766641: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 1: 71 operators, 183 arrays (151 quantized)
2019-06-06 16:57:39.791435: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 2: 71 operators, 183 arrays (155 quantized)
2019-06-06 16:57:39.826873: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 3: 66 operators, 178 arrays (157 quantized)
2019-06-06 16:57:39.840230: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 4: 66 operators, 178 arrays (158 quantized)
2019-06-06 16:57:39.849804: W tensorflow/lite/toco/graph_transformations/quantize.cc:127] Constant array anchors lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.
2019-06-06 16:57:39.852829: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After quantization graph transformations pass 5: 64 operators, 176 arrays (159 quantized)
2019-06-06 16:57:39.861480: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before shuffling of FC weights: 64 operators, 176 arrays (159 quantized)
2019-06-06 16:57:39.866445: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 2880000 bytes, theoretical optimal value: 2160000 bytes.
2019-06-06 16:57:39.868004: I tensorflow/lite/toco/toco_tooling.cc:399] Estimated count of arithmetic ops: 2.49483 billion (note that a multiply-add is counted as 2 ops).
2019-06-06 16:57:39.869067: E tensorflow/lite/toco/toco_tooling.cc:421] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
Traceback (most recent call last):
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\Scripts\toco_from_protos-script.py"", line 10, in <module>
    sys.exit(main())
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""C:\Users\Freyr\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
```

http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz

downloaded model is coco_ssd_mobilenet_v1_1.0_quant_2018_06_29
trying to convert tfile_graph from downloaded zip archive"
29492,Multiple calls to custom layer does not work,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- TensorFlow version: 2.0.0-alpha0
- Python version: 3.6.7

**Describe the current behavior**
When trying to use a custom *layer* into a new custom *Model*, the Model's call method doesn't work when I am initializing the custom layer in the Model's constructor but when instantiating this layer directly in the call method it works


**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
from tensorflow.keras import Model, layers

class BottleneckLayer(layers.Layer):
    def __init__(self, growthRate):
        super().__init__()
        self.conv1 = layers.Conv2D(4 * growthRate, kernel_size=1, strides=1, padding=""same"")
        self.conv2 = layers.Conv2D(growthRate, kernel_size=3, strides=1, padding=""same"")
        self.batchNorm = layers.BatchNormalization(momentum=0.99, epsilon=0.001)
        self.relu = layers.Activation(""relu"")

    def call(self, x):
        y = self.batchNorm(self.relu(self.conv1(x)))
        y = self.batchNorm(self.relu(self.conv2(y)))
        y = layers.concatenate([x, y])
        return y

class DenseNet(Model):
    def __init__(self):
        super().__init__()
        self.relu = layers.Activation(""relu"")
        growthRate = 12
        self.conv1 = layers.Conv2D(2 * growthRate, kernel_size=7, strides=2, padding=""same"")
        self.maxpool = layers.MaxPooling2D((2, 2), strides=2) 

        self.bottleneck = BottleneckLayer(growthRate)

    def call(self, x):
        y = self.maxpool(self.relu(self.conv1(x)))
        print(y.shape)

        ## putting BottleneckLayer directly in call works
        for _ in range(6):
            y = BottleneckLayer(12)(y)
            print(y.shape)

        ## this approach does not work
        for _ in range(6):
            y = self.bottleneck(y)
            print(y.shape)

        return y
```

Specifically with the first approach I have
``` bash 
(16, 56, 56, 24)                                                                 
(16, 56, 56, 36)                                                                 
(16, 56, 56, 48)                                                                 
(16, 56, 56, 60)                                                                 
(16, 56, 56, 72)                                                                 
(16, 56, 56, 84)                                                                 
(16, 56, 56, 96)
```
However for the second, I have the following;
``` bash
(16, 56, 56, 24)                                                                 
(16, 56, 56, 36)                                                                 
2019-06-06 14:10:22.894332: W tensorflow/core/framework/op_kernel.cc:1431] OP_RE QUIRES
 failed at conv_ops.cc:461 : Invalid argument: input depth must be evenly  
divisible by filter depth: 36 vs 24
```
The first call to self.bottleneck worked but not the second one suggesting that we need to instantiate a new custom Bottleneck layer and cannot reuse the self.bottleneck.  
"
29490,TFLite GPU Delegates: Reshape fails to reshape input matrix with batch >1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): master
- Python version: 3.6.5
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
The following test case fails.

```
TEST(ReshapeTest, Smoke) {
  TensorRefFloat32 augend, addend, output;
  augend.type = DataType::FLOAT32;
  augend.ref = 0;
  augend.shape = BHWC(1, 2, 6, 1);

  output.type = DataType::FLOAT32;
  output.ref = 2;
  output.shape = BHWC(2, 3, 2, 1);

  ReshapeAttributes attr;
  attr.new_shape = BHWC(2, 3, 2, 1);

  SingleOpModel model({ToString(OperationType::RESHAPE), std::move(attr)},
                      {augend}, {output});
  ASSERT_TRUE(model.PopulateTensor(0, {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}));
  ASSERT_TRUE(model.Invoke(*NewReshapeNodeShader()));
  EXPECT_THAT(model.GetOutput(0),
              Pointwise(FloatNear(1e-6), {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}));
}

Value of: model.Invoke(*NewReshapeNodeShader())
  Actual: false
Expected: true
```

If the input batch is 2:
```
TEST(ReshapeTest, Smoke) {
  TensorRefFloat32 augend, addend, output;
  augend.type = DataType::FLOAT32;
  augend.ref = 0;
  augend.shape = BHWC(2, 3, 2, 1);

  output.type = DataType::FLOAT32;
  output.ref = 2;
  output.shape = BHWC(2, 2, 3, 1);

  ReshapeAttributes attr;
  attr.new_shape = BHWC(2, 2, 3, 1);

  SingleOpModel model({ToString(OperationType::RESHAPE), std::move(attr)},
                      {augend}, {output});
  ASSERT_TRUE(model.PopulateTensor(0, {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}));
  // ASSERT_TRUE(model.PopulateTensor(1, {2, 2, 3}));
  ASSERT_TRUE(model.Invoke(*NewReshapeNodeShader()));
  EXPECT_THAT(model.GetOutput(0),
              Pointwise(FloatNear(1e-6), {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}));
}

Value of: model.GetOutput(0)
Expected: contains 12 values, where each value and its corresponding value in { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 } are an almost-equal pair
  Actual: { 1, 2, 3, 4, 5, 6, 0, 0, 0, 0, 0, 0 }, where the value pair (0, 7) at index #6 don't match, which is 7 from 0
```
However, the test case passes if the batch dimensions are identical.

**Describe the expected behavior**

The output sequence should match the input, even when the batch dimensions are greater than 1. Why do batch dimensions need to be 1?

**Other info**

I'm not sure if my take is correct. `gid.z` should take the value 1 to read the second batch in the second case, but `gid.z` is always 0. Perhaps it's a bug in the command queue?
"
29489,tf.keras InvalidArgumentError: Incompatible shapes for batch size > 1,"**System information**
- Have I written custom code (as opposed to using example directory):  yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  macOS
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  v1.12.1-1845-g27cfc61581 1.14.1-dev20190514
- Keras version:  using tf.keras
- Python version:  3.7.3
- CUDA/cuDNN version:   -
- GPU model and memory:  -

When fitting a tf.keras LSTM encoder-decoder model (or any model with Timedistributed(Dense(1)) layer at the end)

    model = Sequential()
    model.add(LSTM(200, activation='relu', input_shape=(72,3)))
    model.add(RepeatVector(24))
    model.add(LSTM(200, activation='relu', return_sequences=True))
    model.add(TimeDistributed(Dense(int(100), activation='relu')))
    model.add(TimeDistributed(Dense(1)))
    model.compile(loss='mse', optimizer='adam')

with a `batch_size>1` I see the following Error:

    keras InvalidArgumentError: Incompatible shapes: [100,24,1] vs. [100,24]

where in this case 100 is the `batch_size` and 24 is length of the output sequence.

The training data has the shape: `[samples, time_steps, n_features]`, so something like:

    X_train:(13641, 72, 3) and y_train:(13641, 24, 1)



"
29488,[2.0a0 AutoGraph] segmentation fault after refactoring into smaller functions,"**System information**
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0alpha0
- Python version: 3.6.5

**Code to reproduce the issue**
<pre>
# -*- coding: utf-8 -*-
# @Author  : Lin Lan (ryan.linlan@gmail.com)

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import tensorflow as tf


class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.dense = tf.keras.layers.Dense(10)

    def call(self, inputs):
        return self.dense(inputs)


model = Model()


def forward(x):
    batch_size = x.shape[0]
    ys = tf.TensorArray(tf.float32, size=batch_size)
    for i in tf.range(batch_size):
        y = model(x[i][tf.newaxis, :])
        ys = ys.write(i, y)
    return ys.stack()


def train(x, forward_func):
    with tf.GradientTape() as tape:
        ys = forward_func(x)
        loss = tf.reduce_mean(ys)
    grads = tape.gradient(loss, model.trainable_weights)
    return grads


def big_train(x, forward_func):
    with tf.GradientTape() as tape:
        batch_size = x.shape[0]
        ys = tf.TensorArray(tf.float32, size=batch_size)
        for i in tf.range(batch_size):
            y = model(x[i][tf.newaxis, :])
            ys = ys.write(i, y)
        ys = ys.stack()
        loss = tf.reduce_mean(ys)
    grads = tape.gradient(loss, model.trainable_weights)
    return grads


x = np.random.rand(10, 100).astype(np.float32)

train(x, forward)
print(""pass"")

tf.function(big_train)(x, tf.function(forward))
print(""pass"")

tf.function(train)(x, tf.function(forward))    # lead to segmentation fault (core dumpled)
print(""pass"")
</pre>

**Other info / logs**
Possibly related to #29393 . Also, due to that issue, we have to decorate some nested methods with `tf.function`.
@alextp @mdanatg "
29487,TF 2.0 tf.distribute.MirroredStrategy without methods of experimental_run_v2 experimental_distribute_dataset and so on ,"TF 2.0 tf.distribute.MirroredStrategy without method of experimental_run_v2 experimental_distribute_dataset and so on 

<img width=""722"" alt=""Screen Shot 2019-06-06 at 19 55 11"" src=""https://user-images.githubusercontent.com/6704475/59031038-2e4fd800-8895-11e9-9efa-5f2cef8903c3.png"">

I tried tensorflow==2.0.0-alpha0 and tensorflow-gpu==2.0.0-alpha0 on colab and my own computer.

[tutorial](https://www.tensorflow.org/alpha/guide/distribute_strategy#using_tfdistributestrategy_with_keras) and documents refer to these methods 
"
29486,Crash in sess.run on CPU after restoring model from checkpoint.,"I am trying to perform inference on CPU for tensorflow UNET implementation after restoring from checkpoint on Windows 10 64bit with miniconda (Python 3.6.8 :: Anaconda, Inc.). Here is a list of packages installed on used environment:

```
Package              Version                 
-------------------- ------------------------
absl-py              0.7.1                   
asn1crypto           0.24.0                  
astor                0.7.1                   
backports.weakref    1.0.post1               
bleach               3.1.0                   
certifi              2019.3.9                
cffi                 1.12.3                  
chardet              3.0.4                   
cloudpickle          1.0.0                   
conda                4.6.14                  
cryptography         2.7                     
cycler               0.10.0                  
cytoolz              0.9.0.1                 
dask                 1.2.2                   
decorator            4.4.0                   
gast                 0.2.2                   
grpcio               1.16.1                  
h5py                 2.9.0                   
html5lib             1.0.1                   
idna                 2.8                     
image-slicer         0.2.0                   
imageio              2.5.0                   
joblib               0.13.2                  
Keras                2.2.4                   
Keras-Applications   1.0.7                   
Keras-Preprocessing  1.0.9                   
kiwisolver           1.1.0                   
Mako                 1.0.9                   
Markdown             3.1                     
MarkupSafe           1.1.1                   
matplotlib           3.1.0                   
menuinst             1.4.16                  
mkl-fft              1.0.12                  
mkl-random           1.0.2                   
mkl-service          2.0.2                   
mock                 3.0.5                   
networkx             2.3                     
numpy                1.16.4                  
olefile              0.46                    
pbr                  5.1.3                   
Pillow               6.0.0                   
pip                  19.1.1                  
protobuf             3.7.1                   
pycosat              0.6.3                   
pycparser            2.19                    
pygpu                0.7.6                   
pyOpenSSL            19.0.0                  
pyparsing            2.4.0                   
pyreadline           2.1                     
PySocks              1.7.0                   
python-dateutil      2.8.0                   
pytz                 2019.1                  
PyWavelets           1.0.3                   
pywin32              223                     
PyYAML               5.1                     
requests             2.22.0                  
ruamel-yaml          0.15.46                 
scikit-image         0.15.0                  
scikit-learn         0.21.2                  
scipy                1.2.1                   
setuptools           41.0.1                  
six                  1.12.0                  
tensorboard          1.13.1                  
tensorflow           1.13.1                  
tensorflow-estimator 1.13.0                  
termcolor            1.1.0                   
tf-unet              0.1.1                   
Theano               1.0.3+2.g3e47d39ac.dirty
toolz                0.9.0                   
tornado              6.0.2                   
urllib3              1.24.2                  
webencodings         0.5.1                   
Werkzeug             0.15.2                  
wheel                0.33.4                  
win-inet-pton        1.1.0                   
wincertstore         0.2                     
```

PROBLEM: if you run test file tf_unet_roofs_test.py, then it crashes silently on sess.run, next line of code is not executed. 
Data to reproduce: https://yadi.sk/d/g-KU9fUw41t9_Q"
29483,"how can fix the problem ""Memory cannot be recycled"" in  my web service  build by tensorflow + flask ","**### This is my code:**

```
import numpy as np
from flask import Flask, request
import tensorflow as tf

from tensorflow.python.platform import gfile
from app.utils.log_util import LogUtils
log = LogUtils.get_stream_logger(__name__)

app = Flask(__name__)

with gfile.FastGFile('../20190517-152605.pb', 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    
graph = tf.Graph()
with graph.as_default():
    tf.import_graph_def(graph_def, input_map=None, name='')
    # print(tf.get_default_graph().as_graph_def().node)
    images_placeholder = tf.get_default_graph().get_tensor_by_name(""input:0"")
    embeddings = tf.get_default_graph().get_tensor_by_name(""embeddings:0"")
    phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(""phase_train:0"")
    model = {
        'images_placeholder': images_placeholder,
        'embeddings': embeddings,
        'phase_train_placeholder': phase_train_placeholder
    }

sess = tf.Session(graph=graph)

@app.route('/', methods=['POST'])
def classify():
    log.info('ss')
    # data = request.files.get('data').read()
    face = np.load(""test.npy"")
    images_placeholder = model['images_placeholder']
    embeddings = model['embeddings']
    phase_train_placeholder = model['phase_train_placeholder']
    result = sess.run(embeddings, feed_dict={images_placeholder: face, phase_train_placeholder: False})
    print(result)
    return str(200)
app.run(host='127.0.0.1',port=12480)
```
memory grow situation :
request times: |1 | 2 |4 ... |100 ... n
memory: |400+MB |600+MB | 700MB ... |2GB ... 2GB

- OS Platform :  ubuntu 18.04
- TensorFlow installed from (source or binary): pipenv pypi
- TensorFlow version (use command below):  1.13.1
- Python version: 3.6.4
- run at cpu


"
29481,add_update in cross-replica mode is broken (BatchNormalization layer impossible to use),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Archlinux
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-3374-g9eb67b17bf 2.0.0-dev20190605
- Python version: 3.6
- CUDA/cuDNN version: 10
- GPU model and memory: 1080 Ti

**Describe the current behavior**

I expect to do a forward pass with a model with a BachNormalization layer in training mode, when using the `tf.distribuite.MirroredStrategy` but I can't, because it reises the following exception:

> RuntimeError: `add_update` was called in a cross-replica context. This is not expected. If you require this feature, please file an issue.

Why it is not expected?

**Describe the expected behavior**

It should work.
The commit that introduced this behavior is: https://github.com/tensorflow/tensorflow/commit/316cd57883166e6a0b4c2d0eaacebddad7675b39#diff-8eb7e20502209f082d0cb15119a50413

**Code to reproduce the issue**

```python
import tensorflow as tf

model = tf.keras.Sequential(
    [
        tf.keras.layers.Dense(10),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dense(1),
    ]
)

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    out = model(tf.zeros((1, 10)), training=True)
```"
29480,BatchNorm behavior,"**Describe the feature and the current behavior/state.**
Currently the BatchNorm layer behavior is the following (if I have correctly understood):
If `training=True`:
- The output is centered and scaled using the moving mean and moving variance are updated with the current minibatch mean and variance. The moving mean and variance are updated.

If `training=False`:
- The output is centered and scaled using the moving mean and moving variance. The current batch statistics are not updated. 

I think this is a problem in some cases. For example in pix2pix (code: https://www.tensorflow.org/alpha/tutorials/generative/pix2pix) (paper: https://arxiv.org/abs/1611.07004) the evaluation is done using the flag `training=True` in order to use also the current batch statistics (apart for the dropout layer).

I think that it would be useful to add an additional flag telling whether to use the current batch statistics without updating the moving mean and moving variance. In this case it will be possible to evaluate correctly models like pix2pix. 

In other words: 
The batch norm call can be changed into:
`keras.layers.BatchNormalization()(input, training, update_statistics)`

With the current implementation is very difficult to evaluate models in which we need to use the flag `training=True`without updating the statistics.
"
29479,DLL,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29478,Pix2Pix tutorial BatchNorm issue,"## URL(s) with the issue:
https://www.tensorflow.org/alpha/tutorials/generative/pix2pix

## Description of issue (what needs changing):

The `generate_images` function:

```python
def generate_images(model, test_input, tar):
  # the training=True is intentional here since
  # we want the batch statistics while running the model
  # on the test dataset. If we use training=False, we will get
  # the accumulated statistics learned from the training dataset
  # (which we don't want)
  prediction = model(test_input, training=True)
  plt.figure(figsize=(15,15))

  display_list = [test_input[0], tar[0], prediction[0]]
  title = ['Input Image', 'Ground Truth', 'Predicted Image']

  for i in range(3):
    plt.subplot(1, 3, i+1)
    plt.title(title[i])
    # getting the pixel values between [0, 1] to plot it.
    plt.imshow(display_list[i] * 0.5 + 0.5)
    plt.axis('off')
  plt.show()
```

generate images using the generator model with the flag training=True. The problem is that in this way the batch normalization statistics (moving mean and moving variance) are updated using the test set statistics. 

This is wrong. The original pix2pix paper asserts that they evaluate the model using the flag training=True but they do this in order to normalize using the minibatch (with batch size = 1) statistics. This is done only in the test phase and statistics should not be saved into the model.

I think that a better approach is to visualize the data generated during training (not re-calling the generator but using the data generated in order to calculate the loss). 

Once the training is finished we can evaluate the model.

The problem is that in tf 2.0 is not possible to use the minibatch statistics in the batch normalization layer. Every time we call BatchNorm()(input, training=True) the moving mean and moving variance are updated. I think that this can be managed in a better way by adding a flag that tells the layer whether to use the minibatch statistics. 
"
29477,Different Results on Different Machines,"I am having a problem with the reproducibility of results. When I run the code with the same seed on two different machines I get different results. But on the same machine, it gives me the same results all the time. Are you guys aware of any such issue?"
29476,"There is no docker image with ""devel"" for version 1.13.1 and 1.14 in docker hub","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Docker image for tag '1.13.1-devel-gpu-py3' and for 1.14
- TensorFlow version: 1.13.1 and 1.14
- Python version: 3.6
- Installed using virtualenv? pip? conda?: Docker image unavailability issue
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: 10.0
- GPU model and memory: GTX 1060 NVIDIA 



**Describe the problem**
There is no docker image with ""devel"" for version 1.13.1 and 1.14 in docker hub. I am not able to compile these versions from source and install. There are no tag with names ""1.13.1-devel-gpu-py3"" and ""1.14.0-devel-gpu-py3"".

**Provide the exact sequence of commands / steps that you executed before running into the problem**
The issue is with unavailability of Image with ""devel"" tag for 1.13.1 and 1.14.0.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
NA"
29475,How to run  keras model using tensor flow JNI interface in java,"This is python model which is working good in python:

https://github.com/keras-team/keras/tree/master/examples

lstm_seq2seq.py Trains a basic character-level sequence-to-sequence model.
lstm_seq2seq_restore.py Restores a character-level sequence to sequence model from disk (saved by lstm_seq2seq.py) and uses it to generate predictions.

Do you know if there is way to convert to java?

I used below code to import python model -
 
SavedModelBundle model = SavedModelBundle.load(
                ""DIR"",
                ""serve"");
 
i got below exceptions:
org.tensorflow.TensorFlowException: Could not find SavedModel .pb or .pbtxt at supplied export directory path.
"
29474,Issue with tf.tpu.experimental.initialize_tpu_system in Google Colab,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): NA
- TensorFlow version (use command below): 2.0
- Python version: 3.6
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
```
import os
import pprint

if 'COLAB_TPU_ADDR' not in os.environ:
  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')
else:
  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']
  print ('TPU address is', tpu_address)
  
tf.config.experimental_connect_to_host(tpu_address)

cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)
tf.tpu.experimental.initialize_tpu_system(cluster_resolver)
strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)
```

**Describe the expected behavior**
I get this error on the line - tf.tpu.experimental.initialize_tpu_system(cluster_resolver)

> NotFoundError: No registered 'ConfigureDistributedTPU' OpKernel for TPU_SYSTEM devices compatible with node {{node ConfigureDistributedTPU}}
> 	.  Registered:  <no registered kernels>
> 
> 	 [[{{node ConfigureDistributedTPU}}]]
> Additional GRPC error information:
> {""created"":""@1559792051.046310667"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""No registered 'ConfigureDistributedTPU' OpKernel for TPU_SYSTEM devices compatible with node {{node ConfigureDistributedTPU}}\n\t.  Registered:  <no registered kernels>\n\n\t [[{{node ConfigureDistributedTPU}}]]"",""grpc_status"":5} [Op:__inference__tpu_init_fn_68]

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29472,[TF2.0]tf.lite.converter.convert() error:Cannot find the Placeholder op that is an input to the ReadVariableOp.   watch my second problem,"I test this code for save model in  tf-nightly-2.0-gpu  in ubuntu 19.04,   tf.saved_model.save(model, saved_model_dir)       and get a error:


AttributeError: 'TypeError' object has no attribute 'message'
------------------------
my code like this:

~~~~
# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function, unicode_literals



import tensorflow as tf

import os
import numpy as np
import matplotlib.pyplot as plt

tf.__version__

""""""## Setup Input Pipeline

Download the flowers dataset.
""""""





_URL = ""https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz""

zip_file = tf.keras.utils.get_file(origin=_URL, 
                                   fname=""flower_photos.tgz"", 
                                   extract=True)

base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')

""""""Use `ImageDataGenerator` to rescale the images.

Create the train generator and specify where the train dataset directory, image size, batch size.

Create the validation generator with similar approach as the train generator with the flow_from_directory() method.
""""""

IMAGE_SIZE = 224
BATCH_SIZE = 64

datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255, 
    validation_split=0.2)

train_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE, 
    subset='training')

val_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE, 
    subset='validation')

for image_batch, label_batch in train_generator:
  break
image_batch.shape, label_batch.shape

""""""Save the labels in a file which will be downloaded later.""""""

print (train_generator.class_indices)

labels = '\n'.join(sorted(train_generator.class_indices.keys()))

with open('labels.txt', 'w') as f:
  f.write(labels)


""""""## Create the base model from the pre-trained convnets

Create the base model from the **MobileNet V2** model developed at Google, and pre-trained on the ImageNet dataset, a large dataset of 1.4M images and 1000 classes of web images.

First, pick which intermediate layer of MobileNet V2 will be used for feature extraction. A common practice is to use the output of the very last layer before the flatten operation, the so-called ""bottleneck layer"". The reasoning here is that the following fully-connected layers will be too specialized to the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.

Let's instantiate an MobileNet V2 model pre-loaded with weights trained on ImageNet. By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top, which is ideal for feature extraction.
""""""

IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)

# Create the base model from the pre-trained model MobileNet V2
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                              include_top=False, 
                                              weights='imagenet')

""""""## Feature extraction
You will freeze the convolutional base created from the previous step and use that as a feature extractor, add a classifier on top of it and train the top-level classifier.
""""""

base_model.trainable = False

""""""### Add a classification head""""""

model = tf.keras.Sequential([
  base_model,
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.GlobalAveragePooling2D(),
  tf.keras.layers.Dense(5, activation='softmax')
])

""""""### Compile the model

You must compile the model before training it.  Since there are two classes, use a binary cross-entropy loss.
""""""

model.compile(optimizer=tf.keras.optimizers.Adam(), 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

model.summary()

print('Number of trainable variables = {}'.format(len(model.trainable_variables)))

""""""### Train the model

<!-- TODO(markdaoust): delete steps_per_epoch in TensorFlow r1.14/r2.0 -->
""""""

epochs = 2

history = model.fit(train_generator, 
                    epochs=epochs, 
                    validation_data=val_generator)

""""""### Learning curves

Let's take a look at the learning curves of the training and validation accuracy/loss when using the MobileNet V2 base model as a fixed feature extractor.
""""""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

""""""## Fine tuning
In our feature extraction experiment, you were only training a few layers on top of an MobileNet V2 base model. The weights of the pre-trained network were **not** updated during training.

One way to increase performance even further is to train (or ""fine-tune"") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic features maps to features associated specifically to our dataset.

### Un-freeze the top layers of the model

All you need to do is unfreeze the `base_model` and set the bottom layers be un-trainable. Then, recompile the model (necessary for these changes to take effect), and resume training.
""""""

base_model.trainable = True

# Let's take a look to see how many layers are in the base model
print(""Number of layers in the base model: "", len(base_model.layers))

# Fine tune from this layer onwards
fine_tune_at = 100

# Freeze all the layers before the `fine_tune_at` layer
for layer in base_model.layers[:fine_tune_at]:
  layer.trainable =  False

""""""### Compile the model

Compile the model using a much lower training rate.
""""""

model.compile(loss='categorical_crossentropy',
              optimizer = tf.keras.optimizers.Adam(1e-5),
              metrics=['accuracy'])

model.summary()

print('Number of trainable variables = {}'.format(len(model.trainable_variables)))

""""""### Continue Train the model""""""

history_fine = model.fit(train_generator, 
                         epochs=2,
                         validation_data=val_generator)

""""""## Convert to TFLite

Saved the model using `tf.saved_model.save` and then convert the saved model to a tf lite compatible format.
""""""

#####  error code,save failed ............!!!!!!!!!!!!!!!!!!!!!!!!!1
saved_model_dir = 'save/fine_tuning'
tf.saved_model.save(model, saved_model_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

""""""Download the converted model and labels""""""

# from google.colab import files

# files.download('model.tflite')
# files.download('labels.txt')


acc = history_fine.history['accuracy']
val_acc = history_fine.history['val_accuracy']

loss = history_fine.history['loss']
val_loss = history_fine.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()


~~~~

and  this is  mistake:


~~~~
W0606 11:03:53.153013 140230779684672 saved_model.py:748] Skipping full serialization of Keras layer <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f894c11be80>, because it does not have an input spec defined.
W0606 11:03:53.165678 140230779684672 saved_model.py:748] Skipping full serialization of Keras layer <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f89a64fdba8>, because it does not have an input spec defined.
Traceback (most recent call last):
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py"", line 712, in serialize_all_attributes
    save_model_default_signature)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py"", line 850, in _wrap_layer_functions
    fn.get_concrete_function()
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 681, in get_concrete_function
    self._initialize(args, kwargs, add_initializers_to=initializer_map)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 359, in _initialize
    *args, **kwds))
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1401, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1689, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1582, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 728, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 309, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py"", line 994, in call_and_return_conditional_losses
    return layer_call(inputs, training=training), layer.get_losses_for(inputs)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/normalization.py"", line 651, in call
    outputs = self._fused_batch_norm(inputs, training=training)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/normalization.py"", line 533, in _fused_batch_norm
    self.add_update(mean_update)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1117, in add_update
    updates = [process_update(x) for x in updates]
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1117, in <listcomp>
    updates = [process_update(x) for x in updates]
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1113, in process_update
    reachable = tf_utils.get_reachable_from_inputs(relevant_inputs, [update])
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py"", line 134, in get_reachable_from_inputs
    raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))
TypeError: Expected Operation, Variable, or Tensor, got None

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/mint/ai/tensorflow/flowerlite/flowers_tf_lite.py"", line 204, in <module>
    tf.saved_model.save(model, saved_model_dir)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 812, in save
    checkpoint_graph_view)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_serialization.py"", line 65, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 139, in list_functions
    self._serialization_cache)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 2234, in _list_functions_for_serialization
    fns = (saved_model.serialize_all_attributes(self, serialization_cache)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py"", line 712, in serialize_all_attributes
    save_model_default_signature)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py"", line 818, in _wrap_layer_functions
    original_attrs = _replace_child_layer_functions(layer, serialization_cache)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py"", line 891, in _replace_child_layer_functions
    layer_fns = (serialize_all_attributes(child_layer, serialization_cache)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py"", line 712, in serialize_all_attributes
    save_model_default_signature)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py"", line 818, in _wrap_layer_functions
    original_attrs = _replace_child_layer_functions(layer, serialization_cache)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py"", line 891, in _replace_child_layer_functions
    layer_fns = (serialize_all_attributes(child_layer, serialization_cache)
  File ""/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py"", line 716, in serialize_all_attributes
    'message: {}'.format(layer, e.message))
AttributeError: 'TypeError' object has no attribute 'message'

~~~~

the save code is ok at 2.0alpha0 ,but dismiss some  function like this :tf.lite.TFLiteConverter.from_saved_model


this is my tf2.0 version :


~~~
>>> import tensorflow as tf
>>> print(tf.__version__)
2.0.0-dev20190605

~~~

I think it's bug?is it ?"
29471,can't log my accuracy using tf.estimator,"I can't log during evalution. It seems tf.train.LoggingTensorHook can only log during training. The tf.train.LoggingTensorHook export the prototxt into my terminal when evalutation.
Here's some of my code

```

tf.logging.set_verbosity(tf.logging.INFO)

train_tensors_to_log = {
    ""total_loss"": ""summary/total_loss"",
    ""box_loss"": ""summary/box_loss"",
    ""cls_loss"": ""summary/cls_loss"",
    ""reg_loss"": ""summary/reg_loss""
}
train_logging_hook = tf.train.LoggingTensorHook(tensors=train_tensors_to_log, at_end=True)

eval_tensors_to_log = {
    ""total_loss"": ""summary/total_loss"",
    ""box_loss"": ""summary/box_loss"",
    ""cls_loss"": ""summary/cls_loss"",
    ""reg_loss"": ""summary/reg_loss"",
    ""mAP"": ""eval_summary/mAP""
}
eval_logging_hook = tf.train.LoggingTensorHook(tensors=eval_tensors_to_log, every_n_iter=10)

estimator = tf.estimator.Estimator(model_fn, config=run_config)

train_spec = tf.estimator.TrainSpec(
    input_fn = train_input_fn,
    max_steps = 100000,
    hooks=[train_logging_hook]
)
eval_spec = tf.estimator.EvalSpec(
    input_fn = eval_input_fn,
    steps = 100,
    hooks=[eval_logging_hook],
    throttle_secs=60
)
tf.estimator.train_and_evaluate(
    estimator,
    train_spec,
    eval_spec
)

```

Here's my terminal export:
```

INFO:tensorflow:box_loss = b'\n\x17\n\x10summary/box_loss\x153\x88\xf0?', cls_loss = b'\n\x17\n\x10summary/cls_loss\x15\t;A@', mAP = b'\n\x17\n\x10eval_summary/mAP\x15\x00\x00\x00\x00', reg_loss = b'\n\x17\n\x10summary/reg_loss\x157#,>', total_loss = b'\n\x19\n\x12summary/total_loss\x15\xab \xa2@'
INFO:tensorflow:Evaluation [10/100]
INFO:tensorflow:box_loss = b'\n\x17\n\x10summary/box_loss\x15B\xa5\x08@', cls_loss = b'\n\x17\n\x10summary/cls_loss\x15M\x14r@', mAP = b'\n\x17\n\x10eval_summary/mAP\x15\x00\x00\x00\x00', reg_loss = b'\n\x17\n\x10summary/reg_loss\x157#,>', total_loss = b'\n\x19\n\x12summary/total_loss\x15\xe2\xbd\xc2@' (2.541 sec)
INFO:tensorflow:Evaluation [20/100]
INFO:tensorflow:box_loss = b'\n\x17\n\x10summary/box_loss\x15z \x0c@', cls_loss = b'\n\x17\n\x10summary/cls_loss\x15\x1b;<@', mAP = b'\n\x17\n\x10eval_summary/mAP\x15\x00\x00\x00\x00', reg_loss = b'\n\x17\n\x10summary/reg_loss\x157#,>', total_loss = b'\n\x19\n\x12summary/total_loss\x15\xe4\x8e\xa9@' (1.154 sec)
INFO:tensorflow:Evaluation [30/100]
INFO:tensorflow:box_loss = b'\n\x17\n\x10summary/box_loss\x15\xf4w\x00@', cls_loss = b'\n\x17\n\x10summary/cls_loss\x15\\\xca+@', mAP = b'\n\x17\n\x10eval_summary/mAP\x15\x00\x00\x00\x00', reg_loss = b'\n\x17\n\x10summary/reg_loss\x157#,>', total_loss = b'\n\x19\n\x12summary/total_loss\x15B\x82\x9b@' (1.198 sec)
INFO:tensorflow:Evaluation [40/100]
INFO:tensorflow:box_loss = b'\n\x17\n\x10summary/box_loss\x15\xa2\xcf\x0f@', cls_loss = b'\n\x17\n\x10summary/cls_loss\x15wt{@', mAP = b'\n\x17\n\x10eval_summary/mAP\x15\x00\x00\x00\x00', reg_loss = b'\n\x17\n\x10summary/reg_loss\x157#,>', total_loss = b'\n\x19\n\x12summary/total_loss\x15&\x03\xcb@' (1.140 sec)
INFO:tensorflow:Evaluation [50/100]
INFO:tensorflow:box_loss = b'\n\x17\n\x10summary/box_loss\x15 \x85\x02@', cls_loss = b'\n\x17\n\x10summary/cls_loss\x15s\x9c\x1e@', mAP = b'\n\x17\n\x10eval_summary/mAP\x15\x00\x00\x00\x00', reg_loss = b'\n\x17\n\x10summary/reg_loss\x157#,>', total_loss = b'\n\x19\n\x12summary/total_loss\x15\xe4\xf1\x95@' (1.120 sec)
INFO:tensorflow:Evaluation [60/100]
INFO:tensorflow:box_loss = b'\n\x17\n\x10summary/box_loss\x15\x11\x80\xf7?', cls_loss = b'\n\x17\n\x10summary/cls_loss\x15\xfa3[@', mAP = b'\n\x17\n\x10eval_summary/mAP\x15\x00\x00\x00\x00', reg_loss = b'\n\x17\n\x10summary/reg_loss\x157#,>', total_loss = b'\n\x19\n\x12summary/total_loss\x15\x1b\xdb\xb0@' (1.125 sec)
INFO:tensorflow:Evaluation [70/100]
INFO:tensorflow:box_loss = b'\n\x17\n\x10summary/box_loss\x15\xd9>\xf2?', cls_loss = b'\n\x17\n\x10summary/cls_loss\x15fk\x1e@', mAP = b'\n\x17\n\x10eval_summary/mAP\x15\x00\x00\x00\x00', reg_loss = b'\n\x17\n\x10summary/reg_loss\x157#,>', total_loss = b'\n\x19\n\x12summary/total_loss\x15\x83&\x91@' (1.167 sec)
INFO:tensorflow:Evaluation [80/100]
INFO:tensorflow:box_loss = b'\n\x17\n\x10summary/box_loss\x15\xc4\xe1\xcf?', cls_loss = b'\n\x17\n\x10summary/cls_loss\x15\x00^\x08@', mAP = b'\n\x17\n\x10eval_summary/mAP\x15\x00\x00\x00\x00', reg_loss = b'\n\x17\n\x10summary/reg_loss\x157#,>', total_loss = b'\n\x19\n\x12summary/total_loss\x15\x15\x11{@' (1.152 sec)
INFO:tensorflow:Evaluation [90/100]
INFO:tensorflow:box_loss = b'\n\x17\n\x10summary/box_loss\x15\xb4\x8d\x03@', cls_loss = b'\n\x17\n\x10summary/cls_loss\x15s\x15Y@', mAP = b'\n\x17\n\x10eval_summary/mAP\x15\x00\x00\x00\x00', reg_loss = b'\n\x17\n\x10summary/reg_loss\x157#,>', total_loss = b'\n\x19\n\x12summary/total_loss\x15\xae\xb2\xb3@' (1.158 sec)
INFO:tensorflow:Evaluation [100/100]
INFO:tensorflow:Finished evaluation at 2019-06-06-02:27:09
INFO:tensorflow:Saving dict for global step 3000: global_step = 3000, loss = 5.306427

```
"
29469,Tensorflow Lite model accuracy page not found,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/accuracy/README.md

## Description of issue (what needs changing):

In post_training_quantization page (https://tensorflow.google.cn/lite/performance/post_training_quantization), the link to _TensorFlow Lite model accuracy_ page is invalid, it changes to new address after check (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/accuracy/ilsvrc/README.md), Please fix it

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29468,Tensorflow 2.0 failed to run ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04 LTE
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):gcc (Ubuntu 7.4.0-1ubuntu1~18.04) 7.4.0
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
2019-06-06 02:20:57.389862: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-06 02:20:57.394683: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-06-06 02:20:57.394945: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x3d792a0 executing computations on platform Host. Devices:
2019-06-06 02:20:57.395053: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>
Traceback (most recent call last):
  File ""tfrecord.py"", line 75, in <module>
    main()
  File ""tfrecord.py"", line 70, in main
    download(file1, offset1, length1)
  File ""tfrecord.py"", line 50, in download
    image_masked = tf.boolean_mask(image, image > i_min+2)
  File ""/home/aashishkumar/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py"", line 876, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/home/aashishkumar/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 383, in add
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: Could not find valid device for node.
Node: {{node Add}}
All kernels registered for op Add :
  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='CPU'; T in [DT_STRING]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_UINT8]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_INT16]
  device='CPU'; T in [DT_INT8]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]
 [Op:Add] name: add/
```"
29467,404,TF 2.0 Alpha page 404
29463,AttributeError: 'RefVariable' object has no attribute 'numpy',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: none
- TensorFlow installed from (source or binary): anaconda 3.7 
- TensorFlow version: 1.13.1
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): na
- GCC/Compiler version (if compiling from source): na
- CUDA/cuDNN version: 9.0/7.6.0
- GPU model and memory: 2 NVIDIA GeForceGTX 1080 Ti, 64.0 GB RAM



**Describe the problem**
We are trying to run our own object detection using tensorflow and pretrained models. If you any advice to solve the below issues, pls help.
**Provide the exact sequence of commands / steps that you executed before running into the problem**

This is the command that we are running from the anaconda command line:
`python legacy\train.py --logtostderr --train_dir=training\ --pipeline_config_path=training\ssd_mobilenet_v1_pets.config`

**Any other info / logs**
This is the errors and warnings the command line outputs after running the above command. The main error we are dealing with is AttributeError: 'RefVariable' object has no attribute 'numpy'. 

`WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py:125: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
2019-06-05 16:42:56.976238: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2019-06-05 16:42:57.379496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:17:00.0
totalMemory: 11.00GiB freeMemory: 9.11GiB
2019-06-05 16:42:57.541412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 1 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:65:00.0
totalMemory: 11.00GiB freeMemory: 9.11GiB
2019-06-05 16:42:57.555091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0, 1
2019-06-05 16:43:00.519542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-05 16:43:00.528620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 1
2019-06-05 16:43:00.534150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N N
2019-06-05 16:43:00.540969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N N
2019-06-05 16:43:00.548760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8791 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2019-06-05 16:43:00.566108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8791 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)
WARNING:tensorflow:From C:\Users\nnucs\Documents\Object Detection API\models\research\object_detection\legacy\trainer.py:266: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From C:\Users\nnucs\Documents\Object Detection API\models\research\object_detection\builders\dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
WARNING:tensorflow:From C:\Users\nnucs\Documents\Object Detection API\models\research\object_detection\core\preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
WARNING:tensorflow:From C:\Users\nnucs\Documents\Object Detection API\models\research\object_detection\core\batcher.py:96: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\input.py:784: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:root:Variable [BoxPredictor_0/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[273]], model variable shape: [[6]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_0/ClassPredictor/biases/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[273]], model variable shape: [[6]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_0/ClassPredictor/biases/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[273]], model variable shape: [[6]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_0/ClassPredictor/biases/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[273]], model variable shape: [[6]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_0/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 273]], model variable shape: [[1, 1, 512, 6]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_0/ClassPredictor/weights/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 273]], model variable shape: [[1, 1, 512, 6]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_0/ClassPredictor/weights/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 273]], model variable shape: [[1, 1, 512, 6]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_0/ClassPredictor/weights/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 273]], model variable shape: [[1, 1, 512, 6]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_1/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_1/ClassPredictor/biases/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_1/ClassPredictor/biases/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_1/ClassPredictor/biases/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_1/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 1024, 546]], model variable shape: [[1, 1, 1024, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_1/ClassPredictor/weights/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 1024, 546]], model variable shape: [[1, 1, 1024, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_1/ClassPredictor/weights/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 1024, 546]], model variable shape: [[1, 1, 1024, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_1/ClassPredictor/weights/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 1024, 546]], model variable shape: [[1, 1, 1024, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_2/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_2/ClassPredictor/biases/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_2/ClassPredictor/biases/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_2/ClassPredictor/biases/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_2/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 546]], model variable shape: [[1, 1, 512, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_2/ClassPredictor/weights/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 546]], model variable shape: [[1, 1, 512, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_2/ClassPredictor/weights/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 546]], model variable shape: [[1, 1, 512, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_2/ClassPredictor/weights/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 546]], model variable shape: [[1, 1, 512, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_3/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_3/ClassPredictor/biases/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_3/ClassPredictor/biases/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_3/ClassPredictor/biases/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_3/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_3/ClassPredictor/weights/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_3/ClassPredictor/weights/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_3/ClassPredictor/weights/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_4/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_4/ClassPredictor/biases/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_4/ClassPredictor/biases/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_4/ClassPredictor/biases/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_4/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_4/ClassPredictor/weights/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_4/ClassPredictor/weights/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_4/ClassPredictor/weights/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_5/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_5/ClassPredictor/biases/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_5/ClassPredictor/biases/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_5/ClassPredictor/biases/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_5/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 546]], model variable shape: [[1, 1, 128, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_5/ClassPredictor/weights/ExponentialMovingAverage] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 546]], model variable shape: [[1, 1, 128, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_5/ClassPredictor/weights/RMSProp] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 546]], model variable shape: [[1, 1, 128, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [BoxPredictor_5/ClassPredictor/weights/RMSProp_1] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 546]], model variable shape: [[1, 1, 128, 12]]. This variable will not be initialized from the checkpoint.
WARNING:root:Variable [global_step] is not available in checkpoint
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py:737: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py:737: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2019-06-05 16:43:14.953615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0, 1
2019-06-05 16:43:14.959366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-05 16:43:14.967292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 1
2019-06-05 16:43:14.974644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N N
2019-06-05 16:43:14.980817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N N
2019-06-05 16:43:14.987571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8791 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2019-06-05 16:43:15.003633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8791 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from training\model.ckpt-0
INFO:tensorflow:Restoring parameters from training\model.ckpt-0
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Starting Session.
INFO:tensorflow:Starting Session.
INFO:tensorflow:Error reported to Coordinator: 'RefVariable' object has no attribute 'numpy'
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\coordinator.py"", line 297, in stop_on_exception
    yield
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\coordinator.py"", line 485, in run
    self.start_loop()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\supervisor.py"", line 1067, in start_loop
    self._sess, self._step_counter)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\training_util.py"", line 68, in global_step
    return int(global_step_tensor.numpy())
AttributeError: 'RefVariable' object has no attribute 'numpy'
INFO:tensorflow:Error reported to Coordinator: 'RefVariable' object has no attribute 'numpy'
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\coordinator.py"", line 297, in stop_on_exception
    yield
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\coordinator.py"", line 485, in run
    self.start_loop()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\supervisor.py"", line 1067, in start_loop
    self._sess, self._step_counter)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\training_util.py"", line 68, in global_step
    return int(global_step_tensor.numpy())
AttributeError: 'RefVariable' object has no attribute 'numpy'
INFO:tensorflow:Saving checkpoint to path training\model.ckpt
INFO:tensorflow:Saving checkpoint to path training\model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:Starting Queues.
INFO:tensorflow:Finished training! Saving model to disk.
INFO:tensorflow:Finished training! Saving model to disk.
C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\summary\writer\writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.
  warnings.warn(""Attempting to use a closed FileWriter. ""
Traceback (most recent call last):
  File ""legacy\train.py"", line 184, in <module>
    tf.app.run()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""legacy\train.py"", line 180, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""C:\Users\nnucs\Documents\Object Detection API\models\research\object_detection\legacy\trainer.py"", line 416, in train
    saver=saver)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py"", line 785, in train
    ignore_live_threads=ignore_live_threads)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\supervisor.py"", line 832, in stop
    ignore_live_threads=ignore_live_threads)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\six.py"", line 693, in reraise
    raise value
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\coordinator.py"", line 297, in stop_on_exception
    yield
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\coordinator.py"", line 485, in run
    self.start_loop()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\supervisor.py"", line 1067, in start_loop
    self._sess, self._step_counter)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\training_util.py"", line 68, in global_step
    return int(global_step_tensor.numpy())
AttributeError: 'RefVariable' object has no attribute 'numpy'`
"
29461,Possible race condition when calling custom op with control dependencies,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0
- Python version: 3.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I was trying to study the behavior of tf.control_dependencies when training Resnet50 on distributed CPU, with the benchmark script (https://github.com/tensorflow/benchmarks/tree/cnn_tf_v1.12_compatible/scripts/tf_cnn_benchmarks). 
I have modified this script to load the same dataset on each run, and removed the random params from the model (for predictable repro). 
I have written a dummy custom C++ op where I'm simply printing the input tensor and returning.
I have also modified the benchmark_cnn.py in the above repo to call my custom op, instead of hvd.allreduce. I have also added control dependency between the layers to ensure that my custom op gets called one layer after another. Following are the code changes for this:

```
        pred = None
        for i in range(0, len(grads), 1):
            grad = grads[i]

            import re
            if re.search(""batch.*norm"", params[i].name, re.IGNORECASE) != None:
              grads[i] = grad
            else:
              tensor_name = 'HorovodAllreduce_%s' % hvd_normalize_name(grad.name)
              if pred != None:
                with tf.control_dependencies([pred]):
                  grad = custom_op_cpp(grad, horovod_device, tensor_name, hvd.rank())
              else:
                grad = custom_op_cpp(grad, horovod_device, tensor_name, hvd.rank())

              pred = grad
              grads[i] = grad
```

And custom_op_cpp() function is defined as follows:
```
custom_module = tf.load_op_library('./custom_op_cpp/custom_op.so')

def custom_op_cpp(t_data, dense_device_name, tensor_name, my_rank):
    result = custom_module.dummy_func(t_data, tensor_name, my_rank)
    return result
```

Custom C++ op is defined as:
```
REGISTER_OP(""DummyFunc"")
    .Input(""input: float32"")
    .Input(""tname: string"")
    .Input(""rank: int32"")
    .Output(""output: float32"")
    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
        c->set_output(0, c->input(0));
        return Status::OK();
    });

class DummyFuncOp : public OpKernel {
    explicit DummyFuncOp(OpKernelConstruction* context) : OpKernel(context) {}

    void Compute(OpKernelContext* context) override {
        ....
        const Tensor& input_tensor = context->input(0);
        float *inp_tensor = (float *)(input_tensor.tensor_data().data());
        size_t inp_tensor_size = (size_t)input_tensor.shape().num_elements();
          
        PrintTensorData(inp_tensor, inp_tensor_size);

       //Some code to return copy the input tensor into output and return
    }
}
```

This works as expected, I see the same gradients for each run (1 iteration), since I'm loading the same dataset each time. 
Now, If I reverse the control dependencies from the benchmark script as follows:
`for i in reversed(range(0, len(grads), 1)):`
Then I see that the gradients coming into the dummy op are different for some of the layers, and they are random from run to run. However, if I add a `sleep(4)` in my dummy op's Compute function, then this issue is no longer seen. Hence, I'm suspecting that there may be a race condition, wherein dummy op is getting invoked even before the gradients are properly updated in the backprop phase. 

**Describe the expected behavior**
Whether default or reverse control dependency is used between layers should not have any implications on the gradients seen in dummy c++ op for a given layer, since we are running a predictable model, with same datasets. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29449,RegisterGradient not behaving as expected.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): Docker
- TensorFlow version (use command below): 1.12.0
- Python version: 3.5
- CUDA/cuDNN version: CUDA 9.0
- GPU model and memory: NVIDIA GTX1070 8GB, 32 GB RAM

So I'm trying to modify the tensorflow gradients as it flows through the graph, but I'm getting peculiar results. So as a simple example, if I change the ""Relu"" gradient to my ""Custom"" gradient, which should just pass the gradient through, I get an array of all 1's, rather than expected correct gradient. 

```
import tensorflow as tf
import numpy as np

graph = tf.get_default_graph()
sess = tf.Session(graph=graph)

@tf.RegisterGradient(""Custom"")
def _no_modifications(unused_op, grad):
    return grad

c_input = tf.Variable((np.arange(10).reshape(5, 2) - 5), dtype=tf.float32)

with graph.gradient_override_map({""Relu"": ""Custom""}):
    c_output = tf.nn.relu(c_input)

grad = tf.gradients(c_output, c_input)

sess.run(tf.global_variables_initializer())

input_val, output_val, grad_val = sess.run([c_input, c_output, grad])

input_val
array([[-5., -4.],
       [-3., -2.],
       [-1.,  0.],
       [ 1.,  2.],
       [ 3.,  4.]], dtype=float32)

output_val
array([[0., 0.],
       [0., 0.],
       [0., 0.],
       [1., 2.],
       [3., 4.]], dtype=float32)

grad_val #This is incorrect
[array([[1., 1.],
        [1., 1.],
        [1., 1.],
        [1., 1.],
        [1., 1.]], dtype=float32)]


#The correct gradient should be:
[array([[0., 0.],
        [0., 0.],
        [0., 0.],
        [1., 1.],
        [1., 1.]], dtype=float32)]

```


"
29446,[TF 2.0] CrossShardOptimizer not working with global_step parameter,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Ubuntu 14.04
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): tensorflow==2.0.0.a
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm trying to run CrossShardOptimizer with tf.optimizers.Adam, however, tf.Optimizer.Adam is updated to v2 (with no global_step_parameter), and CrossShardOptimizer is still in version 1 and still have that global_step parameter. So, CrossShardOptimizer is failing Badly.
**Describe the expected behavior**
The CrossShardOptimizer shouldn't break.
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
def model_fn(features, labels, mode, params):
    model = tf.keras.Sequential([
        tf.keras.layers.Flatten(input_shape=[28, 28, 1]),
        tf.keras.layers.Dense(128),
        tf.keras.layers.Dense(10, activation=""softmax"")
    ])
    optimizer = None
    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.optimizers.Adam(params.get(""learing_rate"", 1e-3))
        if params.get(""use_tpu"", True):
          optimizer = tpu_optimizer.CrossShardOptimizer(optimizer)

    with tf.GradientTape() as tape:
        logits = model(features)
        if mode == tf.estimator.ModeKeys.PREDICT:
            preds = {
                ""predictions"": logits
            }
            return tpu_estimator.TPUEstimatorSpec(mode, predictions=preds)
        loss = tf.keras.losses.SparseCategoricalCrossentropy(
            from_logits=True)(labels, logits)
    if mode == tf.estimator.ModeKeys.EVAL:
        return tpu_estimator.TPUEstimatorSpec(mode, loss=loss)

    def train_fn():
        assert optimizer is not None
        gradient = tape.gradient(loss, model.trainable_variables)
        global_step = tf.compat.v1.train.get_global_step()
        update_global_step = tf.compat.v1.assign(global_step, global_step + 1, name='update_global_step')
        with tf.control_dependencies([update_global_step]):
          apply_grads = optimizer.apply_gradients(zip(gradient, model.trainable_variables))
        return apply_grads

    if mode == tf.estimator.ModeKeys.TRAIN:
return tpu_estimator.TPUEstimatorSpec(mode, loss=loss, train_op=train_fn())
```
The complete code can be found at: 
https://github.com/captain-pool/tf2.0-tpu-sample/blob/master/image_retraining_tpu.py
**Other info / logs**
This issue gets fixed when:
https://github.com/tensorflow/tensorflow/blob/eed4d9c4c4f42c1c5338aa0bdca34c6efb956577/tensorflow/python/tpu/tpu_optimizer.py#L173
line is modified to
`self._opt.apply_gradients(summed_grads_and_vars, name=name)`
and updating `global_step` manually.
Like this:
https://github.com/captain-pool/tf2.0-tpu-sample/blob/39d2af5caf1dfbb28d0821b5143a9c534aef6861/image_retraining_tpu.py#L75-L78

**Do you want to contribute?**
Yes."
29445,Feature Columns stock example fails on GPU,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No. this is a stock example, see collab notebook here to reproduce 
https://colab.research.google.com/drive/1O8dCWeYBVjFEax-ZK1XbJE_vfEzB2Ieq
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): '2.0.0-dev20190605'
- Python version: 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Collab

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
model.fit fails in the stock example with the following error:
InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Expected D2 of index to be 2 got 3 at position 1
	 [[node sequential/dense_features_6/age_bucketized_X_thal_indicator/SparseCross (defined at <ipython-input-20-bf1fb22dfeb0>:14) ]]
  (1) Invalid argument:  Expected D2 of index to be 2 got 3 at position 1
	 [[node sequential/dense_features_6/age_bucketized_X_thal_indicator/SparseCross (defined at <ipython-input-20-bf1fb22dfeb0>:14) ]]
	 [[sequential/dense_features_6/age_bucketized_X_thal_indicator/SparseToDense/_56]]
0 successful operations.
0 derived errors ignored. [Op:__inference_keras_scratch_graph_2134]

**Describe the expected behavior**

**Code to reproduce the issue**
https://colab.research.google.com/drive/1O8dCWeYBVjFEax-ZK1XbJE_vfEzB2Ieq


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29444,calling import_graph_def with op_dict dependency,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.13
- Are you willing to contribute it (Yes/No): Yes although I'm far from an expert



**Describe the feature and the current behavior/state.**

I'm using `import_graph_def` to load and deploy a model stored in an `.pb` file. I'm opening an issue because I saw the following message:

> calling import_graph_def (from tensorflow.python.framework.importer) with op_dict is deprecated and will be removed in a future version.
> Instructions for updating:
> Please file an issue at https://github.com/tensorflow/tensorflow/issues if you depend on this feature.

Please let me know if there is an alternative that won't be removed soon.

**Will this change the current api? How?**

Most likely not

**Who will benefit with this feature?**

Users who have such a dependency, including the users of our [CaImAn](https://github.com/flatironinstitute/CaImAn) package. "
29443,TFLite: Slow float global pooling performance,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Raspberry pi, however issue is reproducible on desktop
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): v1.12.1-3185-g1a4a0aee1f 1.13.1
- Python version: 3.6
- CUDA/cuDNN version: -
- GPU model and memory: -

Using tensor flow lite, global av/max pooling is much slower on float than it is for quantised models.  Using tensor flow 2.0 nightly, together with the instructions here:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tutorials/post_training_integer_quant.ipynb

Using the following tf 2.0 code & tflite profiling tool generates the following outputs:

Float
```python
import tensorflow as tf

out_name = 'mobilenet_v2.tflite'
print(tf.version.GIT_VERSION, tf.version.VERSION)

input = tf.keras.layers.Input(shape=(32, 32, 3,))
x = tf.keras.layers.Conv2D(filters=256, kernel_size=(1, 1))(input)
x = tf.keras.layers.Activation('relu')(x)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
model = tf.keras.Model(inputs=[input], outputs=[x])

model.summary()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open(out_name, ""wb"").write(tflite_model)`


============================== Summary by node type ==============================
            [Node type]   [count]   [avg ms]     [avg %]     [cdf %]   [mem KB] [times called]
                    MEAN         1     1.774     91.774%     91.774%     0.000         1
                CONV_2D         1     0.159     8.226%   100.000%     0.000         1

```
Quantized
```python
import tensorflow as tf

out_name = 'mobilenet_v2.tflite'
print(tf.version.GIT_VERSION, tf.version.VERSION)

input = tf.keras.layers.Input(shape=(32, 32, 3,))
x = tf.keras.layers.Conv2D(filters=256, kernel_size=(1, 1))(input)
x = tf.keras.layers.Activation('relu')(x)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
model = tf.keras.Model(inputs=[input], outputs=[x])

model.summary()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

cifar_train, _ = tf.keras.datasets.cifar10.load_data()
images = tf.cast(cifar_train[0], tf.float32) / 255.0
cifar_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)
def representative_data_gen():
  for input_value in cifar_ds.take(100):
    yield [input_value]

converter.representative_dataset = representative_data_gen

tflite_model = converter.convert()
open(out_name, ""wb"").write(tflite_model)

============================== Summary by node type ==============================
            [Node type]   [count]   [avg ms]     [avg %]     [cdf %]   [mem KB] [times called]
                CONV_2D         1     4.625     95.165%     95.165%     0.000         1
                    MEAN         1     0.226     4.650%     99.815%     0.000         1
                QUANTIZE         1     0.009     0.185%   100.000%     0.000         1
              DEQUANTIZE         1     0.000     0.000%   100.000%     0.000         1
```
I had a poke through the source code, I could find the arm neon accelerated pooling code for integers here:
```
tensorflow/lite/kernels/⁨internal/optimized⁩/integer_ops⁩/pooling.h
```
It seems to me that there are no neon optimisations for pooling with float datatype?

"
29442,[2.0a0] different names and initial values of variables with and without tf.function,"**System information**
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0alpha0
- Python version: 3.6.5

**Code to reproduce the issue**
<pre>
# -*- coding: utf-8 -*-
# @Author  : Lin Lan (ryan.linlan@gmail.com)

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf

tf.random.set_seed(123)


class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.dense1 = tf.keras.layers.Dense(100)
        self.dense2 = tf.keras.layers.Dense(100)
        self.dense3 = tf.keras.layers.Dense(100)

    # @tf.function
    def call(self, inputs):
        x = self.dense1(inputs)
        x = self.dense2(x)
        outputs = self.dense3(x)
        return outputs


model = Model()
model(tf.random.normal((1, 10), dtype=tf.float32))
for weight in model.trainable_weights:
    print(weight.name)
</pre>

**Other info / logs**
Without `tf.function`, the output is
<pre>
model/dense/kernel:0
model/dense/bias:0
model/dense_1/kernel:0
model/dense_1/bias:0
model/dense_2/kernel:0
model/dense_2/bias:0
</pre>

With `tf.function`, the output is
<pre>
dense/kernel:0
dense/bias:0
dense_1/kernel:0
dense_1/bias:0
dense_2/kernel:0
dense_2/bias:0
</pre>

Also, the initial values also are different with and without `tf.function`.

I guess the difference is because the code generated by `tf.function` executes in a different graph. But I think most users would expect consistent behaviors between eager and graph modes.

A workaround is to first call `model(inputs)` to initialize weights in eager mode, and then replace the method with `model.call = tf.function(model.call)`.
"
29441,[TF 2.0 API Docs]tf.data.experimental.shuffle_and_repeat,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/shuffle_and_repeat

## Description of issue (what needs changing):

### Clear description

No.
it has warning and it is kinda abstract on when to use the function


### Raises listed and defined
No.
yet while comparing  dataset.shuffle(buffer_size, reshuffle_each_iteration=True).repeat(count).the difference is in the actions performed on the datasets. 


### Usage example
No.
there is need of an example to clearly explain the difference between the two shuffles


"
29439,Unittest and test_session interaction,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.12.1 / 1.13.1 / 1.14.0rc0
- Python version: 3.5 / 3.6 / 3.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.0.130
- GPU model and memory: 7.5.0

Environment capture available at: https://pastebin.com/N26BUeSy

**Describe the current behavior**
Additional ""ghost"" tests are being run but skipped when using unittest with Tensorflow TestCase class. This behavior is present in 1.12.1. When upgrading to 1.13.1 or 1.14.0rc0, the tests are being skipped entirely as the ""ghost"" test is in regards to the test_session method that you have within the tensorflow.python.framework.testutils and unittest believes that the tests are not actually tests.

**Describe the expected behavior**
No ""ghost"" tests should be run at all in 1.12.1 and the tests work in 1.13.1 and 1.14.0rc0.

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
import unittest

print(tf.__version__)

def get_entry_np(t, indices_d1, indices_d2, batch_size):
    result = np.zeros(batch_size)
    for i in range(batch_size):
        result[i] = t[i, indices_d1[i], indices_d2[i]]
    return result
    

def get_entry_tf(t, indices_d1, indices_d2, batch_size):
    indices = tf.stack([tf.range(batch_size), indices_d1, indices_d2], axis=1)
    return tf.gather_nd(t, indices)

## Start of region of interest
# Please enable and disable this region with Tensorflow 1.12.1 and then with 1.13.1 or 1.14.0rc0 and the behaviour will be seen   
try:
    delattr(tf.test.TestCase,'test_session')
except AttributeError:
    pass

class OwnTestCase(tf.test.TestCase):
    pass
## End of region of interest
class TestCaseTest(tf.test.TestCase):
        
    def test_get_entry(self):
        success = True
        for _ in range(10):
            # sample input
            batch_size, d1, d2 = map(int, np.random.randint(low=2, high=100, size=3))
            test_input = np.random.random([batch_size, d1, d2])
            test_indices_d1 = np.random.randint(low=0, high=d1-1, size=[batch_size])
            test_indices_d2 = np.random.randint(low=0, high=d2-1, size=[batch_size])
            # evaluate the numpy version
            test_result = get_entry_np(test_input, test_indices_d1, test_indices_d2, batch_size)
            # evaluate the tensorflow version
            with self.cached_session() as sess:
                tf_input = tf.constant(test_input, dtype=tf.float32)
                tf_indices_d1 = tf.constant(test_indices_d1, dtype=tf.int32)
                tf_indices_d2 = tf.constant(test_indices_d2, dtype=tf.int32)
                tf_result = get_entry_tf(tf_input, tf_indices_d1, tf_indices_d2, batch_size)
                tf_result = sess.run(tf_result)
                # check that outputs are similar
                success = success and np.allclose(test_result, tf_result)
    
        self.assertEqual(success, True)
```"
29438,TimeDistributed wrapper around DepthwiseConv2D broken (AttributeError) in 1.13,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Linux Ubuntu 18.04:
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from pip3:
- TensorFlow version b'v1.13.1-0-g6612da8951' 1.13.1
- Python version:
- CUDA/cuDNN version: 10.0.130 / 7.4.1
- GPU model and memory: NVIDIA K80; 11GB

**Describe the current behavior**
TimeDistributed wrapper around DepthwiseConv2D fails with AttributeError: 'tuple' object has no attribute 'dims'

**Describe the expected behavior**
Wrapper should succesfully apply to layer; previously worked in TF 1.11.0.

**Code to reproduce the issue**
```python
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, TimeDistributed

test_td_input = Input(shape=(None, 1, 128, 8))
TimeDistributed(DepthwiseConv2D(depth_multiplier=1,
                                      kernel_size=(1, 4), strides=(1, 1)))(test_td_input)


**Other info / logs**
Traceback (most recent call last):
  File ""time_distributed_bug.py"", line 12, in <module>
    kernel_size=(1, 4), strides=(1, 1)))(test_td_input))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 538, in __call__
    self._maybe_build(inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 1603, in _maybe_build
    self.build(input_shapes)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/wrappers.py"", line 216, in build
    self.layer.build(tuple(child_input_shape))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py"", line 1811, in build
    if input_shape.dims[channel_axis].value is None:
AttributeError: 'tuple' object has no attribute 'dims'

```"
29437,Nesting Variables in tensorflow,"Hi,
Hope this is simple to answer for experts. Why cant we nest variables in tensorflow. For example, in below snippet, why w1 will not be updated by optimizer?

```
def l():
    x_placeholder=tf.placeholder(shape=(5,4),dtype=tf.float64)
    #x=tf.cast(x,tf.float32)
    w1=tf.Variable(initial_value=tf.random_normal_initializer(dtype=tf.float64)((4,2)))
    w=tf.Variable(w1+w1)
    b=tf.Variable(initial_value=tf.random_normal_initializer(dtype=tf.float64)((2,)))
    logits=tf.matmul(x_placeholder,w)+b
    loss=tf.reduce_sum(logits)
    opt=tf.train.AdamOptimizer(0.02)    
    g_v=opt.compute_gradients(loss,var_list=[w1,w,b])
    optim=opt.apply_gradients(g_v)
    
    return x_placeholder,optim,w1,w,b

x_feed=np.random.randn(5,4)
opt=tf.train.AdamOptimizer(0.02)
x_placeholder,optim,w1,w,b=l()

with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  
  print(""initial values for variables w1 w b"")
  wt1,wt2,wt3=sess.run([w1,w,b],feed_dict={x_placeholder:x_feed}) 
  print(wt1)
  print(wt2)
  print(wt3)
  out=sess.run([optim],feed_dict={x_placeholder:x_feed})
  print(""after optimizer run, variables w1 w b"")
  wt4,wt2,wt3=sess.run([w1,w,b],feed_dict={x_placeholder:x_feed})
  print(wt1)
  print(wt2)
  print(wt3)
  print(np.all(wt1==wt4))
```
"
29436,Error using deepbinner:  ImportError: libcuda.so.1: cannot open shared object file: No such   file or directory   Failed to load the native TensorFlow runtime.,"Hello.
I'm trying to use deepbinner software for demultiplexing native barcodes that separate by patients after MinION sequencing. I've obtained this error. Has anyone got any idea about what's happening? Thank you!

`(Deepbinner) [ugm@et8 Lecturas_30_05_2019]$ deepbinner classify  
--native fast5_pass/ > classifications
Using TensorFlow backend.
Traceback (most recent call last):
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in  
<module>
     from tensorflow.python.pywrap_tensorflow_internal import *
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in  
<module>
     _pywrap_tensorflow_internal = swig_import_helper()
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in  
swig_import_helper
     _mod = imp.load_module('_pywrap_tensorflow_internal', fp,  
pathname, description)
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/imp.py"",  
line 243, in load_module
     return load_dynamic(name, filename, file)
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/imp.py"",  
line 343, in load_dynamic
     return _load(spec)
ImportError: libcuda.so.1: cannot open shared object file: No such  
file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
   File ""/programas/anaconda/3-4.4.0/envs/Deepbinner/bin/deepbinner"",  
line 10, in <module>
     sys.exit(main())
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/deepbinner/deepbinner.py"", line 59, in  
main
     from .classify import classify
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/deepbinner/classify.py"", line 24, in  
<module>
     from keras.models import load_model
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/keras/__init__.py"", line 3, in  
<module>
     from . import utils
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/keras/utils/__init__.py"", line 6, in  
<module>
     from . import conv_utils
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/keras/utils/conv_utils.py"", line 9, in  
<module>
     from .. import backend as K
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/keras/backend/__init__.py"", line 89, in  
<module>
     from .tensorflow_backend import *
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 5, in  
<module>
     import tensorflow as tf
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in  
<module>
     from tensorflow.python import pywrap_tensorflow  # pylint:  
disable=unused-import
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 49, in  
<module>
     from tensorflow.python import pywrap_tensorflow
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in  
<module>
     raise ImportError(msg)
ImportError: Traceback (most recent call last):
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in  
<module>
     from tensorflow.python.pywrap_tensorflow_internal import *
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in  
<module>
     _pywrap_tensorflow_internal = swig_import_helper()
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in  
swig_import_helper
     _mod = imp.load_module('_pywrap_tensorflow_internal', fp,  
pathname, description)
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/imp.py"",  
line 243, in load_module
     return load_dynamic(name, filename, file)
   File  
""/programas/anaconda/3-4.4.0/envs/Deepbinner/lib/python3.6/imp.py"",  
line 343, in load_dynamic
     return _load(spec)
ImportError: libcuda.so.1: cannot open shared object file: No such  
file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.`
"
29434,Python3 Issue with Keras Custom Layer,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary on tx2. (followed this https://devtalk.nvidia.com/default/topic/1038957/jetson-tx2/tensorflow-for-jetson-tx2-/) 
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda-10.0 , cudnn7.3
- GPU model and memory: TX2 (Nvidia jetson)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I am trying to load a model (hdf5) which has a keras custom layer. 
I also see the same error when creating a keras model from scratch. Conv2D however works alright. Note I use python3. Is there a modification needed for custom layer? 

However, the script fails with the following error: 
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py"", line 558, in make_tensor_proto
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py"", line 558, in <listcomp>
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/compat.py"", line 61, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""try.py"", line 82, in <module>
    out = NetVLADLayer( num_clusters=16 )(input_img)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 538, in __call__
    self._maybe_build(inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 1603, in _maybe_build
    self.build(input_shapes)
  File ""try.py"", line 21, in build
    trainable=True )
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 349, in add_weight
    aggregation=aggregation)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py"", line 607, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py"", line 145, in make_variable
    aggregation=aggregation)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py"", line 213, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py"", line 176, in _variable_v1_call
    aggregation=aggregation)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py"", line 155, in <lambda>
    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py"", line 2488, in default_variable_creator
    import_scope=import_scope)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py"", line 217, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 294, in __init__
    constraint=constraint)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py"", line 406, in _init_from_args
    initial_value() if init_from_fn else initial_value,
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py"", line 127, in <lambda>
    shape, dtype=dtype, partition_info=partition_info)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py"", line 266, in __call__
    shape, self.minval, self.maxval, dtype, seed=self.seed)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py"", line 239, in random_uniform
    shape = _ShapeTensor(shape)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py"", line 44, in _ShapeTensor
    return ops.convert_to_tensor(shape, dtype=dtype, name=""shape"")
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1039, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1097, in convert_to_tensor_v2
    as_ref=False)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1175, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py"", line 304, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py"", line 245, in constant
    allow_broadcast=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py"", line 283, in _constant_impl
    allow_broadcast=allow_broadcast))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py"", line 562, in make_tensor_proto
    ""supported type."" % (type(values), values))
TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (1, 1, Dimension(256), 16). Consider casting elements to a supported type.

```


**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
https://gist.github.com/mpkuse/c2daacc3a5b8e07697ea7c595f900413

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29433,Inmediate overfitting when using Eager Execution,"**System information**
- OS Platform and Distribution: Google Colab in GPU mode
- TensorFlow version: 1.13.1
- Python version: Python 3.6.7

I am feeding a 3D Resnet with 3D images from a tfrecord file. Using exactly the same code, I obtain very different results when using Eager Execution. In fact, when I use eager execution, the model has 99% training accuracy since the first epoch, with just 20% validation accuracy. When not using eager execution, the behavior is completely normal, gradually incrementing accuracy with each epoch.

The 3D Resnet model I am using is from this rep: https://github.com/JihongJu/keras-resnet3d

**Code to reproduce the issue**
````
BATCH_SIZE = 8
STEPS_PER_EPOCH = int(n_training_samples / BATCH_SIZE)
VALIDATION_STEPS = int(n_val_samples / BATCH_SIZE)

image_tensor, label_tensor = dataset_parser(training_tfrec, BATCH_SIZE)
model = Resnet3DBuilder.build_resnet_18(
    input_shape=IMG_SHAPE,
    num_outputs=N_CLASSES,
    reg_factor=0.01
)

optimizer = keras.optimizers.Adam(lr=0.0001, decay=1e-6)
model.compile(optimizer=optimizer, 
              loss='categorical_crossentropy', 
              metrics=['acc'])

val_tensor = dataset_parser(validation_tfrec, BATCH_SIZE)

history = model.fit(x=image_tensor, y=label_tensor, 
                    epochs=10, steps_per_epoch=STEPS_PER_EPOCH, 
                    validation_data=val_tensor, validation_steps=VALIDATION_STEPS)

````

I realize this code is probably not enough, but maybe there are some clear reasons why this might be happening, and someone can help.
"
29432,4e0cd04 breaks r1.14 and master,"Kindly ping @aaroey for 4e0cd04.

```
ERROR: /tensorflow_src/tensorflow/core/kernels/BUILD:4164:1: C++ compilation of rule '//tensorflow/core/kernels:fused_batch_norm_op' failed (Exit 1)
tensorflow/core/kernels/fused_batch_norm_op.cc: In member function 'void tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool)':
tensorflow/core/kernels/fused_batch_norm_op.cc:417:44: error: there are no arguments to 'BatchnormSpatialPersistentEnabled' that depend on a template parameter, so a declaration of 'BatchnormSpatialPersistentEnabled' must be available [-fpermissive]
         (BatchnormSpatialPersistentEnabled() &&
                                            ^
tensorflow/core/kernels/fused_batch_norm_op.cc:417:44: note: (if you use '-fpermissive', G++ will accept your code, but allowing the use of an undeclared name is deprecated)
tensorflow/core/kernels/fused_batch_norm_op.cc: In instantiation of 'void tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = Eigen::half; U = float]':
tensorflow/core/kernels/fused_batch_norm_op.cc:780:46:   required from 'void tensorflow::FusedBatchNormOpBase<Device, T, U>::ComputeWithReservedSpace(tensorflow::OpKernelContext*, bool) [with Device = Eigen::GpuDevice; T = Eigen::half; U = float]'
tensorflow/core/kernels/fused_batch_norm_op.cc:1092:1:   required from here
tensorflow/core/kernels/fused_batch_norm_op.cc:417:43: error: 'BatchnormSpatialPersistentEnabled' was not declared in this scope
         (BatchnormSpatialPersistentEnabled() &&
          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~
In file included from ./tensorflow/core/platform/default/logging.h:24:0,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/framework/allocator.h:28,
                 from ./tensorflow/core/framework/tensor.h:22,
                 from ./tensorflow/core/util/tensor_format.h:22,
                 from ./tensorflow/core/kernels/conv_2d.h:23,
                 from tensorflow/core/kernels/fused_batch_norm_op.cc:21:
./tensorflow/core/platform/default/logging.h:112:5: error: invalid use of 'auto'
   (([](int level, const char* fname) {                                      \
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     static const bool vmodule_activated =                                   \
     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         ::tensorflow::internal::LogMessage::VmoduleActivated(fname, level); \
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     return vmodule_activated;                                               \
     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   })(lvl, __FILE__))
   ~~^~~~~~~~~~~~~~~~
./tensorflow/core/platform/macros.h:88:49: note: in definition of macro 'TF_PREDICT_TRUE'
 #define TF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
                                                 ^
./tensorflow/core/platform/default/logging.h:117:20: note: in expansion of macro 'VLOG_IS_ON'
   TF_PREDICT_TRUE(!VLOG_IS_ON(level))                            \
                    ^~~~~~~~~~
tensorflow/core/kernels/fused_batch_norm_op.cc:426:5: note: in expansion of macro 'VLOG'
     VLOG(2) << ""FusedBatchNorm:""
     ^
In file included from /usr/include/c++/6/bits/move.h:57:0,
                 from /usr/include/c++/6/bits/nested_exception.h:40,
                 from /usr/include/c++/6/exception:173,
                 from /usr/include/c++/6/ios:39,
                 from /usr/include/c++/6/istream:38,
                 from /usr/include/c++/6/sstream:38,
                 from /usr/include/c++/6/complex:45,
                 from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:43,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/kernels/conv_2d.h:19,
                 from tensorflow/core/kernels/fused_batch_norm_op.cc:21:
/usr/include/c++/6/type_traits: In instantiation of 'class std::result_of<tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = Eigen::half; U = float]::<lambda()>&()>':
/usr/include/c++/6/functional:1913:9:   required by substitution of 'template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = Eigen::half; U = float]::<lambda()>; <template-parameter-1-2> = void; <template-parameter-1-3> = <missing>]'
tensorflow/core/kernels/fused_batch_norm_op.cc:532:5:   required from 'void tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = Eigen::half; U = float]'
tensorflow/core/kernels/fused_batch_norm_op.cc:780:46:   required from 'void tensorflow::FusedBatchNormOpBase<Device, T, U>::ComputeWithReservedSpace(tensorflow::OpKernelContext*, bool) [with Device = Eigen::GpuDevice; T = Eigen::half; U = float]'
tensorflow/core/kernels/fused_batch_norm_op.cc:1092:1:   required from here
/usr/include/c++/6/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl<false, false, tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = Eigen::half; U = float]::<lambda()>&>::type'
     struct result_of<_Functor(_ArgTypes...)>
            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/include/c++/6/type_traits:2291:12: note: declaration of 'std::__result_of_impl<false, false, tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = Eigen::half; U = float]::<lambda()>&>::type'
     struct __result_of_success : __success_type<_Tp>
            ^~~~~~~~~~~~~~~~~~~
tensorflow/core/kernels/fused_batch_norm_op.cc: In instantiation of 'void tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = Eigen::half; U = float]':
tensorflow/core/kernels/fused_batch_norm_op.cc:780:46:   required from 'void tensorflow::FusedBatchNormOpBase<Device, T, U>::ComputeWithReservedSpace(tensorflow::OpKernelContext*, bool) [with Device = Eigen::GpuDevice; T = Eigen::half; U = float]'
tensorflow/core/kernels/fused_batch_norm_op.cc:1092:1:   required from here
tensorflow/core/kernels/fused_batch_norm_op.cc:532:5: error: conversion from 'tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = Eigen::half; U = float]::<lambda()>' to non-scalar type 'std::function<void()>' requested
     };
     ^
tensorflow/core/kernels/fused_batch_norm_op.cc: In instantiation of 'void tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = float; U = float]':
tensorflow/core/kernels/fused_batch_norm_op.cc:780:46:   required from 'void tensorflow::FusedBatchNormOpBase<Device, T, U>::ComputeWithReservedSpace(tensorflow::OpKernelContext*, bool) [with Device = Eigen::GpuDevice; T = float; U = float]'
tensorflow/core/kernels/fused_batch_norm_op.cc:1092:1:   required from here
tensorflow/core/kernels/fused_batch_norm_op.cc:417:43: error: 'BatchnormSpatialPersistentEnabled' was not declared in this scope
         (BatchnormSpatialPersistentEnabled() &&
          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~
In file included from ./tensorflow/core/platform/default/logging.h:24:0,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/framework/allocator.h:28,
                 from ./tensorflow/core/framework/tensor.h:22,
                 from ./tensorflow/core/util/tensor_format.h:22,
                 from ./tensorflow/core/kernels/conv_2d.h:23,
                 from tensorflow/core/kernels/fused_batch_norm_op.cc:21:
./tensorflow/core/platform/default/logging.h:112:5: error: invalid use of 'auto'
   (([](int level, const char* fname) {                                      \
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     static const bool vmodule_activated =                                   \
     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         ::tensorflow::internal::LogMessage::VmoduleActivated(fname, level); \
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     return vmodule_activated;                                               \
     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   })(lvl, __FILE__))
   ~~^~~~~~~~~~~~~~~~
./tensorflow/core/platform/macros.h:88:49: note: in definition of macro 'TF_PREDICT_TRUE'
 #define TF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
                                                 ^
./tensorflow/core/platform/default/logging.h:117:20: note: in expansion of macro 'VLOG_IS_ON'
   TF_PREDICT_TRUE(!VLOG_IS_ON(level))                            \
                    ^~~~~~~~~~
tensorflow/core/kernels/fused_batch_norm_op.cc:426:5: note: in expansion of macro 'VLOG'
     VLOG(2) << ""FusedBatchNorm:""
     ^
In file included from /usr/include/c++/6/bits/move.h:57:0,
                 from /usr/include/c++/6/bits/nested_exception.h:40,
                 from /usr/include/c++/6/exception:173,
                 from /usr/include/c++/6/ios:39,
                 from /usr/include/c++/6/istream:38,
                 from /usr/include/c++/6/sstream:38,
                 from /usr/include/c++/6/complex:45,
                 from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:43,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/kernels/conv_2d.h:19,
                 from tensorflow/core/kernels/fused_batch_norm_op.cc:21:
/usr/include/c++/6/type_traits: In instantiation of 'class std::result_of<tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = float; U = float]::<lambda()>&()>':
/usr/include/c++/6/functional:1913:9:   required by substitution of 'template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = float; U = float]::<lambda()>; <template-parameter-1-2> = void; <template-parameter-1-3> = <missing>]'
tensorflow/core/kernels/fused_batch_norm_op.cc:532:5:   required from 'void tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = float; U = float]'
tensorflow/core/kernels/fused_batch_norm_op.cc:780:46:   required from 'void tensorflow::FusedBatchNormOpBase<Device, T, U>::ComputeWithReservedSpace(tensorflow::OpKernelContext*, bool) [with Device = Eigen::GpuDevice; T = float; U = float]'
tensorflow/core/kernels/fused_batch_norm_op.cc:1092:1:   required from here
/usr/include/c++/6/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl<false, false, tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = float; U = float]::<lambda()>&>::type'
     struct result_of<_Functor(_ArgTypes...)>
            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/include/c++/6/type_traits:2291:12: note: declaration of 'std::__result_of_impl<false, false, tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = float; U = float]::<lambda()>&>::type'
     struct __result_of_success : __success_type<_Tp>
            ^~~~~~~~~~~~~~~~~~~
tensorflow/core/kernels/fused_batch_norm_op.cc: In instantiation of 'void tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = float; U = float]':
tensorflow/core/kernels/fused_batch_norm_op.cc:780:46:   required from 'void tensorflow::FusedBatchNormOpBase<Device, T, U>::ComputeWithReservedSpace(tensorflow::OpKernelContext*, bool) [with Device = Eigen::GpuDevice; T = float; U = float]'
tensorflow/core/kernels/fused_batch_norm_op.cc:1092:1:   required from here
tensorflow/core/kernels/fused_batch_norm_op.cc:532:5: error: conversion from 'tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = float; U = float]::<lambda()>' to non-scalar type 'std::function<void()>' requested
     };
     ^
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:74:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/kernels/conv_2d.h:19,
                 from tensorflow/core/kernels/fused_batch_norm_op.cc:21:
/usr/include/c++/6/functional: At global scope:
/usr/include/c++/6/functional:2106:7: error: 'std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = Eigen::half; U = float]::<lambda()>; <template-parameter-2-2> = void; <template-parameter-2-3> = void; _Res = const stream_executor::DeviceMemory<float>&; _ArgTypes = {}]', declared using local type 'tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = Eigen::half; U = float]::<lambda()>', is used but never defined [-fpermissive]
       function<_Res(_ArgTypes...)>::
       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/include/c++/6/functional:2106:7: error: 'std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = float; U = float]::<lambda()>; <template-parameter-2-2> = void; <template-parameter-2-3> = void; _Res = const stream_executor::DeviceMemory<float>&; _ArgTypes = {}]', declared using local type 'tensorflow::functor::FusedBatchNorm<Eigen::GpuDevice, T, U>::operator()(tensorflow::OpKernelContext*, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, const tensorflow::Tensor&, U, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::TensorFormat, stream_executor::ScratchAllocator*, stream_executor::ScratchAllocator*, bool) [with T = float; U = float]::<lambda()>', is used but never defined [-fpermissive]
In file included from ./tensorflow/core/kernels/conv_2d.h:23:0,
                 from tensorflow/core/kernels/fused_batch_norm_op.cc:21:
./tensorflow/core/util/tensor_format.h: In function 'int tensorflow::GetTensorSpatialDims(int, tensorflow::TensorFormat)':
./tensorflow/core/util/tensor_format.h:127:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
./tensorflow/core/util/tensor_format.h: In function 'int tensorflow::GetTensorDimsFromSpatialDims(int, tensorflow::TensorFormat)':
./tensorflow/core/util/tensor_format.h:151:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 271.568s, Critical Path: 137.87s
INFO: 13455 processes: 3220 remote cache hit, 212 local, 10023 remote.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
```"
29430,Initializing a tf.Variable with he_normal,"Hi. I am trying to implement [NALU](https://arxiv.org/abs/1808.00508) using TF 2.0. I am on MacBook Air 2015 (CPU) and TensorFlow version is `2.0.0-alpha0`. 

So, I was looking for ways to initialize the `W_hat` parameter using _He Initialization_ in TensorFlow 2.0. 

Things I have tried:
- ```python 
    W_hat = tf.Variable(initial_value=tf.initializers.he_normal(),                        
    trainable=True, 
    name='W_hat', shape=(2,1))
   ```
  👆results in - 
    ```
     
    TypeError                                 Traceback (most recent call last)
    <ipython-input-25-b78fa0d268a9> in <module>
      1 tf.Variable(initial_value=tf.initializers.he_normal(),                        
      2             trainable=True,
      ----> 3             name='W_hat', shape=(2,1))

     /miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in __call__(cls, 
    *args, **kwargs)
    212       return cls._variable_v1_call(*args, **kwargs)
    213     elif cls is Variable:
     --> 214       return cls._variable_v2_call(*args, **kwargs)
    215     else:
    216       return super(VariableMetaclass, cls).__call__(*args, **kwargs)

    TypeError: _variable_v2_call() got an unexpected keyword argument 'shape'
   ```

- The second try was bound to produce the error I think but anyhow I did it just to be sure - 
   ```python
         W_hat = tf.Variable(initial_value=tf.initializers.he_normal(),                        
         trainable=True, 
          name='W_hat')
   ```
   The trace for this one is attached. 
   [trace.txt.zip](https://github.com/tensorflow/tensorflow/files/3256057/trace.txt.zip)

Would be great to see suggestions. "
29429,fit_generator and predict_generator ignores steps_per_epoch parameter when using sequence,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: TITAN

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Hi,

When running fit_generator (and predict_generator) with the steps_per_epoch parameter (and steps in predict) using a custom sequence, the whole dataset is used instead of the number of batches passed in the steps_per_epoch parameter.
According to the documentation:
steps_per_epoch: Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. It should typically be equal to the number of samples of your dataset divided by the batch size. Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.

The code below works as expected in tensorflow 1.12.0 and 2.0.0a0 but not in 1.13.1
 
Seems like the 'convert_to_generator_like' function in file 'engine/training_generator.py' overrides the 'steps_per_epoch' parameter with len(data) without checking if it is not None in case of a sequence:

```
  if data_utils.is_generator_or_sequence(data) or isinstance(
      data, iterator_ops.EagerIterator):
    if isinstance(data, data_utils.Sequence):
      steps_per_epoch = len(data)
    return data, steps_per_epoch

```
Thanks

**Describe the expected behavior**

**Code to reproduce the issue**

```
import numpy as np
from tensorflow import keras
#import keras

INPUT_SIZE = 3
DENSE_OUTPUTS = 2
NUM_OF_SAMPLES = 1000
BATCH_SIZE = 2
NUM_OF_BATCHES = 5


class DummySequence(keras.utils.Sequence):

    def __len__(self):
        return NUM_OF_SAMPLES // BATCH_SIZE

    def __getitem__(self, index):
        data = [np.full(shape=(INPUT_SIZE,), fill_value=(index*BATCH_SIZE + i)) for i in range(BATCH_SIZE)]
        labels = [np.full(shape=(DENSE_OUTPUTS,), fill_value=(index*BATCH_SIZE + i))*INPUT_SIZE for i in range(BATCH_SIZE)]
        return np.stack(data), np.stack(labels)


class CountBatchesCallback(keras.callbacks.Callback):

    def __init__(self):
        super(CountBatchesCallback, self).__init__()

        self.batches = 0

    def on_batch_begin(self, batch, logs=None):
        self.batches += 1


x = keras.layers.Input(shape=(INPUT_SIZE,))
dense_layer = keras.layers.Dense(DENSE_OUTPUTS)
y = dense_layer(x)
model = keras.Model(x, y)

model.compile(optimizer=""sgd"", loss=keras.losses.mean_squared_error)

shapes = [v.shape for v in dense_layer.weights]
dense_layer.set_weights([np.full(shape=shapes[0], fill_value=1.0), np.full(shape=shapes[1], fill_value=0.0)])

seq = DummySequence()

steps = 5
batch_counter_callback = CountBatchesCallback()

print(""running fit with {} steps"".format(steps))
model.fit_generator(
    seq,
    epochs=1,
    steps_per_epoch=steps,
    callbacks=[batch_counter_callback]
)
print(""batches processed: {}"".format(batch_counter_callback.batches))

results = model.predict_generator(seq, steps=steps)
print(""\npredict\nexpected number of results: {}.\nactual number of results: {}.\npredictions:\n{}"".format(
    steps*BATCH_SIZE, len(results), results)
)

```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29428,failed to pip install tensorflow gpu on win10 and Could not install packages due to an EnvironmentError,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):win10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:tf_nightly_gpu_2.0_preview
- Python version:python 3.6.3
- Installed using virtualenv? pip? conda?:pip conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:  cuda_10.0.130_411.31_win10.exe  cudnn-10.0-windows10-x64-v7.5.0.56.zip
- GPU model and memory:GTX 1050



**Describe the problem**
I am trying to install tensorflow gpu on win10,but faild after many times.
I also try to use conda,but failed. It takes me alomost one day to figure it out but failed finnaly,
So upset and come here for help,thank you!
**Provide the exact sequence of commands / steps that you executed before running into the problem**
pip install tf_nightly_gpu_2.0_preview-2.0.0.dev20190604-cp36-cp36m-win_amd64.whl

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
The error occurs when pip install tf-nightly-gpu-2.0-preview
Could not install packages due to an EnvironmentError: [Errno 2] No such file or directory: 'C:\\Users\\XXXX\\AppData\\Local\\Temp\\pip-install-9z06414_\\tf-nightly-gpu-2.0-preview\\tf_nightly_gpu_2.0_preview-2.0.0.dev20190604.data/purelib/tensorflow/include/tensorflow/include/external/eigen_archive/Eigen/src/Core/products/GeneralMatrixMatrixTriangular_BLAS.h'"
29427,[TF 2.0a0] fail to use If within GradientTape which is within tf.range loop.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0alpha0
- Python version: 3.6.5

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
<pre>
# -*- coding: utf-8 -*-
# @Author  : Lin Lan (ryan.linlan@gmail.com)

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import tensorflow as tf


class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.dense1 = tf.keras.layers.Dense(100)
        self.dense2 = tf.keras.layers.Dense(100)
        self.dense3 = tf.keras.layers.Dense(100)

    def call(self, inputs):
        x = self.dense1(inputs)
        x = self.dense2(x)
        outputs = self.dense3(x)
        return outputs


model = Model()
optimizer = tf.keras.optimizers.SGD()


@tf.function
def train(data):
    batch_size = data.shape[0]
    grads = tf.TensorArray(tf.float32, size=batch_size)
    for i in tf.range(batch_size):
        with tf.GradientTape() as tape:
            if True:
                y = model(data[i][tf.newaxis, :])
                loss = tf.reduce_mean(tf.square(y))
        this_grads = tape.gradient(loss, model.trainable_weights)
        this_grads = tf.concat([tf.reshape(g, [-1]) for g in this_grads], axis=0)
        grads = grads.write(i, this_grads)
    return grads.stack()


x = np.random.rand(10, 100).astype(np.float32)
print(train(x))
</pre>
**Other info / logs**
`ValueError: TensorFlow requires that the following symbols must be initialized to a Tensor, Variable or TensorArray before the loop: ('loss',)`.

If we comment `if True`, the code works.
"
29425,failed to pip install tensorflow gpu on win10 and Could not install packages due to an EnvironmentError,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29423,[TF 2.0] Dataset isn't working with TPUStrategy,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colaboratory
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): v1.12.1-3283-geff4ae822a 2.0.0-dev20190604
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When executing a keras model's `fit` method built within a TPUStrategy with eager execution disabled, a series of errors referring to unknown NodeDef attributes occur (the actual unknown attr varies each time). 
Executing the same model (with the same input dataset) not defined within a TPUStrategy's scope works fine.

**Describe the expected behavior**
It should work without a problem.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
import tensorflow as tf
import tensorflow_datasets as tfds

# Disable eager execution, otherwise TPUStrategy won't work at all
tf.compat.v1.disable_eager_execution()

# Load dataset
ds = tfds.load('mnist', split=tfds.Split.TRAIN, as_supervised=True)
ds = ds.map(lambda x,y : (tf.cast(x, tf.float32), y))
ds = ds.shuffle(100).batch(32).prefetch(tf.data.experimental.AUTOTUNE)

# Prepare strategy
import os
TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']
tf.config.experimental_connect_to_host(TPU_ADDRESS)
resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_ADDRESS)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

with strategy.scope():
    net = tf.keras.Sequential([tf.keras.layers.Input([28,28,1]),
                                tf.keras.layers.Flatten(),
                                tf.keras.layers.Dense(10, activation=tf.nn.softmax)])
    net.compile(loss='categorical_crossentropy',
                optimizer=tf.keras.optimizers.SGD(0.01))

# training will raise an exception
net.fit(ds)
```
**Other info / logs**
```python
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1355     try:
-> 1356       return fn(*args)
   1357     except errors.OpError as e:

11 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1338       # Ensure any changes to the graph are reflected in the runtime.
-> 1339       self._extend_graph()
   1340       return self._call_tf_sessionrun(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _extend_graph(self)
   1373     with self._graph._session_run_lock():  # pylint: disable=protected-access
-> 1374       tf_session.ExtendSession(self._session)
   1375 

InvalidArgumentError: NodeDef mentions attr 'parallel_copy' not in Op<name=PaddedBatchDatasetV2; signature=input_dataset:variant, batch_size:int64, padded_shapes:N*int64, padding_values:, drop_remainder:bool -> handle:variant; attr=Toutput_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=N:int,min=1>; NodeDef: {{node PaddedBatchDatasetV2}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-8-fc146f239c6d> in <module>()
----> 1 net.fit(ds)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    641         max_queue_size=max_queue_size,
    642         workers=workers,
--> 643         use_multiprocessing=use_multiprocessing)
    644 
    645   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    622         validation_split=validation_split,
    623         shuffle=shuffle,
--> 624         epochs=epochs)
    625     if not dist_utils.is_distributing_by_cloning(model):
    626       with model._distribution_strategy.scope():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _distribution_standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, validation_split, shuffle, epochs, allow_partial_batch)
   2118         session = None
   2119       else:
-> 2120         session = K.get_session()
   2121 
   2122       first_x_value = nest.flatten(x)[0]

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in get_session(op_input_list)
    462   if not _MANUAL_VAR_INIT:
    463     with session.graph.as_default():
--> 464       _initialize_variables(session)
    465   return session
    466 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in _initialize_variables(session)
    886       v._keras_initialized = True
    887     if uninitialized_vars:
--> 888       session.run(variables_module.variables_initializer(uninitialized_vars))
    889 
    890 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    948     try:
    949       result = self._run(None, fetches, feed_dict, options_ptr,
--> 950                          run_metadata_ptr)
    951       if run_metadata:
    952         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1171     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1172       results = self._do_run(handle, final_targets, final_fetches,
-> 1173                              feed_dict_tensor, options, run_metadata)
   1174     else:
   1175       results = []

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1348     if handle is None:
   1349       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1350                            run_metadata)
   1351     else:
   1352       return self._do_call(_prun_fn, handle, feeds, fetches)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1368           pass
   1369       message = error_interpolation.interpolate(message, self._graph)
-> 1370       raise type(e)(node_def, op, message)
   1371 
   1372   def _extend_graph(self):

InvalidArgumentError: NodeDef mentions attr 'parallel_copy' not in Op<name=PaddedBatchDatasetV2; signature=input_dataset:variant, batch_size:int64, padded_shapes:N*int64, padding_values:, drop_remainder:bool -> handle:variant; attr=Toutput_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=N:int,min=1>; NodeDef: node PaddedBatchDatasetV2 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py:378) . (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).

Errors may have originated from an input operation.
Input Source operations connected to node PaddedBatchDatasetV2:
 ParallelMapDataset (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py:741)
```"
29422,UnicodeDecodeError: 'utf8' codec can't decode byte 0x80 in position 24: invalid start byte when using TensorBoardDebugWrapperSession,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Linux-4.15.0-50-generic-x86_64-with-Ubuntu-16.04-xenial
- TensorFlow installed from: pip
- TensorFlow version: 1.14.1-dev20190424
- Python version: Python 2.7.12
- Bazel version: bazel release 0.24.1
- GCC/Compiler version: gcc version 4.8.5 (Ubuntu 4.8.5-4ubuntu2) & gcc version 4.8.5 (Ubuntu 4.8.5-4ubuntu2)
- CUDA/cuDNN version: CUDA Version: 10.0 /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudart.so.10.0.130


**Describe the current behavior**
I want to use TensorBoardDebugWrapperSession/LocalCLIDebugWrapperSession to check whether my code is right by step by step debugging while inference.

However, when I add TensorBoardDebugWrapperSession/LocalCLIDebugWrapperSession like [tutorial](https://www.tensorflow.org/guide/debugger), it occurs this error:

```
---------------------------------------------------------------------------
UnicodeDecodeError                        Traceback (most recent call last)
<ipython-input-1-ea4f4b4649f9> in <module>()
     20 convert_start = time.time()
     21 # hyps, src_frames, en_frames, scores = pred.Run(['hypotheses', 'src_frames', 'encoder_frames', 'scores'], wav=read_data)
---> 22 hyps, scores = pred.Run(['hypotheses', 'scores'], wav=read_data)
     23 convert_end = time.time()
     24 diff = convert_end - convert_start

/root/.cache/bazel/_bazel_root/17eb95f0bc03547f4f1319e61997e114/execroot/__main__/bazel-out/k8-opt/bin/lingvo/ipython_kernel.runfiles/__main__/lingvo/core/predictor.py in Run(self, fetch_keys, **kwargs)
    224     #     tf.Session.run, fetches, feed_dict=feeds, options=run_options)
    225     return self._RunWithValidSession(
--> 226         tf_debug.TensorBoardDebugWrapperSession.run, fetches, feed_dict=feeds, options=run_options)
    227     # return self._RunWithDebugSession(
    228     #     tf_debug.LocalCLIDebugWrapperSession.run, fetches, feed_dict=feeds, options=run_options)

/root/.cache/bazel/_bazel_root/17eb95f0bc03547f4f1319e61997e114/execroot/__main__/bazel-out/k8-opt/bin/lingvo/ipython_kernel.runfiles/__main__/lingvo/core/retry.pyc in wrapper(*args, **kwargs)
     48       for retries in itertools.count(0):
     49         try:
---> 50           return func(*args, **kwargs)
     51         except retry_value as e:
     52           if retries >= max_retries:

/root/.cache/bazel/_bazel_root/17eb95f0bc03547f4f1319e61997e114/execroot/__main__/bazel-out/k8-opt/bin/lingvo/ipython_kernel.runfiles/__main__/lingvo/core/predictor.py in _RunWithValidSession(self, fn, *args, **kwargs)
    161     try:
    162       # self._sess = tf_debug.TensorBoardDebugWrapperSession(self._sess, ""dm-System-Product-Name:6008"")
--> 163       return fn(self._sess, *args, **kwargs)
    164     except py_utils.transient_tf_errors:
    165       # self._sess is invalid, most likely due to the worker being preempted.

/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/wrappers/grpc_wrapper.pyc in run(self, fetches, feed_dict, options, run_metadata, callable_runner, callable_runner_args, callable_options)
    221       self._sent_graph_version = publish_traceback(
    222           self._grpc_debug_server_urls, self.graph, feed_dict, fetches,
--> 223           self._sent_graph_version)
    224     return super(TensorBoardDebugWrapperSession, self).run(
    225         fetches,

/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/wrappers/grpc_wrapper.pyc in publish_traceback(debug_server_urls, graph, feed_dict, fetches, old_graph_version)
     58   # pylint:enable=g-import-not-at-top
     59   if graph.version > old_graph_version:
---> 60     run_key = common.get_run_key(feed_dict, fetches)
     61     source_remote.send_graph_tracebacks(
     62         debug_server_urls, run_key, traceback.extract_stack(), graph,

/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/common.pyc in get_run_key(feed_dict, fetches)
     85   """"""
     86   return json.dumps(RunKey(get_flattened_names(feed_dict),
---> 87                            get_flattened_names(fetches)))

/usr/lib/python2.7/json/__init__.pyc in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)
    242         cls is None and indent is None and separators is None and
    243         encoding == 'utf-8' and default is None and not sort_keys and not kw):
--> 244         return _default_encoder.encode(obj)
    245     if cls is None:
    246         cls = JSONEncoder

/usr/lib/python2.7/json/encoder.pyc in encode(self, o)
    205         # exceptions aren't as detailed.  The list call should be roughly
    206         # equivalent to the PySequence_Fast that ''.join() would do.
--> 207         chunks = self.iterencode(o, _one_shot=True)
    208         if not isinstance(chunks, (list, tuple)):
    209             chunks = list(chunks)

/usr/lib/python2.7/json/encoder.pyc in iterencode(self, o, _one_shot)
    268                 self.key_separator, self.item_separator, self.sort_keys,
    269                 self.skipkeys, _one_shot)
--> 270         return _iterencode(o, 0)
    271 
    272 def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,

UnicodeDecodeError: 'utf8' codec can't decode byte 0x80 in position 24: invalid start byte
```

**Describe the expected behavior**
I want to be able to see the results of each step of the variable at runtime through TensorBoardDebugWrapperSession.

**Code to reproduce the issue**
I just [modify some codes in lingvo to use tf-debug.](https://github.com/tensorflow/lingvo/issues/94)

**Other info / logs**
I think the problem should be on tensorflow, so I also add the issue here. I hope you can help me. Thank you!"
29419,tf.gather_nd replacement,"Hi,

I am doing a project but their tensorflow, but the hardware does not support tf.gather_nd. I am asking if possible that use tf.gather, tf.slice or tf.strided_slice to rewrite a function of tf.gather_nd?

Thanks,
Peter "
29413,tf.keras throws AlreadyExistsError for LSTM training whereas keras stand-alone throws no error.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.13.1 (keras version 2.2.4)
- Python version: 3.6.5
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: None
- GPU model and memory: None (CPU Training)

**Describe the current behavior**
When using tf.keras models and layers to build a simple LSTM and train on the Penn Treebank Dataset a long list of errors are thrown of the form:

W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE

However, when just importing keras and building the same LSTM, no errors occur. 

**Describe the expected behavior**
It would be expected that both keras's should be operational. I am also not mixing and matching keras and tf.keras layers.

**Code to reproduce the issue**
Attached is a test case that reproduces the problem. It is required that the Penn Treebank Dataset is downloaded/available (Directions in source). Code was modified from:

https://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_lstm.py

Run option 1 to use keras with no errors and use option 2 to run with tf.keras and see all the errors.

**Other info / logs**

2019-06-04 15:27:39.644788: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.647428: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.664264: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.666201: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.671178: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.676772: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.680910: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.685541: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.689694: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.693689: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.702369: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.703234: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.713664: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.725751: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.727035: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.731410: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.734116: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.745524: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.749895: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.750059: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.754578: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.757058: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.764737: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.769848: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.779327: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.779501: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.787285: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2019-06-04 15:27:39.793182: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/
Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
Traceback (most recent call last):
  File ""keras_lstm_issueFile.py"", line 152, in <module>
    validation_steps=len(valid_data)//(batch_size*num_steps))
  File ""/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1426, in fit_generator
    initial_epoch=initial_epoch)
  File ""/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py"", line 191, in model_iteration
    batch_outs = batch_function(*batch_data)
  File ""/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1191, in train_on_batch
    outputs = self._fit_function(ins)  # pylint: disable=not-callable
  File ""/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/keras/backend.py"", line 3076, in __call__
    run_metadata=self.run_metadata)
  File ""/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1439, in __call__
    run_metadata_ptr)
  File ""/home/cyakaboski/python/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.AlreadyExistsError: Resource __per_step_5/training/Adam/gradients/lstm/while/ReadVariableOp/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/N10tensorflow19Tem
poraryVariableOp6TmpVarE
         [[{{node training/Adam/gradients/lstm/while/ReadVariableOp/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var}}]]

[keras_lstm_issueFile.zip](https://github.com/tensorflow/tensorflow/files/3254289/keras_lstm_issueFile.zip)

"
29408,[TF 2.0 API Docs] tf.keras.backend.maximum,"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/backend/maximum

## Description of the issue (what needs changing):

### Clear description

The description is not clear enough.

### Correct links

The links are okay.

### Parameters defined

The parameters are defined.

### Returns defined

The return values are defined.

### Raises listed and defined

Errors are not defined or listed.

### Usage example

There is no usage example.

### Request visuals, if applicable

There are no visuals.

### Submit a pull request?

No.
"
29407,[TF 2.0 API Docs] tf.data.experimental.scan,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/scan

## Description of issue (what needs changing):

### Raises listed and defined
No
It's  hard for a person to tell what is  raising the error 


### Usage example

No. usage example,it might be hard for someone to know under what context to use it 

### Request visuals, if applicable
No


"
29406,[TF 2.0 API Docs] tf.data.experimental.make_saveable_from_iterator,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/make_saveable_from_iterator

## Description of issue (what needs changing):

### Returns defined

The returns section is missing.

### Raises listed and defined

Raises are neither listed nor defined."
29403,tf 2 memory leak of Flatten and BatchNormalization layer,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10 x64
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.0-9492-g2c319fb415 2.0.0-alpha0
- Python version: 3.6.6


**Describe the current behavior**
memory leak when model has Flatten or BN layer.
memory usage keep increasing and never down after gc collection.

**Describe the expected behavior**
models created will be collected by gc, and memory usage go down to initial level

**Code to reproduce the issue**
```python

from time import sleep

import os
import time
import gc
import numpy as np
import tensorflow.keras as k
import tensorflow as tf

if __name__ == '__main__':
	""""""
	the Flatten and BN layer will cause memory leak, and performance problem
	memory usage keep increasing during the iteration, and never down after gc:
		Flatten + BN : mem 1.3GB, time 105s
		Flatten only: mem 1.3GB, time 105s
		BN only: mem 760MB, time 45s
		no Flatten or BN: mem 490M, time 21s
	""""""
	model_file = 'l:/m'
	for i in range(100):
		if os.path.exists(model_file):
			model = k.models.load_model(model_file)
		else:
			model = k.models.Sequential([
				k.layers.Flatten(input_shape=(10,)), # this layer will cause HUGE memory leak and performance problem
				k.layers.Dense(100),
				k.layers.ELU(),
				k.layers.Dense(500),
				k.layers.BatchNormalization(), # this layer will cause memory leak
				k.layers.ELU(),
				k.layers.Dense(2, activation=tf.nn.softmax),
			])
			model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])
			model.fit(np.ndarray((5000, 10), dtype=float), np.array([0, 1] * 2500), epochs=1, verbose=1)
			model.save(model_file)
		
		x = np.ndarray((1, 10), dtype=float)
		x.fill(1)
		print(i, model.predict(x))
	
	os.remove(model_file)
	gc.collect()
	sleep(100000)


```
"
29402,[TF 2.0 API Docs] tf.io.decode_base64,"
## Existing Url with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/decode_base64

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links
The link to the python script where the function is define is inactive
Wrong: python/ops/gen_string_ops.py
Correct (The file is not mentioned in the repo)
### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_columErrors are not defined

### Usage example

No usage example provided
Use case: (The documentation does not define how to use, when to use the symbol)
"
29401,[TF 2.0 API Docs] tf.io.decode_json_example,"**Existing URLs containing the issue:**
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/decode_json_example

### Description of issue (what needs changing):
**Correct Links**
The link to the python script where the function is defined is inactive. 
Wrong: python/ops/gen_parsing_ops.py.
Correct: (The file mentioned here is not in the repo)

**Usage Example**
No usage example is provided.
Use Cases: The documentation does not define when to use and when not to use the symbol.

**Raises Listed and Defined**
Errors are not defined."
29400,https://www.tensorflow.org/versions/api_docs/python/tf link does not exist,"## URL(s) with the issue: 
https://www.tensorflow.org/versions

## Description of issue (what needs changing): 

### Clear Description 

When someone is in [this page](https://www.tensorflow.org/versions) , clicking on the bullet point `r1.13 (stable)` redirects to a `404 not found page`.

### Correct links

The bullet point targets [here](https://www.tensorflow.org/versions/api_docs/python/tf) while it should target [here](https://www.tensorflow.org/api_docs/python/tf). 


### Submit a pull request?

I tried to fix it but I cannot find where this link ref is stated. If someone could point me in the right direction I could fix it, otherwise someone else could do it.
"
29396,[tf2.0] decode numpy array with bytes format stored in tensor,"I can not found any documentation about this. 

I saved some numpy arrays into tfrecord, it stored as bytes (using np.array().to_bytes() method)

When read it back, there were no way to decode that bytes back to numpy.

Anyone knows how to solve it?"
29393,[2.0alpha0 AutoGraph] tf.function does not automatically transform nested class methods,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0alpha0
- Python version: 3.6.5

**Describe the current behavior**
When we define multiple methods for a class and only decorate one of them with `@tf.function`, the nested methods are not automatically transformed and some errors raise.

**Describe the expected behavior**
We only need decorate the outermost method.

**Code to reproduce the issue**
<pre>
# -*- coding: utf-8 -*-
# @Author  : Lin Lan (ryan.linlan@gmail.com)

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf


class Foo(tf.keras.Model):
    def __init__(self):
        super(Foo, self).__init__()
        self.dense = tf.keras.layers.Dense(20)
        self.embeddings = tf.Variable(tf.random.normal((100, 5)), dtype=tf.float32)

    @tf.function
    def call(self, inputs):
        embeddings = tf.nn.embedding_lookup(
            self.embeddings, inputs)
        return self._inner(embeddings)

    # @tf.function
    def _inner(self, embeddings):
        batch = tf.shape(embeddings)[0]
        ta = tf.TensorArray(tf.float32, size=batch)
        for i in tf.range(batch):
            this = self.dense(embeddings[i][tf.newaxis, :])
            ta = ta.write(i, this)
        return ta.stack()


foo = Foo()
res = foo([0, 2, 4, 6, 8])
</pre>

**Other info / logs**
`TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.`

Also decorating the method `_inner` eliminate the error.

"
29392,Error while importing tensorflow,"- OS Platform and Distribution : CentOS Linux release 7.5.1804
- TensorFlow installed from (source or binary): pip
- Python version: 3.7.2
- Installed using virtualenv? pip? conda?: pip


I get the following error when I try to import tensorflow:


Traceback (most recent call last):
  File ""/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/users/pjh/Python-3.7.3/Lib/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/users/pjh/Python-3.7.3/Lib/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/users/pjh/Python-3.7.3/Lib/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/users/pjh/Python-3.7.3/Lib/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/users/pjh/.local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)


Failed to load the native TensorFlow runtime.

-----------------------------------------------

I am not the root user in the server.
I installed python in my directory by downloading 'https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tgz'. Next I downloaded tensorflow by 'python3 -m pip install tensorflow --user' (python3 command is linked to the one installed in my directory). Then I executed 'python3' and tried to import tensorflow.

Thank you so much."
29391,Dropout in GRU/LSTM in Tensorflow 2.0 doesn't reset dropout masks on call,"**System information**

_Tensorflow_
GIT VERSION: `v1.12.1-3283-geff4ae822a`
VERSION: `2.0.0-dev20190604`

Colab environment

**Describe the current behavior**

In RNNs, the dropout masks should be reset after every call. However, in training mode (where the dropouts are activated) GRU and LSTM implementation in tensorflow 2.0 seems to be re-using the same dropout masks, leading to deterministic behavior.

Simple RNN seems to be doing the right thing, re-sampling dropout masks after each call.

**Describe the expected behavior**

The expected behaviour should be the same as SimpleRNN (re-sample dropout masks on each call).

**Code to reproduce the issue**

The following code produces the correct behaviour in tensorflow 1.13.1:

```
from __future__ import absolute_import, division, print_function

import tensorflow as tf
tf.enable_eager_execution()

import numpy as np

tf.enable_eager_execution()
print(tf.__version__)
data = np.random.normal(0, 1, (1, 10, 2)).astype(np.float32)
rnn = tf.keras.layers.GRU(units=10, dropout=0.5, recurrent_dropout=0.5)
print(set([rnn(data, training=True).numpy()[0, 0] for _ in range(5)]))
```

output
```
1.13.1
{0.09432551, -0.07633728, 0.03358479, 0.010588642, 0.0}
```

but in tensorflow 2.0 it doesn't
```
from __future__ import absolute_import, division, print_function

import tensorflow as tf
import numpy as np

print(tf.version.GIT_VERSION, tf.version.VERSION)
data = np.random.normal(0, 1, (1, 10, 2)).astype(np.float32)
rnn = tf.keras.layers.GRU(units=10, dropout=0.5, recurrent_dropout=0.5)
print(set([rnn(data, training=True).numpy()[0, 0] for _ in range(5)]))
```
output
```
v1.12.1-3283-geff4ae822a 2.0.0-dev20190604
{-0.14212656}
```

A quick fix is to call `reset_dropout_mask()` and `reset_recurrent_dropout_mask()` between calls however this looks like a breaking change.

```
def fixed_rnn():
  rnn.cell.reset_dropout_mask()
  rnn.cell.reset_recurrent_dropout_mask()
  return rnn(data, training=True).numpy()[0, 0]

print(set([fixed_rnn() for _ in range(5)]))
```
output
```
{-0.004232532, 1.1669009, -0.009177759, 3.0901778, 4.5860972}
```"
29390,Enable GPU support for Object Detection Sample Android Tflite App ," The [official documentation](https://www.tensorflow.org/lite/performance/gpu#supported_models_and_ops) suggests `mobile_ssd_v2_float_coco.tflite` model for enabling GPU delegate, but after analyzing the Model with [Netron,](https://electronjs.org/apps/netron) ( visualization tool to help identify how the output tensors differ.)
`mobile_ssd_v2_float_coco.tflite`
OUTPUT:
raw_outputs/box_encodings
id: raw_outputs/box_encodings
type: float32[1,2034,4]
raw_outputs/class_predictions
id: raw_outputs/class_predictions
type: float32[1,2034,91]

Whereas the default model `detect.tflite` used in the demo has 4 different parameters.
OUTPUT: 
TFLite_Detection_PostProcess
id: TFLite_Detection_PostProcess
type: float32
TFLite_Detection_PostProcess:1
id: TFLite_Detection_PostProcess:1
type: float32
TFLite_Detection_PostProcess:2
id: TFLite_Detection_PostProcess:2
type: float32
TFLite_Detection_PostProcess:3
id: TFLite_Detection_PostProcess:3
type: float32
ie for **Location, Classes, Scores, Number and detections**

**How can we use `mobile_ssd_v2_float_coco.tflite`or any model to get enable GPU with Object Detection, Please suggest?** "
29386,[TF 2.0 API Docs] tf.image.convert_image_dtype,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/image/convert_image_dtype
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not listed.

### Usage example

Usage example is not provided

### Submit a pull request?

Yes
https://github.com/tensorflow/tensorflow/pull/29387"
29385,Is there any way to get the size of the TFRecordDataset?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): tensorflow-2.0.0-alpha0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
I get some tfrecord files from someone. when I try to train the network with tf.keras.Model.fit(), it needs to pass a parameter ""steps_per_train"", but I don't know the size and how many data was saved in the tfrecord files. I have read the document of tensorflow2.0 but I find nothing help, so is there any way to get the size of the TFRecordDataset? Thank u

**Will this change the current api? How?**
No, it won't change the current api. It may add an attribute with a ""get"" function.

**Who will benefit with this feature?**
Every who need to know the size of tfrecord dataset

**Any Other info.**
"
29384,Missing documentation for executing TF 1.0 frozen and saved models,"
## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf

## Description of issue (what needs changing):

I cannot find a documentation how to do the native inference with a frozen or saved model in TF 2.0.

### Clear description

We would like to do inferences/predictions with existing models we trained in Tensorflow 1. Therefore, we have normal frozen and saved models. However, we cannot find a documentation how we can load these models and execute them afterwards. 
We managed to load the [Graph objects](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Graph) but the Graph objects do not allow us to do predictions.

In the TFJS project the API is clear to us but in TF 2.0 we struggle a lot.  

### Correct links
### Parameters defined
### Returns defined
### Raises listed and defined
### Usage example

Is there a usage example?

```
import os
import tensorflow as tf

# Load the Tensorflow model into memory.
detection_graph = tf.compat.v1.Graph()
with detection_graph.as_default():
    od_graph_def = tf.compat.v1.GraphDef()
    with tf.io.gfile.GFile(PATH_TO_FROZEN_MODEL, 'rb') as fid:
        serialized_graph = fid.read()
        od_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(od_graph_def, name='')
```

### Request visuals, if applicable
### Submit a pull request?

many thanks,
Sebastian
"
29383,skip_mismatch not supported in load_weights for Keras model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.3

**Describe the current behavior**
I have noticed that mixing-and-matching keras and tensorflow.keras imports can cause some issues. I am therefore in the process of changing all keras imports in my projects to tensorflow.keras imports.
I have now stumbled on the following problem: The function `load_weights` for a keras model does support the argument `skip_mismatch` in keras, but not in tensorflow.keras. Is this feature in the making?

**Describe the expected behavior**
The tensorflow.keras function `load_weights` to have the same syntax as Keras's.

**Code to reproduce the issue**
```python
# Behavior depends on the import
# from tensorflow.keras import *
# from keras import *

model = models.Sequential()
model.load_weights(None, by_name=True, skip_mismatch=True)
```
Note that this code fails in any case, however, only with the tf.keras import this is because of invalid parameters."
29381,Unable to build tensorflow from source,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution :Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.13.1, 1.14
- Python version: Py3.5 & 3.6
- Installed using virtualenv? pip? conda?: trying to build from source inside docker container.
- Bazel version (if compiling from source): 0.24.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
- CUDA/cuDNN version: 10
- GPU model and memory: GTX 1060 NVIDIA, Tesla T4

**Describe the problem**
a) I downloaded the docker image from https://hub.docker.com/r/tensorflow/tensorflow/ with tags ""devel-gpu-py3"" and ""nightly-gpu-py3"". 
b) Inside the docker container i ran ./configure and selected the default paths. Python 3.6, TensorRT, CUDA and CUDNN were all detected.
c) Gave the bazel command below:
-------------------------------------------------------------
root@bad5744dae2b:/tensorflow# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
d) i get build failure logs as below.
Starting local Bazel server and connecting to it...
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
DEBUG: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5: 
Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 34, in <module>
    from future.builtins import bytes
ModuleNotFoundError: No module named 'future'
ERROR: /tensorflow/tensorflow/core/BUILD:2750:1: no such package '@local_config_git//': Traceback (most recent call last):
	File ""/tensorflow/third_party/git/git_configure.bzl"", line 61
		_fail(result.stderr)
	File ""/tensorflow/third_party/git/git_configure.bzl"", line 14, in _fail
		fail((""%sGit Configuration Error:%s %...)))
Git Configuration Error: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 34, in <module>
    from future.builtins import bytes
ModuleNotFoundError: No module named 'future' and referenced by '//tensorflow/core:version_info_gen'
ERROR: /tensorflow/tensorflow/core/BUILD:2750:1: no such package '@local_config_git//': Traceback (most recent call last):
	File ""/tensorflow/third_party/git/git_configure.bzl"", line 61
		_fail(result.stderr)
	File ""/tensorflow/third_party/git/git_configure.bzl"", line 14, in _fail
		fail((""%sGit Configuration Error:%s %...)))
Git Configuration Error: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 34, in <module>
    from future.builtins import bytes
ModuleNotFoundError: No module named 'future'

 and referenced by '//tensorflow/core:version_info_gen'
ERROR: /tensorflow/tensorflow/core/BUILD:2750:1: no such package '@local_config_git//': Traceback (most recent call last):
	File ""/tensorflow/third_party/git/git_configure.bzl"", line 61
		_fail(result.stderr)
	File ""/tensorflow/third_party/git/git_configure.bzl"", line 14, in _fail
		fail((""%sGit Configuration Error:%s %...)))
Git Configuration Error: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 34, in <module>
    from future.builtins import bytes
ModuleNotFoundError: No module named 'future'

 and referenced by '//tensorflow/core:version_info_gen'
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@local_config_git//': Traceback (most recent call last):
	File ""/tensorflow/third_party/git/git_configure.bzl"", line 61
		_fail(result.stderr)
	File ""/tensorflow/third_party/git/git_configure.bzl"", line 14, in _fail
		fail((""%sGit Configuration Error:%s %...)))
Git Configuration Error: Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 34, in <module>
    from future.builtins import bytes
ModuleNotFoundError: No module named 'future'

INFO: Elapsed time: 22.198s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (355 packages loaded, 7796 targets configured)
    currently loading: tensorflow/lite/schema


**Any other info / logs**
NA"
29380,Tensorflow.image.resize_images not upgraded,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.0.0a0
- Python version: 3.7.3

**Describe the current behavior**
The function `tensorflow.image.resize_images()` is not upgraded with the tf_upgrade_v2 script. It is not replaced with any working function in tf2.

**Describe the expected behavior**
The function to be converted to `tf.image.resize()`?

**Code to reproduce the issue**
Upgrade the following code with tf_upgrade_v2 and run it in tensorflow 2.0
```python
import tensorflow

tensorflow.image.resize_images()
```"
29378,get sequence length when use tf.dataset,"@ry @jmhodges @eggie5 @bmabey @djones 
I want to get sequence length, when use tf.dataset, but when I got next batch, the length still [?, ?],
I want to know the second element, but as I saw, tf.dataset don't support, Is I wrong or tf.dataset still not support this? Could anyone tell me the reason."
29377,AttributeError: module 'tensorflow.python.keras' has no attribute 'Model' #21927,"The same issue was closed #21927. May not get attention due to that.

**System information**
- Have I written custom code No
- OS Platform and Distribution: Ubuntu 16.04.3 LTS
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.40
- Python version: 3.6

**Describe the current behavior**
```bash
Traceback (most recent call last):
  File ""model_keras.py"", line 21, in <module>
    class sequentialLSTM(tf.keras.Model):
AttributeError: module 'tensorflow.python.keras' has no attribute 'Model'
```
"
29375,My GCP instance runs around 3 times slower than Gcolab with same configs,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.6 LTS
- TensorFlow version (use command below): b'v1.13.1-0-g6612da8951' 1.13.1
- Python version: 3.6.8
- CUDA/cuDNN version: CUDA 10.0/cuDNN 7.6
- GPU model and memory: T4 GPU with 15079MB memory

**Describe the current behavior**
I have an `GCP instance` with T4 GPU with same `tensorflow` `keras` `CUDA` version as `Gcolab`. However, for the same piece of code, my GCP instance is more than 3 times slower than `Gcolab`. Can anyone please give any clue that what should I do to improve the performance of my GCP instance. Thanks!
#### Log on my GCP instance
```
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-06-03 14:37:25.721579: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-06-03 14:37:25.983647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-03 14:37:25.986134: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x43fea10 executing computations on platform CUDA. Devices:
2019-06-03 14:37:25.986176: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2019-06-03 14:37:26.015456: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000160000 Hz
2019-06-03 14:37:26.016362: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4468690 executing computations on platform Host. Devices:
2019-06-03 14:37:26.016393: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-03 14:37:26.016745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
totalMemory: 14.73GiB freeMemory: 14.52GiB
2019-06-03 14:37:26.016772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-06-03 14:37:26.018593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-03 14:37:26.018618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-06-03 14:37:26.018625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-06-03 14:37:26.018699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14127 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
Epoch 1/5
2019-06-03 14:37:28.721949: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
600000/600000 [==============================] - 5s 8us/sample - loss: 10.2455 - acc: 0.3423
Epoch 2/5
600000/600000 [==============================] - 4s 6us/sample - loss: 7.3609 - acc: 0.5225
Epoch 3/5
600000/600000 [==============================] - 4s 7us/sample - loss: 5.8075 - acc: 0.6186
Epoch 4/5
600000/600000 [==============================] - 4s 7us/sample - loss: 5.4575 - acc: 0.6382
Epoch 5/5
600000/600000 [==============================] - 5s 8us/sample - loss: 5.3016 - acc: 0.6465
```
#### Log on Gcolab
```
Epoch 1/5
600000/600000 [==============================] - 2s 3us/sample - loss: 10.2666 - acc: 0.3293
Epoch 2/5
600000/600000 [==============================] - 2s 3us/sample - loss: 7.5881 - acc: 0.4941
Epoch 3/5
600000/600000 [==============================] - 2s 3us/sample - loss: 7.2098 - acc: 0.5236
Epoch 4/5
600000/600000 [==============================] - 2s 3us/sample - loss: 6.8803 - acc: 0.5298
Epoch 5/5
600000/600000 [==============================] - 2s 3us/sample - loss: 6.1390 - acc: 0.5506
<tensorflow.python.keras.callbacks.History at 0x7f708c110a20>
```
**Describe the expected behavior**
The performance on my GCP instance should be the same with Gcolab since everything is the same

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import tensorflow as tf
import tensorflow.keras as keras
import numpy as np

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

train_images = train_images.repeat(10, axis=0)
train_labels = train_labels.repeat(10, axis=0)

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=5, batch_size=60000)
```
**Other info / logs**
#### My GCP instance info
![Screen Shot 2019-06-03 at 2 53 17 PM](https://user-images.githubusercontent.com/41984177/58838297-23861080-8613-11e9-827c-70eb8fa1923a.png)
![Screen Shot 2019-06-03 at 2 58 08 PM](https://user-images.githubusercontent.com/41984177/58838309-2aad1e80-8613-11e9-9617-c1fdcae7bdb7.png)
![Screen Shot 2019-06-03 at 3 00 14 PM](https://user-images.githubusercontent.com/41984177/58838319-33055980-8613-11e9-813a-784cabffe8a1.png)
![Screen Shot 2019-06-03 at 2 58 28 PM](https://user-images.githubusercontent.com/41984177/58838327-3b5d9480-8613-11e9-9a69-7ce7cdd3819a.png)

#### Gcolab info
![Screen Shot 2019-06-04 at 9 54 30 AM](https://user-images.githubusercontent.com/41984177/58898181-d9526d00-86ae-11e9-9a1b-da6ab5de79ea.png)





"
29374,Batched matrix multiplication is incorrect for large batches,"This bug seems to exist in all versions of TensorFlow from (at least) `1.13` to the current `2.0` nightly under multiple configurations (host os, gpu, python versions...) with CUDA 10.0.

It can be reproduced fairly easily:

```python
with tf.device('gpu:0'):
  v = tf.ones((2**17, 1, 1), dtype=tf.float32)
  print(tf.reduce_sum(tf.matmul(v, v)))
```

This prints `65535.0` instead of `131072.0` (stemming from the output values at indices `>= 2**16` being `0`)

Colab: https://colab.research.google.com/drive/1CZiKKWkI96SAVRJ5kMkT5kmMunipJhdx

Some observations:

- This occurs for batch dimensions greater than or equal to 2<sup>16</sup>.
- This only occurs on the GPU. The CPU version seems fine.
- This only occurs for FP32. FP64 seems fine.
- In TensorFlow 2.0, the bug only manifests on the first run (as shown in the colab example). Subsequent runs produce the correct result.
"
29371,ValueError: Output tensors to a Model must be the output of a TensorFlow `Layer`,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): `pip3 install tensorflow`
- TensorFlow version: 1.13.1
- Python version: 3.7
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

I am currently building a few custom Keras layers. However, when I try to return a tf.keras.Model with outputs that is the output of the last layer, I get the error:
`ValueError: Output tensors to a Model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: Tensor(""layer_normalization_1/batchnorm/add_1:0"", shape=(?, ?, 10), dtype=float32)`.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
import tensorflow as tf
inps = tf.keras.Input(shape=(None, 256), name=""inps"")
mask = tf.keras.Input(shape=(1, 1, None), name=""mask"")
m1 = tf.random.uniform(shape=(8, 20))
m2 = tf.random.uniform(shape=(8, 20))
outputs = tf.keras.layers.Dense(units=512)(m1 + m2)
model = tf.keras.Model(inputs=[inps, mask], outputs=outputs, name=""test"")
```
-- These are toy commands that are similar to my actual code. I was confused as to why the 
outputted values from a Dense layer aren't considered outputs from a Tensorflow Layer.

"
29367,[TF2.0] Lazy Tensors,"Hello everyone,

The TF2.0 is great and brings a lot of benefits: ""functions not sessions"", modules and cetera. Although, there are downsides as well. E.g. I found that tensorflow probability framework (TFP) is very coupled with and centric on TF1.0. I do believe that many other projects have the same level of dependency on TF1.0.

Particularly, the problem is in the core feature of TF2.0 - _eager execution_. Operations and tensors are executed at routine invoke time, e.g. `tf.convert_to_tensor(...)` returns a result not a reference to the graph tensor. There are no links between TensorFlow tensors anymore. Let's dive into an example to understand why this causes issues.

In https://github.com/tensorflow/probability/issues/333, I created a distribution and passed tensorflow variables as arguments. In turn, the distribution's init method does the arguments' checking (shape and types) and tries to convert the arguments to a nice form, e.g. passing them to the linear operator class, which can also have another bunch of testing procedures and this can go on and on. Implications of these modifications are not straightforward and not obvious at first glance! Now, we take a look at `tf.Module` abstraction. It is a nice way to organize and build complex models (not only models, but any structure which keeps all relevant things together) by using plain objects like **variables** and other **submodules**. The distribution can be a module or a model can subclass from module class and keep a distribution as a property. Here is a code snippet:

```python
# Model definition
class Model(tf.Module):
    def __init__(self, mean: tf.Tensor, covariance: tf.Tensor):
        self.mean = mean
        self.covariance = covariance
        self.covariance_diag = tf.linalg.LinearOperatorDiag(covariance)  # Operator calls tf.convert_to_tensor and takes diag of the input
        self.distribution = tfd.MultivariateNormalTriL(mean, covariance)  # Uses tf.convert_to_tensor inside and 
    def loss(self):
         # !!!
         # Use **only** distribution sample and linear diag operator to get the loss
         # !!!

# Model creation
M = tf.random.uniform((3,))
L = tf.linalg.band_part(tf.random.uniform((3, 3)), -1, 0)
mean_var = tf.Variable(mean)
cov_var = tf.Variable(tf.matmul(L, L, transpose_b=True))


# Find gradients
model = Model(mean, cov_var)
with tf.GradientTape() as tape:
    loss = model.loss()

grads = tape.gradient(loss, model.trainable_variables)
```

In the code above, everything single computation outside of the gradient tape will not be recorded by new TF2.0 design: it is all operations inside init `Model` method including variables, as they connected with loss via linear operator and distribution objects.

Let's repeat the apparent - _any computation outside of the tape will never be included in the tape recording_ - **that is very strong constraint for developing new models and frameworks in TF2.0**

One solution would be to create a **lazy tensors** which could postpone the execution until we actually invoke a function which is involved in computation with lazy tensors. In that scenario the tensorflow tape could track back the path though the parts created outside of the context.


https://github.com/tensorflow/probability/issues/47
https://github.com/tensorflow/probability/issues/333
https://github.com/tensorflow/probability/issues/348"
29365,training consumes a lot of RAM and gets killed,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 18.04.2 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): n/a
- TensorFlow version (use command below): 1.14.0-rc0
- Python version: 3.5.2
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: CUDA 10.2 
- GPU model and memory: NVIDIA GeForce GTX 1080/PCIe/SSE2


**Describe the current behavior**
I am trying to run the faster rcnn inception v2 model in a docker container.
i follow the instructions from https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#6-run-the-training
and in the past i was able to run training on their dataset (not inside a docker container).
now, when i try to run training, i get a ""killed"" message after ""Recording summary at step 0"".
the proccess is very demanding in terms of memory and reaches over 19 GB just before it stops.
i use nvidia/cuda:10.0-devel-ubuntu16.04 as a container.


**Code to reproduce the issue**
from models-master/research/object_detection:

python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config

**Other info / logs**

2019-06-03 13:02:38.264499: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-03 13:02:38.300525: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-03 13:02:38.320500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-03 13:02:38.326786: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-03 13:02:38.372259: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-03 13:02:38.401320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-03 13:02:38.401629: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64
2019-06-03 13:02:38.401677: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...
2019-06-03 13:02:38.401725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-03 13:02:38.401758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-06-03 13:02:38.401787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-06-03 13:02:40.182868: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
W0603 13:02:41.522990 140514728642304 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
I0603 13:02:41.525922 140514728642304 saver.py:1280] Restoring parameters from /home/models-master/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt
I0603 13:02:42.337087 140514728642304 session_manager.py:500] Running local_init_op.
I0603 13:02:42.828116 140514728642304 session_manager.py:502] Done running local_init_op.
I0603 13:02:51.479744 140514728642304 learning.py:754] Starting Session.
I0603 13:02:51.717492 140509938947840 supervisor.py:1117] Saving checkpoint to path training/model.ckpt
I0603 13:02:51.721246 140514728642304 learning.py:768] Starting Queues.
I0603 13:03:00.753286 140509720868608 supervisor.py:1099] global_step/sec: 0
I0603 13:03:09.625022 140509712475904 supervisor.py:1050] Recording summary at step 0.
Killed



the config file:

model {
  faster_rcnn {
    num_classes: 6
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_inception_v2'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0002
          schedule {
            step: 900000
            learning_rate: .00002
          }
          schedule {
            step: 1200000
            learning_rate: .000002
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""/home/models-master/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt""
  from_detection_checkpoint: true
  num_steps: 200000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}


train_input_reader: {
  tf_record_input_reader {
    input_path: ""/home/models-master/research/object_detection/train.record""
  }
  label_map_path: ""/home/models-master/research/object_detection/training/labelmap.pbtxt""
  queue_capacity: 10
  min_after_dequeue: 5
}

eval_config: {
  num_examples: 67
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""/home/models-master/research/object_detection/test.record""
  }
  label_map_path: ""/home/models-master/research/object_detection/training/labelmap.pbtxt""
  shuffle: false
  num_readers: 1
}


"
29362,"About can't use GPU to run programs, but I have GPU and CUDA environment","&emsp;&emsp;I have 4 GTX1080 graphics card. but I can't using tensorflow-gpu to run my code。
&emsp;&emsp;CUDA？ yes
&emsp;&emsp;Here are my CUDA information, my source code, error alerts, graphics card information
&emsp;&emsp;thanks for your help

## some information

OS Platform and Distribution: Ubuntu 14.04.5 LTS
TensorFlow installed from: pip install
TensorFlow version: 1.2.0
CUDA/cuDNN version: 8.0.61

## This is my ""nvcc -V"" tips

```bash
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2013 NVIDIA Corporation
Built on Wed_Jul_17_18:36:13_PDT_2013
Cuda compilation tools, release 5.5, V5.5.0
```

## This is my source code.

```python
import tensorflow as tf
with tf.device('/device:GPU:0'):
        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
        c = tf.matmul(a, b)
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# 运行这个 op.
print (sess.run(c))
sess.close()
```

## That is my error tip

```
2019-06-03 22:10:41.340072: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations. 2019-06-03 22:10:41.340118: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations. 2019-06-03 22:10:41.340136: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2019-06-03 22:10:41.340151: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2019-06-03 22:10:41.340167: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Device mapping: no known devices.
2019-06-03 22:10:41.350495: I tensorflow/core/common_runtime/direct_session.cc:265] Device mapping:

Traceback (most recent call last):
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1139, in _do_call
    return fn(*args)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1117, in _run_fn
    self._extend_graph()
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1166, in _extend_graph
    self._session, graph_def.SerializeToString(), status)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/contextlib.py"", line 89, in __exit__
    next(self.gen)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.
         [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/device:GPU:0""](a, b)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""cpuOrGpu.py"", line 11, in <module>
    print (sess.run(c))
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 789, in run
    run_metadata_ptr)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 997, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1132, in _do_run
    target_list, options, run_metadata)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.
         [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/device:GPU:0""](a, b)]]

Caused by op 'MatMul', defined at:
  File ""cpuOrGpu.py"", line 7, in <module>
    c = tf.matmul(a, b)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py"", line 1816, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1217, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/leon/.conda/envs/leon/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.
         [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/device:GPU:0""](a, b)]]
```

## This is my NVIDIA graphics card tips

```bash
Mon Jun  3 22:18:34 2019
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.130                Driver Version: 384.130                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1080    Off  | 00000000:02:00.0  On |                  N/A |
|  0%   49C    P8    15W / 260W |      2MiB /  8105MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 1080    Off  | 00000000:03:00.0 Off |                  N/A |
|  0%   45C    P8    17W / 260W |      0MiB /  8114MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 1080    Off  | 00000000:81:00.0 Off |                  N/A |
|  0%   45C    P8    12W / 260W |      0MiB /  8114MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 1080    Off  | 00000000:82:00.0 Off |                  N/A |
|  0%   43C    P8    13W / 260W |      0MiB /  8114MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```
"
29361,CuDNN LSTM fails with XLA on 2080 Ti and CUDA 10.1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): From Official Tensorflow GPU-powered Docker
- TensorFlow version (use command below): 1.13.1
- Python version: 3.5.2, 2.7
- CUDA/cuDNN version: 10.1
- GPU model and memory: NVIDIA GeForce 2080 Ti and NVIDIA Tesla T4

**Describe the current behavior**
When running with XLA on, the code given below fails with the following exception:

```
2019-06-03 14:05:14.646045: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2019-06-03 14:05:14.658647: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x4df19b0 executing computations on platform Host. Devices:
2019-06-03 14:05:14.658738: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-03 14:05:15.083263: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x4e6c080 executing computations on platform CUDA. Devices:
2019-06-03 14:05:15.083333: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-06-03 14:05:15.084392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:06:00.0
totalMemory: 10.73GiB freeMemory: 10.57GiB
2019-06-03 14:05:15.084478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-06-03 14:05:15.640030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-03 14:05:15.640114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-06-03 14:05:15.640129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-06-03 14:05:15.641178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10198 MB memory) ->
 physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:06:00.0, compute capability: 7.5)

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated
and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-06-03 14:05:21.949030: E tensorflow/compiler/xla/status_macros.cc:49] Internal: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc:3171) ShapeUtil::E
qual(first_reduce->shape(), inst->shape())
*** Begin stack trace ***




        tensorflow::Status xla::HloInstruction::Visit<xla::HloInstruction*>(xla::DfsHloVisitorBase<xla::HloInstruction*>*)

        tensorflow::Status xla::HloInstruction::Accept<xla::HloInstruction*>(xla::DfsHloVisitorBase<xla::HloInstruction*>*, bool, bool)
        tensorflow::Status xla::HloComputation::Accept<xla::HloInstruction*>(xla::DfsHloVisitorBase<xla::HloInstruction*>*) const
        xla::gpu::NVPTXCompiler::RunBackend(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::DeviceMemoryAllocator*)
        xla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::
StreamExecutor*, xla::DeviceMemoryAllocator*)


        tensorflow::XlaCompilationCache::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompiler::CompilationResult const&, std::unique_ptr<xla::LocalExecut
able, std::default_delete<xla::LocalExecutable> >*)
        tensorflow::XlaCompilationCache::CompileImpl(tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, absl::Span<tensorflow::XlaCompiler::Argument const>, s
td::function<tensorflow::Status (tensorflow::XlaCompiler*, tensorflow::XlaCompiler::CompilationResult*)> const&, absl::optional<long long>, tensorflow::XlaCompiler::CompilationResul
t const**, xla::LocalExecutable**)
        tensorflow::XlaCompilationCache::Compile(tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, absl::Span<tensorflow::XlaCompiler::Argument const>, tenso
rflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompilationCache::CompileMode, tensorflow::XlaCompiler::CompilationResult const**, xla::LocalExecutable**)

        tensorflow::XlaCompileOp::Compute(tensorflow::OpKernelContext*)
        tensorflow::BaseGPUDevice::ComputeHelper(tensorflow::OpKernel*, tensorflow::OpKernelContext*)
        tensorflow::BaseGPUDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*)


        Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int)

        std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)


        clone
*** End stack trace ***

2019-06-03 14:05:21.949546: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at xla_ops.cc:429 : Internal: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/ir
_emitter_unnested.cc:3171) ShapeUtil::Equal(first_reduce->shape(), inst->shape())
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InternalError: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc:3171) ShapeUtil::Equal(first_reduce->shape(), in
st->shape())
         [[{{node cluster_1_1/xla_compile}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test_tf.py"", line 20, in <module>
    session.run(output, feed_dict={input: np.zeros((1, steps, 1), dtype=np.float32)})
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc:3171) ShapeUtil::Equal(first_reduce->shape(), in
st->shape())
         [[{{node cluster_1_1/xla_compile}}]]
```

Reproduces in the following environments:
— Official Tensorflow Docker: tensorflow/tensorflow:latest-gpu
— NVIDIA Tensorflow Docker: nvcr.io/nvidia/tensorflow:19.03-py3

Fails with the same error on Keras code (CuDNN LSTM keras implementation) too.

**Describe the expected behavior**

Given code completes successfully.

**Code to reproduce the issue**

```
import numpy as np
import tensorflow as tf

config = tf.ConfigProto()
# no fail when XLA is disabled
config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1
session = tf.Session(config=config)

steps = 2  # no fail when = 1
input = tf.placeholder(dtype=tf.float32, shape=[None, steps, 1])

lstm = tf.contrib.cudnn_rnn.CudnnLSTM(num_layers=1, num_units=1, dtype=tf.float32)
lstm.build(input.get_shape())
lstm_output, _ = lstm(input)
output = tf.concat([lstm_output, input], axis=2)
output = tf.reduce_sum(output, axis=1, keepdims=False)
output = tf.nn.l2_normalize(output, axis=1)

session.run(tf.global_variables_initializer())
session.run(output, feed_dict={input: np.zeros((1, steps, 1), dtype=np.float32)})
```

If you remove any of the tf ops above, error doesn't reproduce."
29360,TFLite: Pruning & Distillation Features,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.x, latest
- Are you willing to contribute it (Yes/No): y

**Describe the feature and the current behavior/state.**

In https://www.tensorflow.org/lite/performance/model_optimization, it says that

> 
> Model optimization uses multiple techniques:
> * Reduce parameter count with pruning and structured pruning.
> * Reduce representational precision with quantization.
> * Update the original model topology to a more efficient one with reduced parameters or faster execution. For example, tensor decomposition methods and distillation.
> We support quantization, and are working to add support for other techniques.

Therefore, I wonder roughly *when will the pruning and distillation be supported?* e.g. a month? a year? Thanks very much!

**Will this change the current api? How?**
no

**Who will benefit with this feature?**
**everyone** using tflite to deploy models on mobiles!

**Any Other info.**
n/a"
29359,TF (v1.9+) unable to call subprocess when making a tf.data.dataset during training in an estimator,"What I am trying to do:

I have a TSV file consisting of string and integer values.

Each line in the file corresponds to a record e.g. 

```tsv
a  1  2    # record 1
b  3  4    # record 2
```

The values of these records are a condensed way of storing part of the input data. 

I have a bash function that can take the stringified tsv file, e.g.

```bash
my-bash-func ""a\t\1\t2\nb\t3\t4\n""
```

which will return the input for my model.

I have a python wrapper function which uses `subprocess` to pipe the file to this bash command and return the output to python:

```python
process(['my-bash-func'], stdin=""a\t\1\t2\nb\t3\t4\n"")
```

where process might be defined as:

```python
def process(command:list, stdin:str, popen_options={}):
    '''
    Arguments:
        command (list): a list of strings indicating the command and its
            arguments to spawn as a subprocess.

        stdin (str): passed as stdin to the subprocess. Assumed to be utf-8
            encoded.

        popen_options (dict): used to configure the subprocess.Popen command

    Returns:
        stdout, stderr
    '''
    command = clean_command(command)
    popen_config = POPEN_DEFAULTS.copy()
    popen_config.update(popen_options)
    try:
        pid = subprocess.Popen(args = command, **popen_config)
        stdout_data, stderr_data = pid.communicate(stdin)
    except OSError as err:
        error_message(command, err)
        sys.exit(1)
    if pid.returncode != 0:
        error_message(command, 'pid code {}'.format(pid.returncode), stdout_data, stderr_data)
    return stdout_data, stderr_data
```

an example output might be:

```python
""x\t\y\t3\nw\tv\t8\n""
```

after parsing, splitting lines and tabs, the constructed input is now:

```python
a  1  2  x  y  3  # record 1
b  3  4  w  v  8 # record 2
```

with this information both the input to the model and the label for the input can be constructed, via a python function:

```
record = [""a"", 1, 2, ""x"", ""y"", 3]
(features, label) = restored_record_to_feature_label_tuple(record)
```
for _each_ epoch during training some randomness needs to be injected. This is done via altering the values in the TSV e.g. record 1 (from the TSV) might have the following values over three epochs:

```python
a   1  2    # record 1 from TSV on epoch 1
a  -1  3    # record 1 from TSV on epoch 2
a   2  1    # record 1 from TSV on epoch 3
```

even with `tf.py_func` I have been unable to find a way to string together this input pipeline:

```python
# pseudo-code

# only needs to be done once. This TSV can also be encoded as tf Records.
tsv_data = parse_tsv(read_tsv(filename))

# done once per epoch
tsv_data_plus_randomness = randomify(tsv_data)

# reconstruct input (calls subprocess)
reconstructed_input = parse_tsv(
    process(
        [""my-bash-func""], 
        stringify(tsv_data_plus_randomness)
    )
)


features, labels = restored_record_to_feature_label_tuple(reconstructed_input)
```

Ideally the above code can become a function compatible with tf.Estimator api

```python
train_fn = # everything after reading in the tsv the first time

train_spec = tf.estimator.TrainSpec(input_fn=train_fn)
```


I _understand_ that this amount of processing is a bottleneck for the model. Ideally, if there were 100 epochs, the data for the 100 epochs of randomness would be pre-calculated and stored. Due to the nature of the model and the usefulness going forward, being able to work with the TSV (at the cost of training time) is worth the trade off. I state this after having done this approach already.

I have a reusable custom estimator [template][reusable estimator] which might be of use for trying to figure out why this is not possible. 

It seems that once the data is a tf.data.Dataset (be if from `tf.data.experimental.CsvDataset` or `tf.data.TFRecordDataset`), this amount of pythonic interface is not possible. 




-------------------------------

Addendum: 
I have been very open about what I know and do not know regarding Tensorflow. I have read extensively the documentation and even produced a concept to reduced the redundancy of the tf record interface via [FIO][https://pypi.org/project/fio/].

What I propose above is not an outrageous input pipeline and shouldn't be so obscure in regards to figuring out how to implement it. 

I went on quite an adventure trying to achieve a [reusable estimator]. While tf.estimator is ""supported"" (not actively developed but pre-made estimators may be added) in tf 2.0, it is likely to be removed or completely deprcyated by tf 3.0. Below includes a sampling of the adventure, and it is important to note, that even with some questions having >1k views, many are unanswered. Further, several issues (e.g. the issue regarding exporting device placement https://github.com/tensorflow/tensorflow/issues/23834) took so long to get any attention by developers that now that TF 2.0 is just about here, no one really cares to invest too much time into actually making user estimators functional as they will be replaced with keras models. 

Despite the colabs linked in these SO questions have been quite useful and individuals besides myself have used them (even apparently a company in china), sparing themselves the misery of figuring out how to get a basic custom model going (with some quality of life bells and whistles). 

I state all this to emphasize that I would not be asking this if I could figure out how to do it from the existing TF documentation / source code.

some of the relevant S.O.  questions:

- https://stackoverflow.com/questions/53634736/tensorflow-estimator-api-use-numpy-functions
- https://stackoverflow.com/questions/53414168/tensorflow-exportoutputs-predictouput-and-specifying-signature-constants-defau
- https://stackoverflow.com/questions/53410469/tensorflow-estimator-servinginputreceiver-features-vs-receiver-tensors-when-and
- https://stackoverflow.com/questions/53409652/tensorflow-estimator-clear-deivces-in-exporters
- https://stackoverflow.com/questions/53409547/tensorflow-estimator-bestexporter-event-file-pattern-doesnt-do-anything
- https://stackoverflow.com/questions/53356558/tensorflow-v1-10-load-savedmodel-with-different-device-placement-or-manually-se
- https://stackoverflow.com/questions/53356029/tensorflow-v1-10-serving-custom-estimator
- https://stackoverflow.com/questions/53355055/tensorflow-estimator-to-tensorflow-js
- https://stackoverflow.com/questions/53317235/tensorflow-custom-estimators-defining-estimator-spec-triggers-error
- https://stackoverflow.com/questions/53307954/tensorflow-custom-estimator-predict-throwing-value-error
- https://stackoverflow.com/questions/53226898/tensorflow-custom-estimator-stuck-when-calling-evaluate-after-training
- https://stackoverflow.com/questions/52874647/tensorflow-v1-10-why-is-an-input-serving-receiver-function-needed-when-checkpoi
- https://stackoverflow.com/questions/52641737/tensorflow-1-10-custom-estimator-early-stopping-with-train-and-evaluate
- https://stackoverflow.com/questions/52064866/tensorflow-1-10-tfrecorddataset-recovering-tfrecords
- https://stackoverflow.com/questions/52035692/tensorflow-v1-10-store-images-as-byte-strings-or-per-channel


[reusable estimator]: https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub#scrollTo=L8V8lpVFdyWL"
29358,[Doc] Broken reference link in basic text classification tutorial,"# DOC Issue

## URL(s) with the issue:
https://www.tensorflow.org/tutorials/keras/basic_text_classification

## Description of issue (what needs changing):
Broken(Wrong) Link in basic text classification tutorial. Needs to be updated/removed/changed.

### Clear description
In the basic text classification tutorial (imdb reviews) the reference link for pad_sequences points to https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences but you get redirected to 
https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing
which is pretty unhelpful. 
+
on 
https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing
the reference link to the keras documentation returns a 404.
So there is not much information to be gained from following that link. 

"
29357,Please provide the list of supported hardware architectures (and/or build options) for the pre-built library,"## URL(s) with the issue:
https://www.tensorflow.org/install/lang_c
## Description of issue (what needs changing):
There is no mention on this page what options were used to build the library files.
For example the lib (""Linux GPU support"") requires cuda 6.0 compute architecture (or above) which is not mentioned. While the pip package runs fine on 3.0 or above.
Or which CPU instructions sets/extensions are supported and which are required (minimum).
It would be good if all of these were mentioned alongside the download link.

I just run into this issue using a GPU with compute architecture 3.7, and TF says it ignores the device because it was not built to support that architecture. It also gives me an info message about the lib not built with SSE4.1 SSE4.2 AVX AVX2 FMA in mind.
"
29354,Suggested KMP_AFFINITY settings harm performance,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (actually keras, using tensorflow backend)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.6
- TensorFlow installed from (source or binary): binary (via anaconda)
- TensorFlow version (use command below): 1.13.1 (mkl_py37h54b294f_0)
- Python version: 3.7.3
- CUDA/cuDNN version: N/A

**Describe the current behavior**
Set `KMP_AFFINITY=""granularity=fine,verbose,compact,1,0""` as per the performance guidelines.
https://www.tensorflow.org/guide/performance/overview

With `OMP_NUM_THREADS=4`, I train a model and see the following output on a 44 core (88 hyperthreads) system:
```
OMP: Info #250: KMP_AFFINITY: pid 372422 tid 372422 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372420 tid 372420 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372423 tid 372423 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372424 tid 372424 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372425 tid 372425 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372426 tid 372426 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372427 tid 372427 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372421 tid 372421 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372414 tid 372414 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372415 tid 372415 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372416 tid 372416 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372417 tid 372417 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372418 tid 372418 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372419 tid 372419 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372429 tid 372429 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372413 tid 372413 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 372378 tid 372396 thread 1 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 372378 tid 372460 thread 2 bound to OS proc set 8
OMP: Info #250: KMP_AFFINITY: pid 372378 tid 372461 thread 3 bound to OS proc set 10
OMP: Info #250: KMP_AFFINITY: pid 372378 tid 372462 thread 4 bound to OS proc set 6
```
There are a bunch of processes and threads here. Some are worker processes for feeding in data. Only the final 4 are ""training"" threads, which are pinned appropriately. The other procs/threads are erroneously pinned to a single hardware thread context.

Using `KMP_AFFINITY=""verbose""`, I get the following output (and substantially greater performance):
```
OMP: Info #250: KMP_AFFINITY: pid 373414 tid 373414 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373416 tid 373416 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373420 tid 373420 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373425 tid 373425 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373424 tid 373424 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373418 tid 373418 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373422 tid 373422 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373427 tid 373427 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373415 tid 373415 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373432 tid 373432 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373426 tid 373426 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373421 tid 373421 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373423 tid 373423 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373419 tid 373419 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373429 tid 373429 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373417 tid 373417 thread 0 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373298 tid 373399 thread 1 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373298 tid 373441 thread 2 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373298 tid 373442 thread 3 bound to OS proc set 0-87
OMP: Info #250: KMP_AFFINITY: pid 373298 tid 373443 thread 4 bound to OS proc set 0-87
```
**Describe the expected behavior**
Don't pin non-OMP worker processes to a single hardware thread context. Perhaps the documentation could suggest starting with `KMP_AFFINITY=""disabled""`, as a baseline?

**Other info / logs**
Other performance related issues in the tracker are likely to have been raised because of this problem. E.g. #29008 and #23238 are currently open. There are closed issues that are likely caused by this, but have been closed without proper resolution (#15320 and #22212, but probably many others). At least suggesting `KMP_AFFINITY=""disabled""` in such issues might be warranted in the future."
29353,Error in Building of TFF on virtualenv Windows,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: tensorflow-1.13.1
- Python version :3.7
- Installed using virtualenv (16.6.0) and pip (19.1.1)
- Bazel version (if compiling from source):  bazel v0.26.0 already installed.




I want some new functions in TFF, that are not added to the compiled version, so I want to build the newest code. I cloned it with git, then I followed the steps in [https://github.com/tensorflow/federated/blob/master/docs/install.md](url) 
But stuck in step 7 when building with Bazel. The following is the error:

Error Track:
```
(venv) C:\Users\ezalaab\Documents\eclipse-workspace\MANA-FederatedLearning\location-based-federated-learning\Test\federated>bazel build //tensorflow_federated/tools:build_pip_package
Starting local Bazel server and connecting to it...
INFO: Call stack for the definition of repository 'local_config_cc' which is a cc_autoconf (rule definition at C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/cc_configure.bzl:53:15):
 - C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/cc_configure.bzl:91:5
 - /DEFAULT.WORKSPACE.SUFFIX:286:1
ERROR: An error occurred during the fetch of repository 'local_config_cc':
   Traceback (most recent call last):
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/cc_configure.bzl"", line 46
                configure_windows_toolchain(repository_ctx)
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 349, in configure_windows_toolchain
                _find_missing_vc_tools(repository_ctx, vc_path)
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 252, in _find_missing_vc_tools
                find_msvc_tool(repository_ctx, vc_path, tool)
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 225, in find_msvc_tool
                repository_ctx.path((vc_path + ""\\Tools\\MSVC"")).readdir()
C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC (No such file or directory)
INFO: Call stack for the definition of repository 'benjaminp_six' which is a new_git_repository (rule definition at C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/build_defs/repo/git.bzl:239:22):
 - C:/users/ezalaab/documents/eclipse-workspace/mana-federatedlearning/location-based-federated-learning/test/federated/WORKSPACE:20:1
ERROR: no such package '@local_config_cc//': Traceback (most recent call last):
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/cc_configure.bzl"", line 46
                configure_windows_toolchain(repository_ctx)
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 349, in configure_windows_toolchain
                _find_missing_vc_tools(repository_ctx, vc_path)
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 252, in _find_missing_vc_tools
                find_msvc_tool(repository_ctx, vc_path, tool)
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 225, in find_msvc_tool
                repository_ctx.path((vc_path + ""\\Tools\\MSVC"")).readdir()
C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC (No such file or directory)
ERROR: Analysis of target '//tensorflow_federated/tools:build_pip_package' failed; build aborted: no such package '@local_config_cc//': Traceback (most recent call last):
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/cc_configure.bzl"", line 46
                configure_windows_toolchain(repository_ctx)
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 349, in configure_windows_toolchain
                _find_missing_vc_tools(repository_ctx, vc_path)
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 252, in _find_missing_vc_tools
                find_msvc_tool(repository_ctx, vc_path, tool)
        File ""C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 225, in find_msvc_tool
                repository_ctx.path((vc_path + ""\\Tools\\MSVC"")).readdir()
C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC (No such file or directory)
INFO: Elapsed time: 4.112s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (27 packages loaded, 226 targets conf\
igured)
```
"
29352,Markdown format issue in tutorials/load_data/tf_records,"## URL(s) with the issue:

https://www.tensorflow.org/tutorials/load_data/tf_records

## Description of issue (what needs changing):
in the context

> The tf.train.Feature message type can accept one of the following three types (See the [.proto file](https://www.tensorflow.org/tutorials/load_data/(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto)%20for%20reference). Most other generic types can be coerced into one of these.

Note: the link of `.proto file` is incorrect. 

It should be 

> The tf.train.Feature message type can accept one of the following three types (See the [.proto file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto) for reference). Most other generic types can be coerced into one of these.
"
29351,Tensor traversing,"How to traverse a Tensor? Let's say a tensor is of dims (3, Q, R, S). I want to traverse all three 3D tensor one by one 
0th 3D tensor    (Q,R,S)
1th 3D tensor    (Q,R,S)
2nd 3D tensor   (Q,R,S)
3rd 3D tensor    (Q,R,S)
Any leads will be appreciated.
"
29350,Check failed: host_index <= host_buffer->size() (20138 vs. 10069) in cudnn_conv_algorithm_picker.cc:284,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9.8
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 9628bc838b9f8f4a5abc2f9f76808f2c212c3182
- Python version: 3.5
- Bazel version (if compiling from source): 0.25.2
- GCC/Compiler version (if compiling from source): 6.3
- CUDA/cuDNN version: 10.0/7.4.1
- GPU model and memory: V100-SXM2-16GB

**Describe the expected behavior**

The benchmark script finishes normally and prints performance numbers, as only a single-day of commits before on 2019-05-31 with 2d47a0ebca181a9476cbd6d971c819d05fd6f7e1 (we run into this with our in-house untested nightly build at 2019-06-01).

**Describe the current behavior**

```
I0603 16:27:54.804590 140049462265600 session_manager.py:500] Running local_init_op.
I0603 16:28:02.836288 140049462265600 session_manager.py:502] Done running local_init_op.
2019-06-03 16:28:11.377907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-03 16:28:14.911938: F tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:284] Check failed: host_index <= host_buffer->size() (20138 vs. 10069)
Fatal Python error: Aborted

Thread 0x00007f5fce730700 (most recent call first):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1429 in _call_tf_sessionrun
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1341 in _run_fn
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1356 in _do_call
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1350 in _do_run
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1173 in _run
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 950 in run
  File ""/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 868 in benchmark_one_step
  File ""/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2429 in benchmark_with_session
  File ""/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2293 in _benchmark_graph
  File ""/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2084 in _benchmark_train
  File ""/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1879 in run
  File ""benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py"", line 68 in main
  File ""/usr/local/lib/python3.5/dist-packages/absl/app.py"", line 251 in _run_main
  File ""/usr/local/lib/python3.5/dist-packages/absl/app.py"", line 300 in run
  File ""benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py"", line 72 in <module>
```

**Code to reproduce the issue**

Running https://github.com/tensorflow/benchmarks with the following options:

```
python3 benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \
    --num_gpus=8 \
    --model=resnet50 \
    --batch_size=256 \
    --use_fp16 \
    --variable_update=replicated \
    --all_reduce_spec=nccl \
    --xla
```

or (the error message is all the same)

```
python3 benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \
    --num_gpus=8 \
    --model=resnet50 \
    --batch_size=256 \
    --use_fp16 \
    --variable_update=parameter_server \
    --local_parameter_device=cpu \
    --xla
```

**Other info / logs**

Our Bazel build command is attached below:

```
bazel build \
    -c opt \
    --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \
    --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/gcc"" \
    --action_env=PYTHON_BIN_PATH=""/usr/bin/python3"" \
    --action_env=PYTHON_LIB_PATH=""/usr/local/lib/python3.5/dist-packages"" \
    --action_env=TF_CONFIGURE_IOS=""0"" \
    --action_env=TF_CUDA_COMPUTE_CAPABILITIES=""6.1,7.0,7.5"" \
    --config=cuda \
    --config=gdr \
    --config=tensorrt \
    --config=verbs \
    --copt=-Wno-sign-compare \
    --copt=-march=ivybridge \
    --define=with_default_optimizations=true \
    --define=with_xla_support=true \
    --host_copt=-march=ivybridge \
    --python_path=""/usr/bin/python3"" \
    //tensorflow/tools/pip_package:build_pip_package
```"
29349,The error occurs during the training,"Hi, The following error occurs during the training, and I don't know what is wrong and why ? Can you give me some guides?




> Epoch 14/500
> 
>   1/379 [..............................] - ETA: 2:47 - loss: 0.3781 - acc: 0.0589 - dice_coefficient: 0.6219
>   2/379 [..............................] - ETA: 2:42 - loss: 0.4649 - acc: 0.1007 - dice_coefficient: 0.5351
>   3/379 [..............................] - ETA: 2:41 - loss: 0.4255 - acc: 0.1039 - dice_coefficient: 0.5745
>   4/379 [..............................] - ETA: 2:40 - loss: 0.5212 - acc: 0.1125 - dice_coefficient: 0.4788
>   5/379 [..............................] - ETA: 2:40 - loss: 0.4794 - acc: 0.0989 - dice_coefficient: 0.5206
>   6/379 [..............................] - ETA: 2:39 - loss: 0.4852 - acc: 0.0932 - dice_coefficient: 0.5148
>   7/379 [..............................] - ETA: 2:42 - loss: 0.4820 - acc: 0.0836 - dice_coefficient: 0.5180
>   8/379 [..............................] - ETA: 2:42 - loss: 0.5002 - acc: 0.0879 - dice_coefficient: 0.4998
>   9/379 [..............................] - ETA: 2:41 - loss: 0.4970 - acc: 0.0849 - dice_coefficient: 0.5030
>  10/379 [..............................] - ETA: 2:41 - loss: 0.4749 - acc: 0.0865 - dice_coefficient: 0.5251
>  11/379 [..............................] - ETA: 2:40 - loss: 0.4679 - acc: 0.0840 - dice_coefficient: 0.5321
>  12/379 [..............................] - ETA: 2:39 - loss: 0.4617 - acc: 0.0879 - dice_coefficient: 0.5383
>  13/379 [>.............................] - ETA: 3:42 - loss: 0.4474 - acc: 0.0889 - dice_coefficient: 0.5526
>  14/379 [>.............................] - ETA: 4:58 - loss: 0.4365 - acc: 0.0878 - dice_coefficient: 0.5635
>  15/379 [>.............................] - ETA: 5:51 - loss: 0.4238 - acc: 0.0836 - dice_coefficient: 0.5762
>  16/379 [>.............................] - ETA: 6:52 - loss: 0.4224 - acc: 0.0866 - dice_coefficient: 0.5776
>  17/379 [>.............................] - ETA: 7:45 - loss: 0.4172 - acc: 0.0905 - dice_coefficient: 0.58282019-06-03 16:02:15.556534: F tensorflow/stream_executor/cuda/cuda_dnn.cc:521] Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 0 feature_map_count: 3 spatial: 64 64 64  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}

"
29348,"In eager mode, the name of variables always has a suffix of value index","<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.0.0alpla0
- Are you willing to contribute it (Yes/No):


**Describe the feature and the current behavior/state.**
<pre>
In [32]: type(x)
Out[32]: tensorflow.python.ops.resource_variable_ops.ResourceVariable

In [33]: x.name
Out[33]: 'my_model/context_predictor/kernel:0'

In [34]: x.name.split("":"")[0]
Out[34]: 'my_model/context_predictor/kernel'
</pre>

**Will this change the current api? How?**
We can add a property to `tf.Tensor` like:
<pre>
@property
def unique_name(self):      # or other simpler names
  return self.name.split("":"")[0]
</pre>
**Who will benefit with this feature?**
Who wants to get variable names"
29347,feedable iterator deal sparse feature error,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):centos
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no
- TensorFlow installed from (source or binary): conda
- TensorFlow version (use command below): 1.13
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: no cuda
- GPU model and memory: no gpu

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
except error when run tf.data.Iterator.from_string_handle(handle, training_dataset.output_types, training_dataset.output_shapes)

tensorflow.python.framework.errors_impl.InvalidArgumentError: Data type mismatch at component 0: expected int32 but got variant.
	 [[Node: IteratorFromStringHandle = IteratorFromStringHandle[output_shapes=[[?,?]], output_types=[DT_INT32], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_Placeholder_0_0)]]

print(training_dataset.output_types)
<dtype: 'int32'>

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29344,Android inference AAR build failure from source code,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 LTS
- TensorFlow installed from (source or binary): source
- TensorFlow version: master branch with commit e1c98eeb
- Python version: 2.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): clang 3.8 from android-ndk-r19c
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the problem**
Android aar build with android-ndk-r19c clang 3.8 will have below build error:
    tensorflow/core/kernels/bias_op.cc:278:13: error: default initialization of an object of const type 'const functor::ReduceMiddleDimensions<float, AccumT,  Eigen::internal::scalar_sum_op<AccumT>, Eigen::internal::SumReducer<float> >'   (aka 'const ReduceMiddleDimensions<float, float, scalar_sum_op<float>,  SumReducer<float> >') without a user-provided default constructor
                redux;
                            ^
    tensorflow/core/kernels/quantized_resize_bilinear_op.cc:52:16: error: default initialization of an object of const type 'const tensorflow::LegacyScaler' without a user-provided default constructor
      const Scaler scaler;
                     ^

**Provide the exact sequence of commands / steps that you executed before running into the problem**
    Build cmds:
    $bazel build --cxxopt='--std=c++11' -c opt --config=android_arm64 \
       --config=monolithic //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops

"
29343,ImportError: DLL load failed: The specified module could not be found.,"
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro
- TensorFlow installed from (source or binary): build from source
- TensorFlow version: 1.13.1
- Python version: 3.6.3
- Bazel version (if compiling from source): 0.19.2
- CUDA/cuDNN version: (v10.0), (cudnn-10.0-windows10-x64-v7.5.0.56)

**Any other info / logs**
....
....
Application\vs\tensorflow;C:\msys64\usr\bin;F:\Work\VS\DNN\cuda\bin
    SET PYTHON_BIN_PATH=E:/Application/python/Miniconda3/python.exe
    SET PYTHON_LIB_PATH=E:/Application/python/Miniconda3/lib/site-packages
    SET TF_CUDA_CLANG=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=5.0
    SET TF_CUDA_VERSION=10.0
    SET TF_CUDNN_VERSION=7
    SET TF_NEED_CUDA=1
    SET TF_NEED_OPENCL_SYCL=0
    SET TF_NEED_ROCM=0
  C:/msys64/usr/bin/bash.exe bazel-out/x64_windows-opt/genfiles/tensorflow/tf_python_api_gen_v1.genrule_script.sh
Traceback (most recent call last):
  File ""\\?\C:\Users\Dev\AppData\Local\Temp\Bazel.runfiles_aeo0bwxr\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""\\?\C:\Users\Dev\AppData\Local\Temp\Bazel.runfiles_aeo0bwxr\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""\\?\C:\Users\Dev\AppData\Local\Temp\Bazel.runfiles_aeo0bwxr\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""E:\Application\python\Miniconda3\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""E:\Application\python\Miniconda3\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""\\?\C:\Users\Dev\AppData\Local\Temp\Bazel.runfiles_aeo0bwxr\runfiles\org_tensorflow\tensorflow\python\tools\api\generator\create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""\\?\C:\Users\Dev\AppData\Local\Temp\Bazel.runfiles_aeo0bwxr\runfiles\org_tensorflow\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""\\?\C:\Users\Dev\AppData\Local\Temp\Bazel.runfiles_aeo0bwxr\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""\\?\C:\Users\Dev\AppData\Local\Temp\Bazel.runfiles_aeo0bwxr\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""\\?\C:\Users\Dev\AppData\Local\Temp\Bazel.runfiles_aeo0bwxr\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""\\?\C:\Users\Dev\AppData\Local\Temp\Bazel.runfiles_aeo0bwxr\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""E:\Application\python\Miniconda3\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""E:\Application\python\Miniconda3\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.
"
29342,tf.config.set_soft_device_placement() seems to have no effect,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
MacOSX 10.13.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
VERSION='2.0.0-dev20190527'
GIT_VERSION='v1.12.1-2821-gc5b8e15064'
- Python version:
3.5
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
CUDA 10.0 (it's just a Colab GPU instance)
- GPU model and memory:
Tesla P4 15079MiB

**Describe the current behavior**
The `tf.config.set_soft_device_placement()` function seems to have no effect when I create an integer variable and try to place it on a GPU, I still get an exception.

**Describe the expected behavior**
I expect soft placement to fallback to using the CPU. No error.

**Code to reproduce the issue**
```python
import tensorflow as tf
tf.config.set_soft_device_placement(True)
with tf.device(""/gpu:0""):
    f = tf.Variable(42)
```

**Other info / logs**
The code above causes the following exception:

```
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-3-1babaf613bc3> in <module>()
      2 tf.config.set_soft_device_placement(True)
      3 with tf.device(""/gpu:0""):
----> 4     f = tf.Variable(42)

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    260       return cls._variable_v1_call(*args, **kwargs)
    261     elif cls is Variable:
--> 262       return cls._variable_v2_call(*args, **kwargs)
    263     else:
    264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)
    254         synchronization=synchronization,
    255         aggregation=aggregation,
--> 256         shape=shape)
    257 
    258   def __call__(cls, *args, **kwargs):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in <lambda>(**kws)
    235                         shape=None):
    236     """"""Call on Variable class. Useful to force the signature.""""""
--> 237     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
    238     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access
    239       previous_getter = _make_getter(getter, previous_getter)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)
   2549       synchronization=synchronization,
   2550       aggregation=aggregation,
-> 2551       shape=shape)
   2552 
   2553 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    262       return cls._variable_v2_call(*args, **kwargs)
    263     else:
--> 264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)
    265 
    266 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)
    462           synchronization=synchronization,
    463           aggregation=aggregation,
--> 464           shape=shape)
    465 
    466   def __repr__(self):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, shape)
    616               shared_name=shared_name,
    617               name=name,
--> 618               graph_mode=self._in_graph_mode)
    619         # pylint: disable=protected-access
    620         if (self._in_graph_mode and initial_value is not None and

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in eager_safe_variable_handle(initial_value, shape, shared_name, name, graph_mode)
    223   dtype = initial_value.dtype.base_dtype
    224   return variable_handle_from_shape_and_dtype(
--> 225       shape, dtype, shared_name, name, graph_mode, initial_value)
    226 
    227 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name, graph_mode, extra_handle_data)
    139                                                    shared_name=shared_name,
    140                                                    name=name,
--> 141                                                    container=container)
    142   if extra_handle_data is None:
    143     extra_handle_data = handle

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py in var_handle_op(dtype, shape, container, shared_name, name)
   1416       else:
   1417         message = e.message
-> 1418       _six.raise_from(_core._status_to_exception(e.code, message), None)
   1419   # Add nodes to the TensorFlow graph.
   1420   dtype = _execute.make_type(dtype, ""dtype"")

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

NotFoundError: No registered 'VarHandleOp' OpKernel for GPU devices compatible with node {{node VarHandleOp}}
	 (OpKernel was found, but attributes didn't match) Requested Attributes: container="""", dtype=DT_INT32, shape=[], shared_name=""cd2c89b7-88b7-44c8-ad83-06c2a9158347""
	.  Registered:  device='GPU'; dtype in [DT_VARIANT]
  device='GPU'; dtype in [DT_INT64]
  device='GPU'; dtype in [DT_COMPLEX128]
  device='GPU'; dtype in [DT_COMPLEX64]
  device='GPU'; dtype in [DT_BOOL]
  device='GPU'; dtype in [DT_DOUBLE]
  device='GPU'; dtype in [DT_FLOAT]
  device='GPU'; dtype in [DT_HALF]
  device='CPU'
  device='XLA_CPU'
  device='XLA_GPU'
 [Op:VarHandleOp] name: Variable/
```"
29341,"Build Issues with bazel 0.15.0, branch r1.12,no GPU","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux ubuntu 4.4.0-21-generic
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A
- TensorFlow installed from (source or binary):source
- TensorFlow version: r1.12
- Python version:3.6.6
- Installed using virtualenv? pip? conda?:conda
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):gcc version 5.4.0 20160609
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A



**Describe the problem**
Compilation fails for tensorflow branch r1.12 with the following stacktrace.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1) Bazel installed version - 0.15.0
2)./configure 
    Compilation flags  ""-march=native -mssse3 -mcx16 -msse4.1 -msse4.2 -mpopcnt""

3)bazel build --config=opt --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow/tools/pip_package:build_pip_package


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

**ERROR: /root/tensorflow/tensorflow/BUILD:533:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 55, in <module>
    'tensorflow_estimator.python.estimator'))
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/component_api_helper.py"", line 85, in package_hook
    set_child_as_subpackage()
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/component_api_helper.py"", line 69, in set_child_as_subpackage
    os.path.join(os.path.dirname(child_pkg.__file__), ""..""))]
AttributeError: module **'tensorflow_estimator.python.estimator'** has no attribute '__file__'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1.055s, Critical Path: 0.55s
INFO: 0 processes.
FAILED: Build did NOT complete successfully**
"
29340,Tensorflow 2.0 doesn't start new compute cycle with tensor.numpy(),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: n/a
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.0 alpha
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**:

if __name__ == ""__main__"":
    rand: tf.Tensor = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)
    print([rand.numpy() for i in range(20)])

### Describe the problem
When you run the following (equivalent code from tensorflow 1):
tf.compat.v1.disable_eager_execution()
if __name__ == ""__main__"":
    rand: tf.Tensor = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)
    with tf.compat.v1.Session() as sess:
        print([rand.eval() for i in range(20)])

You get different output for every eval() call. This make sense since every eval() call executes the subgraph to evaluate rand node. When you execute the same code in Tensorflow 2.0, the result seems to be cached for some reason.
"
29339,[TF 2.0 API Docs] tf.data.Dataset.map() example has web render issues.,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/data
https://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset
https://www.tensorflow.org/versions/master/api_docs/python/tf/data/TextLineDataset

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py


## Description of issue (what needs changing):

### The map() method call for each of these classes has an example which is not being rendered properly.

This is what is intended by the docstring

```
   # NOTE: The following examples use `{ ... }` to represent the
    # contents of a dataset.
    # Each element is a `tf.Tensor` object.
    a = { 1, 2, 3, 4, 5 }
    # `map_func` takes a single argument of type `tf.Tensor` with the same
    # shape and dtype.
    result = a.map(lambda x: ...)
```

This is what gets rendered to the web.  It looks like the back tick references have an issue.

```
# NOTE: The following examples use `{ ... }` to represent the
# contents of a dataset.
# Each element is a <a href=""../../tf/Tensor""><code>tf.Tensor</code></a> object.
a = { 1, 2, 3, 4, 5 }
# `map_func` takes a single argument of type <a href=""../../tf/Tensor""><code>tf.Tensor</code></a> with the same
# shape and dtype.
result = a.map(lambda x: ...)
```


### Submit a pull request?

No, the docstring looks correct.  I don't know how to fix the error."
29338,[TF 2.0 API Docs] tf.data.Dataset and tf.data.experimental.CsvDataset list_files,"
## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset#list_files
https://www.tensorflow.org/versions/master/api_docs/python/tf/data/experimental/CsvDataset#list_files

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/


## Description of issue (what needs changing):

### list_files() routine for both classes use the same bit of code to describe how to use the method.  The descriptive text is written in docstring and it looks like this
Example:
      If we had the following files on our filesystem:
        - /path/to/dir/a.txt
        - /path/to/dir/b.py
        - /path/to/dir/c.py
      If we pass ""/path/to/dir/*.py"" as the directory, the dataset
      would produce:
        - /path/to/dir/b.py
        - /path/to/dir/c.py

However, when rendered it is all one line without the indentation or bullet points.  So it looks like this:

If we had the following files on our filesystem: - /path/to/dir/a.txt - /path/to/dir/b.py - /path/to/dir/c.py If we pass ""/path/to/dir/*.py"" as the directory, the dataset would produce: - /path/to/dir/b.py - /path/to/dir/c.py




This should be corrected.

"
29337,[TF 2.0 API Docs] tf.data.Dataset,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py


## Description of issue (what needs changing):

### Need an overall example of how to use tf.data.Dataset

It is a struggle to relate the dataset with the keras model code.  The model.fit() doc describes how to use a tf.dataset as input but without experimentation its hard to discern the correct format of the dataset.

### Correct links

Is the link to the source code correct?  Yes.

### Parameters defined

Are all parameters defined and formatted correctly? Yes

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? Yes.

### Usage example

Is there a usage example?  No.  I added an example for the common use case of most users to use the dataset with a simple model.fit call for keras.

### Request visuals, if applicable

Are there currently visuals? No. yes, it would be helpful.

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue?  Yes.

[[TF 2.0 API Docs] tf.data Add pointer to tutorials which work with r2.0 #29323](https://github.com/tensorflow/tensorflow/pull/29323)"
29336,Tensorflow won't import in python,"All I have done is try to import tensorflow
I am using windows 8.1

Whenever I try to import Tensorflow i get the same error.

Traceback (most recent call last):
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""C:\Program Files\Python37\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Keegan\AppData\Local\atom\app-1.37.0\PriceAdderUpper.py"", line 1, in <module>
    import tensorflow
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow\python\__init__.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""C:\Program Files\Python37\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'


Failed to load the native TensorFlow runtime.

I did the pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.0-py3-none-any.whl install method and I am using python 3.7.3"
29334,[TF 2.0 API Docs] tf.image.central_crop,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/image/central_crop
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py

## Description of issue (what needs changing):

### Usage example

No usage example provided

### Submit a pull request?

Yes"
29332,[TF 2.0 API Docs] tf.image.adjust_saturation,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_saturation
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not listed

### Usage example

No usage example has been provided

### Submit a pull request?

Yes
https://github.com/tensorflow/tensorflow/pull/29333"
29330,[TF 2.0 API Docs] tf.image.adjust_jpeg_quality,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_jpeg_quality
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not listed and defined.

### Usage example

No usage example has been provided

### Submit a pull request?

Yes
https://github.com/tensorflow/tensorflow/pull/29331"
29329,tf.Module doesn't recognise non trainable variables from keras layers [TF 2.0],"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly-2.0-preview==2.0.0.dev20190602
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CPU
- GPU model and memory: 

When using Keras layers inside `tf.Module` module and setting `trainable=False` in the keras layer doesn't results in non-trainable variables in the `tf.Module` scope. 
The below example code module `M`'s `trainable_variables` should return 6, But it returns 8. 

**Code to reproduce the issue**
```import tensorflow as tf


class M(tf.Module):

    def __init__(self):
        super(M, self).__init__()
        self.list = []
        self.list.append([tf.keras.layers.Dense(5, trainable=False), tf.keras.layers.Dense(5)])
        self.list.append([tf.keras.layers.Dense(5), tf.keras.layers.Dense(5)])

    def __call__(self, inputs):
        output = inputs
        for l_list in self.list:
            for l in l_list:
                output = l(output)
        return output

m = M()
m(tf.ones((10, 10)))
Got: print(len(m.trainable_variables))  = 8

Expected: print(len(m.trainable_variables)) = 6
```"
29327,[TF 2.0 API Docs] tf.image.adjust_hue,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_hue
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not listed and defined

### Usage example

No usage example has been provided

### Submit a pull request?

Yes
https://github.com/tensorflow/tensorflow/pull/29328"
29325,[TF 2.0 API Docs] tf.image.adjust_gamma,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_gamma
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py

## Description of issue (what needs changing):

### Usage example

No usage example provided

### Submit a pull request?

Yes
https://github.com/tensorflow/tensorflow/pull/29326"
29324,[TF 2.0 API Docs] tf.data ,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/data
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/__init__.py

## Description of issue (what needs changing):

### Added reference to three tutorials on using tf.data

Since there are a mix of r2.0 and r1.x tutorials on datasets, these three are relevant for 2.0

### Correct links

Yes
### Parameters defined

Yes/NA

### Returns defined

Yes/NA

### Raises listed and defined

No/Perhaps NA

### Usage example

No, this is to add a pointer to usage.

### Request visuals, if applicable

No. It would be good to have some simple visuals relative to the different classes.

### Submit a pull request?

[#29323](https://github.com/tensorflow/tensorflow/pull/29323)
"
29321,[TF 2.0 API Docs] tf.image.adjust_contrast,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_contrast
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not listed and defined

### Usage example

No usage example has been provided

### Submit a pull request?

Yes
https://github.com/tensorflow/tensorflow/pull/29322"
29319,[TF 2.0 API Docs] tf.image.adjust_brightness,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_brightness
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not listed and defined

### Usage example

No usage example has been provided

### Submit a pull request?

Yes
https://github.com/tensorflow/tensorflow/pull/29320"
29317,[TF 2.0 API Docs] tf.identity_n,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/identity_n

## Description of issue (what needs changing):

### Correct links

The path should be href, also the file it refers to does not exists

### Raises listed and defined

Raises are not listed and defined

### Submit a pull request?

No"
29315,[TF 2.0 API Docs] tf.identity,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/identity
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not listed and defined

### Usage example

No usage example provided

### Submit a pull request?

Yes
https://github.com/tensorflow/tensorflow/pull/29316"
29312,android build,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29310,keras.model.load_weights does not consider custom model(layer) ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
- TensorFlow installed from (source or binary): conda/Anaconda
- TensorFlow version (use command below):1.13 (Issue still existed in the latest source code)



I failed to load the official **Resnet** h5 weights with self implemented **Resnet** using the **tf.keras.model**.

I found the behaviour of **load_weights** in **network.py** does not considered the sub **tf.keras.model**.

For example, the **Resnet** has a **ConvBlock** and a **IdentityBlock**. Instead of use a **function** to define them, I used **tf.keras.model** to define them, so it followed the latest standard.

Instead of simply pass the **self.layers** to **load_weights_from_hdf5_group_by_name**.  The **load_weights** function is **network.py** should collect all layers inside the sub model, then pass to **load_weights_from_hdf5_group_by_name**.

[network.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/network.py) line 1415



Suggested naive fix:


    def get_all_layers (model : tf.keras.Model):

        layers = []

        for layer in model.layers:
            if isinstance(layer, tf.keras.Model):
                layers.extend(get_all_layers(layer))
            else:
                layers.append(layer)

        return layers



"
29309,[TF 2.0 API Docs] tf.RegisterGradient,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/RegisterGradient

## Description of issue (what needs changing):

### Raises listed and defined

__init__ method can return __TypeError__ but not listed
"
29308,[TF1.13] gate order in tf.keras.layers.cudnnlstm,"There is a kernel [input_dim, hid_dim * 4] matrix and recurrent kernel [hid_dim, hid_dim * 4] matrix in cudnnlstm.

**My question is what is the order of gate input, forget, new, output in the kernel and recurrent kernel?
[input, forget, new, output]**

I would really appreciate it since I am transfering weights from BasicLSTMCell kernel matrix.
I would also like to confirm the gate order in BasicLSTMCell kernel [input_dim + hid_dim, hid_dim * 4] is 
[input, new, forget, output]

Thank you!
"
29307,[TF 2.0 API Docs] tf.estimator.VocabInfo,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/VocabInfo

## Description of issue (what needs changing):

### Clear description

This API Documentation does not state when or when not to use this symbol. The description lacks details specific to the desired use case. 

### Correct links

The link to the source code is correct.

### Parameters defined

All of the parameters are defined and formatted correctly.

### Returns defined

Return values are not defined.

### Raises listed and defined

Errors are not defined.

### Usage example

The API Symbol also doesn't contain well-documented code sample(s). The current code samples provided are missing concise explanations. For example, why would you use the different backup initializers or invocations?

### Request visuals, if applicable

No visuals specified.

### Submit a pull request?

Yes, I've created a pull request.
https://github.com/tensorflow/tensorflow/pull/29520
"
29304,GFile gcs_file_system crashes with bad header,"**System information**
- OS Platform and Distribution: MacOS Mojave 10.14.3
- TensorFlow installed from (source or binary): binary
- TensorFlow version: `0.12.0-rc1-7-ga13284f-dirty 0.12.0`
- Python version: Python 3.7.0


```
import tensorflow as tf
with tf.gfile.Open('gs://bucket_name/file_name') as f:
    f.write('foo\n')
```
crashes with error 
```
Traceback (most recent call last):
  File ""/tmp/foo.py"", line 4, in <module>
    f.write('foo\n')
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 150, in __exit__
    self.close()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 182, in close
    pywrap_tensorflow.Set_TF_Status_from_Status(status, ret_status)
  File ""/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py"", line 119, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InternalError: Unexpected response from GCS when writing to gs://bucket_name/file_name: 'Location' header not returned.
```

This seems to be due to 
https://github.com/tensorflow/tensorflow/blob/efdc88cf13827a22fbb7f4d58a14a3cfe57fd21c/tensorflow/core/platform/cloud/gcs_file_system.cc#L509
which checks for the ""Location"" header (with specifically a capital 'L').

However on my system:
`curl 'https://www.googleapis.com/upload/storage/v1/b/bucket_name/o?uploadType=resumable&name=file_name' -XPOST -H 'X-Upload-Content-Length: 10' -H'Authorization: Bearer TOKEN' --verbose`
returns the header ""location"" with a lowercase 'l', which causes the above error.

Changing that byte from ""L"" to ""l"" in the tensorflow `so` file fixes this for me (although that code is currently running successfully on other machines, so I'm not sure what makes mine special)."
29297,[TF 2.0 API Docs] tf.keras.layers.maximum,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/maximum

## Description of issue (what needs changing):

Clarify description, and add usage examples.

### Clear description

Description gives no insight into this methods function.

### Usage example

No Usage example provided.
"
29296,[TF 2.0 API Docs] tf.data.experimental.Reducer,"
## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/Reducer

## Description of issue (what needs changing):

### Clear description

Better description could be provided

### Parameters defined

No

### Returns defined

No

### Usage example

No example is provided

"
29294,Issue With Usage Example in tf.estimator.BaselineEstimator,"Link to Issue: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/DNNLinearCombinedEstimator

So I noticed that in the usage example for tf.estimator.BaselineEstimator, it references tf.contrib.estimator.multi_label_head(), and I heard that tf.contrib is being deprecated. There is not replacement yet available for multi_label_head, and I wanted to bring this to you attention."
29293,Issue With Usage Example in tf.estimator.DNNEstimator,"Link to Issue: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/DNNEstimator

So I noticed that in the usage example for tf.estimator.DNNEstimator, it references tf.contrib.estimator.multi_label_head(), and I heard that tf.contrib is being deprecated. There is not replacement yet available for multi_label_head, and I wanted to bring this to you attention."
29292,[TF 2.0 API Docs] tf.data.experimental.OptionalStructure,"
## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/OptionalStructure

## Description of issue (what needs changing):

### Clear description

No description provided to any of the defined methods

### Usage example

No usage example is provided
"
29290,Link not working,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/decode_and_crop_jpeg

## Description of issue (what needs changing):
No hyperlink for 
`Defined in generated file: python/ops/gen_image_ops.py`

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29289,[TF 2.0 API Docs] tf.data.experimental.Optional,"
## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/Optional

### Usage example

No usage example provided
"
29288,Issue With Usage Example in tf.estimator.BaselineEstimator,"Links to Issue: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/BaselineEstimator
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/DNNEstimator
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/DNNLinearCombinedEstimator
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/LinearEstimator

So I noticed that in the usage example for the modules listed above, they reference tf.contrib.estimator.multi_label_head(), and I heard that tf.contrib is being deprecated. There is not replacement yet available for multi_label_head, and I wanted to bring this to you attention. "
29285,[TF 2.0 API Docs] tf.divide,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/divide


### Parameters defined

Parameter 'Name' is defined but no documentation provided regarding how to use it."
29283,[TF 2.0 API Docs] tf.nn.convolution,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/convolution

## Description of issue (what needs changing):

### Usage example

Needs usage example
"
29281,[TF 2.0 API Docs] tf.control_dependencies,"
## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/control_dependencies

## Description of issue (what needs changing):

### Clear description

While current description is sufficiently clear, may want to link to the API doc referenced

* currently: ""Wrapper for `Graph.control_dependencies()` using the default graph.""
* suggested: ""Wrapper for [`Graph.control_dependencies()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Graph#control_dependencies) using the default graph.

### Submit a pull request?

Yes"
29280,tf.data.Options,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Options
## Description of issue (what needs changing):

### Usage example

There is no usage example."
29279,[TF 2.0 API Docs] tf.histogram_fixed_width_bins,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/histogram_fixed_width_bins

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not defined and listed

### Submit a pull request?

No"
29277,[TF 2.0 API Docs] tf.nn.dropout,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/dropout

## Description of issue (what needs changing):

### Usage example

Usages are linked but none are detailed inline on the page

"
29276,[TF 2.0 API Docs] tf.histogram_fixed_width,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/histogram_fixed_width

## Description of issue (what needs changing):

### Raises listed and defined

Raises are not defined and listed

### Submit a pull request?

No"
29275,[TF_2.0_API_docs] tf.custom_gradient,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/custom_gradient

## Description of issue (what needs changing):
### Raises listed and defined

Errors are not defined."
29274,[TF 2.0 API Docs] tf.VariableSynchronization,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/VariableSynchronization


### Usage example

No usage example is provided
"
29273,[TF 2.0 API Docs] tf.keras.metrics,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics

## Description of issue (what needs changing):
the link to the source code links to 404 page
`Defined in python/keras/api/_v2/keras/metrics/__init__.py.`

### Correct links
https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/metrics.py


### Submit a pull request?
no
"
29271,[TF 2.0 API Docs] tf.hessians,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/hessians

## Description of issue (what needs changing):

No usage example defined

### Usage example

Usage example is not provided. Although the method does not work with eager execution enabled and throws this error:
RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.

### Submit a pull request?

No"
29270,tf.autograph.experimental.Feature,"## URL(s) with the issue: 
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/autograph/experimental/Feature

## Description of issue (what needs changing):

### Clear description

There is no description provided.

### Parameters defined

Parameters are undefined.

### Returns defined

Return values are not defined.

### Raises listed and defined

Errors are not defined? 

### Usage example

There is not a usage example.
"
29269,[TF 2.0 API Docs] tf.nn.l2_loss,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/l2_loss

## Description of issue (what needs changing):

### Clear description

The current description could be improved

### Correct links

It refers to a generated python file that we cannot access

### Raises listed and defined

Raises are not defined

### Usage example

No usage example

### Request visuals, if applicable

No visual
"
29267,[TF 2.0 API Docs] tf.guarantee_const,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/guarantee_const

## Description of issue (what needs changing):

No usage example is provided and the link does not exist. The raises are also not defined.

### Correct links

The link does not exists and is also a simple text

### Raises listed and defined

Raises are not listed

### Usage example

No usage example provided.

### Submit a pull request?

No"
29264,[TF 2.0 API Docs] tf.clip_by_norm,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/clip_by_norm

## Description of issue (what needs changing):

### Raises listed and defined

Errors are not defined.

### Request visuals, if applicable

No visuals are included.
"
29262,[TF 2.0 API Docs] tf.group,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/group
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py

## Description of issue (what needs changing):

A clear description should be added and a proper usage example is to be added. 

### Clear description

For example:
A group operations can run multiple operations at the same time, operations are not sequential and they will be executed when tf.group will be called.

### Usage example

There is no usage example provided except for a link to where it's being used.

### Submit a pull request?
Yes
https://github.com/tensorflow/tensorflow/pull/29265"
29261,[TF 2.0 API Docs] tf.VariableAggregation,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/VariableAggregation

## Description of issue (what needs changing):

### Clear description

The description is not opinionated about when to use this symbol, and unclear on what aggregation methods for combining gradients would be useful for.

### Parameters defined

Parameters are poorly defined, and not formatted appropriately.

### Returns defined

Returns are not defined.

### Raises listed and defined

Errors are not defined.

### Usage example

No usage example is provided.

### Request visuals, if applicable

No visuals are included."
29260,[TF 2.0 API Docs] tf.greater_equal,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/math/greater_equal

## Description of issue (what needs changing):

Correct link is not provided in the sense that it is only a text and not an actual link to the file.
No usage example is given in the documentation.
Raises are also not listed

### Correct links

Correct link is not provided in the sense that it is only a text and not an actual link to the file.

### Raises listed and defined

Raises are also not listed

### Usage example

No usage example is given in the documentation."
29259,Failed to load the native TensorFlow runtime,"**System information**
- OS Platform: Windows10
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.13.1
- Python version: Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 22:22:05) [MSC v.1916 64 bit (AMD64)] on win32
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: Cuda V10.0.130/ cuDNN: cudnn-10.0-windows10-x64-v7.5.0.56
- GPU model and memory: RTX 2070 8G
- NVIDIA Driver: NVIDIA-SMI 416.34       Driver Version: 416.34       CUDA Version: 10.0

**Packages**
Package              Version
-------------------- -------
absl-py              0.7.1
astor                0.8.0
gast                 0.2.2
grpcio               1.21.1
h5py                 2.9.0
Keras-Applications   1.0.8
Keras-Preprocessing  1.1.0
Markdown             3.1.1
mock                 3.0.5
numpy                1.16.4
pip                  19.1.1
protobuf             3.8.0
setuptools           41.0.1
six                  1.12.0
tensorboard          1.13.1
tensorflow-estimator 1.13.0
tensorflow-gpu       1.13.1
termcolor            1.1.0
virtualenv           16.6.0
Werkzeug             0.15.4
wheel                0.33.4

**Description**
I have tried every possible combination of CUDA/cuDNN and I still cannot make it work (last 3 days fighting, I need help). I even installed 3.7 (tried already with python 3.6.6 and 3.68)

**Stack-trace**
(venv) F:\workspace\ml>python -c ""import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))""
Traceback (most recent call last):
  File ""F:\workspace\ml\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""F:\workspace\ml\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""F:\workspace\ml\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""F:\workspace\ml\venv\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""F:\workspace\ml\venv\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""F:\workspace\ml\venv\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""F:\workspace\ml\venv\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""F:\workspace\ml\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""F:\workspace\ml\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""F:\workspace\ml\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""F:\workspace\ml\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""F:\workspace\ml\venv\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""F:\workspace\ml\venv\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

**Paths**
C:\WINDOWS
C:\WINDOWS\system32
C:\WINDOWS\System32\Wbem
F:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin
F:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\extras\CUPTI\libx64
F:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\include
F:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT\TensorRT-5.0.4.3\lib
F:\Program Files\NVIDIA GPU Computing Toolkit\cuDNN\cudnn-10.0-windows10-x64-v7.5.0.56\bin
F:\Program Files\NVIDIA GPU Computing Toolkit\cuDNN\cudnn-10.0-windows10-x64-v7.5.0.56\include
C:\Users\JIAM\AppData\Local\Programs\Python\Python37-32\
C:\Users\JIAM\AppData\Local\Programs\Python\Python37-32\Scripts\
C:\Program Files\NVIDIA Corporation\NVSMI
...
(In this order)
"
29257,[TF 2.0 API Docs] tf.greater,"## URL(s) with the issue:

https://www.tensorflow.org/versions/master/api_docs/python/tf/math/greater

## Description of issue (what needs changing):

Correct link is not provided in the sense that it is only a text and not an actual link to the file.
No usage example is given in the documentation.
Raises are also not listed

### Correct links

Correct link is not provided in the sense that it is only a text and not an actual link to the file.

### Raises listed and defined

Raises are not listed in the documentation

### Usage example

There is no usage example provided"
29256,change 'py_func' to 'py_function' in https://www.tensorflow.org/beta/guide/data#applying_arbitrary_python_logic,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

#https://www.tensorflow.org/alpha/guide/data#applying_arbitrary_python_logic
https://www.tensorflow.org/beta/guide/data#applying_arbitrary_python_logic
## Description of issue (what needs changing):

minor typo, just need to update `py_func` in example so it is `py_function`

### Clear description

In last 4 lines of code block underneath ""applying arbitrary python logic"" section

```Python
dataset = dataset.map(
    lambda filename, label: tuple(tf.py_func(
        _read_py_function, [filename, label], [tf.uint8, label.dtype])))
dataset = dataset.map(_resize_function)
```

### Correct links

Yes

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined
Yes

### Usage example

Yes

### Request visuals, if applicable

No, not needed

### Submit a pull request?

No
"
29254,[TF 2.0 API Docs] tf.autograph.to_code,"
## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/autograph/to_code

## Description of issue (what needs changing):

### Clear description

Initial description could be clearer, instead of referring to another function as similar (`to_graph`), restate primary use case: 
* From: “Similar to to_graph, but returns Python source code as a string.”
* To: “`to_code` is a low-level API that returns the AutoGraph generated Python source code as a string. This is similar to `to_graph`, which returns the TensorFlow graph, instead of Python.”

### Usage example

No usage example in docs, only references to guides/example, would suggest uplifting an example from a guide to the docs for completeness (ref https://www.tensorflow.org/alpha/guide/autograph)


### Submit a pull request?

Yes"
29253,[TF 2.0] - freeze_graph not working with converted keras to tensorflow serving model using tf.keras.experimental.export_savedmodel,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution : Linux Ubuntu 16.04
- TensorFlow installed from: binary
- TensorFlow version (use command below): 2.0
- Python version: 3.6
- CUDA/cuDNN version: 10.0
- GPU model and memory:

**Describe the current behavior**
Model saved as tf.keras .hdf5 converted to tensorflow model using  tf.keras.experimental.export_savedmodel and when using freeze_graph to get a single .pb file running into error 

**Describe the expected behavior**

**Code to reproduce the issue**
```python
import tensorflow as tf
model_path = '/home/vsrira10/Desktop/model.hdf5'
model = tf.keras.models.load_model(model_path)
tf.keras.experimental.export_savedmodel(model,newdir)
```
After this a variables folder with files [checkpoint,variables.data-00000-of-00001,variables.index], saved_model.pb and assests folder created in newdir.

I am trying to use saved_model.pb and variables.data-00000-of-00001 files to get single .pb frozen_graph
**Other info / logs**
python /home/vsrira10/anaconda2/envs/tf2/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py --input_graph=/home/vsrira10/Desktop/tf_models/saved_model.pb --input_checkpoint=/home/vsrira10/Desktop/tf_models/variables/variables.data-00000-of-00001 --output_graph=/home/vsrira10/Desktop/tf_models/frozen_graph.pb --output_node_names=classes,corners --input_binary=true
Traceback (most recent call last):
  File ""/home/vsrira10/anaconda2/envs/tf2/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py"", line 492, in <module>
    run_main()
  File ""/home/vsrira10/anaconda2/envs/tf2/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py"", line 489, in run_main
    app.run(main=my_main, argv=[sys.argv[0]] + unparsed)
  File ""/home/vsrira10/anaconda2/envs/tf2/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/vsrira10/anaconda2/envs/tf2/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/vsrira10/anaconda2/envs/tf2/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/home/vsrira10/anaconda2/envs/tf2/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py"", line 488, in <lambda>
    my_main = lambda unused_args: main(unused_args, flags)
  File ""/home/vsrira10/anaconda2/envs/tf2/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py"", line 382, in main
    flags.saved_model_tags, checkpoint_version)
  File ""/home/vsrira10/anaconda2/envs/tf2/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py"", line 341, in freeze_graph
    input_graph_def = _parse_input_graph_proto(input_graph, input_binary)
  File ""/home/vsrira10/anaconda2/envs/tf2/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py"", line 252, in _parse_input_graph_proto
    input_graph_def.ParseFromString(f.read())
google.protobuf.message.DecodeError: Error parsing message
"
29252,[TF 2.0] Dataset has no attribute 'make_one_shot_iterator',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow version (use command below): 2.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the current behavior**
Report attribute error as :
 **AttributeError: 'BatchDataset' object has no attribute 'make_one_shot_iterator'**

**Describe the expected behavior**

**Code to reproduce the issue**
```
from __future__ import absolute_import, division, print_function, unicode_literals

# Install TensorFlow
!pip install tensorflow==2.0.0-alpha0

import tensorflow as tf
import tensorflow.keras.models as Models
import numpy as np

inc_dataset = tf.data.Dataset.range(100)
dec_dataset = tf.data.Dataset.range(0, -100, -1)
dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))
batched_dataset = dataset.batch(4)

iterator = batched_dataset.make_one_shot_iterator()
next_element = iterator.get_next()
```

"
29250,[TF 2.0 API Docs] tf.autograph.set_verbosity,"
## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/autograph/set_verbosity

## Description of issue (what needs changing):

### Clear description

Description could be clearer:

* Reference to Abseil's logging format could be referenced rather than only to Abseil, itself (user would have to hunt through docs to see the logging output format referenced)
* There's a slight misspelling in the args for `alsologtostdout`
    “ it is recommended to set this value to a larges number, like 10” should be “ it is recommended to set this value to a large number, like 10”

### Submit a pull request?

Yes.
"
29247,[TF 2.0 API Docs] tf.keras.layers.LSTM,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM

*Suggestion: Where applicable, the documentation for this should be consistent with the base class [tf.keras.layers.RNN](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/RNN) and other derived classes.*

## Description of issue (what needs changing):

### Clear description

 1. Use of backticks can be made more consistent and in line with the [Documentation Style - Write about code](https://www.tensorflow.org/community/contribute/docs_style#write_about_code). For example, the value ""True"" and ""False"" in the description is not surronded by backticks, as recommended by the Documentation Style guide.

### Correct links

 1. Link to the source code at ""python/keras/layers/recurrent_v2.py"" is incorrect. It points to https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/python/keras/layers/recurrent_v2.py, which is a 404 page. Correct link (for master) should be https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent_v2.py.

### Parameters defined

 1. (As with the Clear Heading section above) Use of backticks can be made more consistent and in line with the [Documentation Style - Write about code](https://www.tensorflow.org/community/contribute/docs_style#write_about_code). For example, the value ""True"" and ""False"" in the description is not surronded by backticks, as recommended by the Documentation Style guide.

 1. `__init__(...)`:
    - Parameter `time_major` is not defined.
    - The default value is specified within the text of some of the parameter definitions *but not all*. For example, the definition for `unroll` is:
       >Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.  

       whereas the definition for `return_state` is:  

       > Boolean. Whether to return the last state in addition to the output.

1. `get_dropout_mask_for_cell(...)`:
    - First word of the definition of the parameters should be capitalized

1. `get_initial_state(...)`:
    - Parameter `inputs` is not defined.

1. `reset_states(...)`:
    - Parameter `states` is not defined.

### Returns defined

Return value is not defined for the following:
 - `get_initial_state(...)`
 - `reset_dropout_mask()`
 - `reset_recurrent_dropout_mask()`
 - `reset_state()`

For the last three items above, perhaps it is sufficiently clear that nothing will be returned.

### Raises listed and defined

No errors are defined.

### Usage example

No usage examples are provided. However, the description does have links to relevant guides and tutorials as follows:

 - Used in the guide:
    - [The Keras Functional API in TensorFlow](https://www.tensorflow.org/alpha/guide/keras/functional)  

 - Used in the tutorials:
    - [Load text with tf.data](https://www.tensorflow.org/alpha/tutorials/load_data/text)
    - [Text classification with an RNN](https://www.tensorflow.org/alpha/tutorials/text/text_classification_rnn)
    - [Text generation with an RNN](https://www.tensorflow.org/alpha/tutorials/text/text_generation)

### Request visuals, if applicable

There are current *no* visuals. LSTM itself might be too broad a topic to be dealt with comprehensively using visuals in this documentation page.

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue?  
**No.** *(I can fix the formatting and syntax issues, but populating the missing parameter definitions is currently beyond my level 😅)*


### Related Issue

#26197"
29246,OOM happens with tf.py_function,"```
def visualize_box(image, boxes, pred):
    image_pil = Image.fromarray(np.uint8((1 - image) * 255.0), ""RGB"")
    draw = ImageDraw.Draw(image_pil)
    w, h = image_pil.size
    boxes *= tf.cast(tf.stack([h, w, h, w], axis=-1), tf.float32)
    font = ImageFont.load_default()
    for b, p in zip(boxes, pred):
        # b (y_min, x_min, y_max, x_max)
        if not b[2] > 0.0:
            continue
        draw.line(
            [(b[1], b[0]), (b[1], b[2]), (b[3], b[2]), (b[3], b[0]), (b[1], b[0])],
            fill=""blue"",
        )
        p_text = str(np.int(p))
        t_w, t_h = font.getsize(p_text)
        margin = np.ceil(0.05 * t_h)
        if b[0] > t_h:
            t_bottom = b[0]
        else:
            t_bottom = b[2] + t_h
        draw.rectangle(
            [b[1], t_bottom - t_h - 2 * margin, b[1] + t_w, t_bottom], fill=""blue""
        )
        draw.text(                                                                                                                                    
            (b[1] + margin, t_bottom - t_h - margin), p_text, fill=""white"", font=font
        )

    context.context()._clear_caches() # from tensorflow.python.eager import context
    del font, draw, w, h                                                                                                                              
    gc.collect()
    return np.expand_dims(np.array(image_pil, dtype=np.float32) / 255.0, 0)
```
```
# images is [1, 416, 416, 3] tensor, allbox [None, 4], all_pred [None]
labeled = tf.py_function(
                visualize_box, (images[0], all_box, all_pred), tf.float32
            )
```
I call the above function is the estimator model function in eval mode. The oom happens after training for some steps. If I comment out the `py_function` then I don't face any OOM.

I use Tensorflow 1.13.1 gpu py3 docker image.

```
Limit:                 10224323788
InUse:                 10028396544
MaxInUse:              10101860352
NumAllocs:                 5509254
MaxAllocSize:           3638034432
```
```
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[13,1024,52,52] and type float on /job:localhost/
replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[{{node main/small/predictor/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation inf
o.

         [[node Mean (defined at main.py:176) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation inf
o.
```
"
29245,[TF 2.0 API Docs] tf.image.transpose,"Doc link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/transpose

## Description of issue (what needs changing):

### Usage example

No usage example is provided.
"
29244,[TF 2.0 API Docs] tf.io.extract_jpeg_shape,"
Doc link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/extract_jpeg_shape

## Description of issue (what needs changing):

### Correct links

Link not provided. Path is written but href is not provided.

### Raises listed and defined

Errors are not defined.

### Usage example

No usage example is provided.
"
29243,[TF 2.0 API Docs] tf.image.rot90,"Doc link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/rot90

## Description of issue (what needs changing):

### Usage example

No usage example is provided.

### Request visuals, if applicable

No Visuals are included. A visual example of rotation can be added although not necessary.
"
29242,[TF 2.0 API Docs] tf.math.maximum / tf.maximum,"**System information**

TensorFlow version: 2.0
Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/maximum

**Describe the documentation issue**

**Links**
python/ops/gen_math_ops.py
The implementation of the code is in c++.
However, the documentation references a generated python file.
which we can't open, or can't view a representative implementation.

Perhaps, we can add a representative implementation for such function.

**Usage Example**
No usage example is provided.

"
29241,[TF 1.14 API Docs] tf.train.experimental.enable_mixed_precision_graph_rewrite,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/train/experimental/enable_mixed_precision_graph_rewrite

## Description of issue (what needs changing):

### Clear description

* Should better explain the graph rewrite algorithm (black/white/grey listed ops) and where to see the list of ops.
* Overall language can be clearer and more precise.
* Minor issues with the formatting.

### Correct links

Links present are all correct.

### Parameters defined

Briefly explain what the value `""dynamic""` (the default value) for `loss_scale` does, and link to the symbol for that.

### Returns defined

Return values are defined properly.

### Raises listed and defined

Exceptions are not listed nor explained.

### Usage example

No usage example, I can provide a simple code snippet.

Additionally, I want to provide a Colab notebook to demonstrate increase in speed without negative impact on accuracy (on CIFAR10 for example).

### Request visuals, if applicable

* Overview of mixed precision process/flow

### Submit a pull request?

Yes, I have submitted a PR. PR is here #29249 
"
29240,[XLA]support of async xlaop kernel  ,"**System information**
- TensorFlow version (you are using):
r1.14
- Are you willing to contribute it (Yes/No):
YES


**Describe the feature and the current behavior/state.**
in the current tf version, there are two types of ops: OpKernel and AsyncOpKernel, but in the xla module, the only xlaop type is XlaOpKernel, which is a sync interface. For most of xlaops, this method works fine, but when it comes to some async op like horovod all reduce op, which derived from AsyncOpKernel in the tfop, this sync interface  will not work. I gonna to learn if it is possible to add a async xla op kernel type? if these idea is contradicted to the original design of XLA module, thanks for letting me know.    
**Will this change the current api? How?**
no
**Who will benefit with this feature?**
anyone who want to add a async op in xla
**Any Other info.**
"
29237,[TF 2.0 API Docs] tf.complex,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/dtypes/complex

## Description of issue (what needs changing):
### Raises listed and defined
No

### Submit a pull request?
#29237
I will"
29236,Node.js (JavaScript) TensorFlow Lite Wrapper API,"Is there any Node.js (JavaScript) API wrapper for TF Lite, for instance, if we can install:
npm install @tensorflow/tfjs-lite
"
29235,Issue with flags in TF2.0,"I am using flags in my code in tensorflow and I have not been getting errors not until I upgraded from TF 1X to TF2.0 and these are the errors I am getting. I need an assistance on resolving this issue.
tf.compat.v1.flags.FLAGS.delattr()
def del_all_flags(FLAGS):
flags_dict = FLAGS._flags()
keys_list = [keys for keys in flags_dict]
for keys in keys_list:
FLAGS.delattr(keys)

del_all_flags(tf.compat.v1.flags.Flag)

flags = tf.app.flags
FLAGS = tf.app.flags.FLAGS
flags.DEFINE_float(""learning_rate"", default = 0.0001, help = ""Initial learning rate."")
flags.DEFINE_integer(""epochs"", default = 700, help = ""Number of epochs to train for"")
flags.DEFINE_integer(""batch_size"", default =128, help = ""Batch size."")
flags.DEFINE_integer(""eval_freq"", default = 400, help ="" Frequency at which to validate the model."")
flags.DEFINE_float(""kernel_posterior_scale_mean"", default = -0.9, help = ""Initial kernel posterior mean of the scale (log var) for q(w)"")
flags.DEFINE_float(""kernel_posterior_scale_constraint"", default = 0.2, help = ""Posterior kernel constraint for the scale (log var) for q(w)"")
flags.DEFINE_float(""kl_annealing"", default = 50, help = ""Epochs to anneal the KL term (anneals from 0 to 1)"")
flags.DEFINE_integer(""num_hidden_layers"", default = 4, help = ""Number of hidden layers"")
flags.DEFINE_integer(""num_monte_carlo"",

                 default=50,

                 help=""Network draws to compute predictive probabilities."")
tf.compat.v1.app.flags.DEFINE_string('f', '', 'kernel')

I end up getting these error while doing some manipulation: DuplicateFlagError: The flag 'batch_size' is defined twice. First from D:/Python/workspace/FCN_dataset/FCN.tensorflow-master/FCN.py, Second from D:/Python/workspace/FCN_dataset/FCN.tensorflow-master/FCN.py. Description from first occurrence: batch size for training and
TypeError: delattr() missing 1 required positional argument: 'flag_name'
_
and DuplicateFlagError: The flag 'master' is defined twice. First from object_detection/train.py, Second from object_detection/train.py.  Description from first occurrence: Name of the TensorFlow master to use."
29230,Wrong color documented in explanation TensorFlow Lite Android,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29229,ExecutorState crash on specific iOS devices,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): iPhone XR, iPhone XS using iOS 12.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: See above. 
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 1.12
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.22.0 
- GCC/Compiler version (if compiling from source): GCC
- CUDA/cuDNN version: N/A
- GPU model and memory:

**Describe the current behavior**

Last year we built an LSTM RNN using Tensorflow 1.12 and Python 3.6.8. After struggling for a couple of weeks we managed to get the tensorflow mobile static libraries compiled and running on iPhone and were able to run our model (a real-time Human Activity Recognition application, FWIW). 

On Apple's latest hardware (iPhone XR and XS) we are seeing seemingly random crashes after running inference for 20+ seconds. We receive a EXC_BAD_ACCESS crash as follows:

tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)

This custom model was built with BasicLSTMCell which makes it, from what we can discern, unsuitable for TFLite at this point (since LSTM Ops are not yet supported outside of the experimental branch). For reference (python code for the graph): 

        lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)
                      for layer in range(n_layers)]
        multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)
        outputs, states = tf.nn.dynamic_rnn(multi_cell, x, dtype=tf.float32)
        top_layer_h_state = states[-1][1]
  
**Other info / logs**

0 | PlayFitt | tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) + 56780
-- | -- | --
1 | PlayFitt | tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) + 58744
2 | PlayFitt | std::__1::__function::__func<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&>, std::__1::allocator<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&> >, void ()>::operator()() + 89040
3 | PlayFitt | Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 276848
4 | PlayFitt | std::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()() + 275152
5 | PlayFitt | void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 56
6 | libsystem_pthread.dylib | _pthread_body + 132
8 | (Missing) | (Missing)
"
29220,Build failure with upcoming Python toolchain change in Bazel 0.27,"Bazel 0.27 will flip [`--incompatible_use_python_toolchains`](https://github.com/bazelbuild/bazel/issues/7899). A [downstream presubmit](https://buildkite.com/bazel/bazel-at-head-plus-downstream/builds/1008#0016c105-4c66-4506-83fd-72ee26749782) shows Tensorflow failing for this change.

One of the side-effects of the flag is that it causes Bazel to actually run Python targets with the interpreter selected by Bazel at analysis time, rather than whatever the system `python` command happens to be. It's likely you have targets that should be Python 2, and were previously running as Python 2, that are now running as Python 3 due to this bug fix. (Note that as of Bazel 0.25, `python_version` defaults to PY3 if not given.)

For each Python 2 `py_binary` / `py_test` target (or macros creating such targets), add the attribute `python_version = ""PY2""`. If you have any PY2 targets built in the host configuration, you must add `--host_force_python=PY2` to your bazelrc.

Looking at the failures, I see for instance [`tf_python_api_gen_v1`](https://github.com/tensorflow/tensorflow/blob/50883f7ca9b98e30d303dad5d20b76e05a947f36/tensorflow/BUILD#L774), generated by `gen_api_init_files`, which [creates](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/api/generator/api_gen.bzl#L66-L76) a `py_binary` with no `python_version` attribute.

See the flag's tracking issue (above) for more details."
29217,Memory leak using C_API,"Hello!

I'm experiencing memory leak in the pre-built tensorflow library using the C_API.
Are there any (preferably valgrind) docs/ignore files which describes whats are the possible false detections?

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, using the c_api
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 64 bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): libtensorflow-gpu-linux-x86_64-1.13.1
- Python version: N/A
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A (5.4.0 20160609 which used to compile and link my executable to the tensorflow lib)
- CUDA/cuDNN version: CUDA 10.0.130, cuDNN 7.5.0
- GPU model and memory: Titan XP 12Gb (used only for CUDA), 1050Ti 4Gb (used only for the displays)

**Describe the current behavior**
Memory leak in TF_NewSession, TF_GraphImportGraphDef.

**Describe the expected behavior**
No memory leak :)

**Code to reproduce the issue**
(sorry, my codebase is huge, this is only workflow how I use the c_api, error checking ommitted for simplicity)
```
TF_Graph* graph = TF_NewGraph();
TF_Status* status = TF_NewStatus(); // are status objects re-usable?
TF_ImportGraphDefOptions* opts = TF_NewImportGraphDefOptions();
TF_ImportGraphDefOptionsSetDefaultDevice(opts, ""/gpu:0"");
TF_Buffer* buffer = TF_NewBuffer();
// code to load a .pb file into buffer
TF_GraphImportGraphDef(graph, buffer, opts, status); // this is one line where valgrind says there is a memleak
TF_DeleteImportGraphDefOptions(opts);
TF_DeleteBuffer(buffer);
buffer = nullptr;
// code to get input operations and create/fill input tensor with input data
TF_SessionOptions* options = TF_NewSessionOptions();
uint8_t config[7] = {0x32, 0x5, 0x20, 0x1, 0x2a, 0x01, 0x30}; // protobuf data for auto memory gpu_options.allow_growth=True and gpu_options.visible_device_list=""0"" 
TF_SetConfig(options,(void*)config,7,status);
TF_Session* session = TF_NewSession(graph, options, status);
TF_DeleteSessionOptions(options);
options = nullptr;

// code to create arrays for input and output tensors, etc
// note that TF_SessionRun is called thousands of times, I cant associate any leak detected by valgrind to it (in other words, im not sure its leak free but I hope so :) )
TF_SessionRun(session,
              nullptr, // no options
              inputs, input_tensors, static_cast<int>(ninputs), // Input tensors, input tensor values, number of inputs.
              outputs, output_tensors, static_cast<int>(noutputs), // Output tensors, output tensor values, number of outputs.
              nullptr, 0, // Target operations, number of targets.
              nullptr, // Run metadata.
              status // Output status.
  );


// code to call TF_DeleteTensor on the output_tensors (since TF_SessionRun passes the ownership to the caller code)
TF_CloseSession(session, status);
TF_DeleteSession(session, status); 
session = nullptr;
TF_DeleteGraph(graph);
graph = nullptr;
TF_DeleteStatus(status);
status = nullptr;

```

**Other info / logs**
Log from valgrind (these are only the detections marked as ""definitely lost""):
```
400 bytes in 1 blocks are definitely lost in loss record 144,731 of 148,938
   at 0x4C2FB55: calloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
   by 0x40138B4: allocate_dtv (dl-tls.c:322)
   by 0x40138B4: _dl_allocate_tls (dl-tls.c:539)
   by 0x515026E: allocate_stack (allocatestack.c:588)
   by 0x515026E: pthread_create@@GLIBC_2.2.5 (pthread_create.c:539)
   by 0x1A97ADC2: std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>, void (*)()) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21)
   by 0x1A97AECC: std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21)
   by 0x24C3511F: tensorflow::(anonymous namespace)::PosixEnv::StartThread(tensorflow::ThreadOptions const&, std::string const&, std::function<void ()>) (in libtensorflow_framework.so)
   by 0x24C0D8FC: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::string const&, int, bool, Eigen::Allocator*) (in libtensorflow_framework.so)
   by 0x24C0DB6E: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, std::string const&, int) (in libtensorflow_framework.so)
   by 0x24BB479D: tensorflow::GraphRunner::GraphRunner(tensorflow::Env*) (in libtensorflow_framework.so)
   by 0xCBC1C86: tensorflow::ShapeRefiner::ShapeRefiner(int, tensorflow::OpRegistryInterface const*) (in libtensorflow.so)
   by 0xCBD68E8: tensorflow::ImportGraphDef(tensorflow::ImportGraphDefOptions const&, tensorflow::GraphDef const&, tensorflow::Graph*, tensorflow::ShapeRefiner*, tensorflow::ImportGraphDefResults*) (in libtensorflow.so)
   by 0x6460FF0: GraphImportGraphDefLocked (in libtensorflow.so)

400 bytes in 1 blocks are definitely lost in loss record 144,732 of 148,938
   at 0x4C2FB55: calloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
   by 0x40138B4: allocate_dtv (dl-tls.c:322)
   by 0x40138B4: _dl_allocate_tls (dl-tls.c:539)
   by 0x515026E: allocate_stack (allocatestack.c:588)
   by 0x515026E: pthread_create@@GLIBC_2.2.5 (pthread_create.c:539)
   by 0x309423EE: ??? (in /usr/lib/x86_64-linux-gnu/libcuda.so.418.56)
   by 0x309B4E15: ??? (in /usr/lib/x86_64-linux-gnu/libcuda.so.418.56)
   by 0x308E795C: ??? (in /usr/lib/x86_64-linux-gnu/libcuda.so.418.56)
   by 0x308E9BDE: ??? (in /usr/lib/x86_64-linux-gnu/libcuda.so.418.56)
   by 0x3081A8EB: ??? (in /usr/lib/x86_64-linux-gnu/libcuda.so.418.56)
   by 0x3096A85A: cuDevicePrimaryCtxRetain (in /usr/lib/x86_64-linux-gnu/libcuda.so.418.56)
   by 0x2505CDDC: stream_executor::cuda::CUDADriver::CreateContext(int, stream_executor::DeviceOptions const&, stream_executor::cuda::CudaContext**) (in libtensorflow_framework.so)
   by 0x25064CB3: stream_executor::cuda::CUDAExecutor::Init(int, stream_executor::DeviceOptions) (in libtensorflow_framework.so)
   by 0x24FA1A86: stream_executor::StreamExecutor::Init(int, stream_executor::DeviceOptions) (in libtensorflow_framework.so)

400 bytes in 1 blocks are definitely lost in loss record 144,733 of 148,938
   at 0x4C2FB55: calloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
   by 0x40138B4: allocate_dtv (dl-tls.c:322)
   by 0x40138B4: _dl_allocate_tls (dl-tls.c:539)
   by 0x515026E: allocate_stack (allocatestack.c:588)
   by 0x515026E: pthread_create@@GLIBC_2.2.5 (pthread_create.c:539)
   by 0x1A97ADC2: std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>, void (*)()) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21)
   by 0x1A97AECC: std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21)
   by 0x24C3511F: tensorflow::(anonymous namespace)::PosixEnv::StartThread(tensorflow::ThreadOptions const&, std::string const&, std::function<void ()>) (in libtensorflow_framework.so)
   by 0x24C0D8FC: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::string const&, int, bool, Eigen::Allocator*) (in libtensorflow_framework.so)
   by 0x24C0DB6E: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, std::string const&, int) (in libtensorflow_framework.so)
   by 0x24BB479D: tensorflow::GraphRunner::GraphRunner(tensorflow::Env*) (in libtensorflow_framework.so)
   by 0xCBC1C86: tensorflow::ShapeRefiner::ShapeRefiner(int, tensorflow::OpRegistryInterface const*) (in libtensorflow.so)
   by 0xCBD5FA8: tensorflow::ConvertGraphDefToGraph(tensorflow::GraphConstructorOptions const&, tensorflow::GraphDef const&, tensorflow::Graph*) (in libtensorflow.so)
   by 0xC804F89: tensorflow::GraphExecutionState::InitBaseGraph(tensorflow::BuildGraphOptions const&) (in libtensorflow.so)

136 (80 direct, 56 indirect) bytes in 1 blocks are definitely lost in loss record 138,565 of 148,938
   at 0x4C2E0EF: operator new(unsigned long) (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
   by 0x24C3506A: tensorflow::(anonymous namespace)::PosixEnv::StartThread(tensorflow::ThreadOptions const&, std::string const&, std::function<void ()>) (in libtensorflow_framework.so)
   by 0x24C0D8FC: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::string const&, int, bool, Eigen::Allocator*) (in libtensorflow_framework.so)
   by 0x24C0DB9A: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::string const&, int) (in libtensorflow_framework.so)
   by 0x24BBA1AA: tensorflow::LocalDevice::LocalDevice(tensorflow::SessionOptions const&, tensorflow::DeviceAttributes const&) (in libtensorflow_framework.so)
   by 0x24BF3C4A: tensorflow::ThreadPoolDevice::ThreadPoolDevice(tensorflow::SessionOptions const&, std::string const&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality const&, tensorflow::Allocator*) (in libtensorflow_framework.so)
   by 0x24B54DB5: tensorflow::GPUCompatibleCPUDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::string const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (in libtensorflow_framework.so)
   by 0x24B8934E: tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::string const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (in libtensorflow_framework.so)
   by 0xC7E8B6C: tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (in libtensorflow.so)
   by 0x24BE9EF8: tensorflow::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (in libtensorflow_framework.so)
   by 0x645C734: TF_NewSession (in libtensorflow.so)
   
 LEAK SUMMARY:
    definitely lost: 1,280 bytes in 4 blocks
    indirectly lost: 56 bytes in 2 blocks
      possibly lost: 682,056 bytes in 142 blocks
    still reachable: 155,113,486 bytes in 238,127 blocks
                       of which reachable via heuristic:
                         stdstring          : 2,753,050 bytes in 69,263 blocks
                         newarray           : 5,656 bytes in 12 blocks
         suppressed: 925,188,500 bytes in 620,115 blocks

```
I'm using a valgrind ignore file which already ignores known false detections inside CUDA/cuDNN.
All of the definitely lost, indirectly lost and possibly lost comes from the tensorflow library.
"
29216,CUDA Compability 3.0 not working,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.13.1
- Python version: 3.5.2
- Installed using virtualenv? pip? conda?: pip3
- Bazel version (if compiling from source): 0.21.0
- GCC/Compiler version (if compiling from source): 5.5.0
- CUDA/cuDNN version: 10.0/7
- GPU model and memory: GTX770 4GB

**Describe the problem**
I compiled tensorflow from sources with compute compability 3.0 but after installation it still looks for 3.5

> 2019-05-31 15:06:10.209035: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299735000 Hz
2019-05-31 15:06:10.209418: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4042a70 executing computations on platform Host. Devices:
2019-05-31 15:06:10.209526: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-05-31 15:06:10.252169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-05-31 15:06:10.252663: I tensorflow/compiler/xla/service/platform_util.cc:194] StreamExecutor cuda device (0) is of insufficient compute capability: 3.5 required, device is 3.0
2019-05-31 15:06:10.252779: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: no supported devices found for platform CUDA

**Any other info / logs**
I followed official guides
https://www.tensorflow.org/install/gpu
https://www.tensorflow.org/install/source
for installation of NVIDIA packages and build process.

In configure step I chose CUDA only, set the paths and select version 3.0 (btw it was default). Everything else was default.
I built tensorflow from v1.13.1 tag.
"
29215,[TF 2.0] Inconvenient graph visualization,"**System information**
- TensorFlow version (use command below): 2.0.0-alpha0
- Python version: 3.6.5

When visualizing the graph with tensorboard, there are many nodes, which maybe generated by auotgraph, to make it quite inconvenient to debug with the graph.

To reproduce:
<pre>
import numpy as np
import tensorflow as tf


class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.dense1 = tf.keras.layers.Dense(100)

    def call(self, inputs):
        outputs = self.dense1(inputs)
        return outputs


model = Model()
optimizer = tf.keras.optimizers.Adam()
writer = tf.summary.create_file_writer(""./logdir"")


@tf.function
def train(data):
    with tf.name_scope(""xxx""):
        with tf.GradientTape() as tape:
            y = model(data)
            loss = tf.reduce_mean(tf.square(y))
        grads = tape.gradient(loss, model.trainable_weights)
        optimizer.apply_gradients(zip(grads, model.trainable_weights))


x = np.random.rand(10, 100).astype(np.float32)
# y = model(x)
# train.python_function(x)
tf.summary.trace_on()
train(x)
with writer.as_default():
    tf.summary.trace_export(""graph"", step=0)
    tf.summary.trace_off()
    writer.flush()
</pre>

The graph visualization contains many `ReadVariableOp` and `AssignVariableOp` outside, as follows:
![png](https://user-images.githubusercontent.com/22030149/59081332-196c5680-8920-11e9-9b76-bfa482ccf2b2.png)

If we unocmment `y = model(x)`, the number of outside ops decrease, as follows:
![png (1)](https://user-images.githubusercontent.com/22030149/59081425-9bf51600-8920-11e9-8dfb-4c3b813f9f5c.png)

If we uncomment `train.python_function(x)`, all `ReadVariableOp` and `AssignVariableOp` decrease:
![png (2)](https://user-images.githubusercontent.com/22030149/59081460-c6df6a00-8920-11e9-8448-6e368ef5d573.png)

I think this is quite related to #29442 . The keras layers add variables during the first call. If the first call is inside `tf.function`, these variables are created in a graph and some unexpected behaviors happen as reported in #29442 .

Uncommenting `y = model(x)` makes sure that the model variables are created in eager mode, and uncommenting `train.python_function(x)` makes sure that optimizer-related variables are also created in eager mode."
29213,GPU OOM error when using keras and distributions strategy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly-gpu==1.14.1.dev20190524
- Python version: Python 3.7.3
- CUDA/cuDNN version: CUDA 10, CUDNN 7.4.2.24
- GPU model and memory: 4 x NVIDIA V100

**Describe the current behavior**
Using `tf.distribute.MirroredStrategy()` together with Keras to train models as described in https://www.tensorflow.org/alpha/tutorials/distribute/keras results in GPU out of memory errors appearing after several epochs of training. We excluded our custom written code as the source of the memory leaks and made sure that the model actually fits into memory with enough headroom. It seams that either `tf.data` or `tf.keras.metrics` have a memory leak that starts showing up after several epochs of training and evaluation.

**Describe the expected behavior**
Tensorflow doesn't throw OOM errors.

**Code to reproduce the issue**
Unfortunately I cannot give a concrete code example to reproduce this issue since memory leaks appear anytime in between 10min to 12h of training. Though I am happy to provide more information and would be eager to get suggestions on how to properly debug this problem.

**Other info / logs**
```python traceback
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 644, in fit
use_multiprocessing=use_multiprocessing)
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_distributed.py"", line 899, in fit
validation_freq=validation_freq)
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_distributed.py"", line 149, in fit_distributed
steps_name='steps_per_epoch')
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_arrays.py"", line 409, in model_iteration
steps_name='validation_steps')
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_arrays.py"", line 274, in model_iteration
batch_outs = f(actual_inputs)
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py"", line 3351, in __call__
run_metadata=self.run_metadata)
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py"", line 1458, in __call__
run_metadata_ptr)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
(0) Resource exhausted: Failed to allocate memory for the batch of component 0

[[{{node MultiDeviceIteratorGetNextFromShard}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
[[RemoteCall]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
[[IteratorGetNext_7]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
(1) Resource exhausted: Failed to allocate memory for the batch of component 0
[[{{node MultiDeviceIteratorGetNextFromShard}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
[[RemoteCall]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
[[IteratorGetNext_7]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
[[metrics_4/categorical_accuracy/Identity_2/_3447]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
0 successful operations.
3 derived errors ignored.
```
"
29212,[TF 2.0 API Docs] tf.queue.FIFOQueue,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/queue/FIFOQueue

## Description of issue (what needs changing):

Some methods not provides raising error lists

### Raises listed and defined

* dequeue
* dequeue_many
* dequeue_up_to
* enqueue
* enqueue_many

### Submit a pull request?
I will

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29210,[TF 2.0 API Docs] tf.dtypes.cast,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/dtypes/cast

## Description of issue (what needs changing):

### Usage example

Is there a usage example?
the example: 
```python
x = tf.constant([1.8, 2.2], dtype=tf.float32)
tf.cast(x, tf.int32)  # [1, 2], dtype=tf.int32
```
is not correct.  
It need to change ```tf.cast``` to ```tf.dtypes.cast```.

this is correct example
```python
x = tf.constant([1.8, 2.2], dtype=tf.float32)
tf.dtypes.cast(x, tf.int32)  # [1, 2], dtype=tf.int32
```

### Submit a pull request?

https://github.com/tensorflow/tensorflow/pull/29214

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
29209,[TF 2.0 API Docs] tf.keras.layers.Conv2D,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D

## Description of issue (what needs changing):


### Correct links

https://www.tensorflow.org/alpha/tutorials/distribute/multi_worker is incorrect. 
It has 404 error.

### Parameters defined

**kwargs is not defined.

### Raises listed and defined

Errors are not defined.

### Usage example

No usage example is provided.

### Request visuals, if applicable

No visuals are included.

"
29208,build micro_speech error,"Deep Learning VM  images/tf-2-0-cpu-experimental-20190502
```bash
googcheng@tensorflow-4-vm:~$ git clone https://github.com/tensorflow/tensorflow.git
Cloning into 'tensorflow'...
remote: Enumerating objects: 2167, done.
remote: Counting objects: 100% (2167/2167), done.
remote: Compressing objects: 100% (845/845), done.
remote: Total 598119 (delta 1392), reused 1643 (delta 1320), pack-reused 595952
Receiving objects: 100% (598119/598119), 343.85 MiB | 47.04 MiB/s, done.
Resolving deltas: 100% (483846/483846), done.
googcheng@tensorflow-4-vm:~$ ls
tensorflow
googcheng@tensorflow-4-vm:~$ cd tensorflow/
googcheng@tensorflow-4-vm:~/tensorflow$ ls
ACKNOWLEDGMENTS     AUTHORS             CODEOWNERS    CONTRIBUTING.md    LICENSE       RELEASE.md   third_party
ADOPTERS.md         BUILD               configure     ISSUES.md          models.BUILD  SECURITY.md  tools
arm_compiler.BUILD  CODE_OF_CONDUCT.md  configure.py  ISSUE_TEMPLATE.md  README.md     tensorflow   WORKSPACE
googcheng@tensorflow-4-vm:~/tensorflow$ bazel run -c opt --copt=-mavx2 --copt=-mfma \
> tensorflow/examples/speech_commands:train -- \
> --model_architecture=tiny_conv --window_stride=20 --preprocess=average \
> --wanted_words=""yes,no"" --silence_percentage=25 --unknown_percentage=25 --quantize=1
Extracting Bazel installation...
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=112
INFO: Reading rc options for 'run' from /home/googcheng/tensorflow/.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
ERROR: /home/googcheng/.cache/bazel/_bazel_googcheng/c7d71bbdf8501e4441f5b58bb2db4ae1/external/io_bazel_rules_closure/closure/protobuf/closure_proto_library.bzl:66:21: name 'ProtoInfo' is not defined (did you mean 'protos'?)
ERROR: error loading package '': Extension 'closure/protobuf/closure_proto_library.bzl' has errors
ERROR: error loading package '': Extension 'closure/protobuf/closure_proto_library.bzl' has errors
INFO: Elapsed time: 5.973s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
FAILED: Build did NOT complete successfully (0 packages loaded)
googcheng@tensorflow-4-vm:~/tensorflow$ git log
commit 94feeb1c0ade3c673a758c0794e19c82b6e868b6
Author: Tiezhen WANG <wangtz@google.com>
Date:   Fri May 31 03:18:30 2019 -0700

    nit remove unnecessary indirection in all_ops_resolver.
    
    PiperOrigin-RevId: 250856298

commit b1a535b3abc11de5e00f5b40b2a7f795b7160376
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri May 31 02:49:19 2019 -0700

    Test that tf.saved_model.load() does not add to the TRAINABLE_VARIABLES
    collection and add a comment why. There is no change in behavior.
```"
29207,TFL GPU gpu::gl::reshape Is attr redundant?,"I'm trying to write a few test cases for `gl::reshape` and noticed that `attr` appears to be of not much use. The only use I can find is [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/gl/kernels/reshape.cc#L49-L52):

```
    if (attr.new_shape != output->tensor.shape) {
      return InvalidArgumentError(
          ""Dimensions for output does not match new_shape attribute"");
    }
```

But `attr.new_shape` always take the tensor shape of the output ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/common/model_builder.cc#L811)). Under what circumstances, if any, would the matching `attr.new_shape` against `output->tensor.shape` fail?"
29206,Deep Learning VM  train failed,"on GCP
('v1.13.1-1-g0bcc025', '1.13.1')

```
# TensorFlow already pre-baked on the image
cd src/tensorflow
bazel run -c opt --copt=-mavx2 --copt=-mfma \
tensorflow/examples/speech_commands:train -- \
--model_architecture=tiny_conv --window_stride=20 --preprocess=average \
--wanted_words=""yes,no"" --silence_percentage=25 --unknown_percentage=25 --quantize=1
```

In file included from ./tensorflow/core/profiler/internal/tfprof_show.h:32:0,
                 from ./tensorflow/core/profiler/internal/tfprof_show_multi.h:32,
                 from ./tensorflow/core/profiler/internal/tfprof_code.h:31,
                 from ./tensorflow/core/profiler/internal/tfprof_stats.h:37,
                 from tensorflow/core/profiler/internal/tfprof_stats.cc:16:
./tensorflow/core/profiler/internal/tfprof_tensor.h: In member function 'bool tensorflow::tfprof::TFProfTensor::AddValue(const T&, tensorflow::tfprof::TFProfTensorProto*)':
./tensorflow/core/profiler/internal/tfprof_tensor.h:79:3: warning: no return statement in function returning non-void [-Wreturn-type]
   }
   ^
In file included from ./tensorflow/core/profiler/internal/tfprof_stats.h:40:0,
                 from tensorflow/core/profiler/internal/tfprof_stats.cc:16:
./tensorflow/core/profiler/internal/tfprof_op.h: In member function 'virtual bool tensorflow::tfprof::TFOp::ShouldShowIfExtra(const tensorflow::tfprof::ShowMultiNode*, const tensorflow::tfprof::Options&, int) const':
./tensorflow/core/profiler/internal/tfprof_op.h:60:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     if (opts.min_occurrence > node->node->graph_nodes().size()) {
         ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO: From Compiling tensorflow/core/kernels/tensor_forest/resources.cc [for host]:
In file included from ./tensorflow/core/platform/default/logging.h:24:0,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/core/status.h:25,
                 from ./tensorflow/core/lib/core/errors.h:21,
                 from ./tensorflow/core/framework/tensor_shape.h:23,
                 from ./tensorflow/core/framework/partial_tensor_shape.h:20,
                 from ./tensorflow/core/framework/attr_value_util.h:23,
                 from ./tensorflow/core/framework/node_def_util.h:22,
                 from ./tensorflow/core/framework/shape_inference.h:20,
                 from ./tensorflow/core/framework/common_shape_fns.h:20,
                 from ./tensorflow/core/framework/resource_mgr.h:25,
                 from ./tensorflow/core/kernels/tensor_forest/resources.h:19,
                 from tensorflow/core/kernels/tensor_forest/resources.cc:16:
./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':
./tensorflow/core/util/tensor_format.h:452:47:   required from here
./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   CHECK(index >= 0 && index < dimension_attributes.size())
                              
./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))
                                               ^
./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'
   CHECK(index >= 0 && index < dimension_attributes.size())
   ^
./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':
./tensorflow/core/util/tensor_format.h:461:54:   required from here
./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   CHECK(index >= 0 && index < dimension_attribute.size())
                              
./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))
                                               ^
./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'
   CHECK(index >= 0 && index < dimension_attribute.size())
   ^
ERROR: /opt/deeplearning/src/tensorflow/tensorflow/core/kernels/BUILD:3206:1: C++ compilation of rule '//tensorf
low/core/kernels:reduction_ops' failed (Exit 1)
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:124:0,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/kernels/reduction_ops_common.h:27,
                 from tensorflow/core/kernels/reduction_ops_sum.cc:16:
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h: In static member function 'static v
oid std::_Function_handler<void(_ArgTypes ...), _Functor>::_M_invoke(const std::_Any_data&, _ArgTypes&& ...) [wi
th _Functor = Eigen::internal::TensorExecutor<Expression, Eigen::ThreadPoolDevice, Vectorizable, Tileable>::run(
const Expression&, const Eigen::ThreadPoolDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorM
ap<Eigen::Tensor<std::complex<float>, 0, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<E
igen::internal::SumReducer<std::complex<float> >, const Eigen::IndexList<Eigen::type2index<0l> >, const Eigen::T
ensorMap<Eigen::Tensor<const std::complex<float>, 1, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer> 
>; bool Vectorizable = true; bool Tileable = false]::<lambda(Eigen::internal::TensorExecutor<const Eigen::Tensor
AssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 0, 1, long int>, 16, Eigen::MakePointer>, const Eig
en::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::IndexList<Eigen::type2inde
x<0l> >, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 1, 1, long int>, 16, Eigen::MakePointer
>, Eigen::MakePointer> >, Eigen::ThreadPoolDevice, true, false>::StorageIndex, Eigen::internal::TensorExecutor<c
onst Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 0, 1, long int>, 16, Eigen::MakeP
ointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::IndexLis
t<Eigen::type2index<0l> >, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 1, 1, long int>, 16, 
Eigen::MakePointer>, Eigen::MakePointer> >, Eigen::ThreadPoolDevice, true, false>::StorageIndex)>; _ArgTypes = {
long int, long int}]':
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h:801:9: internal compiler error: in e
mit_move_insn, at expr.c:3547
         values[i] = internal::InnerMostDimReducer<Self, Op>::reduce(*this, firstIndex + i * num_values_to_reduc
e,
         ^~~~~~
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-6/README.Bugs> for instructions.
Target //tensorflow/examples/speech_commands:train failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1790.965s, Critical Path: 244.43s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, 
process: 0.00%]
INFO: 3599 processes: 3599 local.
FAILED: Build did NOT complete successfully


"
29203,how to use interactive_graphviz for xla?,"in [xla doc](https://www.tensorflow.org/xla/jit#tutorial) it suggest that 

> /tmp/foo will contain the HLO before and after optimizations for each HLO module that's run. You can read this as-is, or you can visualize it using tensorflow/compiler/xla/tools:interactive_graphviz.

but I cannot locate this binary."
29202,Could you provide the weight pruning code for MobileNetV1 and InceptionV3?,
29199,model pruning about conv3d ?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
29198,[2.0] SparseTensor shape becomes none after AutoGraph,"The bug is found with `tf-nightly-gpu-2.0-preview (2.0.0.dev20190530)`.

To reproduce:

<pre>
import tensorflow as tf

x = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])

def foo(q):
  print(q.shape)

foo(x)                              # Output: (3,4)
tf.function(foo)(x)                 # Output: (None, None)
</pre>

The version `2.0.0alpha0` does not have this bug."
29196,To unify the regularizer in keras layer and variable_scope.py?,"**System information**
- TensorFlow version (you are using): master
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**
Don't change current api.

**Who will benefit with this feature?**
I think the regularizer should be declared with variables creation. It is reasonable to put them in variable_scope.py after one atomic variable's creation. But Keras Layer also has the regularization construction after weights' creation and it almost the same with in the variable_scope. 
To unify the regularizer and reserve the logic in variable_scope.py will benefit `DistributionStrategy`. Because when we create one `MirroredVariable`, the corresponding all regularizations should also be created. We can get them from `GraphKeys.REGULARIZATION_LOSS` and wrap them with `Mirrored` type and replace in the `tf.collections`.

**Any Other info.**
I don't know whether it is suitable to make this change because `Keras` is highly recommended in TF2.0. But the same function in two different places is unnecessary. If you agree with me, I will try to contribute for this.
@lukaszkaiser @fchollet "
29195,can't deserialize tf.keras functional api created model,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-dev20190530
- Python version: 3.6.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.0
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I created [a model](https://github.com/breadbread1984/2DFAN4-tf2.0/blob/master/Model.py) with only tf.keras functional api. I can load parameters from [checkpoint](https://pan.baidu.com/s/13rEZz3CxaIOWHEeQaCfobg) (download password: bpy9) and inference with the model correctly. I convert the checkpoint to hdf5 model (graph with weights) with [this script](https://github.com/breadbread1984/2DFAN4-tf2.0/blob/master/save_model.py). When I load from the [hdf5 file](https://pan.baidu.com/s/1MN_HSvYiFDxFJqdbsUe5jQ) (download password: w2k6) with the code

```python
#!/usr/bin/python3
import tensorflow as tf;
model = tf.keras.models.load_model('model.h5');
```

I get error messsage that

> 2019-05-31 10:03:03.862129: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-05-31 10:03:03.866805: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-05-31 10:03:03.866861: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: xieyi-desktop
2019-05-31 10:03:03.866877: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: xieyi-desktop
2019-05-31 10:03:03.866957: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.104.0
2019-05-31 10:03:03.867003: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.104.0
2019-05-31 10:03:03.867019: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.104.0
2019-05-31 10:03:03.895878: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1995530000 Hz
2019-05-31 10:03:03.898224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6617f00 executing computations on platform Host. Devices:
2019-05-31 10:03:03.898260: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
Traceback (most recent call last):
  File ""Landmarker.py"", line 140, in <module>
    landmarker = Landmarker();
  File ""Landmarker.py"", line 18, in __init__
    self.model = tf.keras.models.load_model('model.h5');
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py"", line 146, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 215, in load_model_from_hdf5
    load_weights_from_hdf5_group(f['model_weights'], model.layers)
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 749, in load_weights_from_hdf5_group
    layer, weight_values, original_keras_version, original_backend)
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 374, in preprocess_weights_for_loading
    weights = convert_nested_model(weights)
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 350, in convert_nested_model
    original_backend=original_backend))
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 374, in preprocess_weights_for_loading
    weights = convert_nested_model(weights)
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 350, in convert_nested_model
    original_backend=original_backend))
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 374, in preprocess_weights_for_loading
    weights = convert_nested_model(weights)
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 350, in convert_nested_model
    original_backend=original_backend))
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 374, in preprocess_weights_for_loading
    weights = convert_nested_model(weights)
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 350, in convert_nested_model
    original_backend=original_backend))
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 374, in preprocess_weights_for_loading
    weights = convert_nested_model(weights)
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 362, in convert_nested_model
    original_backend=original_backend))
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 374, in preprocess_weights_for_loading
    weights = convert_nested_model(weights)
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 350, in convert_nested_model
    original_backend=original_backend))
  File ""/home/xieyi/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 455, in preprocess_weights_for_loading
    if K.int_shape(layer.weights[0]) != weights[0].shape:
IndexError: list index out of range

it is worth noting that the serialized model is 92 MB while the checkpoint model is over 500 MB.

**Describe the expected behavior**

I expect correct model loading behavior from both checkpoint and hdf5.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
#!/usr/bin/python3
import tensorflow as tf;
model = tf.keras.models.load_model('model.h5');
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29194,"When building quantize_graph in r1.14 with mkl, it shows ""nothing to build""","**System information**
- OS Platform and Distribution (CentOS 7):
- TensorFlow installed from (source or binary): https://github.com/tensorflow/tensorflow.git
- TensorFlow version: r1.14
- Python version: 3.6
- Installed using virtualenv? pip? conda?: Build from source
bazel build --config=mkl --copt=""-DEIGEN_USE_VML"" -s -c opt //tensorflow/tools/pip_package:build_pip_package can work
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 6.3


**Describe the problem**
Trying
bazel build --config=mkl --copt=""-DEIGEN_USE_VML"" -c opt tensorflow/contrib/quantize:quantize_graph

It shows
Target //tensorflow/contrib/quantize:quantize_graph up-to-date (nothing to build)
I can't find quantize_graph binary after built.
"
29191,tf.function spuriously fails for branched super() calls,"`tf.function` fails spuriously under Python 3.7.3 for the following example:

```python
import tensorflow as tf

class Base(tf.Module):
    def __call__(self, x):
        return x + 1.

class Sub(Base):
    def __call__(self, x):
        return super().__call__(x) if True else 1.

@tf.function
def test():
    return Sub()(tf.constant(42.))

print(test())

```

(Colab: https://colab.research.google.com/drive/1_pS1K0biwse1oTIuuEv0lZYavbE61HAP)

This produces the following error:
```python
RuntimeError: in converted code:

    bug.py:16 test  *
        return Sub()(tf.constant(42.))
    bug.py:12 __call__  *
        return super().__call__(x) if True else 1.

    RuntimeError: super(): no arguments
```

**Observations**

- Everything works correctly without the `tf.function` decoration
- The branch in `__call__` seems necessary to trigger the bug. Skipping the branch doesn't trigger it. Replacing `True` with `False` doesn't trigger it.
- The bug can be triggered even if the condition evaluates to False (for example, replacing `True` with `x < 0` for `x=42`)
- Replacing `tf.constant(42.)` with `42.` doesn't trigger the bug

Tested on TensorFlow 2.0 nightly `2.0.0-dev20190529` on Ubuntu `16.04` with Python `3.7.3`
"
29189,Keras LSTM does not work with tf.distribute [2.0],"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Minor tweak to tutorial code.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.
- TensorFlow version (use command below): tf-nightly-gpu-2.0-preview
- Python version: 3.6
- CUDA/cuDNN version: 10.0/7.4

I copy-pasted [this tutorial code](https://www.tensorflow.org/alpha/tutorials/distribute/multi_worker) (MNIST distributed training with TF2.0) but used tf.distribute.MirroredStrategy() (instead of MultiWorker). It worked. Then I changed the model architecture to a simple Embedding -> LSTM -> Dense architecture. It broke with the following errror: 

```
Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: /job:worker/replica:0/task:0/device:GPU:0 vs /job:worker/replica:0/task:0/device:CPU:0. The edge src node is while_22/exit/_100 , and the dst node is while_0_RetVal
	 [[node sequential/lstm/StatefulPartitionedCall (defined at tf2_multiworker_tutorial/main.py:109) ]]
```

This was executed on a remote cluster single-machine with 2 GPUs. Note that I've been seeing this error ever since the initial 2.0 alpha release. The code is as follows:

```python
import tensorflow as tf

BUFFER_SIZE = 10000
BATCH_SIZE = 64
LEARNING_RATE = 1e-4


def input_fn(mode, input_context=None):
    max_seq_len = 3
    rnn_dataset = tf.data.Dataset\
        .range(10)\
        .repeat(10 * BUFFER_SIZE) \
        .map(lambda x: (
        tf.ones(shape=(max_seq_len,), dtype=tf.int64),
        tf.ones(shape=(max_seq_len,), dtype=tf.int64)))
    if input_context:
        rnn_dataset = rnn_dataset.shard(
            input_context.num_input_pipelines,
            input_context.input_pipeline_id)
    return rnn_dataset.batch(BATCH_SIZE)


def model_fn(features, labels, mode):
    vocab_size = 100
    embed_size = 16
    state_size = 7
    model = tf.keras.Sequential([
        tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_size),
        tf.keras.layers.LSTM(units=state_size, return_sequences=True),
        tf.keras.layers.Dense(10, activation='softmax')])
    logits = model(features, training=False)

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(
            tf.estimator.ModeKeys.PREDICT,
            predictions={'logits': logits})

    optimizer = tf.compat.v1.train.GradientDescentOptimizer(
        learning_rate=LEARNING_RATE)
    loss = tf.keras.losses.SparseCategoricalCrossentropy(
        from_logits=True,
        reduction=tf.keras.losses.Reduction.NONE)
    loss = tf.reduce_sum(loss(labels, logits)) * (1. / BATCH_SIZE)
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode, loss=loss)

    return tf.estimator.EstimatorSpec(
        mode=mode, loss=loss,
        train_op=optimizer.minimize(
            loss, tf.compat.v1.train.get_or_create_global_step()))


def main():
    strategy = tf.distribute.MirroredStrategy()
    config = tf.estimator.RunConfig(
        train_distribute=strategy,
        log_step_count_steps=1)

    classifier = tf.estimator.Estimator(
        model_fn=model_fn, model_dir='/tmp/multiworker', config=config)
    tf.estimator.train_and_evaluate(
        classifier,
        train_spec=tf.estimator.TrainSpec(input_fn=input_fn, max_steps=10),
        eval_spec=tf.estimator.EvalSpec(input_fn=input_fn))


if __name__ == '__main__':
    main()
```

Again, the common theme I've observed is that if tf.keras.LSTM is part of my model and I'm using tf.distribute, it breaks with this error. Otherwise, it works just fine."
29187,TF 2.0: Cannot use recurrent_dropout with LSTMs/GRUs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No (one line modification to stock example)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tensorflow-gpu==2.0.0-alpha0 (also fails with every other tf 2.0 build I have explored)
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: Tried multiple
- GPU model and memory: Tried multiple

**Describe the current behavior**
The program crashes with a TypeError as below:

`TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: encoder/unified_gru/ones_like:0`

This occurs when trying to backprop the gradients through the LSTM/GRU with `recurrent_dropout` enabled.

**Describe the expected behavior**
No error

**Code to reproduce the issue**
Since this problem shows up at the time of training, one needs to have the entire training pipeline (dataset, model etc.) setup to demonstrate this bug. As a result, I used the [Neural Machine Translation tutorial](https://www.tensorflow.org/alpha/tutorials/text/nmt_with_attention) from TensorFlow and modified their model to include `recurrent_dropout`. The entire code can be found in [this Colab notebook](https://colab.research.google.com/drive/1dLE58i2tttY6J_Yr8dX8f57Ai0_54kTE); run the code blocks all the way till the block where we're training the model to see the bug.

**Other info.logs**
<pre>
x---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-26-fa5128338d20> in <module>()
      8 
      9   for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):
---> 10     batch_loss = train_step(inp, targ, enc_hidden)
     11     total_loss += batch_loss
     12 

6 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    436         # Lifting succeeded, so variables are initialized and we can run the
    437         # stateless function.
--> 438         return self._stateless_fn(*args, **kwds)
    439     else:
    440       canon_args, canon_kwds = self._canonicalize_function_inputs(args, kwds)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   1286     """"""Calls a graph function specialized to the inputs.""""""
   1287     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 1288     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1289 
   1290   @property

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs)
    572     """"""
    573     return self._call_flat(
--> 574         (t for t in nest.flatten((args, kwargs))
    575          if isinstance(t, (ops.Tensor,
    576                            resource_variable_ops.ResourceVariable))))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args)
    625     # Only need to override the gradient in graph mode and when we have outputs.
    626     if context.executing_eagerly() or not self.outputs:
--> 627       outputs = self._inference_function.call(ctx, args)
    628     else:
    629       self._register_gradient()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args)
    413             attrs=(""executor_type"", executor_type,
    414                    ""config_proto"", config),
--> 415             ctx=ctx)
    416       # Replace empty list with None
    417       outputs = outputs or None

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     68     if any(ops._is_keras_symbolic_tensor(x) for x in inputs):
     69       raise core._SymbolicException
---> 70     raise e
     71   # pylint: enable=protected-access
     72   return tensors

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,
     59                                                op_name, inputs, attrs,
---> 60                                                num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: encoder/unified_gru/ones_like:0
</pre>"
29183,Test cases for GPU delegate GL ops,"**System information**
- TensorFlow version (you are using): 0.0.1-gpu
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

I was going through the GL ops and noticed that test cases are available for just 3 ops (`add`, `elementwise` and `relu`). Will test cases be available for ops like `reshape`?

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Anyone trying to debug GPU delegate ops.

"
29178,[TF2] Variable List Shape,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): `pip install tf-nightly-2.0-preview`
- TensorFlow version (use command below): `v1.12.1-2995-ge09b015 2.0.0-dev20190530`
- Python version: 3.8

**Describe the current behavior**
Right now, the `tf.Variable` constructor accepts a list as a shape -- but if you do this, then calls to `.assign` raise an error. 

**Describe the expected behavior**
Either `tf.Variable` should automatically convert the list to a `tf.TensorShape` (or it could raise a type error for a list shape, but that seems significantly less ergonomic).

**Code to reproduce the issue**
The following code:

```python
import tensorflow as tf

x = tf.Variable(tf.zeros([50, 50]), shape=[None, 50])
x.assign(tf.zeros([10, 50]))
```

fails with:
```python
Traceback (most recent call last):
  File ""a.py"", line 4, in <module>
    x.assign(tf.zeros([10, 50]))
  File ""/opt/anaconda/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1145, in assign
    self._shape.assert_is_compatible_with(value_tensor.shape)
AttributeError: 'list' object has no attribute 'assert_is_compatible_with'
```

If I use `shape=tf.TensorShape([None, 50])` then this works just fine."
29171,tensorflow v1.13.1 build issue on Windows 10,"I am new to tensorflow and got the cuda version issue while build from source using bazel.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): source 
- TensorFlow version: 1.13.1
- Python version: 3.6.3
- Bazel version (if compiling from source): 0.19.2
- CUDA/cuDNN version: cuda(v10.0) cudnn(7.6.0)

**Any other info / logs**
F:\Work\VS\DNN\tensorflow-1.13.1>bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package
WARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:
f:\work\vs\dnn\tensorflow-1.13.1/.bazelrc
WARNING: detected http_proxy set in env, setting no_proxy for localhost.
Starting local Bazel server and connecting to it...
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
WARNING: Option 'experimental_shortened_obj_file_path' is deprecated
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
        File ""F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl"", line 1556
                _create_local_cuda_repository(repository_ctx)
        File ""F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl"", line 1265, in _create_local_cuda_repository
                _get_cuda_config(repository_ctx)
        File ""F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl"", line 964, in _get_cuda_config
                _cuda_version(repository_ctx, toolkit_path, cpu_va...)
        File ""F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl"", line 521, in _cuda_version
                auto_configure_fail((""CUDA version detected from nvc...)))
        File ""F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl"", line 342, in auto_configure_fail
                fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: CUDA version detected from nvcc (10.0.130) does not match TF_CUDA_VERSION (C:Program FilesNVIDIA GPU Computing ToolkitCUDAv10.0)
WARNING: Target pattern parsing failed.
ERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
        File ""F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl"", line 1556
                _create_local_cuda_repository(repository_ctx)
        File ""F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl"", line 1265, in _create_local_cuda_repository
                _get_cuda_config(repository_ctx)
        File ""F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl"", line 964, in _get_cuda_config
                _cuda_version(repository_ctx, toolkit_path, cpu_va...)
        File ""F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl"", line 521, in _cuda_version
                auto_configure_fail((""CUDA version detected from nvc...)))
        File ""F:/work/vs/dnn/tensorflow-1.13.1/third_party/gpus/cuda_configure.bzl"", line 342, in auto_configure_fail
                fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: CUDA version detected from nvcc (10.0.130) does not match TF_CUDA_VERSION (C:Program FilesNVIDIA GPU Computing ToolkitCUDAv10.0)
INFO: Elapsed time: 3.871s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/tools/pip_package

"
29170,Unable to serialize dict that is wrapped around tracking `_DictWrapper`,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0-rc0
- Python version: 3.7
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
`dict` objects wrapped around `_DictWrapper` by `AutoTrackable` are not serializable by pickle.

**Describe the expected behavior**
`dict` objects wrapped around `_DictWrapper` by `AutoTrackable` are serializable by pickle.

**Code to reproduce the issue**
```python
import pickle
import tensorflow as tf
from tensorflow.python.training.tracking.tracking import AutoTrackable


class MyTrackable(AutoTrackable):
    def __init__(self):
        self.random_op = {
            'tf.trandom.uniform(())': tf.random.uniform(())
        }


def main():
    my_trackable = MyTrackable()
    value = tf.Session().run(my_trackable.random_op)
    print(type(value))
    pickle.dumps(value)


if __name__ == '__main__':
    main()
```
This fails with the following error:
```
$ python ./dict_wrapper_test.py
<class 'tensorflow.python.training.tracking.data_structures._DictWrapper'>
Traceback (most recent call last):
  File ""./tests/dict_wrapper_test.py"", line 20, in <module>
    main()
  File ""./tests/dict_wrapper_test.py"", line 16, in main
    pickle.dumps(value)
NotImplementedError: object proxy must define __reduce_ex__()
```

Not exactly sure if this is a bug or a feature. Should the built-in data structures that are tracked be serializable?"
29168,Can't convert .pb to .tflite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):source
- TensorFlow version (or github SHA if from source):1.13.1
- Bazel version (if compiling from source): 0.22.0
- Python version: 3.6.7

**Command** 
./bazel-bin/tensorflow/lite/toco/toco --input_file=test.pb --output_file=test.tflite 
--input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_arrays=input 
--input_shapes=1,416,416,3 --output_arrays=output

**Provide the text output from tflite_convert**

2019-05-30 23:21:21.565311: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ExtractImagePatches
2019-05-30 23:21:21.615470: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 211 operators, 370 arrays (0 quantized)
2019-05-30 23:21:21.618923: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 211 operators, 370 arrays (0 quantized)
2019-05-30 23:21:22.132104: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 97 operators, 189 arrays (0 quantized)
2019-05-30 23:21:22.133428: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 97 operators, 189 arrays (0 quantized)
2019-05-30 23:21:22.134795: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 68550208 bytes, theoretical optimal value: 66453504 bytes.
2019-05-30 23:21:22.135184: E tensorflow/lite/toco/toco_tooling.cc:421] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, MAXIMUM, MAX_POOL_2D, MUL, PAD. Here is a list of operators for which you will need custom implementations: ExtractImagePatches.

"
29165,"Unicode op tests fail on s390x with ""Could not create converter for input encoding: SHIFT-JIS"" error","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 s390x
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): v1.131.
- Python version: 2.7.15rc1
- Bazel version (if compiling from source): 0.20.0
- GCC/Compiler version (if compiling from source): gcc 7.4
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
`python ./tensorflow/python/kernel_tests/unicode_decode_op_test.py` fails with following error:

InvalidArgumentError (see above for traceback): Could not create converter for input encoding: SHIFT-JIS
         [[node UnicodeDecodeWithOffsets/UnicodeDecodeWithOffsets (defined at /usr/local/lib/python2.7/dist-packages/absl/testing/parameterized.py:264) ]]

**Describe the expected behavior**
This should pass like Intel. 

**Code to reproduce the issue**
bazel test -c opt //tensorflow/python/kernel_tests:unicode_decode_op_test OR 
bazel test -c opt //tensorflow/python/kernel_tests:unicode_transcode_op_test

**Other info / logs**
```
> iconv -l | grep -i shift
CSSHIFTJIS//
SHIFT-JIS//
SHIFT_JIS//
SHIFT_JISX0213//
```
Error logs are updated
[unicode_decode_logs.log](https://github.com/tensorflow/tensorflow/files/3237313/unicode_decode_logs.log)

Can anyone please tell us the impact of this failure on functionality? Also does anyone have any clue on this issue? Thanks in advance."
29163,Please provide the weight pruned InceptionV3 and MobileNetV1 models,"I want to try the compression performance of weight pruning of TensorFlow. Is it OK for you to provide the model after pruning? e.g., the 50% sparsity MobileNetV1?"
29162,tf.estimator.evaluate fails whith one_hot encoded labels,"



**System information**
- Linux Ubuntu 16.04:
- TensorFlow installed from binary
- TensorFlow version: b'v1.13.1-0-g6612da8951' 1.13.1
- Python version: 3.5.3
- CUDA/cuDNN version: NO CUDA
- GPU model and memory: NO GPU

**Describe the current behavior**

When working with one hot encoding, **tf.estimator.evaluate** thows:
`    ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for   'remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [?,10`].

**tf.estimator.train**  works fine


**Describe the expected behavior**
No ValueError

**Code to reproduce the issue**

I''ve changed the official CNN estimator ([https://www.tensorflow.org/tutorials/estimators/cnn](https://www.tensorflow.org/tutorials/estimators/cnn)) to work with _one_hot_ encoding on labels (only changing the _loss_ function)

```
# Calculate Loss (for both TRAIN and EVAL modes)
  loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)

```

I've aslo create dummy labels to test it:

```
train_labels = np.ones((train_data.shape[0],10))
eval_labels = np.ones((eval_data.shape[0],10))


"
29161,tf.keras predict stuck with Sequence when using multi-processing,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: TITAN

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Hi,

When using tf.keras with a custom Sequence, the program hangs during predict (with multi-processing). 
I was able to reproduce the issue with a simple NN that contains a single Dense layer.
This happens after setting the weights of the layer and running predict with multi-processing.
When commenting the 'set_weights' line or running with multi-threading, the program does not hang.
Issue exists also in 1.14.0-rc0,
Same code works OK with tensorflow 1.12.0 and 2.0.0a0.

**Code to reproduce the issue**
```
import numpy as np
from tensorflow import keras

INPUT_SIZE = 3
DENSE_OUTPUTS = 2
NUM_OF_SAMPLES = 1000
BATCH_SIZE = 2
NUM_OF_BATCHES = 5


class DummySequence(keras.utils.Sequence):

    def __len__(self):
        return NUM_OF_SAMPLES // BATCH_SIZE

    def __getitem__(self, index):
        data = [np.full(shape=(INPUT_SIZE,), fill_value=(index*BATCH_SIZE + i)) for i in range(BATCH_SIZE)]
        labels = [np.full(shape=(DENSE_OUTPUTS,), fill_value=(index*BATCH_SIZE + i))*INPUT_SIZE for i in range(BATCH_SIZE)]
        return np.stack(data), np.stack(labels)



x = keras.layers.Input(shape=(INPUT_SIZE,))
dense_layer = keras.layers.Dense(DENSE_OUTPUTS)
y = dense_layer(x)
model = keras.Model(x, y)

# remove comment in tf 1.12
#model.compile(optimizer=""sgd"", loss=keras.losses.mean_squared_error)

shapes = [v.shape for v in dense_layer.weights]
dense_layer.set_weights([np.full(shape=shapes[0], fill_value=1.0), np.full(shape=shapes[1], fill_value=0.0)])

seq = DummySequence()

workers = 5
multiprocessing = True
# works with multi-threaing
#multiprocessing = False
print(""running predict with multiprocessing: {}"".format(multiprocessing))
res = model.predict(seq, workers=workers, use_multiprocessing=multiprocessing, steps=NUM_OF_BATCHES)
print(""predict # of results: {}\nresults:\n{}"".format(len(res), res))

```


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29160,"[TF 2.0 API Docs] Some ""Defied in"" links are broken","## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRU
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRUCell
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM
Also including (but probably not limited to) other recurrent Keras layers.
## Description of issue (what needs changing):
It seems that API docs are generated using `tf-nightly` builds (`master` branch). However, links that define source code of API endpoints lead to `tensorflow==2.0.0-alpha0` build (`r2.0` branch), however using file structure of `master` branch. It causes some 404 errors (see example below).
### Clear description
This problem affects (at least) documentation of all the recurrent tf.keras.layers. For example, on [tf.keras.GRU page](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRU) section ""Defined in"" leads to [https://github.com/tensorflow/tensorflow/tree/**r2.0**/tensorflow/python/keras/layers/recurrent_v2.py](https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/python/keras/layers/recurrent_v2.py). 
This file does not exist in `r2.0`, but it exists in `master`: [https://github.com/tensorflow/tensorflow/tree/**master**/tensorflow/python/keras/layers/recurrent_v2.py](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/keras/layers/recurrent_v2.py)
### Correct links
**Is the link to the source code correct?**
No - see the section above for details.
### Submit a pull request?
I'm pretty sure that docs generation script is ok, but there's some kind of misconfiguration problem."
29159,TFLite GPU supported ops not working,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Oneplus3, Poco F1
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13
- Python version: 3.6.8
- Bazel version (if compiling from source): NIL
- GCC/Compiler version (if compiling from source): NIL
- CUDA/cuDNN version: NIL
- GPU model and memory: NIL

**Describe the current behavior**
Some of the GPU supported TFLite ops, does not run in GPU properly. On CPU it behaves properly and each time with a different combination even with supported ops, the behavior of the model changes and even not able to benchmark it to find the issues. Moreover, fall back mechanism is also not followed, if it is not running in GPU.

**Describe the expected behavior**
TFLite GPU supported ops, must run in GPU. If there are unsupported ops in the graph for which execution cannot be done, execution must fall back to CPU. 

**Code to reproduce the issue**
We have tried appending some nodes on top of Deeplab gpu converted model. All appended nodes are still supported ops by GPU Delegate. We have attached with this issue, the graph and the error log while trying to benchmark the TFLite model.

**Attachments**

**Error Log**

**Command:**
`adb shell taskset f0 /data/local/tmp/benchmark_model --graph=/data/local/tmp/retest_9_27.tflite --enable_op_profiling=true --use_gpu=true`

**Output**
STARTING!
Min num runs: [50]
Min runs duration (seconds): [1]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/data/local/tmp/retest_9_27.tflite]
Input layers: []
Input shapes: []
Use nnapi : [0]
Use legacy nnapi : [0]
Use gpu : [1]
Allow fp16 : [0]
Enable op profiling: [1]
Loaded model /data/local/tmp/retest_9_27.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for GPU.
ERROR: TfLiteGpuDelegate Prepare: Dimension can not be reduced to linear.
ERROR: Node number 93 (TfLiteGpuDelegate) failed to prepare.

Failed to apply GPU delegate.
Aborted 

**File to reproduce the issue**
[retest_9_27.tflite.zip](https://github.com/tensorflow/tensorflow/files/3235853/retest_9_27.tflite.zip)
"
29157,Add implementation of LAYER conv1d_transpose,"Would it be possible that someone implements a conv1d_transpose layer? 

There is a tf.contrib.nn.conv1d_transpose implementation but it has many problems, such as the need for hardcoding batch size. 

**System information**
- TensorFlow version (you are using): 1.3
- Are you willing to contribute it (Yes/No): Yes.


**Will this change the current api? How?**
It will create a new implementation of a layer.

**Who will benefit with this feature?**
Many users, in particular people working on 1d time series, etc. 
"
29156,the cloud TPU training is trapped and do nothing ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux instance-1 4.9.0-8-amd64 #1 SMP Debian 4.9.130-2 (2018-10-27) x86_64 GNU/Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip installed
- TensorFlow version (use command below): 1.13
- Python version: 3.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: NO GPU

**Describe the current behavior** 
training my model on the cloud TPU(3.8) through a VM instance.
The log is:
```
2019-05-30 02:33:14.644845: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:354] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
INFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']
INFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']
INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR

INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR

INFO:tensorflow:Init TPU system
INFO:tensorflow:Init TPU system
INFO:tensorflow:Initialized TPU in 1 seconds
INFO:tensorflow:Initialized TPU in 1 seconds
INFO:tensorflow:Starting infeed thread controller.
INFO:tensorflow:Starting infeed thread controller.
INFO:tensorflow:Starting outfeed thread controller.
INFO:tensorflow:Starting outfeed thread controller.
INFO:tensorflow:Enqueue next (80) batch(es) of data to infeed.
INFO:tensorflow:Enqueue next (80) batch(es) of data to infeed.
INFO:tensorflow:Dequeue next (80) batch(es) of data from outfeed.
INFO:tensorflow:Dequeue next (80) batch(es) of data from outfeed.

```
It looks like everything is ok.But after a period of waiting,I found there was 
no new checkpoint file wrote out on the bucket.
To my supprise is that **the monitor showing the memory usage of the TPU is about 6G,the cpu usage of the TPU is 0 and the cpu usage of the host VM is 0 too**!
Now that what are you doing my host VM and the costly TPU?
Anyone can help?

"
29155,when i use conv algorithm,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Debian
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.13.1,1.14.0，2.0.0a0，1.9.0
- Python version:3.7,3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:Cuda 10/7.5.0,7.4.2,7.4.1,7.4.0,Cuda 9 can't support 2060
- GPU model and memory:rtx 2060 6GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
conda activate base
2.0.0-alpha0
2019-05-29 19:58:31.543654: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-29 19:58:31.557759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-05-29 19:58:31.670769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-05-29 19:58:31.672348: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55c9b57a0a60 executing computations on platform CUDA. Devices:
2019-05-29 19:58:31.672364: I tensorflow/compiler/xla/service/service.cc:169] StreamExecutor device (0): Graphics Device, Compute Capability 7.5
2019-05-29 19:58:31.693201: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz
2019-05-29 19:58:31.693619: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55c9b580db30 executing computations on platform Host. Devices:
2019-05-29 19:58:31.693637: I tensorflow/compiler/xla/service/service.cc:169] StreamExecutor device (0): , 
2019-05-29 19:58:31.693791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties:
name: Graphics Device major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:01:00.0
totalMemory: 5.76GiB freeMemory: 5.17GiB
2019-05-29 19:58:31.693804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-05-29 19:58:31.693844: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-05-29 19:58:31.694402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-29 19:58:31.694413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021] 0
2019-05-29 19:58:31.694419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0: N
2019-05-29 19:58:31.694516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4990 MB memory) -> physical GPU (device: 0, name: Graphics Device, pci bus id: 0000:01:00.0, compute capability: 7.5)
Number of training examples: 60000
Number of test examples: 10000
Epoch 1/5
2019-05-29 19:58:32.786674: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.
2019-05-29 19:58:36.114172: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-05-29 19:58:36.288348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-05-29 19:58:36.934479: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-05-29 19:58:36.945020: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-05-29 19:58:36.945127: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[{{node conv2d/Conv2D}}]]

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29152,How to test a saved model trained with tf.train.batch?,"By calling

graph.get_tensor_by_name(""output:0"")
I found that it returns a tensor shaped [batch_size,num]，How to test a saved model trained with tf.train.batch ?"
29151,Training time for one epoch on TF 1.12 is almost 2 times slower than TF 1.5,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04) :Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.5 and 1.12
- Keras version: 2.2.4
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:CUDA 9.2/ cuDNN 7600
- GPU model and memory: T4 GPU with 15079MB memory

**Describe the current behavior**
Training time for one epoch on TF 1.12 is almost 2 times slower than TF 1.5 when using Keras layer.
I also tried to compare the training time using pure tensorflow layers, the speed is similar for TF1.12, TF1.5 and TF1.13. But I don't understand why the same Keras version will influent training time with different TF version


**Describe the expected behavior**
Training time for one epoch on TF 1.12 should be similar to  TF 1.5

**Code to reproduce the issue**
```
import tensorflow as tf
import keras
import numpy as np

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

train_images = train_images.repeat(10, axis=0)
train_labels = train_labels.repeat(10, axis=0)

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=5, batch_size=60000)
```

**Other info / logs**
on TF 1.5 machine:
```
Using TensorFlow backend.
Epoch 1/5
2019-05-29 18:11:32.262359: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-05-29 18:11:32.485841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-05-29 18:11:32.486163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
totalMemory: 14.73GiB freeMemory: 14.50GiB
2019-05-29 18:11:32.486194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
600000/600000 [==============================] - 4s 6us/step - loss: 10.4676 - acc: 0.3154
Epoch 2/5
600000/600000 [==============================] - 3s 4us/step - loss: 7.8949 - acc: 0.4803
Epoch 3/5
600000/600000 [==============================] - 3s 5us/step - loss: 7.5721 - acc: 0.4956
Epoch 4/5
600000/600000 [==============================] - 2s 4us/step - loss: 7.3566 - acc: 0.5021
Epoch 5/5
600000/600000 [==============================] - 3s 4us/step - loss: 6.2275 - acc: 0.5585
```
On TF 1.12 machine:
```
Using TensorFlow backend.
Epoch 1/5
2019-05-29 18:12:10.157740: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-29 18:12:10.397594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-05-29 18:12:10.398655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
totalMemory: 14.73GiB freeMemory: 14.50GiB
2019-05-29 18:12:10.398702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-05-29 18:12:10.938390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-29 18:12:10.938490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-05-29 18:12:10.938500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-05-29 18:12:10.938768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14028 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
600000/600000 [==============================] - 6s 10us/step - loss: 12.2835 - acc: 0.2249
Epoch 2/5
600000/600000 [==============================] - 5s 8us/step - loss: 9.9552 - acc: 0.3741
Epoch 3/5
600000/600000 [==============================] - 4s 7us/step - loss: 9.8548 - acc: 0.3857
Epoch 4/5
600000/600000 [==============================] - 5s 9us/step - loss: 9.4893 - acc: 0.4046
Epoch 5/5
600000/600000 [==============================] - 5s 8us/step - loss: 8.4112 - acc: 0.4727
```"
29144,"PyCharms can't resolve certain ""from"" imports","PyCharms doesn't provide suggestions for some of the TensorFlow imports. For example:

```python
from tensorflow.nn import rnn_cell
from tensorflow.keras import losses
```

In these cases, PyCharms doesn't provide suggestions for `rnn_cell` or `losses` members.

A potential solution for the `rnn_cell` import is to put API tree under root of TensorFlow pip package instead of under `_api/v1` or `_api/v2`. However, this won't fix suggestions for `keras` import since `keras` API is in a different directory and we create an alias for it under `tensorflow`.

This issue is a follow up from https://github.com/tensorflow/tensorflow/issues/26502."
29141,Import error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10 64 Bt
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): Anaconda
- TensorFlow version: 1.10
- Python version: 3.6.6
- Installed using virtualenv? pip? conda?: Conda
- Bazel version (if compiling from source): Anaconda
- GCC/Compiler version (if compiling from source): Anaconda
- CUDA/cuDNN version: no, because no GPU
- GPU model and memory: no GPU



**Describe the problem**

---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>()
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59   from tensorflow.python.pywrap_tensorflow_internal import __version__

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>()
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\imp.py in load_module(name, file, filename, details)
    242         else:
--> 243             return load_dynamic(name, filename, file)
    244     elif type_ == PKG_DIRECTORY:

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\imp.py in load_dynamic(name, path, file)
    342             name=name, loader=loader, origin=path)
--> 343         return _load(spec)
    344 

ImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-3-979e106fa729> in <module>()
----> 1 from keras import backend as K

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\keras\__init__.py in <module>()
      1 from __future__ import absolute_import
      2 
----> 3 from . import utils
      4 from . import activations
      5 from . import applications

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\keras\utils\__init__.py in <module>()
      4 from . import data_utils
      5 from . import io_utils
----> 6 from . import conv_utils
      7 
      8 # Globally-importable utils.

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\keras\utils\conv_utils.py in <module>()
      7 from six.moves import range
      8 import numpy as np
----> 9 from .. import backend as K
     10 
     11 

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\keras\backend\__init__.py in <module>()
     87 elif _BACKEND == 'tensorflow':
     88     sys.stderr.write('Using TensorFlow backend.\n')
---> 89     from .tensorflow_backend import *
     90 else:
     91     # Try and load external backend.

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\keras\backend\tensorflow_backend.py in <module>()
      3 from __future__ import print_function
      4 
----> 5 import tensorflow as tf
      6 from tensorflow.python.framework import ops as tf_ops
      7 from tensorflow.python.training import moving_averages

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\tensorflow\__init__.py in <module>()
     20 
     21 # pylint: disable=g-bad-import-order
---> 22 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
     23 
     24 try:

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\tensorflow\python\__init__.py in <module>()
     47 import numpy as np
     48 
---> 49 from tensorflow.python import pywrap_tensorflow
     50 
     51 # Protocol buffers

~\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>()
     72 for some common reasons and solutions.  Include the entire stack trace
     73 above this error message when asking for help."""""" % traceback.format_exc()
---> 74   raise ImportError(msg)
     75 
     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\andi\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\andi\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\andi\AppData\Local\Continuum\anaconda3\envs\myenv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\andi\AppData\Local\Continuum\anaconda3\envs\myenv\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\andi\AppData\Local\Continuum\anaconda3\envs\myenv\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.


**Provide the exact sequence of commands / steps that you executed before running into the problem**

from keras import backend as K

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29140,cannot import a pretrained mobilenet multiple times,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):1.12
- Python version:2.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1.105
- GPU model and memory: m60, 8gb

I am trying to use a pre-trained MobileNet for transfer learning however i am running into a problem when i am trying to run the same command the second time

    import tensorflow as tf
    try:
        del g1
    except:
        pass
    tf.reset_default_graph()
    g1 = tf.Graph() #or g1 = tf.get_default_graph() both result in same behavior
    with g1.as_default():
        base_model = tf.keras.applications.MobileNetV2(input_shape=(160,160,3),
                                                           include_top=False,
                                                           weights='imagenet')
I can run this cell in jupyter alright the first time but the second time i try to run this i get 
`TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(""Placeholder_207:0"", shape=(160,), dtype=float32) is not an element of this graph.`
However, I can run this cell multiple times perfectly fine

    base_model = tf.keras.applications.MobileNetV2(input_shape=(160,160,3),
                                                           include_top=False,
                                                           weights='imagenet')
"
29136,Batch Training for different input sizes,"
**System information**
- TensorFlow version (you are using): 2.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
For fully convolution networks training the network with different inputs sizes in batches is not supported, but could be changed.

**Will this change the current api? How?**
The optitmizers would need to be changed, such that the updates for the convolutional layer are summed for the different inputs.

**Who will benefit with this feature?**
People training fully convolutional networks. Padding of the input data could be completely avoided."
29135,tensorflow/tensorflow/lite/java/ovic/,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave v 10.14.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N.A.
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.3
- Bazel version (if compiling from source): 0.25.3
- GCC/Compiler version (if compiling from source): Apple LLVM version 10.0.1 (clang-1001.0.46.4)
- CUDA/cuDNN version: N.A.
- GPU model and memory: N.A.

**Describe the current behavior**
I have followed https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/java/ovic to test a model for OVIC2019 submission. I did this by clone the repository of tensorflow source code and typing the commands as shown below. It failed to pass the test.

**Describe the expected behavior**
Pass the test without bugs.

**Code to reproduce the issue**
`bazel test --cxxopt=--std=c++11 //tensorflow/lite/java/ovic:OvicClassifierTest --cxxopt=-Wno-all --test_output=all`

**Other info / logs**
```
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=191
INFO: Reading rc options for 'test' from /Users/liu/Desktop/tensorflow/.bazelrc:
  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
WARNING: /Users/liu/Desktop/tensorflow/tensorflow/lite/java/BUILD:81:12: in srcs attribute of android_library rule //tensorflow/lite/java:tensorflowlite_java: please do not import '//tensorflow/lite/delegates/nnapi/java/src/main/java/org/tensorflow/lite/nnapi:NnApiDelegate.java' directly. You should either move the file to this package or depend on an appropriate rule there
INFO: Analyzed target //tensorflow/lite/java/ovic:OvicClassifierTest (0 packages loaded, 0 targets configured).
INFO: Found 1 test target...
ERROR: /Users/liu/Desktop/tensorflow/tensorflow/lite/nnapi/BUILD:20:1: undeclared inclusion(s) in rule '//tensorflow/lite/nnapi:nnapi_implementation':
this rule is missing dependency declarations for the following files included by 'tensorflow/lite/nnapi/nnapi_implementation.cc':
  '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/stdint.h'
  '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/pthread.h'
  '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/10.0.1/include/stdint.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/stdint.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_int8_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_int16_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_int32_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_int64_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/_types/_uint8_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/_types/_uint16_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/_types/_uint32_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/_types/_uint64_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/cdefs.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_symbol_aliasing.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_posix_availability.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/machine/_types.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/i386/_types.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_types.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_intptr_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/machine/types.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/i386/types.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_int8_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_int16_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_int32_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_int64_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_uintptr_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/_types/_intmax_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/_types/_uintmax_t.h'
  '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/stdio.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/stdio.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/_stdio.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/Availability.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/AvailabilityInternal.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/_types.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_va_list.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_size_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_null.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/stdio.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_off_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_ssize_t.h'
  '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/stdlib.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/stdlib.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/wait.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_pid_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_id_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/signal.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/appleapiopts.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/machine/signal.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/i386/signal.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/machine/_mcontext.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/i386/_mcontext.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/mach/machine/_structs.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/mach/i386/_structs.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_attr_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_sigaltstack.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_ucontext.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_sigset_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_uid_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_timeval.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/machine/endian.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/i386/endian.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_endian.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/libkern/_OSByteOrder.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/libkern/i386/_OSByteOrder.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/alloca.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_ct_rune_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_rune_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_wchar_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/malloc/_malloc.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_dev_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_mode_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/dlfcn.h'
  '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/stdbool.h'
  '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/10.0.1/include/stdbool.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/fcntl.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/fcntl.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_o_sync.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_o_dsync.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_seek_set.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_s_ifmt.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_timespec.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_filesec_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/mman.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/stat.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_blkcnt_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_blksize_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_ino_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_ino64_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_nlink_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_gid_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_time_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/unistd.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/unistd.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_posix_vdisable.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_useconds_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/select.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_def.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_suseconds_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_setsize.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_set.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_clr.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_isset.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_zero.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_copy.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_select.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_uuid_t.h'
  '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/gethostuuid.h'
  '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstdlib'
Target //tensorflow/lite/java/ovic:OvicClassifierTest failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 6.522s, Critical Path: 2.14s
INFO: 0 processes.
FAILED: Build did NOT complete successfully

FAILED: Build did NOT complete successfully
```"
29134,tf.sparse.placeholder with partial defined shape return a SparseTensor with fully undefined shape,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Anaconda
- TensorFlow version (use command below): 1.13
- Python version: 3.7.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
```python
In [37]: X = tf.sparse.placeholder(tf.float32, (None, 3, 4))

In [38]: X.shape
Out[38]: TensorShape([Dimension(None), Dimension(None), Dimension(None)])
```


**Describe the expected behavior**

I would expect the shape of X to be:
TensorShape([Dimension(None), Dimension(3), Dimension(4)])

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29132,"Tensorflow2.0 keras subclassed model, problems with getting correct output shape, shows 'multiple'","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): TensorFlow 2.0.0-alpha0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0, 7.5
- GPU model and memory: 1080ti 11gb

**Describe the current behavior**
model.summary() prints 'multiple' as layer output shapes

**Describe the expected behavior**

**Code to reproduce the issue**
```
import tensorflow as tf

print('TensorFlow', tf.__version__)

class ResidualBlock(tf.keras.Model):
    def __init__(self, block_type=None, n_filters=None):
        super(ResidualBlock, self).__init__()
        self.n_filters = n_filters
        if block_type == 'identity':
            self.strides = 1
        elif block_type == 'conv':
            self.strides = 2
            self.conv_shorcut = tf.keras.layers.Conv2D(filters=self.n_filters, 
                               kernel_size=1, 
                               padding='same',
                               strides=self.strides,
                               kernel_initializer='he_normal')
            self.bn_shortcut = tf.keras.layers.BatchNormalization(momentum=0.9)
            
        self.conv_1 = tf.keras.layers.Conv2D(filters=self.n_filters, 
                               kernel_size=3, 
                               padding='same',
                               strides=self.strides,
                               kernel_initializer='he_normal')
        self.bn_1 = tf.keras.layers.BatchNormalization(momentum=0.9)
        self.relu_1 = tf.keras.layers.ReLU()
        
        self.conv_2 = tf.keras.layers.Conv2D(filters=self.n_filters, 
                               kernel_size=3, 
                               padding='same', 
                               kernel_initializer='he_normal')
        self.bn_2 = tf.keras.layers.BatchNormalization(momentum=0.9)
        self.relu_2 = tf.keras.layers.ReLU()
        
    def call(self, x, training=False):
        shortcut = x
        if self.strides == 2:
            shortcut = self.conv_shorcut(x)
            shortcut = self.bn_shortcut(shortcut)
        y = self.conv_1(x)
        y = self.bn_1(y)
        y = self.relu_1(y)
        y = self.conv_2(y)
        y = self.bn_2(y)
        y = tf.add(shortcut, y)
        y = self.relu_2(y)
        return y
    
class ResNet34(tf.keras.Model):
    def __init__(self, include_top=True, n_classes=1000):
        super(ResNet34, self).__init__()
        
        self.n_classes = n_classes
        self.include_top = include_top
        self.conv_1 = tf.keras.layers.Conv2D(filters=64, 
                                               kernel_size=7, 
                                               padding='same', 
                                               strides=2, 
                                               kernel_initializer='he_normal')
        self.bn_1 = tf.keras.layers.BatchNormalization(momentum=0.9)
        self.relu_1 = tf.keras.layers.ReLU()
        self.maxpool = tf.keras.layers.MaxPool2D(3, 2, padding='same')
        self.residual_blocks = tf.keras.Sequential()
        for n_filters, reps, downscale in zip([64, 128, 256, 512], 
                                              [3, 4, 6, 3], 
                                              [False, True, True, True]):
            for i in range(reps):
                if i == 0 and downscale:
                    self.residual_blocks.add(ResidualBlock(block_type='conv', 
                                                              n_filters=n_filters))
                else:
                    self.residual_blocks.add(ResidualBlock(block_type='identity', 
                                                              n_filters=n_filters))
        self.GAP = tf.keras.layers.GlobalAveragePooling2D()
        self.fc = tf.keras.layers.Dense(units=self.n_classes)
        
    def call(self, x, training=False):
        y = self.conv_1(x)
        y = self.bn_1(y)
        y = self.relu_1(y)
        y = self.maxpool(y)
        y = self.residual_blocks(y)
        if self.include_top:
            y = self.GAP(y)
            y = self.fc(y)
        return y
    
model = ResNet34()
model.build((1, 224, 224, 3))
model.summary()
```
output log
```

TensorFlow 2.0.0-alpha0
Model: ""res_net34""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              multiple                  9472      
_________________________________________________________________
batch_normalization_v2 (Batc multiple                  256       
_________________________________________________________________
re_lu (ReLU)                 multiple                  0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) multiple                  0         
_________________________________________________________________
sequential (Sequential)      multiple                  21300480  
_________________________________________________________________
global_average_pooling2d (Gl multiple                  0         
_________________________________________________________________
dense (Dense)                multiple                  513000    
=================================================================
Total params: 21,823,208
Trainable params: 21,806,184
Non-trainable params: 17,024
_________________________________________________________________
```"
29131,How to use optimizers from Tensorflow probability in Tensorflow?,"I would like to use the BFGS optimizer from Tensorflow probability (https://www.tensorflow.org/probability/api_docs/python/tfp/optimizer/bfgs_minimize) in Tensorflow. Has anyone done this before and can tell me how to interface the BFGS optimizer?
"
29130,Mixed precision LossScaleOptimizer doesn't work with Keras,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): PyPi
- TensorFlow version (use command below): 1.13.1
- Python version: 3.5.2

**Describe the current behavior**

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/mixed_precision/python/loss_scale_optimizer.py#L102

tf.contrib.mixed_precision.loss_scale_optimizer.LossScaleOptimizer doesn't implement variables() method (because it doesn't call base class `__init__` nor override it), so it fails when used within Keras model training with the following stack trace on model.fit_generator call:

```
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py"", line 1426, in fit_generator
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py"", line 164, in model_iteration
    callbacks._call_begin_hook(mode)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/callbacks.py"", line 212, in _call_begin_hook
    self.on_train_begin()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/callbacks.py"", line 279, in on_train_begin
    callback.on_train_begin(logs)
  File ""/usr/local/lib/python3.5/dist-packages/horovod-0.16.0-py3.5-linux-x86_64.egg/horovod/_keras/callbacks.py"", line 30, in on_train_begin
    self.backend.get_session().run(bcast_op)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py"", line 482, in get_session
    _initialize_variables(session)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py"", line 749, in _initialize_variables
    variables = _get_variables(get_graph())
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py"", line 743, in _get_variables
    variables.update(opt.optimizer.variables())
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py"", line 946, in variables
    optimizer_variables = [v for v in self._non_slot_variables()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py"", line 1025, in _non_slot_variables
    return self._non_slot_dict.values()
AttributeError: 'LossScaleOptimizer' object has no attribute '_non_slot_dict'
```

**Describe the expected behavior**

Wrapping the optimizer in a LossScaleOptimizer should work transparently with Keras models, as it implements tf.optimizers.Optimizer base class.

To solve this problem, there's a need to either pass undelying optimizer variables() method (together with passing LossScaleManager variables too) or fill slot- and non-slot variables some other way.

Workaround example:
```
class MyExponentialUpdateLossScaleManager(ExponentialUpdateLossScaleManager):
    def variables(self):
        return [self._loss_scale, self._num_good_steps, self._num_bad_steps]

class MyLossScaleOptimizer(LossScaleOptimizer):
    def variables(self):
        return self._opt.variables() + self._loss_scale_manager.variables()
```

**Code to reproduce the issue**

```
from tensorflow.train import AdamOptimizer 
from tensorflow.contrib.mixed_precision import LossScaleOptimizer, ExponentialUpdateLossScaleManager
...
optimizer = AdamOptimizer()
loss_scale_manager = ExponentialUpdateLossScaleManager(init_loss_scale=2 ** 32, incr_every_n_steps=1000)
optimizer = LossScaleOptimizer(optimizer, loss_scale_manager)
...
model.compile(optimizer=optimizer, ...)
```

Full example
```
import numpy as np
import tensorflow as tf
from tensorflow.train import AdamOptimizer
from tensorflow.contrib.mixed_precision import LossScaleOptimizer, ExponentialUpdateLossScaleManager

input = tf.keras.layers.Input(shape=(16,))
output = tf.keras.layers.Dense(1)(input)
model = tf.keras.models.Model(input, output)

optimizer = AdamOptimizer()
# Works without these two lines below
loss_scale_manager = ExponentialUpdateLossScaleManager(init_loss_scale=2 ** 32, incr_every_n_steps=1000)
optimizer = LossScaleOptimizer(optimizer, loss_scale_manager)

model.compile(optimizer=optimizer, loss='binary_crossentropy')
model.fit(np.zeros((16, 16)), np.zeros((16,)))
```"
29129,keras lstm cell has no zero state when wrapped with a dropoutwrapper,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Microsoft Windows 10
- TensorFlow installed from (source or binary): Anaconda
- TensorFlow version (use command below): tensorflow 1.13.1  gpu_py37h83e5d6a_0
- Python version: 3.7
- CUDA/cuDNN version: 7.3.1
- GPU model and memory: GTX 1060 6gb

This problem is very similar to #25641. But that issue was closed and the problem was found in a future version of tensorflow (2.0.0. alpha). This is why I opened a new issue, becuase the current stable release version has the same error. 

I want to create a RNN layer with stacked lstm cells. The lstm cells are wrapped with the dropoutwrapper. Since I define no initial state, the RNN tries to get the zero state from the lstm cells. There the error occurs, saying that a lstmcell has no attribute zero_state. 
        
        import tensorflow as tf
        with tf.Session() as sess:
        tensor = tf.zeros(shape=(1, 20, 5), dtype=tf.float32)
        inputs = tf.keras.layers.Input(shape=(10, 5), tensor=tensor)
        cell = tf.keras.layers.LSTMCell(10)
        cell = tf.nn.rnn_cell.DropoutWrapper(cell=cell)
        rnn = tf.keras.layers.RNN(cell=cell)(inputs)

Here is the error message:

          File ""C:/Users/vaith/PycharmProjects/Bayesian_Neural_Nets/bayesian_lstm_main.py"", line 25, in main
           rnn = tf.keras.layers.RNN(cell=cell)(inputs)
           File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\layers \recurrent.py"", line 701, in __call__
           return super(RNN, self).__call__(inputs, **kwargs)
           File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 554, in __call__
           outputs = self.call(inputs, *args, **kwargs)
           File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 759, in call
            inputs, initial_state, constants)
           File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 863, in _process_inputs
            initial_state = self.get_initial_state(inputs)
           File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py"", line 679, in get_initial_state
            inputs=None, batch_size=batch_size, dtype=dtype)
           File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py"", line 298, in get_initial_state
            return self.zero_state(batch_size, dtype)
           File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py"", line 1232, in zero_state
            return self._cell.zero_state(batch_size, dtype)
           AttributeError: 'LSTMCell' object has no attribute 'zero_state'
"
29128,when i use conv1d,"conda activate base
2.0.0-alpha0
2019-05-29 19:58:31.543654: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-29 19:58:31.557759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-05-29 19:58:31.670769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-05-29 19:58:31.672348: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55c9b57a0a60 executing computations on platform CUDA. Devices:
2019-05-29 19:58:31.672364: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): Graphics Device, Compute Capability 7.5
2019-05-29 19:58:31.693201: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz
2019-05-29 19:58:31.693619: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55c9b580db30 executing computations on platform Host. Devices:
2019-05-29 19:58:31.693637: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>
2019-05-29 19:58:31.693791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties: 
name: Graphics Device major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:01:00.0
totalMemory: 5.76GiB freeMemory: 5.17GiB
2019-05-29 19:58:31.693804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-05-29 19:58:31.693844: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-05-29 19:58:31.694402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-29 19:58:31.694413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 
2019-05-29 19:58:31.694419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N 
2019-05-29 19:58:31.694516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4990 MB memory) -> physical GPU (device: 0, name: Graphics Device, pci bus id: 0000:01:00.0, compute capability: 7.5)
Number of training examples: 60000
Number of test examples:     10000
Epoch 1/5
2019-05-29 19:58:32.786674: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.
2019-05-29 19:58:36.114172: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-05-29 19:58:36.288348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-05-29 19:58:36.934479: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-05-29 19:58:36.945020: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-05-29 19:58:36.945127: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node conv2d/Conv2D}}]]"
29127,mirror.tensorflow.org has an invalid https cert,"third_party distfiles that are downloaded from the starlark functions `tf_http_archive` or `third_party_http_archive` currently are mirrored to mirror.tensorflow.org via http. Changing them to https fails with an invalid cert (it currently points to *.storage.googleapis.com) 

For example from `tensorflow/workspace.bzl`:
https://mirror.tensorflow.org/docs.python.org/2.7/_sources/license.rst.txt

The third party archives should be served over https for everyones security, `https://mirror.bazel.build/` used to be over https, so `mirror.tensorflow.org` should too."
29124,Cannot convert VGG19,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): tf-nightly-2.0-preview 2.0.0.dev20190529

**Provide the text output from tflite_convert**
```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, SOFTMAX. Here is a list of operators for which you will need custom implementations: IdentityN.
```

```
Model: ""model_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 32768)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 2048)              67110912  
_________________________________________________________________
dropout_2 (Dropout)          (None, 2048)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 1024)              2098176   
_________________________________________________________________
dropout_3 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 2)                 2050      
=================================================================
Total params: 89,235,522
Trainable params: 69,211,138
Non-trainable params: 20,024,384
_________________________________________________________________
```

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```

---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-3-7f2e78be88e7> in <module>
      1 converter = tf.compat.v1.lite.TFLiteConverter.from_saved_model(os.path.join('fold_0', 'saved_model'))
      2 converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
----> 3 tflite_quant_model = converter.convert()
      4 open(""converted_model.tflite"", ""wb"").write(tflite_quant_model)

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/python/lite.py in convert(self)
    898           input_tensors=self._input_tensors,
    899           output_tensors=self._output_tensors,
--> 900           **converter_kwargs)
    901     else:
    902       result = _toco_convert_graph_def(

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs)
    402   data = toco_convert_protos(model_flags.SerializeToString(),
    403                              toco_flags.SerializeToString(),
--> 404                              input_data.SerializeToString())
    405   return data
    406 

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str)
    170       stderr = _try_convert_to_unicode(stderr)
    171       raise ConverterError(
--> 172           ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
    173   finally:
    174     # Must manually cleanup files.

ConverterError: TOCO failed. See console for info.
2019-05-29 05:12:55.314629: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: IdentityN
2019-05-29 05:12:55.329766: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 205 operators, 248 arrays (0 quantized)
2019-05-29 05:12:55.331674: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 205 operators, 248 arrays (0 quantized)
2019-05-29 05:12:55.406663: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 28 operators, 68 arrays (0 quantized)
2019-05-29 05:12:56.019719: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 27 operators, 67 arrays (0 quantized)
2019-05-29 05:12:56.019942: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 26 operators, 65 arrays (0 quantized)
2019-05-29 05:12:56.020127: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 26 operators, 65 arrays (0 quantized)
2019-05-29 05:12:56.020257: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 26 operators, 65 arrays (0 quantized)
2019-05-29 05:12:56.020521: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 33554432 bytes, theoretical optimal value: 33554432 bytes.
2019-05-29 05:12:56.020581: I tensorflow/lite/toco/toco_tooling.cc:434] Estimated count of arithmetic ops: 51.1266 billion (note that a multiply-add is counted as 2 ops).
2019-05-29 05:12:56.020770: E tensorflow/lite/toco/toco_tooling.cc:462] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, SOFTMAX. Here is a list of operators for which you will need custom implementations: IdentityN.
Traceback (most recent call last):
  File ""/home/marco/anaconda3/envs/tf2/bin/toco_from_protos"", line 10, in <module>
    sys.exit(main())
  File ""/home/marco/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/marco/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/marco/anaconda3/envs/tf2/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/marco/anaconda3/envs/tf2/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/home/marco/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:
```"
29123,tf.data.Dataset.from_generator() empties after use even with repeat(),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- TensorFlow installed from (source or binary): PyPI binary
- TensorFlow version (use command below): 2.0.0-dev20190526
- Python version: 3.7

**Describe the current behavior**

A `tf.data.Dataset` created using `from_generator()` is consumed and not recreated/repeated even when explicitly invoking the `repeat()` method.

**Describe the expected behavior**

If `repeat()` is being invoked, repeat the dataset.

**Code to reproduce the issue**

https://github.com/tensorflow/tensorflow/issues/25254#issuecomment-496828699

**Other info / logs**

The issue is present both when manually iterating over it in a custom training scenario and when using `tf.keras.Model.fit()`.
"
29122,Entity <> could not be transformed and will be staged without change,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0 alpha
- Python version: 3.6
- CUDA/cuDNN version: 10
- GPU model and memory: GTX2080Ti

Hi there, could you please have a look at the issue? A customized network module (in Keras) cannot work as for gradient backpropagation. 


Log:

W0529 19:29:46.658907 140071302989632 tf_logging.py:161] Entity <bound method Layer.__call__ of <tensorflow.python.keras.engine.training.Model object at 0x7f6404415fd0>> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Unexpected error transforming <bound method Layer.__call__ of <tensorflow.python.keras.engine.training.Model object at 0x7f6404415fd0>>. If you believe this is due to a bug, please set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output when filing the bug report. Caused by: node <gast.gast.Subscript object at 0x7f61f416e4e0> has ctx unset
W0529 19:29:52.344057 140071302989632 tf_logging.py:161] Entity <function train_G at 0x7f64c79a9ae8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Unexpected error transforming <function train_G at 0x7f64c79a9ae8>. If you believe this is due to a bug, please set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output when filing the bug report. Caused by: node <gast.gast.Name object at 0x7f61ad7cb588> has ctx unset
W0529 19:29:52.960978 140071302989632 optimizer_v2.py:928] Gradients does not exist for variables ['conv2d_24/kernel:0', 'conv2d_24/bias:0', 'conv2d_25/kernel:0', 'conv2d_25/bias:0', 'conv2d_26/kernel:0', 'conv2d_26/bias:0', 'conv2d_27/kernel:0', 'conv2d_27/bias:0', 'conv2d_28/kernel:0', 'conv2d_28/bias:0', 'conv2d_29/kernel:0', 'conv2d_29/bias:0', 'conv2d_30/kernel:0', 'conv2d_30/bias:0', 'conv2d_31/kernel:0', 'conv2d_31/bias:0', 'conv2d_32/kernel:0', 'conv2d_32/bias:0', 'conv2d_33/kernel:0', 'conv2d_33/bias:0', 'conv2d_34/kernel:0', 'conv2d_34/bias:0', 'conv2d_35/kernel:0', 'conv2d_35/bias:0', 'conv2d_36/kernel:0', 'conv2d_36/bias:0', 'conv2d_37/kernel:0', 'conv2d_37/bias:0', 'conv2d_38/kernel:0', 'conv2d_38/bias:0', 'conv2d_39/kernel:0', 'conv2d_39/bias:0'] when minimizing the loss.
x"
29117,Some of the operators in the model are not supported by the standard TensorFlow Lite runtime.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, ADD_N, CAST, CONCATENATION, CONV_2D, FLOOR, FULLY_CONNECTED, GATHER_ND, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, RESHAPE, RESIZE_NEAREST_NEIGHBOR, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: ROUND.


```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29116,"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, ADD_N, CAST, CONCATENATION, CONV_2D, FLOOR, FULLY_CONNECTED, GATHER_ND, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, RESHAPE, RESIZE_NEAREST_NEIGHBOR, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: ROUND.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29115,Support RaggedTensors in sequence feature columns ,"**System information**
- TensorFlow version (you are using): 2.0.0-dev20190527
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Currently `tf.feature_column.sequence_*` columns support only sparse tensor inputs.
It would be great if they will support ragged tensors too. At least thru type checking and `to_sparse` method (but maybe there will be a better performing way).

**Will this change the current api? How?**
No, API won't changes.

**Who will benefit with this feature?**
Developers who work with NLP models where ragged tensors are more natural than Sparse ones.

**Any Other info.**
See `Code to reproduce` and especially comment `This is my wish` from https://github.com/tensorflow/tensorflow/issues/29113"
29113,All implicitly derived inputs to subclassed Models must be tf.Tensors (found SparseTensor),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.14
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): ('v1.12.1-2821-gc5b8e15064', '2.0.0-dev20190527')
- Python version: 2.7
- Bazel version (if compiling from source): no
- GCC/Compiler version (if compiling from source): no
- CUDA/cuDNN version: no
- GPU model and memory: no

**Describe the current behavior**
Exception raises when trying to feed Sparse/Ragged tensors to keras model.fit().
But that is an ordinary pipeline for Estimators.

Besides, method mentioned in error (`self._add_inputs`) does not exist in TF source code.

**Describe the expected behavior**
Sparse and Ragged tensors should be acceptable input for keras models.

**Code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf

FEATURES_DIM = 5
_randoms = np.random.random((10, 32, FEATURES_DIM))

# # This is my wish: ragged input to sequence feature column
# features = tf.RaggedTensor.from_tensor(_randoms, ragged_rank=1)
# labels = tf.reduce_sum(tf.expand_dims(features, axis=-2), axis=-1)

# This is what should work right now
_indexes = tf.where(tf.not_equal(_randoms, 0.0))
_values = tf.gather_nd(_randoms, _indexes)
features = tf.SparseTensor(_indexes, _values, _randoms.shape)
labels = tf.sparse.reduce_sum(features, axis=-1, keepdims=True)    

dataset = tf.data.Dataset \
    .from_tensor_slices(({'features': features}, labels)) \
    .batch(32)


class MyModel(tf.keras.Model):
    def __init__(self):
        super(MyModel, self).__init__()
        self.features = tf.keras.experimental.SequenceFeatures([
            tf.feature_column.sequence_numeric_column('features', shape=(FEATURES_DIM,))
        ])
        self.dense_1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu'))
        self.dense_2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1))

    def call(self, inputs):
        outputs = self.features(inputs)
        outputs = self.dense_1(outputs)
        outputs = self.dense_2(outputs)
        
        return outputs

    def compute_output_shape(self, input_shape):
        shape = tf.TensorShape(input_shape).as_list()
        shape[-1] = 1
        
        return tf.TensorShape(shape)

    
model = MyModel()
model.compile(optimizer='Adam', loss='mse')
model.fit_generator(dataset, epochs=5)
```

**Other info / logs**
```python
Epoch 1/5
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-37-1cf666c5a52e> in <module>()
     40 model = MyModel()
     41 model.compile(optimizer='Adam', loss='mse')
---> 42 model.fit_generator(dataset, epochs=5)

/usr/local/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.pyc in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1175         shuffle=shuffle,
   1176         initial_epoch=initial_epoch,
-> 1177         steps_name='steps_per_epoch')
   1178 
   1179   def evaluate_generator(self,

/usr/local/lib/python2.7/site-packages/tensorflow/python/keras/engine/training_generator.pyc in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)
    262 
    263       is_deferred = not model._is_compiled
--> 264       batch_outs = batch_function(*batch_data)
    265       if not isinstance(batch_outs, list):
    266         batch_outs = [batch_outs]

/usr/local/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.pyc in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)
    895     x, y, sample_weights = self._standardize_user_data(
    896         x, y, sample_weight=sample_weight, class_weight=class_weight,
--> 897         extract_tensors_from_dataset=True)
    898 
    899     # If `self._distribution_strategy` is True, then we are in a replica context

/usr/local/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.pyc in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)
   2341               'tf.Tensors (found %s). To add non-tf.Tensor inputs, please call '
   2342               'self._add_inputs(tf.keras.Input/SparseInput/RaggedInput (etc)) '
-> 2343               'in your subclassed Model object.' % (input_tensor,))
   2344 
   2345       # Build the model using the retrieved inputs (value or symbolic).

ValueError: All implicitly derived inputs to subclassed Models must be tf.Tensors (found SparseTensor(indices=tf.Tensor(
[[ 0  0  0]
 [ 0  0  1]
 [ 0  0  2]
 ...
 [ 9 31  2]
 [ 9 31  3]
 [ 9 31  4]], shape=(1600, 3), dtype=int64), values=tf.Tensor([0.76254113 0.44757111 0.9459519  ... 0.64881651 0.2802026  0.79660244], shape=(1600,), dtype=float64), dense_shape=tf.Tensor([32 32  5], shape=(3,), dtype=int64))). To add non-tf.Tensor inputs, please call self._add_inputs(tf.keras.Input/SparseInput/RaggedInput (etc)) in your subclassed Model object.
```"
29112,tf.function runtime error when modifying file,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-2828-ga9a1a64d25 2.0.0-dev20190528
- Python version: 3.6.8
- CUDA/cuDNN version: CUDA version 10.0.130
- GPU model and memory: GeForce GTX 1080 Ti

**Describe the current behavior**
I'm running some experiments using tensorflow 2.0 nightly. I decorated the train step with `@tf.function`. In the meantime I'm modifying the file involved in the training.
After some time I get a random error in a function invocation (inside the function decorated with `tf.function`. If I do not modify any file the error does not happen.
I guess it's something related to the implementation of `@tf.function`, probably `tf.function` creates some temp file and updates them. The file update however is not managed well since modifying files the training should not be affected.

**Code to reproduce the issue**
This is an issue difficult to reproduce.
"
29111,tensorflow_addons can not be imported,"Could you plz help to solve this issue?

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution ( Linux Ubuntu 16.04):

- TensorFlow installed from: source
- TensorFlow version: 2.0.0-dev20190528
- Python version: 3.6
- CUDA/cuDNN version: 10
- GPU model and memory: GTX 2080 ti

**Describe the current behavior**

I updated Tensorflow from 2.0 a to 2.0.0-dev20190528 and came up with the error  while importing tensorflow_addons, some object could not be opened by the TF framework:

**Code to reproduce the issue**
import tensorflow_addons as tfa

**Other info / logs**

  File ""/mnt/HDD1/kaiyi/Split-UNet/module.py"", line 1, in <module>
    import tensorflow_addons as tfa
  File ""/home/bmiter/anaconda3/envs/SplitU/lib/python3.6/site-packages/tensorflow_addons/__init__.py"", line 75, in <module>
    from tensorflow_addons import image
  File ""/home/bmiter/anaconda3/envs/SplitU/lib/python3.6/site-packages/tensorflow_addons/image/__init__.py"", line 20, in <module>
    from tensorflow_addons.image.distort_image_ops import adjust_hsv_in_yiq
  File ""/home/bmiter/anaconda3/envs/SplitU/lib/python3.6/site-packages/tensorflow_addons/image/distort_image_ops.py"", line 24, in <module>
    get_path_to_datafile(""custom_ops/image/_distort_image_ops.so""))
  File ""/home/bmiter/anaconda3/envs/SplitU/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py"", line 61, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: libtensorflow_framework.so: cannot open shared object file: No such file or directory

Process finished with exit code 1"
29110,How to test a saved model trained with tf.train.batch?,"By calling graph.get_tensor_by_name(""output:0"")，I found that it returns a tensor shaped [batch_size,num]，How to test a saved model trained with tf.train.batch?"
29108,Gradient clipping by norm has different semantics in tf.keras.optimizers against keras.optimizers,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.0 + cuDNN 7.4
- GPU model and memory: NVIDIA Tesla V100 32GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

The gradient clipping mechanism is implemented in the abstract class, tf.keras.optimizers.Optimizer (keras.optimizers.Optimizer) so that every optimizer inherited from the class supports it.
We find different semantics of the implementations between tf.keras and keras.io.

In tf.keras, the gradient norm is calculated and clipped **per gradient tensor**.

https://github.com/tensorflow/tensorflow/blob/bb8cf258bc87f68612a5e032d5b4def0d3c52566/tensorflow/python/keras/optimizers.py#L98-L99

But in keras.io, the gradient norm is calculated globally **across all gradient tensors**.

```python
        if hasattr(self, 'clipnorm') and self.clipnorm > 0:
            norm = K.sqrt(sum([K.sum(K.square(g)) for g in grads]))
            grads = [clip_norm(g, self.clipnorm, norm) for g in grads]
```
Code link: https://github.com/keras-team/keras/blob/eab1b5bcdf105746ede02d2eb8a5cb3ca359b1b5/keras/optimizers.py#L96-L98

IMO, tf.keras should adopt the latter method since
(1) The paper introducing gradient clipping (https://arxiv.org/abs/1211.5063) suggests the latter one, and
(2) tf.keras should be compliant with keras.io.

"
29105,There is a incorrect link in CONTRIBUTING.md,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md

## Description of issue (what needs changing):
### Correct links

Is the link to the source code correct?
No.
```
1.  Using tools and libraries installed directly on your system.

    Refer to the
    [CPU-only developer Dockerfile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile.devel)
    and
    [GPU developer Dockerfile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile.devel-gpu)
    for the required packages. Alternatively, use the said
```
The link of 'CPU-only developer Dockerfile' and 'GPU developer Dockerfile' are 404.

### Submit a pull request?
I'd like to fix it.
"
29103,tfjs model converted from Keras model cannot be loaded,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):1.9
- Python version:3.7.0
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
- GPU model and memory:

***Step 1***
Train a keras model, and test it OK. saved as `model.h5`
model as below:
```
model = Sequential()

model.add(SeparableConv2D(32,
                          kernel_size=(3, 3),
                          padding='same',
                          activation='relu',
                          input_shape=input_shape))

model.add(SeparableConv2D(64,
                          kernel_size=(3, 3),
                          padding='same',
                          activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(SeparableConv2D(256,
                          kernel_size=(3, 3),
                          padding='same',
                          activation='relu' ))
model.add(AveragePooling2D(pool_size=(14, 14)))
model.add(Flatten())
```
***Step 2***
use `tensorflowjs_converter` to convert keras model to JS model.
```
>$ tensorflowjs_converter --input_format=keras ./my_model.h5 ./assets
```
and generate 2 files `group1-shard1of1` and `model.json`

***Step 3***
use converted model in JS project.
```
this.model = await tf.loadLayersModel(model_path);
```
and get errors like below:
```
core.js:15724 ERROR Error: Uncaught (in promise): Error: Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.
Error: Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.
    at new t (tf-layers.esm.js:17)
    at t [as constructor] (tf-layers.esm.js:17)
    at new t (tf-layers.esm.js:17)
    at e.fromConfig (tf-core.esm.js:17)
    at deserializeKerasObject (tf-layers.esm.js:17)
    at deserialize (tf-layers.esm.js:17)
    at t.fromConfig (tf-layers.esm.js:17)
    at deserializeKerasObject (tf-layers.esm.js:17)
    at deserialize (tf-layers.esm.js:17)
    at tf-layers.esm.js:17
    at resolvePromise (zone.js:831)
    at zone.js:741
    at rejected (tslib.es6.js:69)
    at ZoneDelegate.push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invoke (zone.js:391)
    at Object.onInvoke (core.js:17299)
    at ZoneDelegate.push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invoke (zone.js:390)
    at Zone.push../node_modules/zone.js/dist/zone.js.Zone.run (zone.js:150)
    at zone.js:889
    at ZoneDelegate.push../node_modules/zone.js/dist/zone.js.ZoneDelegate.invokeTask (zone.js:423)
    at Object.onInvokeTask (core.js:17290)
```

## Note: if I replace the `SeparableConv2D` by `Conv2D`, everything will be OK."
29102,Tf 2.0 with cuda 10.1 build from source compiles to 1.13 package,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution:Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version: TF2.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.25.3
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: 10.1
- GPU model and memory: GTX 1060 3GB



**Describe the problem**
I am trying to build tensorflow 2.0 from source with cuda 10.1 . I followed a method used by #28936  but the package I build is always 1.13 even with --config=v2 flag



**Provide the exact sequence of commands / steps that you executed before running into the problem**
conda create -n tf2build pip python=3.7
source activate tf2build
pip install --upgrade --force-reinstall pip setuptools
pip install wheel numpy scipy keras
git clone https://github.com/tensorflow/tensorflow.git --single-branch --branch master
cd tensorflow

./configure
 Use default values except:
 CUDA support: Y

export TMP=/tmp
bazel build -c opt --config=opt --config=v2  \
    --copt=-march=native --cxxopt=-march=native \
    //tensorflow/tools/pip_package:build_pip_package --verbose_failures

./bazel-bin/tensorflow/tools/pip_package/build_pip_package --nightly_flag /tmp/tensorflow_pkg

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

creating the package had the following log:

There are no errors during the compilation process, only warnings

Tue May 28 16:30:14 EDT 2019 : === Preparing sources in dir: /tmp/tmp.C6skAbFOnh
~/tfbuild/tf2build/tensorflow ~/tfbuild/tf2build/tensorflow
~/tfbuild/tf2build/tensorflow
Tue May 28 16:30:32 EDT 2019 : === Building wheel
warning: no files found matching '*.pyd' under directory '*'
warning: no files found matching '*.pd' under directory '*'
warning: no files found matching '*.dylib' under directory '*'
warning: no files found matching '*.dll' under directory '*'
warning: no files found matching '*.lib' under directory '*'
warning: no files found matching '*.csv' under directory '*'
warning: no files found matching '*.h' under directory 'tensorflow/include/tensorflow'
warning: no files found matching '*' under directory 'tensorflow/include/Eigen'
warning: no files found matching '*.h' under directory 'tensorflow/include/google'
warning: no files found matching '*' under directory 'tensorflow/include/third_party'
warning: no files found matching '*' under directory 'tensorflow/include/unsupported'
Tue May 28 16:30:54 EDT 2019 : === Output wheel file is in: /tmp/tensorflow_pkg



"
29101,Random seed not set in graph context of `Dataset#map`,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Jupyter notebook on https://colab.research.google.com
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Stock on https:///colab.research.google.com
- TensorFlow version (use command below): b'v1.13.1-2-g09e3b09e69' 1.13.1
- Python version: 2/3
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA 
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The random seed set via `tf.set_random_seed(seed)` is not set in the context in which the functions passed to `tf.data.Dataset#map` are invoked. Even for the single thread case. 
**Describe the expected behavior**
The random seed set via `tf.set_random_seed(seed)` should be set in the context in which the functions passed to `tf.data.Dataset#map` are invoked, at least for the single thread case. 

**Code to reproduce the issue**
```python
import tensorflow as tf

def seed_assert(elt):
  seed = tf.get_default_graph().seed
  print(""Seed is {}"".format(seed))
  assert seed is not None, ""Random seed is not set. Random graph operations added during mapping will not be reproducible.""
  return elt

seed = 37
      
tf.set_random_seed(seed)  

ds = tf.data.Dataset.from_generator(lambda : (yield (0)), (tf.int64))

seed_assert(None)

ds.map(seed_assert)
```
Can run here:
[Seed in Dataset#Map.ipynb](https://colab.research.google.com/drive/1SIGhYzOKc6Sg147DiB-NFz_lXKym_mto#scrollTo=ENwL9Bo60BYw) 

**Other info / logs**
I originally saw this issue locally but was able to reproduce it on the Jupyter notebook provided by Google. Here is the log of the errors I see when running the above code.

```python
Seed is 37
Seed is None

---------------------------------------------------------------------------

AssertionError                            Traceback (most recent call last)

<ipython-input-7-38991a9ee77e> in <module>()
     15 seed_assert(None)
     16 
---> 17 ds.map(seed_assert)

8 frames

<ipython-input-7-38991a9ee77e> in seed_assert(elt)
      4   seed = tf.get_default_graph().seed
      5   print(""Seed is {}"".format(seed))
----> 6   assert seed is not None, ""Random seed is not set. Random graph operations added during mapping will not be reproducible.""
      7   return elt
      8 

AssertionError: Random seed is not set. Random graph operations added during mapping will not be reproducible.
```"
29100,Keras Vanilla Installation | RuntimeError: Python version >= 3.5 required,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
[+] No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
[+] Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
[+] NA
- TensorFlow installed from (source or binary):
[+] Binary
- TensorFlow version (use command below):
[+] Tensorflow v1.13.1-0-g6612da8951
- Python version:
[+] Python 3.6.0
- Bazel version (if compiling from source):
[+] NA
- GCC/Compiler version (if compiling from source):
[+] GCC 7.4.0
- CUDA/cuDNN version:
[+] CUDA v9.1.85
- GPU model and memory:
[+] GTX 1050 Mobile 4Gb

**Describe the current behavior**

Installation of Keras from source fails by doing the following.

Running the commands as per the Keras installation instructions in a virtual environment.

sudo python setup.py install
...
File ""/tmp/easy_install-vOk903/scipy-1.3.0/setup.py"", line 31, in
author_email='francois.chollet@gmail.com',
RuntimeError: Python version >= 3.5 required.

**Describe the expected behavior**

Successful Keras installation.

**Code to reproduce the issue**

[+] conda create -n kerasenv python=3.5.0
[+] conda activate kerasenv
[+] pip install tensorflow
[+] git clone https://github.com/keras-team/keras.git
[+] cd keras
[+] sudo python setup.py install

**Other info / logs**
[+] [errorlog2.txt](https://github.com/tensorflow/tensorflow/files/3230162/errorlog2.txt)

[+] Keras Issue: https://github.com/keras-team/keras/issues/12837
"
29099,Drastically different behavior between TF1 and TF2,"I've noticed drastically different behavior of the following code between _2.0.0-alpha0_ and _1.13.1_.
```python
import numpy as np
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

(x_train_raw, y_train_raw), (x_test_raw, y_test_raw) = mnist.load_data()
x_train = x_train_raw.reshape(60000, 784)
x_test = x_test_raw.reshape(10000, 784)
y_train = to_categorical(y_train_raw)
y_test = to_categorical(y_test_raw)

basic_net = Sequential([
    Dense(36, activation='relu', input_shape=(784,)),
    Dense(10, activation='softmax')
])

W_bio = np.load('W_bio.npy')

basic_net.layers[0].set_weights([W_bio.transpose(), basic_net.layers[0].get_weights()[1]])
basic_net.layers[0].trainable = False
basic_net.compile(optimizer=Adam(lr=0.0001), metrics=['accuracy'], loss='categorical_crossentropy')
basic_net.fit(x=x_train, y=y_train, epochs=15)
```

In _2.0.0-alpha0_ the accuracy of the network consistently reaches >80% in the first few epochs. In _1.13.1_ the accuracy consistently reaches only <20% after all 15 epochs. What is going on?

Here is the file with weights: [W_bio.npy](https://drive.google.com/file/d/12O0XE98jl_yYmiBbZMWyLMaeZiHH-FXH/view?usp=sharing)"
29096,Cannot install tensorflow via PIP ,"so following the tutorial: https://www.tensorflow.org/install/pip?lang=python3 didnt really work..
i even deleted all my previous python versions and got a singe python 3.6.0 64 bit running (all my other where 32 bit)

`python --version` => 3.6.0
`pip --version` =>19.1.1
`virtualenv --version `=>16.6.0

`pip install --upgrade tensorflow`
=>
> Collecting tensorflow
>   ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
> ERROR: No matching distribution found for tensorflow"
29092,There have no tensorflow/contrib/tpu/ops module in b211c7a commit,"Sorry if I'm something miss. It's my first attempt to make an issue.

commit b211c7a

In the :
tensorflow/contrib/cmake/python_modules.txt:
....
tensorflow/contrib/tpu
tensorflow/contrib/tpu/ops   <<< line 435
tensorflow/contrib/tpu/profiler
tensorflow/contrib/tpu/python
...

But this module is not in the directory:
tensorflow/contrib/tpu

"
29089,TFLite model almost the same size as frozen graph,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v1.13.1
- Python version: 3.6
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**

Freeze [xception65_coco_voc_trainaug](http://download.tensorflow.org/models/deeplabv3_pascal_train_aug_2018_01_04.tar.gz) from this [model zoo](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md) using:
```
python tensorflow/models/deeplab/export_model.py ...
```

Resulting `.pb` is 157mb.

Convert `.pb` to `.tflite` using `tflite_convert`. Resulting `.tflite` is 156mb. Just 1mb smaller than the `.pb`.

**Describe the expected behavior**

The TFLite model should perhaps be considerably smaller. If not, why not?

[The frozen graph I'm using](https://drive.google.com/file/d/14usyseWBL36SGNdYPm17D07OQ1P_5Hjx/view?usp=sharing)"
29088,TF 2.0 Beta: custom metric example from documentation is wrong,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I implemented the custom metric shown in this page (CatgoricalTruePositives) https://www.tensorflow.org/alpha/guide/keras/training_and_evaluation

I think it is full of bugs, it has some comments saying (#TODO: fix this). Any way, here what's particularly wrong about it. The accuracy of the NN approaches 99%, yet, this metric says:

binary_true_positives: 8459.0000

(as shown on the website too). If number of samples in MNIST is 50,000, then at least 45k of them should be true positives.  It is unstable. I messed with it once and I got 49k true positive (which makes total sense). Then I reran it and it returned to 8k.

**Describe the expected behavior**
The results are shown on the website. For a low loss of 0.03, the true positives should be close to 50k. However they're shown to be 8k only.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29086,Error trying tensorflow litem operations are not supported by GPU delegate,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Yes, aarch64, android 8.1
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.12.2
- Python version: 2.7
- Bazel version (if compiling from source): 0.22.0
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm trying to run a c++ demo of tflite+opengles on my aarch64 android 8.1 board.
I have tried to build  benchmark_model tool with bazel, it ran the [deeplabv3_257_mv_gpu.tflite ](https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/deeplabv3_257_mv_gpu.tflite)model successfully on my device.

Now I want to integrate a simple demo of tflite (similar to benchmark) to my codes, which is built by cmake. I spent some time extract all the static libs of tensorflowlite from bazle-out folder and linked them in my cmake. I built the code successfully with ndk standalone toolchain r17c. 

But when I ran this new demo on my device it shows me errors like:

`INFO: Created TensorFlow Lite delegate for GPU.
Apply delegate for GPU
Next operations are not supported by GPU delegate:
AVERAGE_POOL_2D: Expected 1 input tensor(s), but node has 0 runtime input(s).
CONV_2D: Expected 1 input tensor(s), but node has 0 runtime input(s).
CONV_2D: Expected 1 input tensor(s), but node has 2 runtime input(s).
CONV_2D: Expected 1 input tensor(s), but node has 3 runtime input(s).
DEPTHWISE_CONV_2D: Expected 1 input tensor(s), but node has 2 runtime input(s).
DEPTHWISE_CONV_2D: Expected 1 input tensor(s), but node has 3 runtime input(s).
RESIZE_BILINEAR: Expected 1 input tensor(s), but node has 2 runtime input(s).
First 1 operations will run on the GPU, and the remaining 69 on the CPU.
TfLiteGpuDelegate Prepare: ReadValue: value is a constant tensor: 183
Node number 70 (TfLiteGpuDelegate) failed to prepare.

Failed to apply GPU delegate.
Delegate setting done
Node number 70 (TfLiteGpuDelegate) failed to prepare.

Failed to allocate tensors!
`
The model here is still deeplabv3_257_mv_gpu.tflite, which have been proved working on my device. I also have tried to build my new demo code in bazel, which perform correctly.


**Describe the expected behavior**
Build Tflite + opengl delegate successfully with Cmake and perform correctly on my aarch64 board. 



**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
use your official benchmark_model.cc

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29083,ImportError: DLL load failed: The specified module could not be found.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 7 Enterprise 64-bit (6.1, Build 7601)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): not sure
- TensorFlow version:  1.13.1
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version:  cudatoolkit: 10.0.130/ cudnn: 7.3.1
- GPU model and memory: Intel(R) HD Graphics 520, 1888 MB



**Describe the problem**
I installed tensorflow from anaconda and first installed everything in base (root), upon running `import tensorflow` I encountered this issue.
Then per suggestions from #22794 , I followed the instructions from [link](https://www.pugetsystems.com/labs/hpc/The-Best-Way-to-Install-TensorFlow-with-GPU-Support-on-Windows-10-Without-Installing-CUDA-1187/) which is detailed below. But the same issue persisted.


**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
conda update conda
conda update anaconda
conda update python
conda update --all

conda create --name tf-gpu
cmd
conda activate tf-gpu

conda install tensorflow-gpu keras-gpu  
conda install -c aaronzs tensorflow-gpu
conda install -c anaconda cudatoolkit
conda install -c anaconda cudnn

python
import tensorflow as tf
```


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

> ImportError: Traceback (most recent call last):
>   File ""C:\Users\JOLOU\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
>     from tensorflow.python.pywrap_tensorflow_internal import *
>   File ""C:\Users\JOLOU\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
>     _pywrap_tensorflow_internal = swig_import_helper()
>   File ""C:\Users\JOLOU\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
>   File ""C:\Users\JOLOU\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 242, in load_module
>     return load_dynamic(name, filename, file)
>   File ""C:\Users\JOLOU\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 342, in load_dynamic
>     return _load(spec)
> ImportError: DLL load failed: The specified module could not be found.
> 
> 
> Failed to load the native TensorFlow runtime.
> 
> See https://www.tensorflow.org/install/errors
> 
> for some common reasons and solutions.  Include the entire stack trace
> above this error message when asking for help.
> 
> "
29081,A loss function for calculating categorical cross-entropy from the softmax probabilities,"**System information**
- TensorFlow version (you are using): 1.12
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
I wish for a loss function that calculates categorical cross-entropy based on softmax predictions. As far as I have seen, there are only function that work with the logits. Why is there no way to use the softmax scores?

**Will this change the current api? How?**
Yes, a function will be added.

**Who will benefit with this feature?**
People who wish to conceptually separate the model output and loss calculation. Also, in this way I do not have to change the model in order to use it for prediction."
29079,Error convert pb file to tflite,"## System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Maybe, prelu function, See[link](https://github.com/sirius-ai/MobileFaceNet_TF/blob/bccb7bd7faf503ffb792f18d7ea3ed7ec6e1d092/nets/MobileFaceNet.py#L268)
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.13
Python version: 3.7.3
Bazel version (if compiling from source): not compile

## Describe the current behavior

I use the project of [MobileFaceNet_TF](https://github.com/sirius-ai/MobileFaceNet_TF)

The project has pretrained model in the path of [arch/pretrained_model](https://github.com/sirius-ai/MobileFaceNet_TF/tree/master/arch/pretrained_model).

I want to convert [the freeze pb file](https://github.com/sirius-ai/MobileFaceNet_TF/blob/master/arch/pretrained_model/MobileFaceNet_9925_9680.pb) to tflite file, the pb file freezed by [the script](https://github.com/sirius-ai/MobileFaceNet_TF/blob/master/utils/freeze_graph.py)

1. In the path of `arch/pretrained_model`, i use under tflite_conver command to convert model to tflite.

```cmd
tflite_convert  ^
--output_file  MobileFaceNet_9925_9680.tflite  ^
--graph_def_file  MobileFaceNet_9925_9680.pb    ^
--input_arrays  ""input""  ^
--input_shapes  ""1,112,112,3""  ^
--output_arrays  embeddings  ^
--output_format  TFLITE
```

2. I also use toco, but the error is same.

```cmd
toco ^
--output_file MobileFaceNet_9925_9680.tflite ^
--graph_def_file MobileFaceNet_9925_9680.pb ^
--output_format TFLITE ^
--inference_type FLOAT ^
--inference_input_type FLOAT ^
--input_arrays input ^
--input_shapes 1,112,112,3 ^
--output_arrays embeddings
```

3. I use python api, the error is same.

```py
import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_frozen_graph('arch/pretrained_model/MobileFaceNet_9925_9680.pb',input_arrays=['input'],output_arrays=['embeddings'],input_shapes={'input':[1,112,112,3]})
tflite_model = converter.convert()
open(""test.tflite"", ""wb"").write(tflite_model)
```

4. I try tensorflow 2.0, but not found api which can import pb file.😓

## Code to reproduce the issue

### the tflite_convert tool error infomation

```cmd
λ tflite_convert  ^
More? --output_file  MobileFaceNet_9925_9680.tflite  ^
More? --graph_def_file  MobileFaceNet_9925_9680.pb    ^
More? --input_arrays  ""input""  ^
More? --input_shapes  ""1,112,112,3""  ^
More? --output_arrays  embeddings  ^
More? --output_format  TFLITE
2019-05-28 15:32:07.380246: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2019-05-28 15:32:08.157890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce MX150 major: 6 minor: 1 memoryClockRate(GHz): 1.341
pciBusID: 0000:01:00.0
totalMemory: 2.00GiB freeMemory: 1.62GiB
2019-05-28 15:32:08.185527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-05-28 15:32:08.727623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-28 15:32:08.742876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-05-28 15:32:08.753078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-05-28 15:32:08.764321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1365 MB memory) -> physical GPU (device: 0, name: GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\Scripts\tflite_convert-script.py"", line 10, in <module>
    sys.exit(main())
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 442, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 438, in run_main
    _convert_model(tflite_flags)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 191, in _convert_model
    output_data = converter.convert()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\lite.py"", line 455, in convert
    **converter_kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\convert.py"", line 442, in toco_convert_impl
    input_data.SerializeToString())
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\convert.py"", line 205, in toco_convert_protos
    ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
2019-05-28 15:32:13.074828: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2019-05-28 15:32:13.078767: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-05-28 15:32:13.079077: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-05-28 15:32:13.079438: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-05-28 15:32:13.079756: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-05-28 15:32:13.087213: E tensorflow/lite/toco/import_tensorflow.cc:2079] tensorflow::ImportGraphDef failed with status: Not found: Op type not registered 'Placeholder' in binary running on DESKTOP-TG1FKM4. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
2019-05-28 15:32:13.434412: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2747 operators, 4533 arrays (0 quantized)
2019-05-28 15:32:13.816499: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1810 operators, 3076 arrays (0 quantized)
2019-05-28 15:32:14.122395: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1810 operators, 3076 arrays (0 quantized)
2019-05-28 15:32:14.124627: F tensorflow/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:98] Check failed: other_op->type == OperatorType::kMerge Found BatchNormalization as non-selected output from Switch, but only Merge supported.
```

### the toco tool error information

```cmd
toco ^
More? --output_file MobileFaceNet_9925_9680.tflite ^
More? --graph_def_file MobileFaceNet_9925_9680.pb ^
More? --output_format TFLITE ^
More? --inference_type FLOAT ^
More? --inference_input_type FLOAT ^
More? --input_arrays input ^
More? --input_shapes 1,112,112,3 ^
More? --output_arrays embeddings
2019-05-29 09:50:45.125226: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2019-05-29 09:50:45.877324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce MX150 major: 6 minor: 1 memoryClockRate(GHz): 1.341
pciBusID: 0000:01:00.0
totalMemory: 2.00GiB freeMemory: 1.62GiB
2019-05-29 09:50:45.899741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-05-29 09:50:46.412028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-29 09:50:46.424631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-05-29 09:50:46.434346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-05-29 09:50:46.441283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1365 MB memory) -> physical GPU (device: 0, name: GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\Scripts\toco-script.py"", line 10, in <module>
    sys.exit(main())
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 442, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 438, in run_main
    _convert_model(tflite_flags)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\tflite_convert.py"", line 191, in _convert_model
    output_data = converter.convert()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\lite.py"", line 455, in convert
    **converter_kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\convert.py"", line 442, in toco_convert_impl
    input_data.SerializeToString())
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\convert.py"", line 205, in toco_convert_protos
    ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
2019-05-29 09:50:50.939448: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2019-05-29 09:50:50.942638: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-05-29 09:50:50.942917: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-05-29 09:50:50.943314: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-05-29 09:50:50.943634: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-05-29 09:50:50.950475: E tensorflow/lite/toco/import_tensorflow.cc:2079] tensorflow::ImportGraphDef failed with status: Not found: Op type not registered 'Placeholder' in binary running on DESKTOP-TG1FKM4. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
2019-05-29 09:50:51.309990: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2747 operators, 4533 arrays (0 quantized)
2019-05-29 09:50:51.724318: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1810 operators, 3076 arrays (0 quantized)
2019-05-29 09:50:52.042452: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1810 operators, 3076 arrays (0 quantized)
2019-05-29 09:50:52.045060: F tensorflow/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:98] Check failed: other_op->type == OperatorType::kMerge Found BatchNormalization as non-selected output from Switch, but only Merge supported.
```

### the python api error information
```py
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-7-5a3c093c4e77> in <module>
      1 import tensorflow as tf
      2 converter = tf.lite.TFLiteConverter.from_frozen_graph('arch/pretrained_model/MobileFaceNet_9925_9680.pb',input_arrays=['input'],output_arrays=['embeddings'],input_shapes={'input':[1,112,112,3]})
----> 3 tflite_model = converter.convert()
      4 open(""test.tflite"", ""wb"").write(tflite_model)

~/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)
    453           input_tensors=self._input_tensors,
    454           output_tensors=self._output_tensors,
--> 455           **converter_kwargs)
    456     else:
    457       result = _toco_convert_graph_def(

~/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs)
    440   data = toco_convert_protos(model_flags.SerializeToString(),
    441                              toco_flags.SerializeToString(),
--> 442                              input_data.SerializeToString())
    443   return data
    444 

~/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str)
    203       stderr = _try_convert_to_unicode(stderr)
    204       raise ConverterError(
--> 205           ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
    206   finally:
    207     # Must manually cleanup files.

ConverterError: TOCO failed. See console for info.
2019-05-29 09:43:46.962261: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-05-29 09:43:46.985465: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3499530000 Hz
2019-05-29 09:43:46.987287: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a9808ffee0 executing computations on platform Host. Devices:
2019-05-29 09:43:46.987353: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-05-29 09:43:47.089108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-05-29 09:43:47.089794: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a980904a30 executing computations on platform CUDA. Devices:
2019-05-29 09:43:47.089868: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-05-29 09:43:47.090474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6575
pciBusID: 0000:42:00.0
totalMemory: 10.91GiB freeMemory: 9.87GiB
2019-05-29 09:43:47.090496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-05-29 09:43:47.095453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-29 09:43:47.095478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-05-29 09:43:47.095487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-05-29 09:43:47.095829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9601 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)
2019-05-29 09:43:47.227671: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2747 operators, 4533 arrays (0 quantized)
2019-05-29 09:43:47.335840: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1810 operators, 3076 arrays (0 quantized)
2019-05-29 09:43:47.418666: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1810 operators, 3076 arrays (0 quantized)
2019-05-29 09:43:47.419336: F tensorflow/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:98] Check failed: other_op->type == OperatorType::kMerge Found BatchNormalization as non-selected output from Switch, but only Merge supported.
Aborted (core dumped)
```
"
29078,Many false positives in a custom SSD model with Tensorflow object detection API,"My model has 2 classes (no background class) and is trained using transfer learning with ssd_mobilenet_v2_coco. It detects and classifies well the objects it was trained on. However, on new images it also detects many false positive bounding box's of the background. Sometimes the background objects that are detected are objects that existed in the coco data set (e.g. a cup), but not only - also a black screen is detected as an object.

Can it be that my model features are still sensitive to the Coco data set objects?
I think that on the config file, the relevant part for this issue is the hard_example_miner. However I did not understand how is this related and if I should change my current configuration.
This is the configuration I'm using:

hard_example_miner {

num_hard_examples: 3000

iou_threshold: 0.99

loss_type: CLASSIFICATION

max_negatives_per_positive: 3

in_negatives_per_image: 3

}

Should I make any changes to this? Or any other solutions to improve the model on background images?"
29077,Issue with tf.nn.softmax_cross_entropy_with_logits when label value is 100+,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:  Installed from Docker official repo
- **TensorFlow version (use command below)**: Ver 1.12.0
- **Python version**: python 3.6
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:  7.4
Cuda Toolkit: 10.1
- **GPU model and memory**: Tesla P100


I have written a custom CNN for a semantic segmentation problem. For the loss function, I have used 
tf.nn.softmax_cross_entropy_with_logits(labels=tf.cast(tf.squeeze(one_hot_labels),dtype=tf.float32),logits =tf.squeeze(pred))
Here is the interesting part, when some of my components within the image are labelled with values such as 100+(such as 105) the network fails to converge during training. If the same components are labelled with less than 100 such as (97) the loss converges. What could be the root cause of this issue here? 

"
29076,TensorBoard UI issue with tf.function,"The code does not behave like the code in https://www.tensorflow.org/tensorboard/r2/graphs. It is rather a blank you with 3 words. 

"
29075,tf.function with input_signature slower on unseen sequence length,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Linux Ubuntu 16.04:
- TensorFlow installed from: binary
- TensorFlow version: `2.0.0-dev20190526`
- Python version: 3.6.6
- CUDA/cuDNN version: 10.0
- GPU model and memory: GTX 1060

**Describe the current behavior**

When running a `tf.function` on 3D inputs (a batch of sequence), I found that the execution is slower on unseen sequence length even if a compatible `input_signature` is set. On a large graph, this results in a low GPU usage and a growing CPU memory usage for several iterations until most sequence lengths are seen. It is as if new graphs were compiled internally even though the function does not seem to be retraced.

This effect does not affect eager mode or V1 graph mode where the execution directly runs at its target speed and memory usage.

**Describe the expected behavior**

`tf.function` with an input signature should behave like graph mode with constant memory usage and no ""warmup"" phase.

**Code to reproduce the issue**

While this issue is very visible on large graphs, I tried to compile a small example to consistently show the effect:

```python
import time
import itertools
import random

import tensorflow as tf

def generate_token_based_shapes(num_tokens=4096):
    while True:
        length = random.randint(1, 100)
        batch_size = int(num_tokens / length)
        yield (batch_size, length)

# Generate 500k tensors of shape [None, None, 512] but with similar total size.
shapes = list(itertools.islice(generate_token_based_shapes(), 500000))
dataset = tf.data.Dataset.from_tensor_slices(shapes)
dataset = dataset.shuffle(len(shapes))
dataset = dataset.map(lambda shape: tf.zeros(tf.concat([shape, [512]], axis=0)))
dataset = dataset.repeat()
dataset = dataset.prefetch(1)

# Define a model with some layers.
model = tf.keras.Sequential([
    tf.keras.layers.Dense(1024),
    tf.keras.layers.Dense(1024),
    tf.keras.layers.Dense(1024),
    tf.keras.layers.Dense(1024),
    tf.keras.layers.Dense(1024)])

@tf.function(input_signature=(tf.TensorSpec([None, None, 512], dtype=tf.float32),))
def run_step(inputs):
    return model(inputs)

seen_lengths = set()
for x in dataset:
    length = x.shape[1]
    start = time.time()
    _ = run_step(x)
    end = time.time()
    print(length in seen_lengths, end - start)
    seen_lengths.add(length)
```

**Other info / logs**

The above code produced the following logs when run on CPU:

```text
False 0.43003296852111816
False 0.11496973037719727
False 0.11308979988098145
False 0.11620664596557617
False 0.11439895629882812
False 0.11322546005249023
True 0.095062255859375
False 0.11357808113098145
False 0.11438512802124023
False 0.11338496208190918
False 0.1123197078704834
False 0.11295366287231445
False 0.11250948905944824
False 0.11576318740844727
False 0.1139533519744873
False 0.11278915405273438
False 0.11090493202209473
True 0.09256935119628906
False 0.11287093162536621
False 0.11374545097351074
False 0.11446619033813477
False 0.11277508735656738
False 0.11354255676269531
False 0.11325383186340332
False 0.1137855052947998
False 0.11451315879821777
False 0.11423110961914062
True 0.09340834617614746
False 0.1146705150604248
False 0.11285781860351562
False 0.11371898651123047
True 0.09309053421020508
True 0.09239482879638672
True 0.09140896797180176
False 0.11467862129211426
False 0.11377716064453125
False 0.11178278923034668
False 0.11260485649108887
True 0.09450674057006836
True 0.09363818168640137
True 0.09272456169128418
False 0.11517977714538574
False 0.11325454711914062
True 0.09257698059082031
False 0.11360836029052734
True 0.09241485595703125
False 0.11343145370483398
True 0.09368515014648438
False 0.11366653442382812
True 0.09125065803527832
False 0.1126089096069336
False 0.11182904243469238
True 0.09548735618591309
True 0.09283709526062012
```

When the length is unseen, it takes about 0.113s but 0.092s after that.

On this example the effect is small but I'm trying to train a Transformer model with `tf.function` and it takes very long for the training to reach full speed. The CPU memory usage also keeps growing during this ""warmup"" phase. The same model works well when integrated with `tf.estimator` as I'm trying to move from Estimator to V2 custom loops."
29074,Cmake Project is abandoned?,"- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows/Ubuntu

- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.12-1.14
- Python version: 3.5/3.6
- Bazel version (if compiling from source): 0.21-0.253
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: 10.0 7.5
- GPU model and memory: 11G

I found cmake project from 1.12 is abandoned.
I want to build c++  dll on windows.
The ubuntu so is compiled easily by bazel. Windows is hard.
What should I do?

"
29073,Empty trainable variables in keras model (tf 2.0),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-2504-g2be59a5191 2.0.0-dev20190522
- Python version: 3.6.8
- CUDA/cuDNN version: CUDA Version 10.0.130
- GPU model and memory: Nvidia GeForce GTX 1080 Ti

**Describe the current behavior**
I want to create UNet using the Keras Model subclassing API:
The current code is:
```python
class UNet(keras.Model):
    """"""
    UNet Architecture concatenating encoder and decoder

    Examples:
        * Direct Usage:

            .. testcode::

                x = tf.ones((1, 512, 512, 3))
                u_net = UNet(input_res = 512,
                             min_res=4,
                             kernel_size=4,
                             initial_filters=64,
                             filters_cap=512,
                             channels=3)
                y = u_net(x)
                print(y.shape)

            .. testoutput::
                (1, 512, 512, 3)

    """"""

    def __init__(
        self,
        input_res,
        min_res,
        kernel_size,
        initial_filters,
        filters_cap,
        channels,
        use_dropout_encoder=True,
        use_dropout_decoder=True,
        dropout_prob=0.3,
        encoder_non_linearity=keras.layers.LeakyReLU,
        decoder_non_linearity=keras.layers.ReLU,
    ):
        super().__init__()

        # layer specification
        self.use_dropout_encoder = use_dropout_encoder
        self.use_dropout_decoder = use_dropout_decoder
        self.dropout_probability = dropout_prob
        self.encoder_non_linearity = encoder_non_linearity
        self.decoder_non_linearity = decoder_non_linearity
        self.kernel_size = kernel_size

        # encoder layers is a list of list, each list is a ""block"",
        # this makes easy the creation of decoder
        self.encoder_layers = []
        self.decoder_layers = []
        self.concat_layers = []

        # ########### Encoder creation
        encoder_layers_spec = [128, 256, 512, 512, 512, 512, 512, 512]

        decoder_layer_spec = []
        for i, filters in enumerate(encoder_layers_spec):
            self.encoder_layers.append(self.get_encoder_block(filters, use_bn=(i != 0)))

        # ############## Decoder creation
        decoder_layer_spec =[512, 512, 512, 512, 512, 256, 128]

        for i, filters in enumerate(decoder_layer_spec):
            self.concat_layers.append(keras.layers.Concatenate())
            self.decoder_layers.append(
                self.get_decoder_block(filters, use_dropout=(i < 3))
            )

        # final layer
        initializer = tf.random_normal_initializer(0.0, 0.02)
        self.final_layer = keras.layers.Conv2DTranspose(
            channels,
            self.kernel_size,
            strides=(2, 2),
            padding=""same"",
            activation=keras.activations.tanh,
            kernel_initializer=initializer,
        )

    def get_block(
        self,
        filters,
        conv_layer=None,
        use_bn=True,
        use_dropout=False,
        non_linearity=keras.layers.LeakyReLU,
    ):
        initializer = tf.random_normal_initializer(0.0, 0.02)
        # Conv2D
        block = [
            conv_layer(
                filters,
                self.kernel_size,
                strides=(2, 2),
                padding=""same"",
                use_bias=False,
                kernel_initializer=initializer,
            )
        ]

        # Batch normalization
        if use_bn:
            block.append(keras.layers.BatchNormalization())

        # dropout
        if use_dropout:
            block.append(keras.layers.Dropout(self.dropout_probability))

        # Non linearity
        block.append(non_linearity())

        return block

    def get_encoder_block(self, filters, use_bn=True):
        return self.get_block(
            filters,
            conv_layer=keras.layers.Conv2D,
            use_bn=use_bn,
            use_dropout=self.use_dropout_encoder,
            non_linearity=self.encoder_non_linearity,
        )

    def get_decoder_block(self, filters, use_bn=True, use_dropout=False):
        return self.get_block(
            filters,
            conv_layer=keras.layers.Conv2DTranspose,
            use_bn=use_bn,
            use_dropout=self.use_dropout_decoder and use_dropout,
            non_linearity=self.decoder_non_linearity,
        )

    def __call__(self, inputs, training=True):
        # encoders evaluated
        encoder_layer_eval = []
        x = inputs

        for block in self.encoder_layers:
            for layer in block:
                if isinstance(layer, keras.layers.BatchNormalization) or isinstance(
                    layer, keras.layers.Dropout
                ):
                    x = layer(x, training=training)
                else:
                    x = layer(x)
            encoder_layer_eval.append(x)

        encoder_layer_eval = encoder_layer_eval[:-1]

        for i, block in enumerate(self.decoder_layers):
            for layer in block:
                if isinstance(layer, keras.layers.BatchNormalization) or isinstance(
                    layer, keras.layers.Dropout
                ):
                    x = layer(x, training=training)
                else:
                    x = layer(x)
            x = self.concat_layers[i]([x, encoder_layer_eval[-1 - i]])

        x = self.final_layer(x)

        return x

```

When I evaluate the model using an input and check the trainable variables they are empty:

```python
x = tf.ones((1, 512, 512, 3))
u_net = UNet(input_res = 512,
                       min_res=4, 
                       kernel_size=4,
                       initial_filters=64,
                       filters_cap=512,
                       channels=3)
                y = u_net(x)               
                print(u_net.trainable_variables) # it prints: []
```

**Describe the expected behavior**
The code should print the list of trainable variables of the Net. The output is correct so the `__call__` method is correctly called.

"
29072,Documenting the Ref keyword from operations input/output types,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## Description of issue (what needs changing):

### Clear description

Some operations, like `Assign`, use a `Ref` keyword for their input and/or output. (example: tensorflow/core/ops/state_ops.cc). This keyword is not documented anywhere.

Additionally, I haven't found any way to combine `Ref` with `list` (i.e. make an operation take a list of mutable tensors as input).
"
29071,Does tf.nn.batch_normalization support fp16,"fp16 is new feature of Nvida GPUs, does batch_normalization support fp16?"
29070,tf_upgrade_v2 has no attribute __pasta__,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.5
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0.0-alpha0
- Python version: 3.7.3
- GPU model and memory: cpu

**Describe the current behavior**
When running the tf2 upgrade script on any of my projects I would get the following error:
```
$ tf_upgrade_v2 --intree my_project --outtree my_project_upgrade

INFO line 46:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'
INFO line 49:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'
INFO line 30:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'
INFO line 33:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'
INFO line 21:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'
INFO line 24:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'
INFO line 21:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'
INFO line 24:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'
INFO line 35:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'
INFO line 38:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'
INFO line 68:17: Added keywords to args of function 'tf.convert_to_tensor'
INFO line 69:17: Added keywords to args of function 'tf.convert_to_tensor'
INFO line 72:34: Renamed 'tf.log' to 'tf.math.log'
INFO line 75:21: Added keywords to args of function 'tf.reduce_max'
INFO line 76:15: Added keywords to args of function 'tf.reduce_mean'
INFO line 56:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'
INFO line 59:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'
INFO line 75:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'
INFO line 78:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'
INFO line 41:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'
INFO line 43:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'
INFO line 65:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'
INFO line 67:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'
INFO line 41:13: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'
INFO line 43:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'
INFO line 45:22: Renamed 'tf.Summary' to 'tf.compat.v1.Summary'
INFO line 84:22: Renamed 'tf.Summary' to 'tf.compat.v1.Summary'
Traceback (most recent call last):
  File ""/usr/local/bin/tf_upgrade_v2"", line 10, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/tf_upgrade_v2_main.py"", line 123, in main
    args.input_tree, output_tree, args.copy_other_files)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py"", line 624, in process_tree
    _, l_report, l_errors = self.process_file(input_path, output_path)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py"", line 494, in process_file
    temp_file)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py"", line 548, in process_opened_file
    self.update_string_pasta("""".join(lines), in_filename))
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py"", line 510, in update_string_pasta
    t = pasta.parse(text)
  File ""/usr/local/lib/python3.7/site-packages/pasta/__init__.py"", line 25, in parse
    annotator.visit(t)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 1190, in visit
    super(AstAnnotator, self).visit(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py"", line 262, in visit
    return visitor(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 47, in wrapped
    f(self, node, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 220, in visit_Module
    self.generic_visit(node)
  File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py"", line 270, in generic_visit
    self.visit(item)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 1190, in visit
    super(AstAnnotator, self).visit(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py"", line 262, in visit
    return visitor(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 95, in wrapped
    f(self, node, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 381, in visit_ClassDef
    self.visit(stmt)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 1190, in visit
    super(AstAnnotator, self).visit(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py"", line 262, in visit
    return visitor(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 95, in wrapped
    f(self, node, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 411, in visit_FunctionDef
    self.visit(stmt)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 1190, in visit
    super(AstAnnotator, self).visit(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py"", line 262, in visit
    return visitor(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 47, in wrapped
    f(self, node, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 530, in visit_Assign
    self.visit(node.value)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 1190, in visit
    super(AstAnnotator, self).visit(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py"", line 262, in visit
    return visitor(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 47, in wrapped
    f(self, node, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 829, in visit_IfExp
    self.visit(node.body)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 1190, in visit
    super(AstAnnotator, self).visit(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py"", line 262, in visit
    return visitor(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 47, in wrapped
    f(self, node, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 700, in visit_BoolOp
    self.visit(value)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 1190, in visit
    super(AstAnnotator, self).visit(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 132, in visit
    super(BaseVisitor, self).visit(node)
  File ""/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py"", line 262, in visit
    return visitor(node)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 47, in wrapped
    f(self, node, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 803, in visit_Dict
    self.visit(key)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/annotate.py"", line 1188, in visit
    fmt.set(node, 'indent', self._indent)
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/formatting.py"", line 37, in set
    _formatting_dict(node)[name] = value
  File ""/usr/local/lib/python3.7/site-packages/pasta/base/formatting.py"", line 49, in _formatting_dict
    return getattr(node, PASTA_DICT)
AttributeError: 'NoneType' object has no attribute '__pasta__'
```

I have tried updating pasta (`pip3 install --upgrade pasta`) which now results in 
```
$ tf_upgrade_v2 --intree my_project --outtree my_project_upgrade

Traceback (most recent call last):
  File ""/usr/local/bin/tf_upgrade_v2"", line 10, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/tf_upgrade_v2_main.py"", line 123, in main
    args.input_tree, output_tree, args.copy_other_files)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py"", line 624, in process_tree
    _, l_report, l_errors = self.process_file(input_path, output_path)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py"", line 494, in process_file
    temp_file)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py"", line 548, in process_opened_file
    self.update_string_pasta("""".join(lines), in_filename))
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/tools/compatibility/ast_edits.py"", line 510, in update_string_pasta
    t = pasta.parse(text)
AttributeError: module 'pasta' has no attribute 'parse'
```
I was unable to find anyone with similar problems.
What is the supported pasta version that is needed to run the tf2 upgrade script?
"
29067,Unable to use tf.ragged_tensor with tf.from tensor_slices,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
29065,output of make_one_shot_iterator of TFRecord Dataset without eager disabled,"*System information*
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (almost same as template)
- OS Platform and Distribution : Linux Ubuntu 16.04
- TensorFlow installed from : binary
- TensorFlow version : 1.13.1
- Python version: 3.5.2

With eager enabled:
input from TFRecordDataset with dimension (batchsize, data_shape) 
Without eager:
dimension are (?, data_shape)

expected the same behavior as with eager

```
import tensorflow as tf


SHUFFLE_BUFFER = 1000
BATCH_SIZE = 32
NUM_CLASSES = 12

feature_description = {
    'feature0': tf.FixedLenFeature([32768], tf.float32),
    'feature1': tf.FixedLenFeature([1], tf.int64)
}

def _parse_function(example_proto):
    parsed_example = tf.parse_single_example(example_proto, feature_description)
    parsed_example[""feature0""] = tf.transpose(tf.reshape(parsed_example['feature0'], (256,128)))
    return parsed_example

def create_dataset(filepath):
    
    dataset = tf.data.TFRecordDataset(filepath)
    
    dataset = dataset.map(_parse_function) #, num_parallel_calls=8)
    
    dataset = dataset.repeat()
    
    dataset = dataset.shuffle(SHUFFLE_BUFFER)
    dataset = dataset.batch(BATCH_SIZE)
    
    iterator = dataset.make_one_shot_iterator()
    
    feature = iterator.get_next()
    #print(feature)
    lmfcc = feature[""feature0""]
    label = feature[""feature1""]
    
    lmfcc = tf.reshape(lmfcc, [-1,128, 256, 1])
    
    label = tf.one_hot(label, NUM_CLASSES)
    print(lmfcc.shape)
    print(label.shape)

    return lmfcc, label

 lmfcc, label = create_dataset(""../data/debug/sample.tfrecords"")`
```
output eager disabled

(?, 128, 256)
(?, 1, 12)"
29064,"What does GradientTape.gradient(target, ...) when target is a list of tensors and not a single tensor ?","## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/GradientTape?hl=en#gradient

## Description of issue (what needs changing):

### Clear description

Actually there is no way to know what does the gradient method when target is not a tensor but a list of tensors, like `target=[loss_1, loss_2]`. Does it compute the sum of the gradients of `loss_1` and `loss_2` ? It seems like no, from some tests I did. What does it do then ?

I tried to follow the source code, without success. GradientTape.gradient calls tensorflow.python.eager.imperative_grad.imperative_grad, which calls tensorflow.python.pywrap_tensorflow.TFE_Py_TapeGradient, which is a C++ function calling ComputeGradient. But I couldn't find the code of ComputeGradient. I just found it mentioned in tensorflow/c/eager/tape.h. But I don't find tape.cc.


### Usage example

There is no usage example for this case."
29063,"""tensorflow.python.eager.core._FallbackException: Expecting int64_t value for attr strides, got numpy.int32"" + ""ValueError: Incompatible conversion from float32 to uint8"" when calling fit() on my model","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.12.2
- Python version: 3.5
- CUDA/cuDNN version: V8.0.61
- GPU model and memory: Tesla P100-PCIE, 12193MiB

**Describe the current behavior**
When I call

```
model.fit(train, steps_per_epoch=int(np.ceil(num_train_samples / BATCH_SIZE)), epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_data=val, validation_steps=int(np.ceil(num_val_samples / BATCH_SIZE)))
```

I get the following error:

```
ValueError: Incompatible type conversion requested to type 'uint8' for variable of type 'float32'
```

This error occurs during handling of a first exception:

```
tensorflow.python.eager.core._FallbackException: Expecting int64_t value for attr strides, got numpy.int32
```

I only use NumPy to load ndarrays (using `np.load()`) after which they are immediately converted to TensorFlow tensors. I've also made sure those tensors contain TensorFlow data types, so I am puzzled as to how a NumPy datatypes manages to sneak through. I also couldn't find any variables with numpy.int32 type during debugging.

**Code to reproduce the issue**
My full script is as follows:

```
from __future__ import absolute_import, division, print_function
import tensorflow as tf
import numpy as np
import os

CLASSES = [""aluminium"", ""asphalt"", ""brick"", ""cloud"", ""concrete"", ""fabric"", ""foliage"", ""glass"", ""grass"", ""gravel"", ""iron"", ""living"", ""other"", ""plastic"", ""sky"", ""soil"", ""stone"", ""steel"", ""tile"", ""water"", ""wood""]
NUM_CLASSES = len(CLASSES)
DIR_DATASET = ""/folder/to/numpyndarrays""
WIDTH = 512
HEIGHT = 512
BATCH_SIZE = 10
NUM_EPOCHS = 10
TRAIN_VAL_SPLIT = 0.9
num_samples = len([filename[:-4] for filename in os.listdir(DIR_DATASET + ""ndarrays/"")])
num_train_samples = round(num_samples * TRAIN_VAL_SPLIT)
num_val_samples = round(num_samples * (1 - TRAIN_VAL_SPLIT))

#os.environ[""CUDA_VISIBLE_DEVICES""] = """"
tf.enable_eager_execution()

def train_sample_fetcher():
    return sample_fetcher()

def val_sample_fetcher():
    return sample_fetcher(is_validations=True)

def sample_fetcher(is_validations=False):
    sample_names = [filename[:-4] for filename in os.listdir(DIR_DATASET + ""ndarrays/"")]
    if not is_validations: sample_names = sample_names[:int(len(sample_names) * TRAIN_VAL_SPLIT)]
    else: sample_names = sample_names[int(len(sample_names) * TRAIN_VAL_SPLIT):]
    for sample_name in sample_names:
        rgb = tf.image.decode_jpeg(tf.read_file(DIR_DATASET + sample_name + "".jpg""))
        rgb = tf.image.resize_images(rgb, (HEIGHT, WIDTH))
        #d = tf.image.decode_jpeg(tf.read_file(DIR_DATASET + ""depth/"" + sample_name + "".jpg""))
        #d = tf.image.resize_images(d, (HEIGHT, WIDTH))
        #rgbd = tf.concat([rgb,d], axis=2)
        onehots = tf.convert_to_tensor(np.load(DIR_DATASET + ""ndarrays/"" + sample_name + "".npy""), dtype=tf.float32)
        yield rgb, onehots

def deconvolve(tensor, num_filters):
    tensor = tf.layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(tensor)
    tensor = tf.layers.BatchNormalization()(tensor)
    tensor = tf.keras.layers.Activation('relu')(tensor)
    tensor = tf.layers.Conv2D(num_filters, (3, 3), padding='same')(tensor)
    tensor = tf.layers.BatchNormalization()(tensor)
    tensor = tf.keras.layers.Activation('relu')(tensor)
    tensor = tf.layers.Conv2D(num_filters, (3, 3), padding='same')(tensor)
    tensor = tf.layers.BatchNormalization()(tensor)
    tensor = tf.keras.layers.Activation('relu')(tensor)
    return tensor

def dice_loss(y_true, y_pred):
    smooth = 1.
    y_true_f = tf.reshape(y_true, [-1]) # Flatten
    y_pred_f = tf.reshape(y_pred, [-1]) # Flatten
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    dice_coefficient = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)
    loss = 1 - dice_coefficient
    return loss

train = tf.data.Dataset.from_generator(generator=train_sample_fetcher, output_types=(tf.uint8, tf.float32))
train = train.repeat()
train = train.batch(BATCH_SIZE)
train = train.shuffle(10)
val = tf.data.Dataset.from_generator(generator=val_sample_fetcher, output_types=(tf.uint8, tf.float32))

# i = 0
# for sample in train:
#     i = i + 1
#     print(sample[0].dtype)
#     print(sample[1].dtype)

input = tf.keras.Input(shape=(HEIGHT, WIDTH, 3))
resnet = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(HEIGHT, WIDTH, 3), pooling=None, classes=1000)(input)
tensor = deconvolve(resnet, 512)
tensor = deconvolve(tensor, 256)
tensor = deconvolve(tensor, 128)
tensor = deconvolve(tensor, 64)
tensor = deconvolve(tensor, 32)
output = tf.layers.Conv2D(NUM_CLASSES, (1, 1), activation='sigmoid')(tensor)

model = tf.keras.models.Model(inputs=[input], outputs=[output])
adam = tf.train.AdamOptimizer()
model.compile(optimizer=adam, loss=dice_loss, metrics=[dice_loss])
history = model.fit(train, steps_per_epoch=int(np.ceil(num_train_samples / BATCH_SIZE)), epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_data=val, validation_steps=int(np.ceil(num_val_samples / BATCH_SIZE)))
```

**Other info / logs**
Here are some of the NumPy arrays I read: https://we.tl/t-aml3GBKorK

The full stacktrace I get:
```
2019-05-27 19:05:49.960354: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-27 19:05:50.173624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:04:00.0
totalMemory: 11.91GiB freeMemory: 11.62GiB
2019-05-27 19:05:50.345182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:82:00.0
totalMemory: 11.91GiB freeMemory: 11.62GiB
2019-05-27 19:05:50.345255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1
2019-05-27 19:05:50.969891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-27 19:05:50.969933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 
2019-05-27 19:05:50.969940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N N 
2019-05-27 19:05:50.969943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   N N 
2019-05-27 19:05:50.970428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11241 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
2019-05-27 19:05:50.970865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11241 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-12GB, pci bus id: 0000:82:00.0, compute capability: 6.0)
python3.5/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.
  warnings.warn('The output shape of `ResNet50(include_top=False)` '
Epoch 1/10
2019-05-27 19:06:03.844910: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 5 of 10
2019-05-27 19:06:13.468298: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 9 of 10
2019-05-27 19:06:15.918664: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:136] Shuffle buffer filled.
Traceback (most recent call last):
  File ""python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 976, in conv2d
    ""data_format"", data_format, ""dilations"", dilations)
tensorflow.python.eager.core._FallbackException: Expecting int64_t value for attr strides, got numpy.int32

During handling of the above exception occurred:

Traceback (most recent call last):
  File ""/dir/to/my/script.py"", line 89, in <module>
    history = model.fit(train, steps_per_epoch=int(np.ceil(num_train_samples / BATCH_SIZE)), epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_data=val, validation_steps=int(np.ceil(num_val_samples / BATCH_SIZE)))
  File ""python3.5/site-packages/tensorflow/python/keras/engine/training.py"", line 1614, in fit
    validation_steps=validation_steps)
  File ""python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py"", line 705, in fit_loop
    batch_size=batch_size)
  File ""python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py"", line 251, in iterator_fit_loop
    model, x, y, sample_weights=sample_weights, training=True)
  File ""python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py"", line 511, in _process_single_batch
    training=training)
  File ""python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py"", line 90, in _model_loss
    outs, masks = model._call_and_compute_mask(inputs, **kwargs)
  File ""python3.5/site-packages/tensorflow/python/keras/engine/network.py"", line 856, in _call_and_compute_mask
    mask=masks)
  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py"", line 1029, in _run_internal_graph
    computed_tensor, **kwargs)
  File ""python3.5/site-packages/tensorflow/python/keras/engine/network.py"", line 856, in _call_and_compute_mask
    mask=masks)
  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py"", line 1031, in _run_internal_graph
    output_tensors = layer.call(computed_tensor, **kwargs)
  File ""python3.5/site-packages/tensorflow/python/keras/layers/convolutional.py"", line 194, in call
    outputs = self._convolution_op(inputs, self.kernel)
  File ""python3.5/site-packages/tensorflow/python/ops/nn_ops.py"", line 868, in __call__
    return self.conv_op(inp, filter)
  File ""python3.5/site-packages/tensorflow/python/ops/nn_ops.py"", line 520, in __call__
    return self.call(inp, filter)
  File ""python3.5/site-packages/tensorflow/python/ops/nn_ops.py"", line 204, in __call__
    name=self.name)
  File ""python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 982, in conv2d
    name=name, ctx=_ctx)
  File ""python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1015, in conv2d_eager_fallback
    _attr_T, _inputs_T = _execute.args_to_matching_eager([input, filter], _ctx)
  File ""python3.5/site-packages/tensorflow/python/eager/execute.py"", line 195, in args_to_matching_eager
    ret = [internal_convert_to_tensor(t, dtype, ctx=ctx) for t in l]
  File ""python3.5/site-packages/tensorflow/python/eager/execute.py"", line 195, in <listcomp>
    ret = [internal_convert_to_tensor(t, dtype, ctx=ctx) for t in l]
  File ""python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1146, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""python3.5/site-packages/tensorflow/python/ops/variables.py"", line 828, in _TensorConversionFunction
    ""of type '%s'"" % (dtype.name, v.dtype.name))
ValueError: Incompatible type conversion requested to type 'uint8' for variable of type 'float32'
2019-05-27 19:06:16.022529: W tensorflow/core/kernels/data/generator_dataset_op.cc:78] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_INT64], token=""pyfunc_2""](arg0)]]
```
"
29062,[Java] Reduce Sum operation not usable,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.1 Cinnamon
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary / jar file downloaded from Maven Repository
- TensorFlow version (use command below): 1.13.1
- Python version: N/A
- Java version: 11.0.3
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A (using CPU only)

**Describe the current behavior**
Trying to create an instance of the ReduceSum Operation causes the following exception:
`Error: 
java.lang.IllegalArgumentException: Op type not registered 'ReduceSum' in binary running on lucah-Super-Server. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed. while building NodeDef 'reduce'
	at org.tensorflow.OperationBuilder.finish(Native Method)
	at org.tensorflow.OperationBuilder.build(OperationBuilder.java:58)
	at theGhastModding.tfTest.main.Cifar10.main(Cifar10.java:35)`
The same also occurs for the ReduceAll, ReduceAny, ReduceJoin, ReduceMax, ReduceMean, ReduceMin and ReduceProd Operations, every other Operation works as expected.

**Describe the expected behavior**
The Operation is built successfully and can be used normally.

**Code to reproduce the issue**
The following code causes the above Exception to be thrown at the third line:
`Graph graph = new Graph();

Operation pl = graph.opBuilder(""Placeholder"", ""z"").setAttr(""dtype"", DataType.FLOAT).build();

Operation sum = graph.opBuilder(""ReduceSum"", ""reduce"").addInput(pl.output(0)).build();`"
29061,"InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with 'AAAAAAAAAAAAAAAA' ","**System information**
- OS Platform and Distribution: MacOS Sierra 10.12.6
- TensorFlow installed from (source or binary): with pip
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.0

**Describe the problem**

I'm preparing my trained model (custom Keras) for deploy on Tensorflow Serving so that it receives image bytes and returns a prediction mask. Here's my `signature_def`:
```
signature_def['predict_images']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['inputs'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: image_bytes:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['outputs'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 256, 256, 1)
        name: conv2d_23/Sigmoid:0
  Method name is: tensorflow/serving/predict
```
My `serving_input_receiver_fn` function is:
```
def process_image(self, image_buffer):
    image = tf.image.decode_jpeg(image_buffer, channels=3)
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    image = tf.expand_dims(image, 0)
    image = tf.image.resize_bilinear(image, [256, 256], align_corners=False)
    image = tf.squeeze(image, [0])
    image = tf.cast(image, tf.float32) / 255.0
    return image

def serving_input_receiver_fn(self):
    input_ph = tf.placeholder(dtype=tf.string, shape=[None], name='image_bytes')
    images_tensor = tf.map_fn(self.process_image, input_ph, back_prop=False, dtype=tf.float32)
    return tf.estimator.export.ServingInputReceiver({'input_1': images_tensor}, {'image_bytes': input_ph})
```

When i load my image from S3 with the following code:
```
image = load_image_from_s3('s3://bucket/path/to/image.png')
bytes_image = base64.b64encode(image).decode('utf-8')
with tf.Session(graph=tf.Graph()) as sess:
    model = tf.saved_model.loader.load(sess, [""serve""], 'gs://bucket/saved/model/dir/')
    graph = tf.get_default_graph()
    input_dict, output_dict = _signature_def_to_tensors(model.signature_def['predict_images'])
    predictions = sess.run(output_dict, feed_dict={input_dict['inputs']: [bytes_image]})
```
i get the following error:
```
InvalidArgumentError (see above for traceback): Expected image (JPEG, PNG, or GIF), got unknown format starting with 'AAAAAAAAAAAAAAAA'
```
but if i load the same image from local as follows:
```
image_data = tf.gfile.GFile('/local/path/to/image.png', 'rb').read()
```
and call predictions as:
```
predictions = sess.run(output_dict, feed_dict={input_dict['inputs']: [image_data]})
```
It does work. How can i get it to work with base64 encoding  so that i can then deploy and use it with Tensorflow Serving and my live application?


**Notes**:
This works too:
```
tf.image.decode_jpeg(bytes_image, channels=3)
<tf.Tensor 'DecodeJpeg:0' shape=(?, ?, 3) dtype=uint8>
```
I've already tried a similar versions of this issue [on StackOverflow](https://stackoverflow.com/questions/56275522/tensorflow-serving-how-to-decode-base64-encoded-png-images-during-preprocessing)

Thank you so much for the support! I hope it's a question relevant to this channel




"
29060,"""Cache iterator is in an invalid state"" error","**System information**
- OS Platform and Distribution: macOS High Sierra 10.13.6
- TensorFlow for CPU installed from PyPI
- TensorFlow version: v1.13.0-rc2-5-g6612da8951, 1.13.1
- Python version: 3.6.6

**Describe the current behavior**

Minimal not working example:
```python
import tensorflow as tf
from tensorflow.python.framework.errors_impl import OutOfRangeError


dataset = tf.data.Dataset.range(10)
dataset = dataset.cache('cache1')
dataset = dataset.map(lambda a: a)
dataset = dataset.batch(4)

batch = dataset.make_one_shot_iterator().get_next()

with tf.Session() as sess:
    while True:
        try:
            res = sess.run(batch)
            print(res)
        except OutOfRangeError:
            print('out-of-range')
            break
```

The code above properly iterates through the dataset only the first run when a cache doesn't exist. But when it loads the dataset from the cache file it crashes with an error:
```
tensorflow.python.framework.errors_impl.InternalError: Cache iterator is in an invalid state. (Perhaps GetNext called after end_of_sequence?)
	 [[{{node IteratorGetNext}}]
```

**A workaround**

It happens because the `map` operation follows right after the `cache`. It starts working as expected if some other dataset operation is added between `cache` and `map` steps. For example:
```python
...

dataset = tf.data.Dataset.range(10)
dataset = dataset.cache('cache1')
dataset = dataset.filter(lambda x: True)  # a fake filter is added
dataset = dataset.map(lambda a: a)
dataset = dataset.batch(4)

...
```"
29059,Not able to install tensorflow alpha on Mac OS,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Mojave 10.14.4
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0.0 alpha
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: none
- GPU model and memory: Intel Iris Graphics 6100 - 1536 MB


**Describe the problem**

I'm not able to install tensorflow with the following command: `pip3 install tensorflow==2.0.0-alpha0`. Every time when I run the command I get the error zsh: 2.0.0-alpha0 not found. I tried different python3 versions, but none of them worked

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Just install python 3.7.3 and run the command `pip3 install tensorflow==2.0.0-alpha0`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Error: `zsh: 2.0.0-alpha0 not found`"
29056,TFLite GPU delegate model inconsistencies: Mobilenet v1 1.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 0.0.1-gpu-experimental
- Python version: 3.6
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**

The [mobilenet v1 1.0](https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/mobilenet_v1_1.0_224.tflite) model in the [guide](https://www.tensorflow.org/lite/performance/gpu) contains a squeeze operation that isn't supported by GPU, but the [mobilenet v1 1.0](http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224.tgz) at  [tensorflow/models](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md) does. AFAIK, squeeze isn't a supported operation, but both of them contain at least one. How come the operations are different even when the models are of the same version? Is the one in the guide deliberately modified? If so, would it be a better idea to have it noted in the guide? The page on tensor/models claims 569mil MACs, but the number of MACs this modified 1.0 has is unclear.

What I've found is that the one provided in the guide contains 89 tensors but the one in tensorflow/models 88.

**Describe the expected behavior**

Models of the same version should be identical. Any modification should be explicitly documented."
29054,"mobile_ssd_v2_float_coco.tflite model :Cannot copy between a TensorFlowLite tensor with shape [1, 2034, 4] and a Java object with shape [1, 10, 4].","When using mobile_ssd_v2_float_coco.tflite model with Tensorflow Object Detection [example](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android) code,  I am facing this error:

` Process: org.tensorflow.lite.examples.detection, PID: 30765
    java.lang.IllegalArgumentException: Cannot copy between a TensorFlowLite tensor with shape [1, 2034, 4] and a Java object with shape [1, 10, 4].
        at org.tensorflow.lite.Tensor.throwIfShapeIsIncompatible(Tensor.java:282)
        at org.tensorflow.lite.Tensor.throwIfDataIsIncompatible(Tensor.java:249)
        at org.tensorflow.lite.Tensor.copyTo(Tensor.java:141)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:161)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:275)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:220)
        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:197)
        at android.os.Handler.handleCallback(Handler.java:873)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at android.os.Looper.loop(Looper.java:214)
        at android.os.HandlerThread.run(HandlerThread.java:65)`

- I did change the
` `private static final int TF_OD_API_INPUT_SIZE = 320;`` 
 - Followed this StackOverflow solution [https://stackoverflow.com/questions/54423649/tensorflow-lite-gpu-support-on-object-detector](url)
This gives only a partial soluton the problem. Can anyone suggest a proper solution. "
29053,building from source failed ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: latest master from github
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): 0.25.3
- GCC/Compiler version (if compiling from source): gcc version 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC)
- CUDA/cuDNN version: CUDA 10/ cuDNN 7
- GPU model and memory:V100 32G

**Describe the problem**
when I run: `bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`, I get error:
```
WARNING: The following configs were expanded more than once: [cuda, using_cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=129
INFO: Reading rc options for 'build' from /home/minds/isaac/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include
INFO: Reading rc options for 'build' from /home/minds/isaac/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/minds/.virtualenvs/venv_tf/bin/python --action_env PYTHON_LIB_PATH=/home/minds/.virtualenvs/venv_tf/lib/python3.6/site-packages --python_path=/home/minds/.virtualenvs/venv_tf/bin/python --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda --action_env TF_CUDA_COMPUTE_CAPABILITIES=7.0,7.0 --action_env GCC_HOST_COMPILER_PATH=/bin/gcc --config=cuda --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:cuda in file /home/minds/isaac/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/minds/isaac/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:opt in file /home/minds/isaac/tensorflow/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true
INFO: Found applicable config definition build:cuda in file /home/minds/isaac/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/minds/isaac/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: An error occurred during the fetch of repository 'io_bazel_rules_docker'
INFO: Call stack for the definition of repository 'io_bazel_rules_docker':
 - /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - /home/minds/isaac/tensorflow/WORKSPACE:29:1
ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):
	File ""/home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 234
		_clone_or_update(ctx)
	File ""/home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 74, in _clone_or_update
		fail((""error cloning %s:\n%s"" % (ctx....)))
error cloning io_bazel_rules_docker:
+ cd /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external
+ rm -rf /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker
+ git clone '' https://github.com/bazelbuild/rules_docker.git /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker
Too many arguments.

usage: git clone [options] [--] <repo> [<dir>]

    -v, --verbose         be more verbose
    -q, --quiet           be more quiet
    --progress            force progress reporting
    -n, --no-checkout     don't create a checkout
    --bare                create a bare repository
    --mirror              create a mirror repository (implies bare)
    -l, --local           to clone from a local repository
    --no-hardlinks        don't use local hardlinks, always copy
    -s, --shared          setup as shared repository
    --recursive           initialize submodules in the clone
    --recurse-submodules  initialize submodules in the clone
    --template <template-directory>
                          directory from which templates will be used
    --reference <repo>    reference repository
    -o, --origin <name>   use <name> instead of 'origin' to track upstream
    -b, --branch <branch>
                          checkout <branch> instead of the remote's HEAD
    -u, --upload-pack <path>
                          path to git-upload-pack on the remote
    --depth <depth>       create a shallow clone of that depth
    --single-branch       clone only one branch, HEAD or --branch
    --separate-git-dir <gitdir>
                          separate git dir from working tree
    -c, --config <key=value>
                          set config inside the new repository

+ git clone https://github.com/bazelbuild/rules_docker.git /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker
+ git -C /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker reset --hard 251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
+ git -C /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker fetch '' origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
+ git -C /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker fetch origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):
	File ""/home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 234
		_clone_or_update(ctx)
	File ""/home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 74, in _clone_or_update
		fail((""error cloning %s:\n%s"" % (ctx....)))
error cloning io_bazel_rules_docker:
+ cd /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external
+ rm -rf /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker
+ git clone '' https://github.com/bazelbuild/rules_docker.git /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker
Too many arguments.

usage: git clone [options] [--] <repo> [<dir>]

    -v, --verbose         be more verbose
    -q, --quiet           be more quiet
    --progress            force progress reporting
    -n, --no-checkout     don't create a checkout
    --bare                create a bare repository
    --mirror              create a mirror repository (implies bare)
    -l, --local           to clone from a local repository
    --no-hardlinks        don't use local hardlinks, always copy
    -s, --shared          setup as shared repository
    --recursive           initialize submodules in the clone
    --recurse-submodules  initialize submodules in the clone
    --template <template-directory>
                          directory from which templates will be used
    --reference <repo>    reference repository
    -o, --origin <name>   use <name> instead of 'origin' to track upstream
    -b, --branch <branch>
                          checkout <branch> instead of the remote's HEAD
    -u, --upload-pack <path>
                          path to git-upload-pack on the remote
    --depth <depth>       create a shallow clone of that depth
    --single-branch       clone only one branch, HEAD or --branch
    --separate-git-dir <gitdir>
                          separate git dir from working tree
    -c, --config <key=value>
                          set config inside the new repository

+ git clone https://github.com/bazelbuild/rules_docker.git /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker
+ git -C /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker reset --hard 251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
+ git -C /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker fetch '' origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
+ git -C /home/minds/.cache/bazel/_bazel_minds/7c1f2bd7870d1ecc8754a91ebff0746c/external/io_bazel_rules_docker fetch origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
INFO: Elapsed time: 7.123s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
followed this [guide](https://www.tensorflow.org/install/source), until I faced the issue

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29052,ArithmeticOptimizer fails for stack with axis=R and axis=-(R+1),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

In the `stack` op, the allowed range for `axis` is `[ -(R+1),(R+1) )`. However, if you take a strided slice over the result with `axis=-(R+1)` or `axis=R`, the ArithmeticOptimizer will fail with a warning.

It also fails for scalars with any value in `axis`.

The results are still correct, but this disables the arithmetic optimizer for some (all?) of the code. See the repro code for an example.

**Describe the expected behavior**

I would not expect ArithmeticOptimizer to fail.

**Code to reproduce the issue**
Scalar example:
```
import tensorflow as tf
with tf.Session() as sess:
    a = tf.Variable(tf.constant(0))
    b = tf.Variable(tf.constant(1))
    sess.run(tf.initializers.global_variables())
    sess.run(tf.stack([a, b])[::2])
```

Vector example
```
import tensorflow as tf
with tf.Session() as sess:
    a = tf.Variable(tf.constant([0,1]))
    b = tf.Variable(tf.constant([2,3]))
    sess.run(tf.initializers.global_variables())
    for axis in range(-2, 2):
        print(axis)
        sess.run(tf.stack([a, b], axis)[::2])
```

Executes sucessfully, but the ArithmeticOptimizer fails with a warning:

```
-2
2019-05-27 11:35:54.164917: W ./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241] Failed to run optimizer ArithmeticOptimizer, stage RemoveStackStridedSliceSameAxis node strided_slice. Error: Pack node (stack) axis attribute is out of bounds: -2
2019-05-27 11:35:54.166279: W ./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241] Failed to run optimizer ArithmeticOptimizer, stage RemoveStackStridedSliceSameAxis node strided_slice. Error: Pack node (stack) axis attribute is out of bounds: -2
-1
0
1
2019-05-27 11:35:54.183014: W ./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241] Failed to run optimizer ArithmeticOptimizer, stage RemoveStackStridedSliceSameAxis node strided_slice_3. Error: Pack node (stack_3) axis attribute is out of bounds: 1
2019-05-27 11:35:54.184915: W ./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241] Failed to run optimizer ArithmeticOptimizer, stage RemoveStackStridedSliceSameAxis node strided_slice_3. Error: Pack node (stack_3) axis attribute is out of bounds: 1
```"
29051,"How to avoid asking when executing ""python ./configure.py""","This is not a truely issue with building or installing TF, but a important question for us.

When we execute ""python ./configure.py"" it will ask the dependencies, configuration and others, we have to manually confirm. What I should do to have ""python ./configure.py"" read the default parameters(we use default parameters) directly and don't need us to confirm. Or is there some parameters to avoid these questions?

Because we need to integrate the build steps into a script for daily build testing, every time we run the script it will empty the configuration and get the latest source to rebuild the TF , but ""python ./configure.py"" will prevent the script from continuing, 

This question is important to us. Can you provide solution to solve this problem? Thanks in advance."
29049,"Big bug, tf.keras is slower then keras.","I just change all keras api to tf.keras. But training become too slower, gpu is usable
"
29048,the output of `tf.sigmoid` is abnormal when input has nans.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 64bit, AWS EC2 p3.2xlarge instance
- TensorFlow installed from (source or binary): `pip install tensorflow-gpu`
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.7
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: 10.1
- GPU model and memory: NVIDIA Tesla V100 16GB

**Describe the current behavior**

the output of the `tf.sigmoid` function seems abnormal when the input has nans.
```python
In [1]: import tensorflow as tf
In [2]: tf.enable_eager_execution()
In [3]: a = tf.constant([float('nan')]*5)
In [4]: tf.sigmoid(a)
Out[4]: <tf.Tensor: id=1, shape=(5,), dtype=float32, numpy=array([ 1.,  1.,  1.,  1., nan], dtype=float32)>
```
**Describe the expected behavior**
```python
In [4]: tf.sigmoid(a)
Out[4]: <tf.Tensor: id=1, shape=(5,), dtype=float32, numpy=array([ nan,  nan,  nan,  nan, nan], dtype=float32)>
```
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
import tensorflow as tf
tf.enable_eager_execution()
a = tf.constant([float('nan')]*5)
b = tf.sigmoid(a)
print(b)
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29047,one 404 page needs to be fixed,"At the beginning of sub title [Train from tf.data datasets](https://www.tensorflow.org/alpha/guide/keras/overview#train_from_tfdata_datasets), there is a super link pointing to **Datasets API**.

But when you click it out, only 404 page is what you get.

Since this API is very often been used, it would be better to correct this as soon as possible."
29046,Website claims that there is no internet connection,"JavaScript on the website runs some sort of detection to see if there is network connectivity or tries to establish a connection in a surprising way.

This fails and I get a message ""There is no Internet connection :("" which is clearly wrong. I am writing this issue with the same internet connection.

The JS console says:

    Failed to load ‘https://www.google-analytics.com/analytics.js’. A ServiceWorker passed a promise to FetchEvent.respondWith() that rejected with ‘TypeError: NetworkError when attempting to fetch resource.’.

    Failed to load ‘https://www.tensorflow.org/_d/profile/ogb’. A ServiceWorker passed a promise to FetchEvent.respondWith() that rejected with ‘TypeError: NetworkError when attempting to fetch resource.’.

    Failed to load ‘https://www.tensorflow.org/_d/profile/user’. A ServiceWorker passed a promise to FetchEvent.respondWith() that rejected with ‘TypeError: NetworkError when attempting to fetch resource.’.
"
29044,cuda9.1 can not support tensorflow,"import tensorflow as tf
Traceback (most recent call last):
File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in
from tensorflow.python.pywrap_tensorflow_internal import *
File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in
_pywrap_tensorflow_internal = swig_import_helper()
File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
File ""C:\Program Files\Python36\lib\imp.py"", line 243, in load_module
return load_dynamic(name, filename, file)
File ""C:\Program Files\Python36\lib\imp.py"", line 343, in load_dynamic
return _load(spec)
ImportError: DLL load failed: The specified module could not be found.
"
29043,[TF2.0] tf.feature_column.shared_embeddings trace twice and throw exception with @tf.function,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): osx 10.13.1 (17B1003)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): tf-nightly-2.0-preview           2.0.0.dev20190506 
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
[shared_embeddings](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/shared_embeddings) not surport eager mode, so i call it with @tf.function, but still throw exception:
ValueError: Variable color_color2_color3_shared_embedding already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?

Find the reason is that the function will be traced twice after add line `df =  tf.keras.layers.DenseFeatures(color_column_embed)(color_data)`,  the print will run twice. 

first time stack:
```
embedding_weights, feature_column_v2.py:3247
_get_dense_tensor_internal, feature_column_v2.py:3326
get_dense_tensor, feature_column_v2.py:3349
_call_unconverted, api.py:173
converted_call, api.py:271
loop_body, tmpf4q73us7.py:51
_py_for_stmt, control_flow.py:111
for_stmt, control_flow.py:102
tf__call, tmpf4q73us7.py:70
converted_call, api.py:375
wrapper, api.py:89
__call__, base_layer.py:632
_call_unconverted, api.py:173
converted_call, api.py:271
tf__shared_embedding_column_with_hash_bucket, tmp5d_py4a8.py:16
converted_call, api.py:375
wrapper, func_graph.py:705
wrapped_fn, def_function.py:292
func_graph_from_py_func, func_graph.py:713
_create_graph_function, function.py:1529
_maybe_define_function, function.py:1596
_get_concrete_function_internal_garbage_collected, function.py:1333
_initialize, def_function.py:342
__call__, def_function.py:399
<module>, main.py:43
```

second time call stack:
```
embedding_weights, feature_column_v2.py:3247
_get_dense_tensor_internal, feature_column_v2.py:3326
get_dense_tensor, feature_column_v2.py:3349
_call_unconverted, api.py:173
converted_call, api.py:271
loop_body, tmpf4q73us7.py:51
_py_for_stmt, control_flow.py:111
for_stmt, control_flow.py:102
tf__call, tmpf4q73us7.py:70
converted_call, api.py:375
wrapper, api.py:89
__call__, base_layer.py:632
_call_unconverted, api.py:173
converted_call, api.py:271
tf__shared_embedding_column_with_hash_bucket, tmp5d_py4a8.py:16
converted_call, api.py:375
wrapper, func_graph.py:705
wrapped_fn, def_function.py:292
func_graph_from_py_func, func_graph.py:713
_create_graph_function, function.py:1529
_maybe_define_function, function.py:1596
__call__, function.py:1307
__call__, def_function.py:411
<module>, main.py:43
```

The only difference is before `_maybe_define_function, function.py:1596`.


The code in second time fails,  because it is new obj , so there's no cache in self._embedding_weights, then will run `variable_scope.get_variable` with no reuse:
```
  @property
  def embedding_weights(self):
    key = ops.get_default_graph()._graph_key  # pylint: disable=protected-access
    if key not in self._embedding_weights:
      embedding_shape = (self._num_buckets, self._dimension)
      var = variable_scope.get_variable(
          name=self._name,
          shape=embedding_shape,
          dtype=dtypes.float32,
          initializer=self._initializer,
          trainable=self._trainable)

      if self._ckpt_to_load_from is not None:
        to_restore = var
        if isinstance(to_restore, variables.PartitionedVariable):
          to_restore = to_restore._get_variable_list()  # pylint: disable=protected-access
        checkpoint_utils.init_from_checkpoint(
            self._ckpt_to_load_from, {self._tensor_name_in_ckpt: to_restore})
      self._embedding_weights[key] = var
    return self._embedding_weights[key]
```





**Describe the expected behavior**
Could use the shared_embeddings.

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import feature_column

@tf.function
def shared_embedding_column_with_hash_bucket():
    color_data = {'color': [[2], [5], [-1], [0]],
                  'color2': [[2, 2], [5, 5], [0, -1], [0, 0]],
                  'color3': [[2,2,2], [5,5,5], [-1,-1,-1], [0,0,0]]
                 }
    color_column = feature_column.categorical_column_with_hash_bucket('color', 5, dtype=tf.int32)
    color_column2 = feature_column.categorical_column_with_hash_bucket('color2', 5, dtype=tf.int32)
    color_column3 = feature_column.categorical_column_with_hash_bucket('color3', 5, dtype=tf.int32)
    color_column_embed = tf.feature_column.shared_embeddings([color_column, color_column2, color_column3], 4, combiner='sum')
    print(color_column_embed)
    print(type(color_column_embed))
    print('use input_layer' + '_' * 40)
    df =  tf.keras.layers.DenseFeatures(color_column_embed)(color_data)
    return df

dense = shared_embedding_column_with_hash_bucket()
print(dense)
```

**Other info / logs**

```
Traceback (most recent call last):
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py"", line 1758, in <module>
    main()
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py"", line 1752, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py"", line 1147, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/Users/lqk/project/PycharmProjects/TF2/main.py"", line 40, in <module>
    dense = shared_embedding_column_with_hash_bucket()
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 411, in __call__
    return self._stateless_fn(*args, **kwds)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1307, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1596, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1529, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 713, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 292, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 705, in wrapper
    ), args, kwargs)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 375, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File ""/var/folders/4x/njl257j95bx4mt08j65fxqg00000gp/T/tmp5y1g76hx.py"", line 16, in tf__shared_embedding_column_with_hash_bucket
    df = ag__.converted_call(tf.keras.layers.DenseFeatures(color_column_embed), None, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (color_data,), None)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 271, in converted_call
    return _call_unconverted(f, args, kwargs)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 173, in _call_unconverted
    return f(*args)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 632, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 89, in wrapper
    ), args, kwargs)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 375, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File ""/var/folders/4x/njl257j95bx4mt08j65fxqg00000gp/T/tmpshzfamoc.py"", line 70, in tf__call
    ag__.for_stmt(self._feature_columns, None, loop_body, ())
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/operators/control_flow.py"", line 102, in for_stmt
    return _py_for_stmt(iter_, extra_test, body, init_state)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/operators/control_flow.py"", line 111, in _py_for_stmt
    state = body(target, *state)
  File ""/var/folders/4x/njl257j95bx4mt08j65fxqg00000gp/T/tmpshzfamoc.py"", line 51, in loop_body
    tensor = ag__.converted_call('get_dense_tensor', column, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (transformation_cache, self._state_manager), None)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 271, in converted_call
    return _call_unconverted(f, args, kwargs)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 173, in _call_unconverted
    return f(*args)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py"", line 3349, in get_dense_tensor
    return self._get_dense_tensor_internal(transformation_cache, state_manager)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py"", line 3326, in _get_dense_tensor_internal
    embedding_weights = self.shared_embedding_column_creator.embedding_weights
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py"", line 3253, in embedding_weights
    trainable=self._trainable)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 1496, in get_variable
    aggregation=aggregation)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 1239, in get_variable
    aggregation=aggregation)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 562, in get_variable
    aggregation=aggregation)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 514, in _true_getter
    aggregation=aggregation)
  File ""/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 856, in _get_single_variable
    raise ValueError(err_msg)
ValueError: Variable color_color2_color3_shared_embedding already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?
```
"
29042,"CMake build fails v1.13.1 fatal error: tensorflow/stream_executor/dnn.pb.h: No such file or directory  #include ""tensorflow/stream_executor/dnn.pb.h""","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): source 
- TensorFlow version: v1.13.1
- Python version: 3.6
- Installed using virtualenv? pip? conda?: NA
- Bazel version (if compiling from source): 0.25 NA
- GCC/Compiler version (if compiling from source): gcc/4.8.5
- CUDA/cuDNN version: 10.0.130, 7.4.2.24
- GPU model and memory: GTX 1060 6Gb




**Describe the problem**

CMake build doesnt complete

```
[ 18%] Building CXX object CMakeFiles/tf_core_profiler.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/core/profiler/internal/tfprof_scope.cc.o
[ 18%] Building CXX object CMakeFiles/tf_core_profiler.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/core/profiler/internal/tfprof_op.cc.o
[ 18%] Building CXX object CMakeFiles/tf_core_profiler.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/core/profiler/internal/tfprof_show_multi.cc.o
[ 18%] Building CXX object CMakeFiles/tf_core_profiler.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/core/profiler/internal/tfprof_show.cc.o
[ 18%] Building CXX object CMakeFiles/tf_stream_executor.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/stream_executor/blas.cc.o
[ 18%] Building CXX object CMakeFiles/tf_stream_executor.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/stream_executor/device_description.cc.o
[ 18%] Building CXX object CMakeFiles/tf_core_profiler.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/core/profiler/internal/tfprof_stats.cc.o
[ 18%] Building CXX object CMakeFiles/tf_stream_executor.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/stream_executor/dnn.cc.o
[ 18%] Linking CXX executable proto_text
In file included from /home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/stream_executor/dnn.cc:16:0:
/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/stream_executor/dnn.h:34:47: fatal error: tensorflow/stream_executor/dnn.pb.h: No such file or directory
 #include ""tensorflow/stream_executor/dnn.pb.h""
                                               ^
compilation terminated.
[ 18%] Built target proto_text
[ 18%] Building CXX object CMakeFiles/tf_stream_executor.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/stream_executor/dso_loader.cc.o
make[2]: *** [CMakeFiles/tf_stream_executor.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/stream_executor/dnn.cc.o] Error 1
make[2]: *** Waiting for unfinished jobs....
[ 18%] Building CXX object CMakeFiles/tf_core_profiler.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/core/profiler/internal/tfprof_tensor.cc.o
[ 18%] Building CXX object CMakeFiles/tf_core_profiler.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/core/profiler/internal/tfprof_timeline.cc.o
make[1]: *** [CMakeFiles/tf_stream_executor.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
[ 18%] Building CXX object CMakeFiles/tf_core_profiler.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/core/profiler/internal/tfprof_utils.cc.o
[ 19%] Building CXX object CMakeFiles/tf_core_profiler.dir/home/kognat/dev/tensorflow-v1.13.1-static-gpu-centos6/tensorflow/tensorflow/core/profiler/tfprof_options.cc.o
[ 19%] Built target tf_core_profiler
make: *** [all] Error 2
```
**Provide the exact sequence of commands / steps that you executed before running into the problem**

git checkout https://github.com/tensorflow/tensorflow.git
cd tensorflow/tensorflow/contrib/cmake
mkdir build && cd build
CUDA_HOME=/usr/local/cuda-10.0 cmake3 .. -DCMAKE_PREFIX_PATH=/usr/local/cuda-10.0:/usr/local/cudnn-7.4.2.24/cuda -DCMAKE_INSTALL_PREFIX=/home/samh/opt/tensorflow-v1.13.1-static-gpu -Dtensorflow_BUILD_PYTHON_BINDING=off -Dtensorflow_ENABLE_GPU=on -Dtensorflow_ENABLE_GRPC_SUPPORT=on -Dtensorflow_ENABLE_POSITION_INDEPENDENT_CODE=on -Dtensorflow_ENABLE_SNAPPY_SUPPORT=on -Dtensorflow_OPTIMIZE_FOR_NATIVE_ARCH=on -Dtensorflow_PATH_CUDA_LIB=/usr/local/cuda-10.0/lib -Dtensorflow_PATH_CUDNN_LIB=/usr/local/cudnn-7.4.2.24/cuda/lib  -Dtensorflow_CUDNN_INCLUDE=/usr/local/cudnn-7.4.2.24/cuda/include -Dtensorflow_BUILD_SHARED_LIB=on -Dtensorflow_NCCL_INCLUDE=/usr/local/nccl-2.4.7/include -Dtensorflow_PATH_NCCL_LIB=/usr/local/nccl-2.4.7/lib -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-10.0 -DCUDA_cupti_LIBRARY=/usr/local/cuda-10.0/extras/CUPTI/lib -DOPENSSL_NO_ASM=1
make -j12

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I need a static build with GPU support, any process to do this would be considered an alternative.

Sam
"
29041,TFLite model exported from Keras cannot be executed on Android,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows/Android
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: Huawei P10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.13.1
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**: Geforce Gtx1080 8Gb
- **Exact command to reproduce**:

### Describe the problem
I have exported a model from Keras using following code:
```

converter = lite.TFLiteConverter.from_keras_model_file(weights_path_2)
tfmodel = converter.convert()
open (""model.tflite"" , ""wb"") .write(tfmodel)

```

Export and import into Android works fine, executing however throws following error:
```

java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/fully_connected.cc:112 input_size != batch_size * filter->dims->data[1] (4096 != 0)Node number 7 (FULLY_CONNECTED) failed to prepare.

```
I also tried exporting the model using toco, but the same issue happens.
The model I used here can be found here https://github.com/krasserm/face-recognition/blob/master/model.py
Any idea on how to fix this? 
### Describe expected behaviour

If the model can be exported without problems I should be able to executed it too.

"
29040,Why are ResNet101/ResNeXt50/ResNeXt101 not included in TensorFlow´s Keras distribution?,"**System information**
- TensorFlow version (you are using): 1.13.1
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
`tf.keras.applications` contains only ResNet50, as browsing to the `site-packages/tensorflow/python/keras/applications` folder shows only `resnet50.py`. Why are ResNet101/ResNeXt50/ResNeXt101 not included? Is there a repo where I can get them from?

**Will this change the current api? How?**
No.

**Who will benefit with this feature?**
Users who wish to use pretrained ResNet101/ResNeXt50/ResNeXt101, which are available in Keras´ stand-alone distribution (if the documentation is right)."
29039,Support the __cuda_array_interface__ protocol,"- Are you willing to contribute it (Yes/No):

Not me personally, but perhaps someone I work with

**Describe the feature and the current behavior/state.**

A number of GPU array computing libraries in Python (Numba, CuPy, PyTorch, RAPIDS) support the `__cuda_array_interface__`, protocol as described in the [Numba documentation](https://numba.pydata.org/numba-doc/dev/cuda/cuda_array_interface.html).  This protocol helps to migrate data between different GPU array computing systems without explicit coordination.  

```python
x = lib_1.create_array()
y = lib_2.as_array(x)
```

or more concretely

```python
t = torch.Tensor(...)
x = tensorflow.convert_to_tensor(t)
```

This involves two changes to TensorFlow

1.  We would add a property `__cuda_array_interface__` to tensor objects backed by a GPU that provided information about the GPU memory.
2.  We would add checks in functions designed to convert external objects into TensorFlow tensors to check for this attribute and use it if present.


**Will this change the current api? How?**

Only in a backwards compatible way.  It will add a new property `__cuda_array_interface__` to tensor objects, an will also add a check for these objects in functions designed to convert other objects into TensorFlow tensors.

**Who will benefit with this feature?**

This typically already exists on the CPU side with protocols like `__array__`, but on the GPU side things are still manual.  Protocols like this make it easier both to use these array computing libraries together, and also to make external systems that are generic and can interoperate with a number of different array computing libraries.

**Any Other info.**

Relevant issues in other libraries:

-  https://github.com/pytorch/pytorch/issues/11914
-  https://github.com/pytorch/pytorch/issues/15601
-  https://github.com/rapidsai/cudf/issues/529
-  https://github.com/cupy/cupy/pull/1144
-  https://docs-cupy.chainer.org/en/stable/reference/interoperability.html

cc @seibert "
29038,faild to retrain the Inception v3 model.,"![2019-05-26 18-12-22 的屏幕截图](https://user-images.githubusercontent.com/36025537/58380553-033bcd80-7fe5-11e9-88d5-1d6486a4ef6b.png)
"
29036,Evaluating the value of a tensor from inside the model_function of a custom `tf.TPUEstimator`,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.13
- Are you willing to contribute it (Yes/No):Yes



**Describe the feature and the current behavior/state.**
I am implementing an NLP model based on BERT, using `tf.TPUEstimator()`. I want to implement layer-wise training, where I need to select only one layer of the model to train for each epoch. In order to do this I wanted to change my model_fn and get the value of current_epoch. 

I know how to compute the value of current_epoch as a tensor using `tf.train.get_or_create_global_step()` inside the `model_fn` BUT, I need to evaluate the value of this tensor to select which layer to train and implement  return the correct `train_op` to the `tf.estimator` (**train_op pertaining to a single layer chosen accrding to the value of the current_epoch**).

I am unable to evaluate this tensor (current_epoch / global_step) from inside the model_fn. I tried the following but the training hangs at the step `my_sess.run(my_global_step.initializer`

```
global_step = tf.train.get_or_create_global_step()
graph = tf.get_default_graph()
my_sess = tf.Session(graph=graph)
current_epoch = (global_step * full_bs) // train_size

my_sess.run(my_global_step.initializer)
current_epoch = sess.run(current_epoch)

# My program hangs at the initialising step: my_sess.run(my_global_step.initializer)
```
Q) Is there currently any way to evaluate a tensor inside the `tf.estimator`
Q)Is there any way to evaluate a tensor using the tf.Estimators default session? How do I get the default session/ Graph?
Q)**Most importantly what is wrong in my code and why does the training hang when using tpu's and TPUEstimator**?
"
29035,CUDA Toolkit 10.1 Update compile tf2.0,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.0
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):0.25.2
- GCC/Compiler version (if compiling from source):gcc
- CUDA/cuDNN version: 10.1 Update
- GPU model and memory: GTX960M 2G



**Describe the problem**

When I get tensorflow source from ""git clone https://github.com/tensorflow.git"" and ""git checkout r2.0"",  why do I get that the package is tensorflow 1.13.1 yet, rather than the tensorflow 2.0 after compiling it successfully.
"
29034,GPU text classification notebook produces CUDNN error,"**Error Message**
UnknownError: Fail to find the dnn implementation.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Pop!_OS 19.04
- TensorFlow installed from (source or binary): jupyter
- TensorFlow version (use command below): !pip install tensorflow-gpu
- Python version: 3.7.3
- CUDA/cuDNN version: 10.0, cudnn 7.4.5.1
- GPU model and memory: See below RTX 2070 Max-q


[I 21:20:12.056 LabApp] Saving file at /Downloads/text_classification_rnn.ipynb
[W 21:20:12.057 LabApp] Notebook Downloads/text_classification_rnn.ipynb is not trusted
[I 21:21:07.912 LabApp] Kernel interrupted: fe30308a-41da-4a83-8fa9-93bf6c87fb6c
[I 21:22:12.102 LabApp] Saving file at /Downloads/text_classification_rnn.ipynb
[W 21:22:12.103 LabApp] Notebook Downloads/text_classification_rnn.ipynb is not trusted
2019-05-25 21:22:15.359388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-05-25 21:22:15.359425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-25 21:22:15.359432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 
2019-05-25 21:22:15.359436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N 
2019-05-25 21:22:15.359592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/device:GPU:0 with 6704 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-05-25 21:22:19.514494: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.
2019-05-25 21:22:20.872486: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-05-25 21:22:20.872526: W tensorflow/core/framework/op_kernel.cc:1431] OP_REQUIRES failed at cudnn_rnn_ops.cc:1280 : Unknown: Fail to find the dnn implementation.
2019-05-25 21:22:20.872567: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Unknown: Fail to find the dnn implementation.
	 [[{{node bidirectional_2/CudnnRNN}}]]
	 [[loss_2/dense_5_loss/binary_crossentropy/weighted_loss/broadcast_weights/assert_broadcastable/is_valid_shape/else/_1/has_valid_nonscalar_shape/then/_47/has_invalid_dims_0/_52]]
2019-05-25 21:22:20.872626: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Unknown: Fail to find the dnn implementation.
	 [[{{node bidirectional_2/CudnnRNN}}]]
2019-05-25 21:22:20.872655: E tensorflow/core/common_runtime/process_function_library_runtime.cc:764] Component function execution failed: Unknown: Fail to find the dnn implementation.
	 [[{{node bidirectional_2/CudnnRNN}}]]
	 [[loss_2/dense_5_loss/binary_crossentropy/weighted_loss/broadcast_weights/assert_broadcastable/is_valid_shape/else/_1/has_valid_nonscalar_shape/then/_47/has_invalid_dims_0/_52]]
2019-05-25 21:22:20.875125: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-05-25 21:22:20.875145: W tensorflow/core/framework/op_kernel.cc:1431] OP_REQUIRES failed at cudnn_rnn_ops.cc:1280 : Unknown: Fail to find the dnn implementation.
2019-05-25 21:22:20.875197: E tensorflow/core/common_runtime/process_function_library_runtime.cc:764] Component function execution failed: Unknown: Fail to find the dnn implementation.
	 [[{{node bidirectional_2/CudnnRNN}}]]
"
29031,"Where is ""tensorflow/lite/delegates/gpu/gl/compiled_model_generated.h""?","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: master
- Python version: n/a
- Installed using virtualenv? pip? conda?: n/a
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the problem**

I'm looking at [serialization.h#L28](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/gl/serialization.h#L28) where it includes `tensorflow/lite/delegates/gpu/gl/compiled_model_generated.h`, but where's the file located? Is it meant to be generated at compile time? How is it generated?

Thanks"
29030,eigen/get/a0d250e79c79.tar.gz: Error 404,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): master
- Python version: 3.6
- Bazel version (if compiling from source): 0.25
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**

```
$./tensorflow/lite/tools/make/download_dependencies.sh

downloading http://mirror.tensorflow.org/bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz
tar: Unrecognized archive format
tar: Error exit delayed from previous errors.
```

Error 404.

Related #28926."
29028,Tflite Qualcomm DSP acceleration ,"Hello folks, it is exciting to see announcement of qcomm DSP acceleration, aimed to be released late this summer, creating issue to track it. 


![Screenshot_2019-05-25-20-01-49-069_com google android youtube](https://user-images.githubusercontent.com/11027129/58370789-3704ed80-7f28-11e9-8859-9d643a6cb605.png)
![Screenshot_2019-05-25-20-02-11-683_com google android youtube](https://user-images.githubusercontent.com/11027129/58370790-379d8400-7f28-11e9-8619-294e108d4ed1.png)

"
29027,Cpu memory leak when using `tf.function` with gpu model.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-2319-g81f2165 2.0.0-dev20190520
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.1
- GPU model and memory:

**Describe the current behavior**
When using `tf.function`, the cpu memory usage increase forever.

**Describe the expected behavior**
No cpu memory leak when training models on gpu device using 'tf.function'.

**Code to reproduce the issue**
A part of my code, since the whole source code is huge...
And the `dataset_train` in the following code is a `tf.data.DataSet` object.
```
    DATA_TRAIN_SPEC = [
        tf.TensorSpec(shape=(None, IMAGE_FIX_HEIGHT, None, 3), dtype=tf.float32),
        tf.TensorSpec(shape=None, dtype=tf.int32),
        tf.TensorSpec(shape=None, dtype=tf.int32),
        tf.TensorSpec(shape=None, dtype=tf.int32),
    ]

    # @tf.function(input_signature=DATA_TRAIN_SPEC)
    def train_step(*batch_data):
        imgs, labels, imgs_width, labels_len = batch_data
        with tf.GradientTape() as tape:
            logits = model(imgs, training=True)
            logits_len = tf.cast(tf.math.ceil(
                tf.divide(imgs_width, block_size)), tf.int32)
            loss, accuracy = loss_fn(
                labels, logits, labels_len, logits_len, CLASSES)
        grads = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(grads, model.trainable_variables))

        return loss, accuracy

    def train_epoch(epoch):
        print(f'Epoch {epoch} training start ...')
        for step, batch_data in enumerate(dataset_train.take(num)):
            loss, accuracy = train_step(*batch_data)

            if (step+1) % ARGS.show_per_iterations == 0:
                loss, accuracy = get_numpy((loss, accuracy))

                loss_mean = np.mean(loss)
                accuracy_mean = np.mean(accuracy)*100

                prefix = f'Epoch#{epoch}/Step#{step+1}/training'
                print(f'Loss of {prefix} is: {""%.6f""%loss_mean} ...')
                print(f'Accuracy of {prefix} is: {""%.3f""%accuracy_mean}% ...')
        print(f'Epoch {epoch} training finish ...\n')

```
"
29026,LSTM with sample_weight fails with batch_size > 1,"**System information**

* Have I written custom code: Yes
* OS Platform and Distribution: Debian 9.9
* TensorFlow installed from: pip
* TensorFlow version: 1.13.1
* Python version: 3.7.3
* GPU model and memory: n/a - tested in CPU mode

**Describe the current behavior**

An unexpected error occurs when training an LSTM with `sample_weight` and `batch_size > 1`. The error does not occur if `batch_size = 1`, or if omitting `sample_weight`.

**Describe the expected behavior**

I would expect to be able to train an LSTM using `sample_weight` and `batch_size > 1`. As far as I understand it, `sample_weight` can be used for weighting the loss function, and according to the [docs](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model) it can be ""a flat (1D) Numpy array with the same length as the input samples"" - i.e. same length as `batch_size`.

**Code to reproduce the issue**

Here's a minimal example:

```python
import numpy as np
import tensorflow as tf

batch_size = 32
sequence_len = 1
embedding_size = 100

x_train = np.random.randn(batch_size, sequence_len, embedding_size)
y_train = np.random.randn(batch_size, embedding_size)
sample_weight = np.random.randn(batch_size)

train_input = tf.keras.Input(shape=(sequence_len, embedding_size),
                             batch_size=batch_size)

lstm_layer = tf.keras.layers.LSTM(200,
                                  return_sequences=False,
                                  )(train_input)

dense_layer = tf.keras.layers.Dense(embedding_size,
                                    )(lstm_layer)

model = tf.keras.models.Model(inputs=train_input, outputs=dense_layer)

model.summary()

model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),
              loss=tf.losses.mean_squared_error)

loss = model.train_on_batch(x_train,
                            y=y_train,
                            sample_weight=sample_weight)
```

**Other info / logs**

Traceback:

```
Traceback (most recent call last):
  File ""bug_minimal_example.py"", line 35, in <module>
    sample_weight=sample_weight)
  File ""/home/john/miniconda3/envs/py_main/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1188, in train_on_batch
    outputs = self.train_function(ins)  # pylint: disable=not-callable
  File ""/home/john/miniconda3/envs/py_main/lib/python3.7/site-packages/tensorflow/python/keras/backend.py"", line 3076, in __call__
    run_metadata=self.run_metadata)
  File ""/home/john/miniconda3/envs/py_main/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1439, in __call__
    run_metadata_ptr)
  File ""/home/john/miniconda3/envs/py_main/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[0], expected a dimension of 1, got 32
	 [[{{node loss/dense_loss/Squeeze}}]]
```"
29024,Dataset passed to group_by_window's reduce_func is a DatasetV2 instead of DatasetV1,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from: binary
- TensorFlow version: 1.14.0rc0
- Python version: 3.6.6

**Describe the current behavior**

In 1.14.0rc0, the dataset passed to the `reduce_func` function of `tf.data.experimental.group_by_window` is a `DatasetV2` instance instead of `DatasetV1`.

**Describe the expected behavior**

In TF V1, the dataset instance should inherit from `DatasetV1`, not `DatasetV2`.

**Code to reproduce the issue**

The following code raises an assertion error:

```python
import tensorflow as tf

def _reduce_func(key, dataset):
    assert isinstance(dataset, tf.data.Dataset)
    return dataset.batch(5)

dataset = tf.data.Dataset.range(100)
dataset = dataset.apply(tf.data.experimental.group_by_window(
    lambda x: x % 2, _reduce_func, window_size=5))
```

**Other info / logs**

This specifically breaks codes that use the V1 properties `output_*` within the `reduce_func` function."
29023,Error occurred while compiling TensorFlow for Java ,"Error occurred while compiling TensorFlow for Java 
Hi guys. Can you help me to see why?
The following is the environment:
GPU: no
Gcc:4.8
TensorFlow: 1.7.1
Bazel: 0.10.0
![image](https://user-images.githubusercontent.com/10007145/58367415-9572a180-7f11-11e9-9c37-f1cb06670748.png)
"
29022,'Tensor' object has no attribute 'unstack',"@ry @jmhodges @eggie5 @bmabey @djones 
Is this a bug?
![image](https://user-images.githubusercontent.com/30991932/58367256-d5388980-7f0f-11e9-8534-2fd81f95eff6.png)
the tensor is 
![image](https://user-images.githubusercontent.com/30991932/58367268-fbf6c000-7f0f-11e9-92a2-8a1b3346e8ef.png)

"
29011,"could not create a primitive descriptor iterator, in file tensorflow/core/kernels/mkl_relu_op.cc:871","I am using tensorflow 1.13.1 on mac os sierra.
when I try to use tf.contrib.predictor.from_saved_model to do prediction on a trained model I get this error:

could not create a primitive descriptor iterator, in file tensorflow/core/kernels/mkl_relu_op.cc:871"
29008,How to improve MKL performance? ,"**system information**

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
TensorFlow installed from (source or binary): source
TensorFlow version: 1.13.1
Python version: 2.7.13
GCC/Compiler version (if compiling from source): 5.4
MKL  version: mklml_lnx_2019.0.3.20190220/

**Describe the problem**
My steps are as follows:

1. I trained with Python on GPU
2. converted model with freeze_graph.py
3. put it on CPU and use c++  for inference 
   (build tensorflow source with --config=mkl --copt=""-DEIGEN_USE_VML""

**my MKL setting is**
setenv(""KMP_BLOCKTIME"",""0"",1);
setenv(""KMP_SETTIONS"",""1"",1);
setenv(""KMP_AFFINITY"",""granularity=fine,verbose,compact,1,0"",1);
setenv(""OMP_NUM_THREADS"",num_of_theads.c_str(),1);

**my model is bert**

**my cpuinfo is** 
vendor_id	: GenuineIntel
cpu family	: 6
model		: 79
model name	: Intel(R) Xeon(R) CPU E5-26xx v4
stepping	: 1
microcode	: 0x1
cpu MHz		: 2394.446
cache size	: 4096 KB
physical id	: 0
siblings	: 16
core id		: 15
cpu cores	: 16
apicid		: 15
initial apicid	: 15
fpu		: yes
fpu_exception	: yes
cpuid level	: 13
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch bmi1 avx2 bmi2 rdseed adx xsaveopt
bogomips	: 4788.89
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual

**my test result  :**
(C++ inference CPU)
a. use MKL :  200ms
b. do not use MKL: 200ms


**How can I improve performance？？**

@Leslie-Fang  @TensorFlow-MKL 

"
29007,"[TF 2.0] Converted code from autograph.to_code has undefined variable name, causing 'NameError: x is not defined'","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.12.6 (16G1815)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version: 3.6.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
2.0.0-dev20190521

**Describe the current behavior**
currently, the `autograph.to_code` covert the query function in the following code piece

```
import random
import tensorflow as tf


class ImagePool():
    def __init__(self, pool_size):
        self.pool_size = pool_size
        self.count = 0
        self.images = []
        print(tf.autograph.to_code(self.query))

    def query(self, images):
        if self.pool_size == 0:
            return images
        return_images = []
        for image in images:
            # if the buffer is not full; keep inserting current images to the buffer
            if self.count < self.pool_size:
                self.count = self.count + 1
                self.images.append(image)
                return_images.append(image)
            else:
                p = random.uniform(0, 1)
                if p > 0.5:
                    # by 50% chance, the buffer will return a previously stored image
                    # and insert the current image into the buffer
                    # randint is inclusive
                    random_id = random.randint(0, self.pool_size - 1)
                    tmp = self.images[random_id].clone()
                    self.images[random_id] = image
                    return_images.append(tmp)
                else:
                    # by another 50% chance, the buffer will return the current image
                    return_images.append(image)
        return return_images
```

to this:


```
def tf__query(self, images):
  do_return = False
  retval_ = ag__.UndefinedReturnValue()
  cond_2 = self.pool_size == 0

  def get_state_2():
    return self.count, self.images[random_id]

  def set_state_2(vals):
    self.count, self.images[random_id] = vals

  def if_true_2():
    do_return = True
    retval_ = images
    return retval_

  def if_false_2():
    return_images = []

    def loop_body(loop_vars, self_count):
      image = loop_vars
      cond_1 = self_count < self.pool_size

      def get_state_1():
        return self_count, self.images[random_id]

      def set_state_1(vals):
        self_count, self.images[random_id] = vals

      def if_true_1():
        self_count = self_count + 1
        ag__.converted_call('append', self.images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)
        ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)
        return ag__.match_staging_level(1, cond_1)

      def if_false_1():
        p = ag__.converted_call('random', random, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None)
        cond = p > 0.5

        def get_state():
          return self.images[random_id],

        def set_state(vals):
          self.images[random_id], = vals

        def if_true():
          random_id = ag__.converted_call('randint', random, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (0, self.pool_size - 1), None)
          tmp = ag__.converted_call('clone', self.images[random_id], ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None)
          self.images[random_id] = image
          ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (tmp,), None)
          return ag__.match_staging_level(1, cond)

        def if_false():
          ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)
          return ag__.match_staging_level(1, cond)
        ag__.if_stmt(cond, if_true, if_false, get_state, set_state)
        return ag__.match_staging_level(1, cond_1)
      ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_1, set_state_1)
      return self_count,
    self.count, = ag__.for_stmt(images, None, loop_body, (self.count,))
    do_return = True
    retval_ = return_images
    return retval_
  retval_ = ag__.if_stmt(cond_2, if_true_2, if_false_2, get_state_2, set_state_2)
  cond_3 = ag__.is_undefined_return(retval_)

  def get_state_3():
    return ()

  def set_state_3(_):
    pass

  def if_true_3():
    retval_ = None
    return retval_

  def if_false_3():
    return retval_
  retval_ = ag__.if_stmt(cond_3, if_true_3, if_false_3, get_state_3, set_state_3)
  return retval_

def tf__query(self, images):
  do_return = False
  retval_ = ag__.UndefinedReturnValue()
  cond_2 = self.pool_size == 0

  def get_state_2():
    return self.count, self.images[random_id]

  def set_state_2(vals):
    self.count, self.images[random_id] = vals

  def if_true_2():
    do_return = True
    retval_ = images
    return retval_

  def if_false_2():
    return_images = []

    def loop_body(loop_vars, self_count):
      image = loop_vars
      cond_1 = self_count < self.pool_size

      def get_state_1():
        return self_count, self.images[random_id]

      def set_state_1(vals):
        self_count, self.images[random_id] = vals

      def if_true_1():
        self_count = self_count + 1
        ag__.converted_call('append', self.images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)
        ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)
        return ag__.match_staging_level(1, cond_1)

      def if_false_1():
        p = ag__.converted_call('random', random, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None)
        cond = p > 0.5

        def get_state():
          return self.images[random_id],

        def set_state(vals):
          self.images[random_id], = vals

        def if_true():
          random_id = ag__.converted_call('randint', random, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (0, self.pool_size - 1), None)
          tmp = ag__.converted_call('clone', self.images[random_id], ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None)
          self.images[random_id] = image
          ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (tmp,), None)
          return ag__.match_staging_level(1, cond)

        def if_false():
          ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)
          return ag__.match_staging_level(1, cond)
        ag__.if_stmt(cond, if_true, if_false, get_state, set_state)
        return ag__.match_staging_level(1, cond_1)
      ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_1, set_state_1)
      return self_count,
    self.count, = ag__.for_stmt(images, None, loop_body, (self.count,))
    do_return = True
    retval_ = return_images
    return retval_
  retval_ = ag__.if_stmt(cond_2, if_true_2, if_false_2, get_state_2, set_state_2)
  cond_3 = ag__.is_undefined_return(retval_)

  def get_state_3():
    return ()

  def set_state_3(_):
    pass

  def if_true_3():
    retval_ = None
    return retval_

  def if_false_3():
    return retval_
  retval_ = ag__.if_stmt(cond_3, if_true_3, if_false_3, get_state_3, set_state_3)
  return retval_
```


but note that in the converted code


```
        def get_state():
          return self.images[random_id],
```

this is causing an undefined error: NameError: name 'random_id' is not defined

the reason I'm calling to_code to this class method is because i used it in a tf.function so i think autograph is going to convert this

**Describe the expected behavior**
the code to be converted correctly

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

as above

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
29006,ImportError: cannot import name 'text_summary',"I am trying to use -
from tensorflow.python.summary import text_summary
but getting the error -
ImportError: cannot import name 'text_summary'
How do I fix it?"
29005,Group convolutions UnimplementedError for nightly build,"I am getting the following error message while running the following code using the nightly version of tensorflow 1.14.1-dev20190524. When will this feature be available?

Code:
`weights = tf.ones([3,3,1,3])`
`X = tf.ones([3,1024,1024,3])`
`Y = tf.nn.conv2d(X, weights, [1, 1, 1, 1], ""VALID"")`

Error:
UnimplementedError: Generic conv implementation does not support grouped convolutions for now.
	 [[node Conv2D_4 (defined at <ipython-input-13-3298cb87493e>:4) ]]
"
28999,Is there any c++ api examples for tensorflow lite？,"I dont like java and swift.
I prefer c++.
However, I seldom see any c++ api helps."
28998,AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_***' when calling any function in tf.io,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.12.0
- Python version: 3.5
- CUDA/cuDNN version: V8.0.61
- GPU model and memory: Tesla P100-PCIE, 12193MiB

**Describe the current behavior**
When I call `tf.io.decode_jpg()` (or any function from `tf.io`), I get the following error: `AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_***'`. I import TensorFlow as `import tensorflow as tf`. I also tried importing the `io` module directly, but to no avail.

**Code to reproduce the issue**
```
from __future__ import absolute_import, division, print_function
import tensorflow as tf
import numpy as np
import sys
import os

CLASSES = [""aluminium"", ""asphalt"", ""brick"", ""cloud"", ""concrete"", ""fabric"", ""foliage"", ""glass"", ""grass"", ""gravel"", ""iron"", ""living"", ""other"", ""plastic"", ""sky"", ""soil"", ""stone"", ""steel"", ""tile"", ""water"", ""wood""]
NUM_CLASSES = len(CLASSES)
DIR_DATASET = ""/media/nfs/7_raid/ebos/dataset/cycloramas/""
WIDTH = 512
HEIGHT = 512

#os.environ[""CUDA_VISIBLE_DEVICES""] = """"
tf.enable_eager_execution()

def sample_fetcher():
    sample_names = [filename[:-4] for filename in os.listdir(DIR_DATASET) if filename[-4:] == "".jpg""]
    for sample_name in sample_names:
        rgb = tf.io.decode_image(tf.read_file(DIR_DATASET + sample_name + "".jpg""))
        rgb = tf.image.resize_images(rgb, (HEIGHT, WIDTH))
        #d = tf.io.decode_jpeg(tf.read_file(DIR_DATASET + ""depth/"" + sample_name + "".jpg""))
        #d = tf.image.resize_images(d, (HEIGHT, WIDTH))
        #rgbd = tf.concat([rgb,d], axis=2)
        onehots = tf.convert_to_tensor(np.load(DIR_DATASET + ""ndarrays/"" + sample_name + "".npy""), dtype=tf.uint8)
        yield tf.stack([rgb, onehots])


train = tf.data.Dataset.from_generator(generator=sample_fetcher, output_types=(tf.uint8, tf.uint8))
train = train.repeat()
train = train.batch(10)

for sample in train:
    print(sample)

resnet = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(HEIGHT, WIDTH, 3), pooling=None, classes=1000)
print(resnet.summary())
```

**Other info / logs**
Full traceback:
```
2019-05-24 17:28:06.378578: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-24 17:28:06.583733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:04:00.0
totalMemory: 11.91GiB freeMemory: 11.62GiB
2019-05-24 17:28:06.758594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:82:00.0
totalMemory: 11.91GiB freeMemory: 11.62GiB
2019-05-24 17:28:06.758660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1
2019-05-24 17:28:07.388910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-24 17:28:07.388951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 
2019-05-24 17:28:07.388959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N N 
2019-05-24 17:28:07.388963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   N N 
2019-05-24 17:28:07.389557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11241 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
2019-05-24 17:28:07.390009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11241 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-12GB, pci bus id: 0000:82:00.0, compute capability: 6.0)
2019-05-24 17:28:07.420058: W tensorflow/core/framework/op_kernel.cc:1261] Unknown: AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'
Traceback (most recent call last):

  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py"", line 206, in __call__
    ret = func(*args)

  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 451, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/all_cf/src/experimental/cityfusion/tasks/material_segmentation/semantic_fpn.py"", line 21, in sample_fetcher
    rgb = tf.io.decode_image(tf.read_file(DIR_DATASET + sample_name + "".jpg""))

AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'


2019-05-24 17:28:07.420191: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at iterator_ops.cc:1031 : Unknown: AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'
Traceback (most recent call last):

  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py"", line 206, in __call__
    ret = func(*args)

  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 451, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/all_cf/src/experimental/cityfusion/tasks/material_segmentation/semantic_fpn.py"", line 21, in sample_fetcher
    rgb = tf.io.decode_image(tf.read_file(DIR_DATASET + sample_name + "".jpg""))

AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'


	 [[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_UINT8, DT_UINT8], token=""pyfunc_1""](arg0)]]
Traceback (most recent call last):
  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/all_cf/src/experimental/cityfusion/tasks/material_segmentation/semantic_fpn.py"", line 34, in <module>
    for sample in train:
  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 543, in __next__
    return self.next()
  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 574, in next
    return self._next_internal()
  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 564, in _next_internal
    output_shapes=self._flat_output_shapes)
  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2266, in iterator_get_next_sync
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.UnknownError: AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'
Traceback (most recent call last):

  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py"", line 206, in __call__
    ret = func(*args)

  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 451, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/all_cf/src/experimental/cityfusion/tasks/material_segmentation/semantic_fpn.py"", line 21, in sample_fetcher
    rgb = tf.io.decode_image(tf.read_file(DIR_DATASET + sample_name + "".jpg""))

AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'


	 [[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_UINT8, DT_UINT8], token=""pyfunc_1""](arg0)]] [Op:IteratorGetNextSync]
2019-05-24 17:28:07.457913: W tensorflow/core/kernels/data/generator_dataset_op.cc:78] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_INT64], token=""pyfunc_2""](arg0)]]

Process finished with exit code 1
``
"
28997,Unable to get predictions from .tflite graph.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary): tensorflow installed using pip
- TensorFlow version (use command below): 1.13.1
- Python version: python 3.6
- Bazel version (if compiling from source): 0.25.2
- CUDA/cuDNN version:  10.0
- GPU model and memory: NVIDIA GeForce GTX 1080 Ti 

**Describe the current behavior**
I have fine tuned ssdlite_mobilenet_v1 model and have the frozen graph post completion of training process.

Used the below mentioned code to convert the frozen.pb grpah into tflite version.
tflite_convert \
--output_file=test.tflite \
--graph_def_file=tflite_graph.pb \
--input_arrays=normalized_input_image_tensor \
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \
--input_shape=1,300,300,3 \
--allow_custom_ops

I wanted to confirm if the results on test data of tflite model matches the frozen.pb file, however the model would not give out any output at all. 

	interpreter =tf.lite.Interpreter(model_path=""path/to/test.tflite"")
	interpreter.allocate_tensors()
	input_details = interpreter.get_input_details()
	output_details = interpreter.get_output_details()
        // image is of format 1 x300x300x3 and the avlues are between -1 to 1
      	interpreter.set_tensor(input_details[0]['index'], image)
	output_data1 = interpreter.get_tensor(output_details[0]['index'])
	classes = interpreter.get_tensor(output_details[1]['index'])
	confidence_scores = interpreter.get_tensor(output_details[2]['index'])
print(output_data1)
print(classes)
print(confidence_scores)

The print statements give no result out. 

Any help provided would be greatly appreciated. "
28996,how to use xla with c++ api in tensorflow,"tensorflow_version: 1.13.1
other： C++ inference; CPU
My steps are as follows: 
1. I trained with Python on GPU
2. converted  model with freeze_graph.py
3. put it on CPU and use c++ language for inference.

How to use C++ to open the XLA settings, I use the following code,  no effect(before timecost == after timecost).

OptimizerOptions optimizer_options = _tf_options.config.graph_options().optimizer_options();
optimizer_options.set_global_jit_level(OptimizerOptions::ON_1);

GraphOptions graph_options = _tf_options.config.graph_options();
graph_options.mutable_optimizer_options()->CopyFrom(optimizer_options);

_tf_options.config.mutable_graph_options()->CopyFrom(graph_options);
@sanjoy "
28995,Keras doesn't allow tf.data validation without validation_steps,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac 10.14.4, Ubuntu 18.01
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.1.dev20190524 | 1.14.0rc0 | 1.14.0
- Python version: 3.6.8
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**
Using `tf.data` as `validation_data` without defining `validation_steps` fails with `TypeError: 'DatasetV1Adapter' object does not support indexing`.  Using `tf.data` without `steps_per_epoch` works as expected when using it as training data instead.

**Describe the expected behavior**
I think the behaviour of training data and validation data in Keras `model.fit` should be consistent. This would make Keras a lot easier to use together with `tf.data` because it gets rid of the need for defining a exact number of steps. 
**Code to reproduce the issue**
```python
import tensorflow as tf
import tensorflow_datasets as tfds

train, test = tfds.load(name=""mnist"", split=[tfds.Split.TRAIN, tfds.Split.TEST], as_supervised=True)

def scale(image, label):
    return tf.cast(image, tf.float32) / 255, label

model = tf.keras.Sequential(
    [
        tf.keras.layers.Conv2D(32, 3, activation=""relu"", input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation=""relu""),
        tf.keras.layers.Dense(10, activation=""softmax""),
    ]
)

model.compile(loss=""sparse_categorical_crossentropy"", optimizer=""adam"")

model.fit(
    train.batch(256),
    validation_data=test.batch(256),
)
```

**Other info / logs**
```python traceback
  File ""test.py"", line 24, in <module>
    epochs=10,
  File ""/Users/lukasgeiger/miniconda3/envs/tf-nightly/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 644, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/Users/lukasgeiger/miniconda3/envs/tf-nightly/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 615, in fit
    steps_name='steps_per_epoch')
  File ""/Users/lukasgeiger/miniconda3/envs/tf-nightly/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 145, in model_iteration
    _print_train_info(inputs, val_inputs, steps_per_epoch, verbose)
  File ""/Users/lukasgeiger/miniconda3/envs/tf-nightly/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 450, in _print_train_info
    hasattr(inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):
TypeError: 'DatasetV1Adapter' object does not support indexing
```
"
28994,[Translation] Translation for Korean,"We've translated this part of guidelines to Korean on our repository with github pages.

This is URL of Korean repository : https://github.com/BangSeongJin/translation_to_korean.git"
28993,Performance issue with ParameterServerStrategy and Gather,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

I've developed a custom logistic regression using Estimator API. The model itself is quite simple and is composed of two variables, one for the bias b (scalar) and one for weights w which shape is (n,). n~60 millions:
```
...
with tf.variable_scope(""weights""):
        w = tf.get_variable(
            ""weights"", initializer=tf.zeros([n]),
             trainable=True, partitioner=tf.fixed_size_partitioner(w_nb_shards)
        )

with tf.variable_scope(""bias""):
        b = tf.get_variable(""bias"", initializer=tf.zeros([1]), trainable=True)

logits = \
        tf.add(
            b,
            tf.reduce_sum(
                tf.multiply(
                    tf.cast(tf.gather(w, feature_indices), tf.float32),
                    feature_values
                ),
                axis=1
            )
        )
batch_size = tf.shape(feature_indices)[0]
logits = tf.reshape(logits, [batch_size, -1])

predictions = tf.sigmoid(logits)

if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(
            mode=mode,
            predictions={""predictions"": predictions}
        )

tf.losses.sigmoid_cross_entropy(
        labels,
        logits,
        reduction=tf.losses.Reduction.SUM,
        weights=weight_column
)

if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = params.get(""optimizer"", tf.train.AdamOptimizer())
        train_op = optimizer.minimize(
            loss=loss, global_step=tf.train.get_global_step())
        return tf.estimator.EstimatorSpec(
            mode=mode, loss=loss, train_op=train_op)
...
```

The training is distributed on yarn with tf-yarn (https://github.com/criteo/tf-yarn) and ParameterServerStrategy. The variable w (weights) is sharded (fixed size) across all parameter servers. The training itself runs successfully but I have performance issues, it is slow. I've used the profiler hook (tf.train.ProfilerHook) to detect what ops take time (cumulative or not) and I noticed that most of the time is spent on op Ftrl/update_weights/weights/part_0/Unique (about 6 sec). Besides the execution time, I was surprised to see that this op , run by all parameter servers for weight updates, only take that much time for ps/1. The same op takes about 5ms for other parameter servers.

![image](https://user-images.githubusercontent.com/41445208/58318802-d0dd7500-7e18-11e9-8085-db8ff087bdf4.png)

After having taken a closer look at events Ftrl/update_weights/weights/part_X/Unique, I noticed that op Unique is applied to ~1 millions integers for ps/1 and less than 15000 integers for other parameter servers. ~1 milions integers seem to match with the number of weights in the model. You can find a subset of events matching ops Unique in the file below.

Is it an expected behavior or known issue ? Should I implement the linear regression part of the model in a different way ? Thanks a lot in advance.

[EventsOpsUnique.txt](https://github.com/tensorflow/tensorflow/files/3216246/EventsOpsUnique.txt)
"
28992,failed call to cuInit: CUDA_ERROR_INVALID_DEVICE: invalid device ordinal,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from (source or binary): `pip install tensorflow-gpu==2.0.0-alpha0`
- TensorFlow version (use command below): 2.0.0-alpha0
- Python version: 3.6.8
- CUDA version: 10
- GPU model and memory: GeForce GTX 1050 / 4Gb

**Describe the current behavior**
Tensorflow does not detect my GPU (it used to - I don't know what changed).

**Code to reproduce the issue**
```python
import os
import tensorflow as tf

os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""

a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
c = tf.matmul(a, b)

print(c)
```
Output:
```sh
2019-05-24 10:16:30.726799: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-24 10:16:30.740369: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-05-24 10:16:30.777178: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_INVALID_DEVICE: invalid device ordinal
2019-05-24 10:16:30.777232: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:166] retrieving CUDA diagnostic information for host: joao-Yoga730
2019-05-24 10:16:30.777242: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:173] hostname: joao-Yoga730
2019-05-24 10:16:30.777331: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 410.48.0
2019-05-24 10:16:30.777364: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 410.48.0
2019-05-24 10:16:30.777371: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:308] kernel version seems to match DSO: 410.48.0
2019-05-24 10:16:30.799754: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1992000000 Hz
2019-05-24 10:16:30.801312: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55e937b11800 executing computations on platform Host. Devices:
2019-05-24 10:16:30.801384: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>
tf.Tensor(
[[22. 28.]
 [49. 64.]], shape=(2, 2), dtype=float32)

Process finished with exit code 0
```

**Other info / logs**
`nvidia-smi`
```sh
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.48                 Driver Version: 410.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1050    Off  | 00000000:3B:00.0 Off |                  N/A |
| N/A   52C    P0    N/A /  N/A |    509MiB /  4042MiB |     33%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1474      G   /usr/lib/xorg/Xorg                           301MiB |
|    0      1650      G   /usr/bin/gnome-shell                         148MiB |
|    0      2107      G   ...uest-channel-token=16113907172495644879    56MiB |
|    0      4229      G   /snap/pycharm-community/128/jre64/bin/java     2MiB |
+-----------------------------------------------------------------------------+
```

p.s. I have tried doing sudo apt install nvidia-modprobe. It didn't work."
28990,bazel build failed on tf1.6 on tx2,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 (aarch64)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source (trying to install)
- TensorFlow version: v1.6.0
- Python version: 2.7
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.11 (installed from sourcecode)
- GCC/Compiler version (if compiling from source): 5.4
- CUDA/cuDNN version: 9.0/7
- GPU model and memory: Nvidia Jetson TX2 (DJI Manifold2)



**Describe the problem**
On my DJI Manifold2 (Nvidia TX2) I am trying to install tensorflow. I am trying to install from scratch. 
The tx2 was not setup with the jetpack, however, it has cuda9 and cudnn7 installed. 
I am following these instructions: https://gist.github.com/vellamike/7c26158c93e89ef155c1cc953bbba956 

I could install bazel (0.11.0) successfully. 
`./configure` works alright. I have said no to everything accept for cuda and jemalloc. 

```
bazel build --verbose_failures --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package 
```

This fails to give: 
````
INFO: From Compiling tensorflow/core/kernels/tile_functor_gpu.cu.cc:
Killed
ERROR: /home/dji/Downloads/tensorflow/tensorflow/core/kernels/BUILD:848:1: output 'tensorflow/core/kernels/_objs/tile_ops_gpu/tensorflow/core/kernels/tile_functor_gpu.cu.pic.o' was not created
ERROR: /home/dji/Downloads/tensorflow/tensorflow/core/kernels/BUILD:848:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 84.543s, Critical Path: 82.14s
FAILED: Build did NOT complete successfully
```
Please see attachement for full lowg
[errorlog.txt](https://github.com/tensorflow/tensorflow/files/3216060/errorlog.txt)
"
28989,Unexpected behavior when scheduling different learning rates,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0
- Python version: 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

I've implemented a custom logistic regression using Estimator API which gives good results when learning with a fixed set of hyperparameters. However, I'm getting unexpected results when learning the model with a learning rate which varies over time. As you can see in the screenshot below, variables of the model (weights and bias), losses and metric prediction_mean abruptly changed twice during the learning, coinciding with learning rate modification.

Here is the piece of code describing instanciation of the estimator:
```
tf.estimator.Estimator(
    model_fn=my_model_fn,
    params={
        ""optimizer"": lambda: tf.train.FtrlOptimizer(
            learning_rate=tf.where(
                tf.less(tf.train.get_global_step(), 100000),
                3e-3,
                tf.where(
                    tf.less(tf.train.get_global_step(), 200000),
                    9e-4,
                    tf.where(
                        tf.less(tf.train.get_global_step(), 300000),
                        6e-4,
                        3e-4
                    )
                )
            ),
            l2_regularization_strength=1e-2
        )
    },
    model_dir=model_dir
)
```

![image](https://user-images.githubusercontent.com/41445208/58311641-b8b22980-7e09-11e9-9460-a33cd94f713e.png)

I was wondering if the modification of the learning rate could trigger the modification of the state of FTRL which could explain this behavior. Any clue ? Thanks a lot in advance."
28988,how to compile the Tensorflow source code  on Mac,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Mac
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version:  r1.12
- Python version: 2.7
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.15.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
when I build the TensorFlow, The error result is:
ERROR: /private/var/tmp/_bazel_xmly/88507af8aae72d6d7037a76bc898c925/external/protobuf_archive/BUILD:260:1: Linking of rule '@protobuf_archive//:js_embed' failed (Exit 1)
ld: unknown option: -no-as-needed
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow:libtensorflow_cc.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1.394s, Critical Path: 0.40s
INFO: 0 processes.
FAILED: Build did NOT complete successfully

**Provide the exact sequence of commands / steps that you executed before running into the problem**

The methods I already tried are:
./configure
bazel build -c opt //tensorflow:libtensorflow_cc.so

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28983,[TF 1.13]: Mishandling dropout and recurrent dropout when feeding them as placeholder inputs to SimpleRNNCell in tf.keras.layers,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): NA (Working on Google Colab)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): NA (Working on Google Colab)
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.7
- Bazel version (if compiling from source): NA (Working on Google Colab)
- GCC/Compiler version (if compiling from source): NA (Working on Google Colab)
- CUDA/cuDNN version: NA (Working on Google Colab)
- GPU model and memory: NA (Working on Google Colab)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I am trying to use `tf.keras.layers` in my code to see how it works. While trying to forecast time series in Tensorflow using RNN, I am using dropout method. If I hard-code the values of `dropout` and `recurrent_dropout`, my program runs perfectly. However, I need to perform inference on the model and for that the dropout needs to be turned off. I am using `tf.placeholder_with_default` but this is throwing an error.

**Describe the expected behavior**
Ideally there should be no error while using `tf.placeholder_with_default` but since `recurrent.py` allows only float values for `dropout` and `recurrent_dropout` this error is coming up. Is there any way to pass `dropout` and `recurrent_dropout` values at runtime?

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```Python
# Library imports
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np

# Variable initialization
t_min = 0
t_max = 30
resolution = 1e-2
n_steps = 20
n_inputs = 1
n_outputs = 1
n_neurons = 100
learning_rate = 1e-2

TimeSeriesDropout_graph = tf.Graph()
with TimeSeriesDropout_graph.as_default():
  keep_prob_input_default = np.array(1.0,dtype='float32')
  keep_prob_input = tf.placeholder_with_default(keep_prob_input_default,shape=())
  keep_prob_state_default = np.array(1.0,dtype='float32')
  keep_prob_state = tf.placeholder_with_default(keep_prob_state_default,shape=())
#   keep_prob_input = 0.5
#   keep_prob_state = 0.5
  X = tf.placeholder(dtype=tf.float32,shape=(None,n_steps,n_inputs))
  y = tf.placeholder(dtype=tf.float32,shape=(None,n_steps,n_outputs))
  multiple_rnn_cell = [tf.keras.layers.SimpleRNNCell(units=n_neurons,activation='relu'
                                                     ,dropout=keep_prob_input
                                                     ,recurrent_dropout=keep_prob_state)
                     ,tf.keras.layers.SimpleRNNCell(units=n_neurons//2,activation='relu'
                                                     ,dropout=keep_prob_input
                                                    ,recurrent_dropout=keep_prob_state)
                     ,tf.keras.layers.SimpleRNNCell(units=n_neurons//4,activation='relu'
                                                     ,dropout=keep_prob_input
                                                    ,recurrent_dropout=keep_prob_state)
                     ,tf.keras.layers.SimpleRNNCell(units=n_neurons//8,activation='relu'
                                                     ,dropout=keep_prob_input
                                                    ,recurrent_dropout=keep_prob_state)]
  stacked_rnn_cell = tf.keras.layers.StackedRNNCells(multiple_rnn_cell)
  rnn_output = tf.keras.layers.RNN(stacked_rnn_cell,return_sequences=True,return_state=True)(X)
  outputs_reshaped = tf.reshape(rnn_output[0],(-1,n_neurons//8))
  output = tf.keras.layers.Dense(units=n_outputs)(outputs_reshaped)
  output_stacked = tf.reshape(output,(-1,n_steps,n_outputs))
  loss = tf.reduce_mean(tf.square(y-output_stacked))
  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
  training_op = optimizer.minimize(loss)
  init = tf.global_variables_initializer()
  saver = tf.train.Saver()
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```bash
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-30-16da420b4722> in <module>()
     10   multiple_rnn_cell = [tf.keras.layers.SimpleRNNCell(units=n_neurons,activation='relu'
     11                                                      ,dropout=keep_prob_input
---> 12                                                      ,recurrent_dropout=keep_prob_state)
     13                      ,tf.keras.layers.SimpleRNNCell(units=n_neurons//2,activation='relu'
     14                                                      ,dropout=keep_prob_input

1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py in __init__(self, units, activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, kernel_regularizer, recurrent_regularizer, bias_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, **kwargs)
   1061     self.bias_constraint = constraints.get(bias_constraint)
   1062 
-> 1063     self.dropout = min(1., max(0., dropout))
   1064     self.recurrent_dropout = min(1., max(0., recurrent_dropout))
   1065     self.state_size = self.units

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in __bool__(self)
    651       `TypeError`.
    652     """"""
--> 653     raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""
    654                     ""Use `if t is not None:` instead of `if t:` to test if a ""
    655                     ""tensor is defined, and use TensorFlow ops such as ""

TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.
```
"
28980,Hamming distance support,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.13
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Take binary representation class (predicted label ) number into account and compute loss.
Say, for example, the loss for true label = 0 and predicted label = 1 should be less than the loss for true label = 0 and predicted = 100

**Will this change the current API? How?**
No. This will add a new function

**Who will benefit with this feature?**
Helpful for users with the above-mentioned requirement.

If this is of interest, I would like to create a PR.
"
28979,Adding multiclass support to BoostedTreesClassifier,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.13.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
The BoostedTreesClassifier supports binary classification only.

**Will this change the current api? How?**
No. The API already has a placeholder parameter `n_classes`.

**Who will benefit with this feature?**
People who need to perform multiclass classification.

**Any Other info.**"
28976,TF2.0 tf.keras.estimator.model_to_estimator does not store input_names from tf.keras.layers.DenseFeatures,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): NA
- TensorFlow version (use command below): v1.12.0-9492-g2c319fb415 2.0.0-alpha0
- Python version: 3.6.7 (default, Oct 22 2018, 11:32:17)  [GCC 8.2.0]
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I created a Keras model that takes as input 2 feature columns named 'store' and 'loc'.

Converting it to an Estimator and then training it throws an exception because it assumes the input names are 'input_1' and 'input_2'.

**Describe the expected behavior**
Train the keras estimator without errors

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

Please see this gist: https://gist.github.com/hsm207/ed5a28f4156e0088b0d1098e225e70fb

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28972,Adding R-Square and FBeta Score metric under tf.metric,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.13
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Adding R-Square and FBeta metrics as one of the metrics under tf.metrics

**Will this change the current api? How?**
I will not affect the current API

**Who will benefit with this feature?**
R-Square and FBeta are quite popular metrics. Adding this will benefit a lot of people

I would like to create a PR if this is of our interest and not existing.

Thanks in advance.
"
28969,Unexpected behavior with warm start,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not relevant
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0
- Python version: 3.6
- Bazel version (if compiling from source): Not relevant
- GCC/Compiler version (if compiling from source): Not relevant
- CUDA/cuDNN version: Not relevant
- GPU model and memory: Not relevant

I've implemented a custom logistic regression which is working as expected. My implementation is based on Estimator API. I managed to train the model with a set of hyperparameter. After  that, I wanted to train another model but with a different learning rate and a warm start using the previously trained model. The learning itself ran succesfully. Since the new learning started from the last checkpoint of the previous learning (due to the warm start), I would expect the new model to start with the variable values of the last checkpoint of the previous learning. But looking at the metrics of tensorboard, It seems the new learning started from scratch. As we can see in the screenshot, the prediction_mean metric starts above 5e-4 and converges around 2.5e-4. The problem here is the same metric prediction_mean already converged around 2.5e-4 for the previous learning. Same observation regarding the metric auc.

![image](https://user-images.githubusercontent.com/41445208/58267669-63800480-7d84-11e9-92db-85d547cf8812.png)

Model trainings are run on yarn and are distributed according to the parameter server strategy.

The following is the piece of code to instantiate the estimator with a warm start:
```
tf.estimator.Estimator(
    model_fn=model_fn_babaflow.model_fn,
    params={
        ""optimizer"": tf.train.FtrlOptimizer(
            1e-1,
            l2_regularization_strength=1e-1
        )
    },
    model_dir=model_dir,
    warm_start_from=""viewfs://path_to_model_dir_of_previous_learning""
)
```

The following is an extract of the log of the chief:

> 2019-05-22 14:59:36,321:INFO:tensorflow: Starting execution chief:0
> 2019-05-22 14:59:36,322:INFO:tensorflow: Broadcasting chief:0/train_eval_start_time = '1558537176.3222742'
> 2019-05-22 14:59:36,323:INFO:tensorflow: Broadcasting chief:0/start = ''
> 2019-05-22 14:59:36,331:INFO:tensorflow: Not using Distribute Coordinator.
> 2019-05-22 14:59:36,912:INFO:tensorflow: Calling model_fn.
> 2019-05-22 14:59:39,613:WARNING:tensorflow: From /tmp/9e20594d-0554-4d16-8b21-122638b68185/install/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl.e0ceba8cc1b266d3356296be2708e12fb322668e/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
> 2019-05-22 14:59:50,953:INFO:tensorflow: Done calling model_fn.
> 2019-05-22 14:59:50,953:INFO:tensorflow: Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='viewfs://...', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})
> 2019-05-22 14:59:50,953:INFO:tensorflow: Warm-starting from: ('viewfs://...',)
> 2019-05-22 14:59:50,957:INFO:tensorflow: Warm-starting variable: weights/weights; prev_var_name: Unchanged
> 2019-05-22 15:00:02,025:DEBUG:tensorflow: Initialize variable weights/weights/part_0:0,weights/weights/part_1:0,weights/weights/part_2:0,weights/weights/part_3:0,weights/weights/part_4:0,weights/weights/part_5:0,weights/weights/part_6:0,weights/weights/part_7:0,weights/weights/part_8:0,weights/weights/part_9:0,weights/weights/part_10:0,weights/weights/part_11:0,weights/weights/part_12:0,weights/weights/part_13:0,weights/weights/part_14:0,weights/weights/part_15:0,weights/weights/part_16:0,weights/weights/part_17:0,weights/weights/part_18:0,weights/weights/part_19:0,weights/weights/part_20:0,weights/weights/part_21:0,weights/weights/part_22:0,weights/weights/part_23:0,weights/weights/part_24:0,weights/weights/part_25:0,weights/weights/part_26:0,weights/weights/part_27:0,weights/weights/part_28:0,weights/weights/part_29:0,weights/weights/part_30:0,weights/weights/part_31:0,weights/weights/part_32:0,weights/weights/part_33:0,weights/weights/part_34:0,weights/weights/part_35:0,weights/weights/part_36:0,weights/weights/part_37:0,weights/weights/part_38:0,weights/weights/part_39:0,weights/weights/part_40:0,weights/weights/part_41:0,weights/weights/part_42:0,weights/weights/part_43:0,weights/weights/part_44:0,weights/weights/part_45:0,weights/weights/part_46:0,weights/weights/part_47:0,weights/weights/part_48:0,weights/weights/part_49:0,weights/weights/part_50:0,weights/weights/part_51:0,weights/weights/part_52:0,weights/weights/part_53:0,weights/weights/part_54:0,weights/weights/part_55:0,weights/weights/part_56:0,weights/weights/part_57:0,weights/weights/part_58:0,weights/weights/part_59:0,weights/weights/part_60:0,weights/weights/part_61:0,weights/weights/part_62:0,weights/weights/part_63:0,weights/weights/part_64:0,weights/weights/part_65:0,weights/weights/part_66:0,weights/weights/part_67:0,weights/weights/part_68:0,weights/weights/part_69:0,weights/weights/part_70:0,weights/weights/part_71:0,weights/weights/part_72:0,weights/weights/part_73:0,weights/weights/part_74:0,weights/weights/part_75:0,weights/weights/part_76:0,weights/weights/part_77:0,weights/weights/part_78:0,weights/weights/part_79:0,weights/weights/part_80:0,weights/weights/part_81:0,weights/weights/part_82:0,weights/weights/part_83:0,weights/weights/part_84:0,weights/weights/part_85:0,weights/weights/part_86:0,weights/weights/part_87:0,weights/weights/part_88:0,weights/weights/part_89:0,weights/weights/part_90:0,weights/weights/part_91:0,weights/weights/part_92:0,weights/weights/part_93:0,weights/weights/part_94:0,weights/weights/part_95:0,weights/weights/part_96:0,weights/weights/part_97:0,weights/weights/part_98:0,weights/weights/part_99:0,weights/weights/part_100:0,weights/weights/part_101:0,weights/weights/part_102:0,weights/weights/part_103:0,weights/weights/part_104:0,weights/weights/part_105:0,weights/weights/part_106:0,weights/weights/part_107:0,weights/weights/part_108:0,weights/weights/part_109:0,weights/weights/part_110:0,weights/weights/part_111:0,weights/weights/part_112:0,weights/weights/part_113:0,weights/weights/part_114:0,weights/weights/part_115:0,weights/weights/part_116:0,weights/weights/part_117:0,weights/weights/part_118:0,weights/weights/part_119:0,weights/weights/part_120:0,weights/weights/part_121:0,weights/weights/part_122:0,weights/weights/part_123:0,weights/weights/part_124:0,weights/weights/part_125:0,weights/weights/part_126:0,weights/weights/part_127:0,weights/weights/part_128:0,weights/weights/part_129:0,weights/weights/part_130:0,weights/weights/part_131:0,weights/weights/part_132:0,weights/weights/part_133:0,weights/weights/part_134:0,weights/weights/part_135:0,weights/weights/part_136:0,weights/weights/part_137:0,weights/weights/part_138:0,weights/weights/part_139:0,weights/weights/part_140:0,weights/weights/part_141:0,weights/weights/part_142:0,weights/weights/part_143:0,weights/weights/part_144:0,weights/weights/part_145:0,weights/weights/part_146:0,weights/weights/part_147:0,weights/weights/part_148:0,weights/weights/part_149:0 from checkpoint viewfs://... with weights/weights
> 2019-05-22 15:00:02,026:INFO:tensorflow: Warm-starting variable: bias/bias; prev_var_name: Unchanged
> 2019-05-22 15:00:09,259:DEBUG:tensorflow: Initialize variable bias/bias:0 from checkpoint viewfs://root/... with bias/bias
> 2019-05-22 15:00:09,262:INFO:tensorflow: Create CheckpointSaverHook.
> 2019-05-22 15:00:37,061:INFO:tensorflow: Graph was finalized.

Is there anything wrong about what I'm doing ? Issue already known ?"
28968,Tensorflow lite elementwise operation not working in gpu delegate (ADD & SUB),"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NIL
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: OnePlus 3 , Android 8.0.0
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): TF 1.13
- Python version: 3.5
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version: 5.4.0
- GPU model and memory: NIL


**Describe the current behavior**
 
When we are trying to run a tflite model with element-wise operations like ADD and SUB (appended via custom code) on an android application (**org.tensorflow:tensorflow-lite:0.0.1-gpu-experimental**)   it throws an error message and crashes the application.

Also it fails during android benchmark test in gpu mode, with the same error message. However  the same model runs in CPU mode in the same android application and also clears the android benchmark test in CPU mode without errors.

We also tried the same model with tensorflow-lite gpu nightly version. But it does not give any any information about where the nodes are being run (i.e CPU or GPU). The problem is with the last couple of elementwise operations at the end of the model and it looks like they automatically falls back to CPU with '**org.tensorflow:tensorflow-lite:0.0.0-nightly**'. Even the cast operator (not supported by GPU), runs in nighlty tflite GPU delegate without any warning. We believe it is running in CPU, based on the speed or time taken to execute those nodes. TF-lite nightly doesn't give any info of whether it falls back to CPU or runs in GPU (unlike experimental version), when it encounters an unsupported op in GPU.Also it looks like errors and warnings are suppressed in nightlty version.

**Describe the expected behavior**

The tensorflow lite model should run without errors in GPU and CPU with element-wise operators.

**Code to reproduce the issue**

Here is the snapshot of the models which produced the aforementioned errors.

1. Model 1:-

![2](https://user-images.githubusercontent.com/1130185/58264257-2c691d80-7d9b-11e9-8f8f-0d10b9c94e32.png)


2. Model 2:-

![3](https://user-images.githubusercontent.com/1130185/58264318-473b9200-7d9b-11e9-8838-68871f946df3.png)

Models: 
[Models.zip](https://github.com/tensorflow/tensorflow/files/3212972/Models.zip)

Both run in CPU mode; but fails in GPU !!!

**Other info / logs**

1. **Model 1 Error Log :  With ADD and SUB**

adb shell /data/local/tmp/benchmark_model_gpu --graph=/data/local/tmp/work_test_trial_fulltest_257op_dm05_257_blend_cast_dbadd6.tflite --use_gpu=true
adb: /opt/intel/intelpython27/lib/libcrypto.so.1.0.0: no version information available (required by adb)
STARTING!
Min num runs: [50]
Min runs duration (seconds): [1]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/data/local/tmp/work_test_trial_fulltest_257op_dm05_257_blend_cast_dbadd6.tflite]
Input layers: []
Input shapes: []
Use nnapi : [0]
Use legacy nnapi : [0]
Use gpu : [1]
Allow fp16 : [0]
nnapi error: requires android sdk version to be at least 27
Loaded model /data/local/tmp/work_test_trial_fulltest_257op_dm05_257_blend_cast_dbadd6.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for GPU.
ERROR: Next operations are not supported by GPU delegate:
**SUB: Incorrect operation type passed**
First 77 operations will run on the GPU, and the remaining 2 on the CPU.
**ERROR: TfLiteGpuDelegate Prepare: fuse_auto_input failed**
ERROR: Node number 79 (TfLiteGpuDelegate) failed to prepare.

Failed to apply GPU delegate.
Aborted 

2. **Model 2 Error Log: With ADD only**

adb shell /data/local/tmp/benchmark_model_gpu --graph=/data/local/tmp/work_test_trial_fulltest_257op_dm05_257_blend_cast_dbadd8.tflite --use_gpu=true
adb: /opt/intel/intelpython27/lib/libcrypto.so.1.0.0: no version information available (required by adb)
STARTING!
Min num runs: [50]
Min runs duration (seconds): [1]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/data/local/tmp/work_test_trial_fulltest_257op_dm05_257_blend_cast_dbadd8.tflite]
Input layers: []
Input shapes: []
Use nnapi : [0]
Use legacy nnapi : [0]
Use gpu : [1]
Allow fp16 : [0]
nnapi error: requires android sdk version to be at least 27
Loaded model /data/local/tmp/work_test_trial_fulltest_257op_dm05_257_blend_cast_dbadd8.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for GPU.
ERROR: TfLiteGpuDelegate Prepare: fuse_auto_input failed
ERROR: Node number 76 (TfLiteGpuDelegate) failed to prepare.

Failed to apply GPU delegate.
Aborted

Also refer: Issue #28606

Is the issue fixed in latest nightly or experimental versions?
We tried the following gradle dependencies in app:-
1. org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly
2. org.tensorflow:tensorflow-lite:0.0.1-gpu-experimental

But it does not run properly with either of the versions ..."
28967,windows 10 installation with cpu version,"**System Information:**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.13.1
- Python version: 3.6.0
- Installed using virtualenv? pip? conda?: virtualenv with pip v19.1.1
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A (CPU version)



**Describe the Problem:**
I have installed the Microsoft Visual C++ 2015 Redistributable Update 3 and Python 3.6. I have tried several releases of Python 3.6, but each time I receive a runtime load error as described below

**Commands:**
```
>.\venv\Scripts\activate
(venv) > pip install --upgrade tensorflow
(venv) > python -c ""import tensorflow as tf;""
```
**Stack Trace:**
```
Traceback (most recent call last):
  File ""C:\Users\aherk\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\aherk\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\aherk\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\aherk\venv\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\aherk\venv\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Users\aherk\venv\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\aherk\venv\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\aherk\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\aherk\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\aherk\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\aherk\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\aherk\venv\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\aherk\venv\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.
```
"
28966,[TF2.0] Gradients become None when using a SparseTensor kernel in a custom layer.,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOSX 10.14.5
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.0-9492-g2c319fb415 2.0.0-alpha0
- Python version: 3.6
- CUDA/cuDNN version: running on mac/cpu
- GPU model and memory: running on mac/cpu

**Describe the current behavior**
In a DeepRL setting, using a DQN implementation in TF2. After a certain number of calls, the custom training loop with gradient tape is not able to compute gradient for the SparseMatrices used in the model (weights inside the sparse matrice), the gradient for biases is computed without any issue. 
The model can still be called, the weights are not zero. The gradients in _SparseTensorDenseMatMulGrad() are not None, and seem ok. That is, a_values_grad and b_grad are not None (also not None in _gradient_function)

`(None, a_values_grad, None, b_grad)`

But the output of `pywrap_tensorflow.TFE_Py_TapeGradient()` in `imperative_grad` has None for the weights in the SparseTensor. 

It is worth noting that if I do not call the model before the first training loop, the gradients are OK. Next loop they become None. 

**Describe the expected behavior**
Valid gradient for the weights in the SparseTensor whatever the number of calls done previously to the model.

**Code to reproduce the issue**
The model is quite complex. But the issue seem to come from one of the custom Layer which has a kernel defined like so:
```python 
kernel_weights = self.add_weight('kernel_weights',
                                         shape=[self.indices.shape[0]],
                                         initializer=self.kernel_initializer,
                                         regularizer=self.kernel_regularizer,
                                         constraint=self.kernel_constraint,
                                         dtype=self.dtype,
                                         trainable=self.trainable)

self.kernel = tf.SparseTensor(self.indices,
                                      kernel_weights,
                                      self.dense_shape)
```

And a call function defined as so:
```python
def call(self, x, **kwargs): 
        x = tf.transpose(tf.sparse.sparse_dense_matmul(self.kernel, x, adjoint_b=True))
        if self.use_bias:
            x += self.bias
        x = self.activation(x)
        return x
```

I tried to optimize the layer outside of the RL setting, with a dummy loss, and the issue remains. Here is the code for the custom loop:

```python
optimizer = Adam(learning_rate=1e-3)
x = tf.Variable(tf.ones((160, 41)))
data = Dataset.from_tensor_slices((x)).batch(20) 
for obs0 in data:
    with tf.GradientTape() as tape: 
        x = model(obs0) 
        
        loss_value = tf.reduce_mean(x, name='dummy_loss')
        
        grads = tape.gradient(loss_value, model.trainable_weights)
        # Here the gradient for the sparse kernel is None on the second loop
        #The gradient for the bias is fine
        
        optimizer.apply_gradients(zip(grads, model.trainable_weights))
```

**Other info / logs**
```
W0523 16:11:28.381706 4529878464 optimizer_v2.py:928] Gradients does not exist for variables ['custom_layer/kernel_weights:0'] when minimizing the loss.
```"
28961,tensorflow compile error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>
**grpc** **sha256** checksum was""*"" but wanted""*""
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version:branch:master  05/23/2019
- Python version:2.7
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):0.24.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10/7.5.1
- GPU model and memory:


8g
**Describe the problem**
Downloading  **grpc** from github ,the sha256 checksum is not suit for the .bzl files.
**Provide the exact sequence of commands / steps that you executed before running into the problem**
Almost every time I compile tensorflow ,this bug will turn out.
the last few times I was lucky,the  sha code was right after  tried so .many times.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28959,`BaseSession._Callable.__del__` doesn’t detect closed session correctly,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not tested
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.3
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

`BaseSession._Callable.__del__` doesn’t detect closed session correctly. Running the code I provided below will causes the following error message being printed:

```
Exception ignored in: <function BaseSession._Callable.__del__ at 0x7fe50cc480d0>
Traceback (most recent call last):
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1455, in __del__
    self._session._session, self._handle, status)
  File ""/usr/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.
```

The error message doesn’t affect the correctness of the program, but it is annoying to see.

**Describe the expected behavior**

The test program exits without printing the error message.

**Code to reproduce the issue**

```python
import tensorflow as tf
from tensorflow.core.protobuf.config_pb2 import CallableOptions


def main():
    with tf.Session() as session:
        t = tf.zeros(shape=())

        c = session._make_callable_from_options(CallableOptions(fetch=[t.name]))

        print(c())


if __name__ == '__main__':
    main()
```

**Other info / logs**

Here is my analysis:

- This is the definition of `BaseSession.close`:

  https://github.com/tensorflow/tensorflow/blob/592fa18bc134d9b9527f3d87ba51d6ae0378e3da/tensorflow/python/client/session.py#L736-L747

  If it is called on an alive session, `self._closed` will be set to `True` but `self._session` will not change.
- This is the definition of `BaseSession.__del__`:

  https://github.com/tensorflow/tensorflow/blob/592fa18bc134d9b9527f3d87ba51d6ae0378e3da/tensorflow/python/client/session.py#L749-L764

  This method will set `self._session` to `None`.

- This is the definition of `BaseSession._Callable.__del__`:

  https://github.com/tensorflow/tensorflow/blob/592fa18bc134d9b9527f3d87ba51d6ae0378e3da/tensorflow/python/client/session.py#L1467-L1473

  It only detect `self._session._session`, but not `self._session._closed`.

So if a `BaseSession._Callable` is being destroyed after the corresponding session being closed, but before the session being destroyed, `TF_SessionReleaseCallable` will be called on a closed session, which will raise the exception mentioned above.

There are two possible fixes:

1. Set `self._session` to `None` in `BaseSession.close`.
2. Detect `self._session._closed` in `BaseSession._Callable.__del__`.

Maybe related: #3388, #24367."
28958,Merge bn with depthwise conv for *.bp ,"**System information**
- TensorFlow version (you are using):1.10
- Are you willing to contribute it (Yes/No):yes

I used graph_transforms  and optimize_for_inference to optimize the freeze_graph. I  focus on merging bn with  conv layers to speed up the inference time. But both method can only merge bn with CONV2D, and can not merge bn with DEPTHWISE CONV. As far as  i know, the tool toco can merge all the conv with  bn to *.tflite. So, will the graph_transforms support to do so for *.bp.

"
28957,Eager execution in tf.data map_func,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):tf-2.0-alpha
- Are you willing to contribute it (Yes/No):No

**Describe the feature and the current behavior/state.**
I really want the release version of TF2.0 could bring the eager mode in the [map_function](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) in its tf.data API. For now, TF2.0-alpha do not apply eager mode in the map_function in tf.data API. However, pepole usually use map_function in tf.data API to parse data and do some image augmentation. To parse data in TF is really convenient. But when it comes to image augmentation, the official TF API is far less sufficient(under non eager mode), for people could use some origin Python API or the API from many other third party libraries to do image augmentation which is badly in need of eager mode. So eager mode in tf.data map_function pipeline is really really necessary for us tensorflow users.

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
28956,Distribute Strategy wrong reduction,"## URL(s) with the issue: https://www.tensorflow.org/guide/distribute_strategy#using_tfdistributestrategy_with_custom_training_loops

## Description of issue (what needs changing):
In the documentation the snippet:

```python
def train_step():
  def step_fn(inputs):
    features, labels = inputs
    logits = model(features)
    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(
        logits=logits, labels=labels)  
    loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)
    train_op = optimizer.minimize(loss)
    with tf.control_dependencies([train_op]):
      return tf.identity(loss)

  per_replica_losses = mirrored_strategy.experimental_run(
      step_fn, input_iterator)
  mean_loss = mirrored_strategy.reduce(
      tf.distribute.ReduceOp.MEAN, per_replica_losses)
  return mean_loss
```
calculates the loss using the distribution strategy. However the loss for each replica is reduced using `tf.distribute.ReduceOp.MEAN`. I think that the correct loss to return is the loss reduced using `tf.distribute.ReduceOp.SUM` since every loss is already reduced using the partial mean over the `global_batch_size` (` tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)`) . 

I think a better snippet would be:

```python
def train_step():
  def step_fn(inputs):
    features, labels = inputs
    logits = model(features)
    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(
        logits=logits, labels=labels)  
    loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)
    train_op = optimizer.minimize(loss)
    with tf.control_dependencies([train_op]):
      return tf.identity(loss)

  per_replica_losses = mirrored_strategy.experimental_run(
      step_fn, input_iterator)
  loss = mirrored_strategy.reduce(
      tf.distribute.ReduceOp.SUM, per_replica_losses)
  return loss
```

Am I wrong?

### Submit a pull request?

Maybe I can submit a pull request to fix this.

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
28955,fatal error LNK1000: Internal error during CImplib::EmitThunk,"**System information**
- Windows 10
- TensorFlow installed from (source or binary): source
- C++ Visual Studio 2015 Update 3
- GPU model and memory: NO USE



**Describe the problem**

Hi,
I have a Static library project, containing some codes that are using Tensorflow as Additional Dependencies.
I want to make a static libray (name ""`myLib.lib`"") from these codes to use in another Win32 App.
In my static library project, I used `/WHOLEARCHIVE` flag to include all tensorflow's lib files to the my final static library, `myLib.lib` file.
I build it and make `myLib.lib` file.
In another Win32 App I link this `myLib.lib` to use it and also use `/WHOLEARCHIVE:myLib.lib` as a Additional options in Linker->Command Line.
But when I run this win32app, I got the error:

`fatal error LNK1000: Internal error during CImplib::EmitThunk`

I searched many topics but I didn't find any appropriate solution. I totaly confused. What should I do?

I have to say that I added `/WHOLEARCHIVE` flag in order to prevent error `No session factory registered for the given session options` when using Tensorflow.
"
28954,mfcc,"preprocess: Spectrogram processing mode. Can be ""mfcc"" or ""average"".


what is average?"
28953,[TF 2.0] Cannot use `tf.image.decode_image` with `tf.map_fn` in `tf.data.Dataset.map` when `elems` is empty,"- Tensorflow: latest `tf-nightly-2.0-preview` (as of today).
- Python 3.7
- Ubuntu 19.04

When using `tf.data.Dataset.map` , it can happen that an image does not have any objects in it and so tensors describing masks or boxes are empty.

A common preprocessing step is to decode a list of masks encoded as string in JPEG or PNG. Consider the following code:

```python
import tensorflow as tf
import numpy as np

def generate_encoded_image():
    im = np.random.random((256, 256, 1)).astype('uint8')
    return tf.image.encode_png(im)

def fake_data_generator(feature):
    # Here you can change the range to modify the number of objects.
    # The issue araise when feature does not have any objects in it,
    # when `n_objects = 0`.
    n_objects = np.random.randint(0, 1)
    
    feature = {}
    feature['label_ids'] = np.random.random((n_objects,)).astype('int64')
    feature['bboxes'] = np.random.random((n_objects, 4)).astype('float32')    
    
    if n_objects == 0:
        feature['masks'] = tf.constant([], dtype=tf.string)
    else:
        feature['masks'] = [generate_encoded_image() for _ in range(n_objects)]
        
    return feature

def decode_masks(feature):
    decode_image_fn = lambda x: tf.image.decode_image(x)
    
    # Using the following works
    # decode_image_fn = lambda x: tf.constant([3, 4, 5], dtype=tf.uint8)
    
    feature['masks_new'] = tf.map_fn(decode_image_fn, feature['masks'], dtype=tf.uint8)
    return feature
   
dataset = tf.data.Dataset.from_tensors(tf.range(20))
dataset = dataset.map(fake_data_generator)
dataset = dataset.map(decode_masks)

for feature in dataset:
    pass
```

Running it as this will raise this error:

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-135-af99bdf86e00> in <module>
     36 dataset = dataset.map(decode_masks)
     37 
---> 38 for feature in dataset:
     39     pass

~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in __next__(self)
    584 
    585   def __next__(self):  # For Python 3 compatibility
--> 586     return self.next()
    587 
    588   def _next_internal(self):

~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in next(self)
    621     """"""
    622     try:
--> 623       return self._next_internal()
    624     except errors.OutOfRangeError:
    625       raise StopIteration

~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    613             self._iterator_resource,
    614             output_types=self._flat_output_types,
--> 615             output_shapes=self._flat_output_shapes)
    616 
    617       return self._structure._from_compatible_tensor_list(ret)  # pylint: disable=protected-access

~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)
   2118       else:
   2119         message = e.message
-> 2120       _six.raise_from(_core._status_to_exception(e.code, message), None)
   2121   # Add nodes to the TensorFlow graph.
   2122   if not isinstance(output_types, (list, tuple)):

~/local/conda/envs/tf/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Tried to stack elements of an empty list with non-fully-defined element_shape: <unknown>
	 [[{{node map/TensorArrayV2Stack/TensorListStack}}]] [Op:IteratorGetNextSync]
```

The error only happens when `n_objects = 0` and when I use `tf.image.decode_image`.

I also tried to use something like:

```python
if tf.shape(feature['masks'])[0] == 0:
        feature['masks_new'] = tf.constant([], dtype=tf.uint8)
    else:
        feature['masks_new'] = tf.map_fn(decode_image_fn, feature['masks'], dtype=tf.uint8)
```

But it raises the same error. It looks like ` tf.shape(feature['masks'])[0] == 0` is never `True`.

I also tried to `@tf.function` for `decode_masks()` but then TF complains because I modify the input structure:

```
ValueError: The two structures don't have the same nested structure.

First structure: type=tuple str=({'label_ids': <tf.Tensor 'feature_1:0' shape=(0,) dtype=int64>, 'bboxes': <tf.Tensor 'feature:0' shape=(0, 4) dtype=float32>, 'masks': <tf.Tensor 'feature_2:0' shape=(0,) dtype=string>},)

Second structure: type=tuple str=({'label_ids': <tf.Tensor 'feature_1:0' shape=(0,) dtype=int64>, 'bboxes': <tf.Tensor 'feature:0' shape=(0, 4) dtype=float32>, 'masks': <tf.Tensor 'feature_2:0' shape=(0,) dtype=string>, 'masks_new': <tf.Tensor 'map/TensorArrayV2Stack/TensorListStack:0' shape=<unknown> dtype=uint8>},)

More specifically: The two dictionaries don't have the same set of keys. First structure has keys type=list str=['label_ids', 'bboxes', 'masks'], while second structure has keys type=list str=['label_ids', 'bboxes', 'masks', 'masks_new']

During handling of the above exception, another exception occurred:
```

I am out of idea here. Help is welcome :-)"
28952,feature_bin_count,"train.py中的三个参数
parser.add_argument(
      '--window_size_ms',
      type=float,
      default=30.0,
      help='How long each spectrogram timeslice is.',)
parser.add_argument(
      '--window_stride_ms',
      type=float,
      default=10.0,
      help='How far to move in time between spectogram timeslices.',)
parser.add_argument(
      '--feature_bin_count',
      type=int,
      default=40,
      help='How many bins to use for the MFCC fingerprint',
  )

是 下面的意思吗？？
1每隔30秒，生成一个40维的向量。
2窗口向前移动10秒，重复1的操作。"
28948,Updated Eigen breaks builds,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 30
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: source in virtualenv
- Bazel version (if compiling from source): 0.25.2-1
- GCC/Compiler version (if compiling from source): 9.1.1-1
- CUDA/cuDNN version: 10.1

**Describe the problem**

master branch earlier today could compile fine, now it no longer can with the following error in many files:

```
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/GPU/Half.h(717): error: no suitable constructor exists to convert from ""float"" to ""Eigen::half""
```

It seems commit cf5687d4b3f66fecbab4ac35f89be0b9edac17eb may have caused this since it updated the Eigen version.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
virtualenv tensorflow
cd tensorflow
. bin/activate
pip install --upgrade --force-reinstall pip setuptools
pip install wheel numpy scipy keras
git clone https://github.com/tensorflow/tensorflow.git --single-branch --branch master
cd tensorflow

./configure
# Use default values except:
#   CUDA support: Y and TensorRT support: Y
#   Only support compute capability 7.0 and not 6.1

export TMP=/tmp
bazel build --jobs 15 -c opt --config=opt --config=v2 --config=mkl --config=numa \
    --copt=-march=native --cxxopt=-march=native --copt=-O3 --cxxopt=-O3 \
    //tensorflow/tools/pip_package:build_pip_package --verbose_failures
```
"
28945,CUDA GPU support for contrib static makefile build on Linux and possibly MacOS and Windows,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): v1.13.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Using contrib make file I can build static libraries on Windows and Linux

git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout v1.13.1
./configure #give details for CPU
bazel build --opt config //tensorflow:libtensorflow_cc.so #setup up proto headers etc
./tensorflow/contrib/makefile/build_all_linux.sh
export LD_LIBRARY_PATH=$PWD/tensorflow/contrib/makefile/gen/host-protobuf/lib
./tensorflow/contrib/makefile/gen/bin/benchmark --help

(The above works pretty well under OSX also)

I can see in the Makefile there is some support for CUDA builds on the NVIDIA Tegra platform for Android.

would it be possible to make it create the .a file for CUDA linkage mentioned in the Tegra part of the build script?

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
People integrating Tensorflow who need static linkage AND GPU acceleration using C++ API.

If you are using Tensorflow as a plugin then the function init can only be called once

see
https://stackoverflow.com/questions/43665674/what-is-the-purpose-of-tensorflowportinitmain
https://github.com/tensorflow/tensorflow/issues/22810
https://stackoverflow.com/questions/52683649/libtensorflow-cc-so-initialised-a-second-time-causes-segfault

Allowing static linking overcomes this problem

**Any Other info.**
Also see:
https://github.com/tensorflow/tensorflow/issues/28388"
28944,Link for migrating from deprecated DNNLinearCombinedRegressor is broken,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py#L849

## Description of issue (what needs changing):

Link is broken. Why is it deprecated? What should I do about it?"
28942,Missing Op DenseToDenseSetOperation in contrib makefile static build,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux el6 and MacOS 10.13
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: na
- TensorFlow installed from (source or binary): source
- TensorFlow version: v1.13.1
- Python version: na
- Installed using virtualenv? pip?  na
- Bazel version (if compiling from source): 19.1
- GCC/Compiler version (if compiling from source): clang Xcode 9.4 and gcc 4.8.5
- CUDA/cuDNN version: na yet
- GPU model and memory: na yet



**Describe the problem**
With one of models derived from Materport RCNN

I get the following error during inference in C++ which doesn’t happen with dynamic linking to the bazel targets libtensorflow_cc.so and libtensorflow_framework.so

ERROR: Op type not registered 'DenseToDenseSetOperation' in binary running on creative2. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) tf.contrib.resampler should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.

Creative2 is the clients machine name

Having a quick GitHub search it seems this op is a thing

https://github.com/tensorflow/tensorflow/blob/9590c4c32dd4346ea5c35673336f5912c6072bf2/tensorflow/core/ops/set_ops.cc

So given that it is there in core I don’t know what to do to make sure it is initialised it is in the dynamic version of the same software

Sam
**Provide the exact sequence of commands / steps that you executed before running into the problem**

Build Tensorflow makefile contrib to build libtensorflow_core.a nsync.a and libprotobuf.a

Link load a model with the above mentioned Op

This doesn’t happen with libtensorflow_framework.so and libtensorflow_cc.so and identical inference code and model.

**Any other info / logs**
"
28941,Can't use padded_batch on dataset with distributed strategy make_dataset_iterator,"I can't use padded_batch when I'm trying to create a distributed iterator using the following code.

```
import tensorflow_datasets as tfds
import tensorflow as tf

tf.enable_v2_behavior()

strategy = tf.distribute.MirroredStrategy()

def encode(lang1, lang2):
    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(
        lang1.numpy()) + [tokenizer_pt.vocab_size+1]

    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(
        lang2.numpy()) + [tokenizer_en.vocab_size+1]

    return lang1, lang2

def tf_encode(pt, en):
    return tf.py_function(encode, [pt, en], [tf.int64, tf.int64])

with strategy.scope():
    examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)
    train_examples, test_examples = examples['train'], examples['test']

    tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus((en.numpy() for pt, en in train_examples), target_vocab_size=10000)

    tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus((pt.numpy() for pt, en in train_examples), target_vocab_size=10000)

    train_dataset = train_examples.map(tf_encode)
    train_dataset = train_dataset.shuffle(200000)
    train_dataset = train_dataset.padded_batch(64, padded_shapes=([-1], [-1]))
    train_dataset = strategy.make_dataset_iterator(train_dataset)
```

It throws this exception:

```
ValueError: Unable to get batched dataset from the input dataset. `batch` `map_and_batch` need to be the last operations on the dataset. The batch operations can be followed by a prefetch.
```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.0/CuDNN 7.3.1
- GPU model and memory: Nvidia Titan V
"
28940,"Misleading ""Not built with GPU enabled. Skip GPU library dlopen check."" message when using GPU 2.0 nightly build","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 x86
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190521
- TensorFlow version (use command below): ('v1.12.1-2420-g4fd6e533f6', '2.0.0-dev20190521')
- Python version:  2.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.0 / 7
- GPU model and memory: P100 16 GB

**Describe the current behavior**

TensorFlow compiled with GPU support prints the misleading message:
```
I tensorflow/stream_executor/platform/default/dlopen_checker.cc:62] Not built with GPU enabled. Skip GPU library dlopen check.
```

This confuses the user into believe GPU is not working (or at least not fully working), when it really is.

**Describe the expected behavior**

The message should not be printed when built with GPU support, or should be worded better.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190521
python
import tensorflow as tf
input_string = 'Hello, TensorFlow!'
hello = tf.constant(input_string)
```

**Other info / logs**
```
root@f2ce3e981b16:~# python
Python 2.7.15rc1 (default, Nov 12 2018, 14:31:15)
[GCC 7.3.0] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> input_string = 'Hello, TensorFlow!'
>>> hello = tf.constant(input_string)
2019-05-22 18:10:31.116739: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-05-22 18:10:31.936204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:06:00.0
2019-05-22 18:10:31.937373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:81:00.0
2019-05-22 18:10:31.937394: I tensorflow/stream_executor/platform/default/dlopen_checker.cc:62] Not built with GPU enabled. Skip GPU library dlopen check.
2019-05-22 18:10:31.942721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2019-05-22 18:10:31.944135: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-22 18:10:32.163526: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5611c578aac0 executing computations on platform CUDA. Devices:
2019-05-22 18:10:32.163568: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0
2019-05-22 18:10:32.163580: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla P100-PCIE-16GB, Compute Capability 6.0
2019-05-22 18:10:32.167321: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199905000 Hz
2019-05-22 18:10:32.171784: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5611c5bc4df0 executing computations on platform Host. Devices:
2019-05-22 18:10:32.171814: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-05-22 18:10:32.173360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:06:00.0
2019-05-22 18:10:32.174698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:81:00.0
2019-05-22 18:10:32.174718: I tensorflow/stream_executor/platform/default/dlopen_checker.cc:62] Not built with GPU enabled. Skip GPU library dlopen check.
2019-05-22 18:10:32.179748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2019-05-22 18:10:32.180155: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-05-22 18:10:32.183049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-22 18:10:32.183069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1
2019-05-22 18:10:32.183083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N
2019-05-22 18:10:32.183093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N
2019-05-22 18:10:32.189364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2019-05-22 18:10:32.191715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15216 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:81:00.0, compute capability: 6.0)
```
"
28939,TypeError in RNNs tutorial,"
## URL(s) with the issue:
https://www.tensorflow.org/tutorials/keras/basic_regression
#### Description of issue (what needs changing): https://www.tensorflow.org/tutorials/keras/basic_regression#build_the_model

### Clear description

The `model = build_model()` function results in a `TypeError` and gives the following trace:
```
TypeError                                 Traceback (most recent call last)
<ipython-input-19-671884cecb64> in <module>
----> 1 model = build_model()

<ipython-input-18-d3556ed39f80> in build_model()
      3     layers.Dense(64, activation=tf.nn.relu, input_shape=[64]),
      4     layers.Dense(64, activation=tf.nn.relu),
----> 5     layers.Dense(1)
      6   ])
      7 

~/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py in __init__(self, layers, name)
     91         if layers:
     92             for layer in layers:
---> 93                 self.add(layer)
     94 
     95     @property

~/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py in add(self, layer)
    130             raise TypeError('The added layer must be '
    131                             'an instance of class Layer. '
--> 132                             'Found: ' + str(layer))
    133         self.built = False
    134         if not self._layers:

TypeError: The added layer must be an instance of class Layer. Found: <tensorflow.python.keras.layers.core.Dense object at 0x7efe86908f28>


```





### Parameters defined

Are all parameters defined and formatted correctly? <br>
Yes. This method does not use any parameters apart from `train_dataset` which has been replaced with a constant in my above example.



### Raises listed and defined

This raises a TypeError.






"
28938,Is there any difference in mAP from fronzen graph to .tflite model?,"I'm running android example following this [artichle](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193) from tensorflow. On it, the author talk about the mAP while the training is running. The mAP[0.5] it's equals to 82%. Then, next in the article, the model is transformed to .tflite, but he do not talk about mAP or any difference on this value. Can any one tell me if there is any change or some documentation that can help me on that? Thanks!"
28937,C++17 features used even though C++11 standard explicitly given,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 30
- TensorFlow installed from (source or binary): source, master branch (c156831c298e27ce4d058c6ab03ec61bc6e910bf)
- TensorFlow version: 2.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: building in virtualenv
- Bazel version (if compiling from source): 0.25.2-1
- GCC/Compiler version (if compiling from source): 9.1.1-1
- CUDA/cuDNN version: 10.1.168
- GPU model and memory: (unimportant)

**Describe the problem**

Building error messages about use of C++17 features but the `-std=c++17` is not being passed to GCC (even if I do `--copt=-std=c++17` for the `bazel` command). Temporary workaround was to change that `constexpr` to `const` however I cannot be certain that actually worked since I have not successfully built yet due to other errors.

```
ERROR: /home/x/tf/tensorflow/tensorflow/tensorflow/compiler/tf2tensorrt/BUILD:330:1: C++ compilation of rule '//tensorflow/compiler/tf2tensorrt:trt_conversion' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/x/.cache/bazel/_bazel_x/5f286644534b1c99abf8273939acd3e7/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64 \
    PATH=/usr/local/cuda/bin:/home/x/.npm-packages/bin:/usr/local/cuda/bin:/home/x/.npm-packages/bin:/home/x/.local/bin:/home/x/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin \
    PWD=/proc/self/cwd \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/compiler/tf2tensorrt/_objs/trt_conversion/convert_nodes.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/compiler/tf2tensorrt/_objs/trt_conversion/convert_nodes.pic.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -DTENSORFLOW_USE_NUMA -iquote . -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/gif_archive -iquote bazel-out/host/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/bin/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/host/bin/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -iquote external/double_conversion -iquote bazel-out/host/bin/external/double_conversion -iquote external/local_config_tensorrt -iquote bazel-out/host/bin/external/local_config_tensorrt -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/host/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header -isystem third_party/eigen3/mkl_include -isystem bazel-out/host/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem external/gif_archive/lib -isystem bazel-out/host/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/host/bin/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include -isystem external/double_conversion -isystem bazel-out/host/bin/external/double_conversion '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' '-DGOOGLE_CUDA=1' '-DGOOGLE_TENSORRT=1' '-DINTEL_MKL=1' -DEIGEN_USE_VML -DENABLE_MKL -fopenmp -msse3 -pthread '-DGOOGLE_CUDA=1' '-DINTEL_MKL=1' -DENABLE_MKL '-DGOOGLE_TENSORRT=1' -c tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc -o bazel-out/host/bin/tensorflow/compiler/tf2tensorrt/_objs/trt_conversion/convert_nodes.pic.o)
Execution platform: @bazel_tools//platforms:host_platform
tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc: In function 'tensorflow::Status tensorflow::tensorrt::convert::ConvertMatMulHelper(tensorflow::tensorrt::convert::OpConverterParams*, tensorflow::tensorrt::convert::TRT_TensorOrWeights, tensorflow::tensorrt::convert::TRT_TensorOrWeights, bool, bool, std::string)':
tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:4198:18: error: the type 'const tensorflow::tensorrt::convert::ConvertMatMulHelper(tensorflow::tensorrt::convert::OpConverterParams*, tensorflow::tensorrt::convert::TRT_TensorOrWeights, tensorflow::tensorrt::convert::TRT_TensorOrWeights, bool, bool, std::string)::<lambda(nvinfer1::ITensor*, bool)>' of 'constexpr' variable 'get_matrix_op' is not literal
 4198 |   constexpr auto get_matrix_op =
      |                  ^~~~~~~~~~~~~
tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:4199:8: note: 'tensorflow::tensorrt::convert::ConvertMatMulHelper(tensorflow::tensorrt::convert::OpConverterParams*, tensorflow::tensorrt::convert::TRT_TensorOrWeights, tensorflow::tensorrt::convert::TRT_TensorOrWeights, bool, bool, std::string)::<lambda(nvinfer1::ITensor*, bool)>' is not literal because:
 4199 |       [](nvinfer1::ITensor* in, bool transpose) -> nvinfer1::MatrixOperation {
      |        ^
cc1plus: note:   'tensorflow::tensorrt::convert::ConvertMatMulHelper(tensorflow::tensorrt::convert::OpConverterParams*, tensorflow::tensorrt::convert::TRT_TensorOrWeights, tensorflow::tensorrt::convert::TRT_TensorOrWeights, bool, bool, std::string)::<lambda(nvinfer1::ITensor*, bool)>' is a closure type, which is only literal in C++17 and later
tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc: At global scope:
tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:637:41: warning: 'std::vector<std::pair<int, int> > tensorflow::tensorrt::convert::CreateSamePadding(const nvinfer1::DimsHW&, const nvinfer1::DimsHW&, const std::vector<long int>&)' defined but not used [-Wunused-function]
  637 | static std::vector<std::pair<int, int>> CreateSamePadding(
      |                                         ^~~~~~~~~~~~~~~~~
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

The command line explicitly contains `'-std=c++11'` but GCC says that the feature used cannot be used without `'-std=c++17'`.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
sudo dnf install @development-tools @""C Development Tools and Libraries"" dnf-plugins-core cmake xz wget llvm clang python3-devel openssl-devel zlib-devel bzip2-devel readline-devel sqlite-devel ncurses-devel tk-devel libnccl-devel libcudnn7-devel libnvinfer-devel
virtualenv tensorflow
cd tensorflow
. bin/activate
pip install --upgrade --force-reinstall pip setuptools
pip install wheel numpy scipy keras
git clone https://github.com/tensorflow/tensorflow.git --single-branch --branch master
cd tensorflow
./configure # all defaults except Y for CUDA and TensorRT support and 7.0 for compute support
export TMP=/tmp
bazel build -c opt --config=opt --config=v2 --config=mkl --config=numa --verbose_failures \
    //tensorflow/tools/pip_package:build_pip_package
```

Some other arguments tried with `bazel` are `--copt=-std=c++17` (didn't fix problem \#1 and caused other issues) and `--verbose_failures` to get longer messages."
28936,CUDA 10.1 Support (continued),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 30
- TensorFlow installed from (source or binary): source, master branch (c156831c298e27ce4d058c6ab03ec61bc6e910bf)
- TensorFlow version: 2.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: building in virtualenv
- Bazel version (if compiling from source): 0.25.2-1
- GCC/Compiler version (if compiling from source): 9.1.1-1
- CUDA/cuDNN version: 10.1.168
- GPU model and memory: (unimportant)

**Describe the problem**

I can see that lots of progress has been made on CUDA 10.1 support recently however there still seem to be a few problems:

1. libcublas.so.10 is not in the expected location. This is known and some recently fixes have corrected the issue during the configuration phase however during the actual build process there is still an error:

```
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; cp -f ""/usr/local/cuda/lib64/stubs/libcuda.so"" ""bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcuda.so"" && cp -f ""/usr/local/cuda/lib64/libcudart.so.10.1"" ""bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcudart.so.10.1"" && cp -f ""/usr/local/cuda/lib64/libcudart_static.a"" ""bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcudart_static.a"" && cp -f ""/usr/local/cuda/lib64/libcublas.so.10"" ""bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcublas.so.10"" && cp -f ""/usr/local/cuda/lib64/libcusolver.so.10"" ""bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcusolver.so.10"" && cp -f ""/usr/local/cuda/lib64/libcurand.so.10"" ""bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcurand.so.10"" && cp -f ""/usr/local/cuda/lib64/libcufft.so.10"" ""bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcufft.so.10"" && cp -f ""/usr/lib64/libcudnn.so.7"" ""bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcudnn.so.7"" && cp -f ""/usr/local/cuda/extras/CUPTI/lib64/libcupti.so.10.1"" ""bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcupti.so.10.1"" && cp -f ""/usr/local/cuda/lib64/libcusparse.so.10"" ""bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcusparse.so.10"" ')
Execution platform: @bazel_tools//platforms:host_platform
cp: cannot stat '/usr/local/cuda/lib64/libcublas.so.10': No such file or directory
```

Workaround is as per #26150:

```
sudo ln -s /usr/lib64/libcublas.so.10 /usr/local/cuda-10.1/targets/x86_64-linux/lib/libcublas.so.10
```

2. The header files are also not being dealt with as is indicated in commit 922386b9fcc23596877da3500787a045a861cb52. They are supposed to be copied to ""cublas/include/cublas*.h"" (and then referenced as ""third_party/gpus/cuda/include/cublas*.h""). However, when the following error occurs the copied files are nowhere to be found anywhere in the build tree. My guess is that the copy tasks are not marked as prereqs of some of the tasks that use the copied files. Example error messages:

```
ERROR: /home/x/tf/tensorflow/tensorflow/tensorflow/core/kernels/BUILD:3135:1: C++ compilation of rule '//tensorflow/core/kernels:cuda_solvers' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/x/.cache/bazel/_bazel_x/5f286644534b1c99abf8273939acd3e7/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64 \
    PATH=/usr/local/cuda/bin:/home/x/.npm-packages/bin:/usr/local/cuda/bin:/home/x/.npm-packages/bin:/home/x/.local/bin:/home/x/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin \
    PWD=/proc/self/cwd \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/core/kernels/_objs/cuda_solvers/cuda_solvers.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/core/kernels/_objs/cuda_solvers/cuda_solvers.pic.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -DTENSORFLOW_USE_NUMA -iquote . -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/gif_archive -iquote bazel-out/host/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/bin/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/host/bin/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -isystem third_party/eigen3/mkl_include -isystem bazel-out/host/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem external/gif_archive/lib -isystem bazel-out/host/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/host/bin/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' '-DGOOGLE_CUDA=1' '-DGOOGLE_TENSORRT=1' '-DINTEL_MKL=1' -DEIGEN_USE_VML -DENABLE_MKL -fopenmp -msse3 -pthread '-DGOOGLE_CUDA=1' '-DINTEL_MKL=1' -DENABLE_MKL '-DGOOGLE_TENSORRT=1' -c tensorflow/core/kernels/cuda_solvers.cc -o bazel-out/host/bin/tensorflow/core/kernels/_objs/cuda_solvers/cuda_solvers.pic.o)
Execution platform: @bazel_tools//platforms:host_platform
In file included from tensorflow/core/kernels/cuda_solvers.cc:17:
./tensorflow/core/kernels/cuda_solvers.h:29:10: fatal error: third_party/gpus/cuda/include/cublas_v2.h: No such file or directory
   29 | #include ""third_party/gpus/cuda/include/cublas_v2.h""
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
```

```
ERROR: /home/x/tf/tensorflow/tensorflow/tensorflow/stream_executor/cuda/BUILD:211:1: C++ compilation of rule '//tensorflow/stream_executor/cuda:cublas_stub' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/x/.cache/bazel/_bazel_x/5f286644534b1c99abf8273939acd3e7/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64 \
    PATH=/usr/local/cuda/bin:/home/x/.npm-packages/bin:/usr/local/cuda/bin:/home/x/.npm-packages/bin:/home/x/.local/bin:/home/x/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin \
    PWD=/proc/self/cwd \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_stub/cublas_stub.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_stub/cublas_stub.pic.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -DTENSORFLOW_USE_NUMA -iquote . -iquote bazel-out/host/bin -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/host/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/bin/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/host/bin/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem third_party/eigen3/mkl_include -isystem bazel-out/host/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/host/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/host/bin/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 -c tensorflow/stream_executor/cuda/cublas_stub.cc -o bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_stub/cublas_stub.pic.o)
Execution platform: @bazel_tools//platforms:host_platform
tensorflow/stream_executor/cuda/cublas_stub.cc:15:10: fatal error: third_party/gpus/cuda/include/cublas.h: No such file or directory
   15 | #include ""third_party/gpus/cuda/include/cublas.h""
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
```
```
ERROR: /home/x/tf/tensorflow/tensorflow/tensorflow/stream_executor/cuda/BUILD:231:1: C++ compilation of rule '//tensorflow/stream_executor/cuda:cublas_plugin' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/x/.cache/bazel/_bazel_x/5f286644534b1c99abf8273939acd3e7/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64 \
    PATH=/usr/local/cuda/bin:/home/x/.npm-packages/bin:/usr/local/cuda/bin:/home/x/.npm-packages/bin:/home/x/.local/bin:/home/x/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin \
    PWD=/proc/self/cwd \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_plugin/cuda_blas.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_plugin/cuda_blas.pic.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -DTENSORFLOW_USE_NUMA -iquote . -iquote bazel-out/host/bin -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/host/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/bin/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/host/bin/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem third_party/eigen3/mkl_include -isystem bazel-out/host/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/host/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/host/bin/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 -c tensorflow/stream_executor/cuda/cuda_blas.cc -o bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_plugin/cuda_blas.pic.o)
Execution platform: @bazel_tools//platforms:host_platform
tensorflow/stream_executor/cuda/cuda_blas.cc:16:10: fatal error: third_party/gpus/cuda/include/cublas_v2.h: No such file or directory
   16 | #include ""third_party/gpus/cuda/include/cublas_v2.h""
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
``` 


**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
sudo dnf install @development-tools @""C Development Tools and Libraries"" dnf-plugins-core cmake xz wget llvm clang python3-devel openssl-devel zlib-devel bzip2-devel readline-devel sqlite-devel ncurses-devel tk-devel libnccl-devel libcudnn7-devel libnvinfer-devel
virtualenv tensorflow
cd tensorflow
. bin/activate
pip install --upgrade --force-reinstall pip setuptools
pip install wheel numpy scipy keras
git clone https://github.com/tensorflow/tensorflow.git --single-branch --branch master
cd tensorflow
./configure # all defaults except Y for CUDA and TensorRT support and 7.0 for compute support
export TMP=/tmp
bazel build -c opt --config=opt --config=v2 --config=mkl --config=numa --verbose_failures \
    //tensorflow/tools/pip_package:build_pip_package
```"
28934,Request for ScatterNd on Tensorflow Lite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 16.04
- TensorFlow installed from (source or binary):
Binary
- TensorFlow version (or github SHA if from source):
1.13.1 and 2.0-preview


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ........

. Here is a list of operators for which you will need custom implementations: ScatterNd.
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28933,Optimize transpose ops,"**System information**
- TensorFlow version (you are using): 1.13.1
- Are you willing to contribute it (Yes/No): No (I lack the expertise to mess with the graph optimizer).

**Describe the feature and the current behavior/state.**
TF is not very smart about transpositions. For example, the graph optimizer could do the following:
1. Merge adjacent transpositions (each transpose op costs time and creates a new tensor).
2. Pull transpositions through reshapes where possible (transposing with fewer dimensions should be faster, and is currently often *much* see #32).
3. Merge transpose ops with adjacent matmul ops where possible (turn a matrix transpose into a transpose argument for the matmul op).

Currently, none of these appear to happen.
I can provide some test cases that illustrate these improvements if desired.

**Will this change the current api? How?**
No API changes.

**Who will benefit with this feature?**
People who build graphs with lots of transpose operations.
"
28932, java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find custom op for name 'TFLite_Detection_PostProcess' with version 1  Registration failed.,"
windows
android 8.0.0
huawei mate9  

    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'

CameraActivity: Exception!
    java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find custom op for name 'TFLite_Detection_PostProcess' with version 1
    Registration failed.
    
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:125)
        at org.tensorflow.lite.examples.detection.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:102)
        at org.tensorflow.lite.examples.detection.CameraActivity.onPreviewFrame(CameraActivity.java:199)
        at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1137)
        at android.os.Handler.dispatchMessage(Handler.java:108)
        at android.os.Looper.loop(Looper.java:166)
        at android.app.ActivityThread.main(ActivityThread.java:7406)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:245)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:926)
     Caused by: java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find custom op for name 'TFLite_Detection_PostProcess' with version 1
    Registration failed.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:73)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:52)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:114)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:123)
        	... 9 more


java.lang.NullPointerException: Attempt to invoke virtual method 'void org.tensorflow.lite.NativeInterpreterWrapper.close()' on a null object reference
        at org.tensorflow.lite.Interpreter.close(Interpreter.java:252)
        at org.tensorflow.lite.Interpreter.finalize(Interpreter.java:259)
        at java.lang.Daemons$FinalizerDaemon.doFinalize(Daemons.java:254)
        at java.lang.Daemons$FinalizerDaemon.runInternal(Daemons.java:241)
        at java.lang.Daemons$Daemon.run(Daemons.java:104)
        at java.lang.Thread.run(Thread.java:784)"
28931,RuntimeError when using distribution strategy (Distributed training in TensorFlow: Keras Tutorial throws error),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Cent OS 7
- TensorFlow installed from (source or binary): conda
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.3
- CUDA/cuDNN version: 10.0 / 7.3.1 (conda installed cudnn)
- GPU model and memory: 8x GeForce RTX 2080 / 7951MiB each

**Describe the current behavior**
Model fails to train, raising a `RuntimeError: Replica-local variables may only be assigned in a replica context.` I was able to reproduce this issue just by using the official tutorial, so that's the code given below rather than mine.

**Describe the expected behavior**
This code should correctly utilize my GPUs.

**Code to reproduce the issue**
This code is taken straight from [the tutorial](https://www.tensorflow.org/tutorials/distribute/keras)
```python
#!/usr/bin/env python
import tensorflow as tf
import tensorflow_datasets as tfds

import os
datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)

mnist_train, mnist_test = datasets['train'], datasets['test']
strategy = tf.distribute.MirroredStrategy()

num_train_examples = info.splits['train'].num_examples
num_test_examples = info.splits['test'].num_examples

BUFFER_SIZE = 10000
BATCH_SIZE_PER_REPLICA = 64
BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync

def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255
    return image, label

train_dataset = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)

with strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=tf.keras.optimizers.Adam(),
                  metrics=['accuracy'])
# Define the checkpoint directory to store the checkpoints
checkpoint_dir = './training_checkpoints'
# Name of the checkpoint files
checkpoint_prefix = os.path.join(checkpoint_dir, ""ckpt_{epoch}"")

callbacks = [
    tf.keras.callbacks.TensorBoard(log_dir='./logs'),
    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,
                                    save_weights_only=True),
    tf.keras.callbacks.LearningRateScheduler(decay),
]

model.fit(train_dataset, epochs=10, callbacks=callbacks)
```

**Other info / logs**
Full output including traceback:
```sh
$ CUDA_VISIBLE_DEVICES=2,3,4,5,6,7 python -m mnist_tf_check

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING: Logging before flag parsing goes to stderr.
W0522 08:53:17.781122 140396075140928 deprecation.py:323] From /home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-05-22 08:53:17.916369: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-05-22 08:53:17.931970: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200015000 Hz
2019-05-22 08:53:17.934971: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55cb744b5090 executing computations on platform Host. Devices:
2019-05-22 08:53:17.935018: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-05-22 08:53:20.146420: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55cb74533ed0 executing computations on platform CUDA. Devices:
2019-05-22 08:53:20.146509: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce RTX 2080, Compute Capability 7.5
2019-05-22 08:53:20.146535: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): GeForce RTX 2080, Compute Capability 7.5
2019-05-22 08:53:20.146556: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): GeForce RTX 2080, Compute Capability 7.5
2019-05-22 08:53:20.146591: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): GeForce RTX 2080, Compute Capability 7.5
2019-05-22 08:53:20.146613: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (4): GeForce RTX 2080, Compute Capability 7.5
2019-05-22 08:53:20.146634: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (5): GeForce RTX 2080, Compute Capability 7.5
2019-05-22 08:53:20.148829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:08:00.0
totalMemory: 7.77GiB freeMemory: 7.62GiB
2019-05-22 08:53:20.149286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 1 with properties:
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:09:00.0
totalMemory: 7.77GiB freeMemory: 7.62GiB
2019-05-22 08:53:20.149717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 2 with properties:
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:84:00.0
totalMemory: 7.77GiB freeMemory: 7.62GiB
2019-05-22 08:53:20.150156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 3 with properties:
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:85:00.0
totalMemory: 7.77GiB freeMemory: 7.62GiB
2019-05-22 08:53:20.150586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 4 with properties:
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:88:00.0
totalMemory: 7.77GiB freeMemory: 7.62GiB
2019-05-22 08:53:20.151019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 5 with properties:
name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:89:00.0
totalMemory: 7.77GiB freeMemory: 7.62GiB
2019-05-22 08:53:20.152662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0, 1, 2, 3, 4, 5
2019-05-22 08:53:20.169207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-22 08:53:20.169256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 1 2 3 4 5
2019-05-22 08:53:20.169281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N N N N N N
2019-05-22 08:53:20.169326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N N N N N N
2019-05-22 08:53:20.169345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N N N N N N
2019-05-22 08:53:20.169379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N N N N N N
2019-05-22 08:53:20.169398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 4:   N N N N N N
2019-05-22 08:53:20.169416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 5:   N N N N N N
2019-05-22 08:53:20.171379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7416 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:08:00.0, compute capability: 7.5)
2019-05-22 08:53:20.171960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7416 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080, pci bus id: 0000:09:00.0, compute capability: 7.5)
2019-05-22 08:53:20.172517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 7416 MB memory) -> physical GPU (device: 2, name: GeForce RTX 2080, pci bus id: 0000:84:00.0, compute capability: 7.5)
2019-05-22 08:53:20.173011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 7416 MB memory) -> physical GPU (device: 3, name: GeForce RTX 2080, pci bus id: 0000:85:00.0, compute capability: 7.5)
2019-05-22 08:53:20.173526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 7416 MB memory) -> physical GPU (device: 4, name: GeForce RTX 2080, pci bus id: 0000:88:00.0, compute capability: 7.5)
2019-05-22 08:53:20.174043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 7416 MB memory) -> physical GPU (device: 5, name: GeForce RTX 2080, pci bus id: 0000:89:00.0, compute capability: 7.5)
2019-05-22 08:53:20.184131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0, 1, 2, 3, 4, 5
2019-05-22 08:53:20.185576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-22 08:53:20.185617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 1 2 3 4 5
2019-05-22 08:53:20.185638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N N N N N N
2019-05-22 08:53:20.185656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N N N N N N
2019-05-22 08:53:20.185673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N N N N N N
2019-05-22 08:53:20.185692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N N N N N N
2019-05-22 08:53:20.185709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 4:   N N N N N N
2019-05-22 08:53:20.185749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 5:   N N N N N N
2019-05-22 08:53:20.187543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:0 with 7416 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:08:00.0, compute capability: 7.5)
2019-05-22 08:53:20.188006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:1 with 7416 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080, pci bus id: 0000:09:00.0, compute capability: 7.5)
2019-05-22 08:53:20.188405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:2 with 7416 MB memory) -> physical GPU (device: 2, name: GeForce RTX 2080, pci bus id: 0000:84:00.0, compute capability: 7.5)
2019-05-22 08:53:20.188747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:3 with 7416 MB memory) -> physical GPU (device: 3, name: GeForce RTX 2080, pci bus id: 0000:85:00.0, compute capability: 7.5)
2019-05-22 08:53:20.189115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:4 with 7416 MB memory) -> physical GPU (device: 4, name: GeForce RTX 2080, pci bus id: 0000:88:00.0, compute capability: 7.5)
2019-05-22 08:53:20.189446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:5 with 7416 MB memory) -> physical GPU (device: 5, name: GeForce RTX 2080, pci bus id: 0000:89:00.0, compute capability: 7.5)
Traceback (most recent call last):
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/stilljm/tensorflow_is_terrible/mnist_tf_check.py"", line 38, in <module>
    metrics=['accuracy'])
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/base.py"", line 442, in _method_wrapper
    method(self, *args, **kwargs)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 499, in compile
    sample_weights=self.sample_weights)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1844, in _handle_metrics
    return_stateful_result=return_stateful_result))
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1800, in _handle_per_output_metrics
    stateful_metric_result = _call_stateful_fn(stateful_fn)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1773, in _call_stateful_fn
    fn, y_true, y_pred, weights=weights, mask=mask)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py"", line 852, in call_metric_function
    return metric_fn(y_true, y_pred, sample_weight=weights)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 438, in __call__
    update_op = self.update_state(*args, **kwargs)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 98, in decorated
    update_op = update_state_fn(*args, **kwargs)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 651, in update_state
    matches, sample_weight=sample_weight)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py"", line 604, in update_state
    update_total_op = state_ops.assign_add(self.total, values)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/ops/state_ops.py"", line 191, in assign_add
    return ref.assign_add(value)
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/distribute/values.py"", line 911, in assign_add
    _assert_replica_context()
  File ""/home/stilljm/.conda/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/distribute/values.py"", line 894, in _assert_replica_context
    ""Replica-local variables may only be assigned in a replica context."")
RuntimeError: Replica-local variables may only be assigned in a replica context.
```
"
28929,TF2.0 Problem making prediction from a checkpoint if model has an embedding column,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): NA
- TensorFlow version (use command below):  v1.12.0-9492-g2c319fb415 2.0.0-alpha0
- Python version: 3.6.7 (default, Oct 22 2018, 11:32:17) \n[GCC 8.2.0]
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I have a keras model that has an embedding column as a  feature.

I can train and save the model's weights just fine. Making predictions immediately after training works too.

The problem is when I recreate the model and reload the weights. Making a prediction from that model gives a shape error.

**Describe the expected behavior**
Same output as making predictions immediately after training.



**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Please refer to this [gist](https://gist.github.com/hsm207/305d068c982edf9e1df7db77446df50c).

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28928,[TF2.0] steps_per_epoch parameter not working when input data passed as dictionary,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (use command below): v1.12.0-9492-g2c319fb415 2.0.0-alpha0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
- GPU model and memory:

**Describe the current behavior**
If using a dictionary to pass input to a `keras.Model` with named inputs, the `steps_per_epoch` argument appears to have no effect. Instead as many steps are performed as needed for a full epoch.

**Describe the expected behavior**
I would expect only as many iterations as specified by `steps_per_epoch` in each iteration. While it's possible I have misunderstood something, this is the behaviour in TensorFlow 1 when I run analogous code.

**Code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf

x = np.random.random((1000, 2))
y = 2 * x[:, 0] + 3 * x[:, 1] + np.random.normal(size=(1000,))

input_ = tf.keras.Input((2,), name=""input"")
output = tf.keras.layers.Dense(1)(input_)
model = tf.keras.Model(inputs=[input_], outputs=[output])

model.compile(tf.optimizers.Adam(), loss=tf.losses.mse)
```

with this setup, I observe

```python
model.fit(
    x, y, steps_per_epoch=2, batch_size=10,
)
```
```
2/2 [==============================] - 0s 38ms/step - loss: 1.5998
```

but on the other hand, if I pass the input as a dictionary I observe

```python
model.fit(
    {""input"": x}, y, steps_per_epoch=2, batch_size=10,
)
```
```
1000/1000 [==============================] - 5s 5ms/sample - loss: 1.5324
```

Strangely, if I then run the first `.fit` command again, it also performs a full pass over the data, rather than doing the specified number of steps as originally.

In TensorFlow 1, with the same code as above, but a TensorFlow 1 friendly model compilation step

```python
model.compile(
    tf.train.AdamOptimizer(),
    loss=tf.losses.mean_squared_error,
)
```

I do not see the same issue, the number of steps is as specified, whether data is passed in a dictionary or not.


**Other info / logs**
This could be related to #28710? Though the author there was using TensorFlow 1 and reported that data input as NumPy arrays did not cause problems, so this seemed different enough for its own issue. Happy for them to be consolidated if they are too similar.
"
28926,Build tensorflow lite for aarch64: Error in script download_dependencies.sh and build_aarch64_lib.sh,"**System information**
- OS Platform and Distribution: Google coral board aarch64
- TensorFlow lite installed from source
- TensorFlow version: master branch

If I run the script ./tensorflow/lite/tools/make/download_dependencies.sh  from the root directory of the repo I am getting following error:

**downloading http://mirror.tensorflow.org/bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz**

**gzip: stdin: not in gzip format**
**tar: Child returned status 1**
**tar: Error is not recoverable: exiting now**

2 days ago I had not the problem to run the script download_dependencies.sh.
There was some clean up of dependencies for tensorflow lite at least if I check the commit messages of the master branch.
Could it have something to do with that?

Thanks in advance!
"
28925,ValueError: Attempt to convert a value (<6x6 sparse matrix of type '<class 'numpy.float64'>' 	with 1 stored elements in COOrdinate format>) with an unsupported type (<class 'scipy.sparse.coo.coo_matrix'>) to a Tensor.,"
I am building a recommendation model using the WALS algorithm and implementing it in Tersorflow. I have processed the data and when I try to initialize the object I get the error below. 

ValueError: Attempt to convert a value (<6x6 sparse matrix of type '<class 'numpy.float64'>'
	with 1 stored elements in COOrdinate format>) with an unsupported type (<class 'scipy.sparse.coo.coo_matrix'>) to a Tensor.

`input_tensor = tf.SparseTensor(indices=list(zip(tr_sparse.row, tr_sparse.col)),
                                values=(tr_sparse).astype(np.float64),
                                dense_shape=tr_sparse.shape)`"
28924,tensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Custom code
- Ubuntu 18

- TensorFlow installed from source:
- TensorFlow version :2.0
- Python version: 3.6
- CUDA/cuDNN version:10.0/
- GPU model and memory: 1080Ti/11Go

Contrary to the docs, tf.print do not handle printing tensors in a session run (for example when building a keras model with the model API)
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/print


**Describe the expected behavior**
I expect the example shown in the docs to run smoothly



**Code to reproduce the issue**
```pytho
import os
import tensorflow as tf
from tensorflow.keras.layers import BatchNormalization
import numpy as np
input = np.random.uniform(size=(6, 40, 40, 1)).astype(np.float32)

ds = tf.data.Dataset.from_tensor_slices(input).batch(2)

iterator = iter(ds)
inp = tf.keras.Input((None, None, 1))
print_op = tf.print(inp)
with tf.control_dependencies([print_op]):
    out = tf.keras.layers.Conv2D(5, 3)(inp)
model = tf.keras.Model(inputs=inp, outputs=out)
model(next(iterator))
```

Which raises:
```python
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_string_ops.py"", line 807, in string_format
    summarize)
tensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""log_test.py"", line 13, in <module>
    print_op = tf.print(inp)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/logging_ops.py"", line 339, in print_v2
    name=format_name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/string_ops.py"", line 192, in string_format
    name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_string_ops.py"", line 813, in string_format
    summarize=summarize, name=name, ctx=_ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_string_ops.py"", line 867, in string_format_eager_fallback
    _attr_T, inputs = _execute.convert_to_mixed_eager_tensors(inputs, _ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 210, in convert_to_mixed_eager_tensors
    types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 210, in <listcomp>
    types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access
AttributeError: 'Tensor' object has no attribute '_datatype_enum'
```

"
28923,TF 2.0 save/restore DenseFeatures,"** Code **
Follwing this guide i created a model to classify structured data https://www.tensorflow.org/alpha/tutorials/keras/feature_columns :
```
feature_columns = []
headers = dataframe.columns.tolist()

# feature cols
for header in headers:
    temp = feature_column.numeric_column(header)
    feature_columns.append(feature_column.bucketized_column(temp, boundaries=[-89, -70, -65, -60, -55, -50, -40, -30, -20]))
    #feature_columns.append(temp) #old code used without buckets. only numeric columns


feature_layer = tf.keras.layers.DenseFeatures(feature_columns)

model = tf.keras.Sequential([
  feature_layer,
  layers.Dense(128, activation='relu'),
  layers.Dense(128, activation='relu'),
  layers.Dense(128, activation='relu'),
  layers.Dense(3, activation='sigmoid') #cambiare con il numero di zone
])
```


**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10
- TensorFlow version (use command below): 2.0.0 alpha
- Python version: 3.6

**Describe the behavior**

Now when i try to save with the usual 
`model.save('path_to_my_model.h5')`
i cannot restore the model since i get an exception:

> Unknown layer: DenseFeatures

looking at some other [https://github.com/tensorflow/tensorflow/issues/26835](url) posts  I tried with 
`tf.keras.experimental.export_saved_model(model, 'experimental.h5')`
but here I get another exception:
> __init__() missing 1 required positional argument: 'feature_columns'

Tried to restore using 
```
for header in headers:
    temp = feature_column.numeric_column(header)
    feature_columns.append(feature_column.bucketized_column(temp, boundaries=[-89, -70, -65, -60, -55, -50, -40, -30, -20]))

feature_layer = tf.keras.layers.DenseFeatures(feature_columns)

new_model = tf.keras.models.load_model('guesser.h5',custom_objects={'DenseFeatures':feature_layer})

new_model.summary()
```
but it always give me the feature_columns error
"
28922,newest dockerfile did not include nccl,"
"
28921,"AWS S3 implementation can't handle weird path containing an ""="" sign","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6

**Describe the current behaviour**
the AWS S3 implementation can't handle weird path

**Describe the expected behavior**
the AWS S3 implementation should be able to handle weird path

**Code to reproduce the issue**
```bash
export AWS_ACCESS_KEY_ID=XXX
export AWS_SECRET_ACCESS_KEY=XXX
export AWS_REGION=eu-west-1
export S3_ENDPOINT=XXX
export S3_USE_HTTPS=0
export S3_VERIFY_SSL=0

export S3_BUCKET=accesstest
export NORMAL_FILENAME=normal.txt
export WEIRD_FILENAME=weird=true.txt # Contains an ""=""


# Make bucket
if ! aws --endpoint-url http://$S3_ENDPOINT s3api head-bucket --bucket ""$S3_BUCKET"" 2>/dev/null
then
  echo ""Creating bucket $S3_BUCKET""
  aws --endpoint-url http://$S3_ENDPOINT s3 mb s3://$S3_BUCKET
fi

echo ""Creating file""
echo ""test"" > file.txt


echo ""Upload a normal file""
aws --endpoint-url http://$S3_ENDPOINT s3 cp file.txt s3://$S3_BUCKET/$NORMAL_FILENAME
echo """"

echo ""Upload a weird name file""
aws --endpoint-url http://$S3_ENDPOINT s3 cp file.txt s3://$S3_BUCKET/$WEIRD_FILENAME
echo """"

echo ""Check that files exist""
aws --endpoint-url http://$S3_ENDPOINT s3 ls --human-readable s3://$S3_BUCKET/
echo """"


echo ""Check TF access""
python bug.py

```
```python
import os
from tensorflow.python.lib.io import file_io

assert ""AWS_ACCESS_KEY_ID"" in os.environ
assert ""AWS_SECRET_ACCESS_KEY"" in os.environ
assert ""S3_ENDPOINT"" in os.environ
assert ""S3_USE_HTTPS"" in os.environ
assert ""S3_VERIFY_SSL"" in os.environ

assert ""S3_BUCKET"" in os.environ
assert ""NORMAL_FILENAME"" in os.environ
assert ""WEIRD_FILENAME"" in os.environ

print(""Checking access to normal file {} \nShould return '<tensorflow.python.pywrap_tensorflow_internal.FileStatistics; proxy of <Swig Object of type 'tensorflow::FileStatistics *' at 0x10c2171b0> >'\n"".format(os.environ[""NORMAL_FILENAME""]))
print(file_io.stat('s3://{}/{}'.format(os.environ[""S3_BUCKET""], os.environ[""NORMAL_FILENAME""])))

print(""\n"")
print(""Checking access to weird file {} \nShould return '<tensorflow.python.pywrap_tensorflow_internal.FileStatistics; proxy of <Swig Object of type 'tensorflow::FileStatistics *' at 0x10c2171b0> >'\n"".format(os.environ[""WEIRD_FILENAME""]))
print(file_io.stat('s3://{}/{}'.format(os.environ[""S3_BUCKET""], os.environ[""WEIRD_FILENAME""])))
```

**Other info / logs**
Results of the scripts:
```
Upload a normal file
upload: ./file.txt to s3://accesstest/normal.txt               

Upload a weird name file 
upload: ./file.txt to s3://accesstest/weird=true.txt          

Check that files exist
2019-05-22 10:04:32    5 Bytes normal.txt
2019-05-22 10:04:33    5 Bytes weird=true.txt

Check TF access
Checking access to normal file normal.txt 
Should return '<tensorflow.python.pywrap_tensorflow_internal.FileStatistics; proxy of <Swig Object of type 'tensorflow::FileStatistics *' at 0x10c2171b0> >'

2019-05-22 10:04:35.615026: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /Users/morgangiraud//.aws/config and using profilePrefix = 1
2019-05-22 10:04:35.615056: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /Users/morgangiraud//.aws/credentials and using profilePrefix = 0
2019-05-22 10:04:35.615074: I tensorflow/core/platform/s3/aws_logging.cc:54] Setting provider to read credentials from /Users/morgangiraud//.aws/credentials for credentials file and /Users/morgangiraud//.aws/config for the config file , for use with profile default
2019-05-22 10:04:35.615101: I tensorflow/core/platform/s3/aws_logging.cc:54] Creating HttpClient with max connections2 and scheme http
2019-05-22 10:04:35.615134: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 2
2019-05-22 10:04:35.615155: I tensorflow/core/platform/s3/aws_logging.cc:54] Creating Instance with default EC2MetadataClient and refresh rate 900000
2019-05-22 10:04:35.615178: I tensorflow/core/platform/s3/aws_logging.cc:54] Found secret key
2019-05-22 10:04:35.615462: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 25
2019-05-22 10:04:35.615566: I tensorflow/core/platform/s3/aws_logging.cc:54] Found secret key
2019-05-22 10:04:35.615716: I tensorflow/core/platform/s3/aws_logging.cc:54] Pool grown by 2
2019-05-22 10:04:35.615726: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.
2019-05-22 10:04:35.758012: I tensorflow/core/platform/s3/aws_logging.cc:54] Found secret key
2019-05-22 10:04:35.758177: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.
<tensorflow.python.pywrap_tensorflow_internal.FileStatistics; proxy of <Swig Object of type 'tensorflow::FileStatistics *' at 0x122576990> >


Checking access to weird file weird=true.txt 
Should return '<tensorflow.python.pywrap_tensorflow_internal.FileStatistics; proxy of <Swig Object of type 'tensorflow::FileStatistics *' at 0x10c2171b0> >'

2019-05-22 10:04:35.827145: I tensorflow/core/platform/s3/aws_logging.cc:54] Found secret key
2019-05-22 10:04:35.827307: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.
2019-05-22 10:04:35.891635: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 403
2019-05-22 10:04:35.891774: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.
2019-05-22 10:04:35.892084: I tensorflow/core/platform/s3/aws_logging.cc:54] Found secret key
2019-05-22 10:04:35.892314: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.
Traceback (most recent call last):
  File ""bug.py"", line 19, in <module>
    print(file_io.stat('s3://{}/{}'.format(os.environ[""S3_BUCKET""], os.environ[""WEIRD_FILENAME""])))
  File ""/Users/morgangiraud/miniconda3/envs/clever-tensorboard/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 735, in stat
    return stat_v2(filename)
  File ""/Users/morgangiraud/miniconda3/envs/clever-tensorboard/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 754, in stat_v2
    return file_statistics
  File ""/Users/morgangiraud/miniconda3/envs/clever-tensorboard/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Object s3://accesstest/weird=true.txt does not exist
```
"
28920,Limit of Classes (label_map.txt or label_map.pbtxt),Is there any limit in label map classes used in the training config file?
28919,resize_image_with_pad output dimensions must be positive,"**System information**
- Custom code
- OS Platform and Distribution Windows 10:
- TensorFlow installed using pip
- TensorFlow versions: tested 1.12, 1.13:
- Python version: 3.6
- CUDA/cuDNN version: 9
- GPU model and memory:  GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:02:00.0
totalMemory: 8.00GiB freeMemory: 6.63GiB

**Describe the current behavior**
I have a custom estimator which i trained and i use predictor.from_saved_model(model_dir) to load an exported model. At the preprocessing stage i resize the image with tf.image.resize_image_with_pad with the bilinear method to keep the aspectratio. This works well for a seemingly arbitrary amount of images but sometimes the program crashes with this error:

InvalidArgumentError (see above for traceback): output dimensions must be positive

I read the file with PIL and convert it to a numpy array. Afterwards i check
1. If the image has 3 dimensions
2. Has at least 5 rows and cols 
3. Has 3 channels
4. The image is not all zeros
5. The image values lie between 0 and 255
So i guess it should be a valid input array.

I do provide correct input parameters for the resize fn, and try to resize the images to 128x128.

**Other info / logs**
Traceback (most recent call last):
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\client\session.py"", line 1334, in _do_call
    return fn(*args)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\client\session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\client\session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: output dimensions must be positive
	 [[{{node map/while/resize_image_with_pad/resize_images/ResizeBilinear}} = ResizeBilinear[T=DT_FLOAT, align_corners=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](map/while/resize_image_with_pad/control_dependency, map/while/resize_image_with_pad/resize_images/size)]]
	 [[{{node add_19/_165}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_561_add_19"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/bab/projects/vat_image_classification/run_inference.py"", line 31, in <module>
    main(sys.argv)
  File ""C:/bab/projects/vat_image_classification/run_inference.py"", line 27, in main
    inf.inference_multi(model_dir, config)
  File ""C:\bab\projects\vat_image_classification\inference\multi_predict_from_sql_roi.py"", line 163, in inference_multi
    predict_to_sql(result, predict_fn, config, engine)
  File ""C:\bab\projects\vat_image_classification\inference\multi_predict_from_sql_roi.py"", line 122, in predict_to_sql
    prediction.append(predict_fn({'images_ul': [image]})['probabilities'][0][1])
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\contrib\predictor\predictor.py"", line 77, in __call__
    return self._session.run(fetches=self.fetch_tensors, feed_dict=feed_dict)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\client\session.py"", line 929, in run
    run_metadata_ptr)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\client\session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\client\session.py"", line 1328, in _do_run
    run_metadata)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\client\session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: output dimensions must be positive
	 [[node map/while/resize_image_with_pad/resize_images/ResizeBilinear (defined at C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\contrib\predictor\saved_model_predictor.py:153)  = ResizeBilinear[T=DT_FLOAT, align_corners=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](map/while/resize_image_with_pad/control_dependency, map/while/resize_image_with_pad/resize_images/size)]]
	 [[{{node add_19/_165}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_561_add_19"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'map/while/resize_image_with_pad/resize_images/ResizeBilinear', defined at:
  File ""C:/bab/projects/vat_image_classification/run_inference.py"", line 31, in <module>
    main(sys.argv)
  File ""C:/bab/projects/vat_image_classification/run_inference.py"", line 27, in main
    inf.inference_multi(model_dir, config)
  File ""C:\bab\projects\vat_image_classification\inference\multi_predict_from_sql_roi.py"", line 136, in inference_multi
    predict_fn = predictor.from_saved_model(model_dir)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\contrib\predictor\predictor_factories.py"", line 153, in from_saved_model
    config=config)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\contrib\predictor\saved_model_predictor.py"", line 153, in __init__
    loader.load(self._session, tags.split(','), export_dir)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\saved_model\loader_impl.py"", line 197, in load
    return loader.load(sess, tags, import_scope, **saver_kwargs)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\saved_model\loader_impl.py"", line 350, in load
    **saver_kwargs)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\saved_model\loader_impl.py"", line 278, in load_graph
    meta_graph_def, import_scope=import_scope, **saver_kwargs)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\training\saver.py"", line 1696, in _import_meta_graph_with_return_elements
    **kwargs))
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\framework\meta_graph.py"", line 806, in import_scoped_meta_graph_with_return_elements
    return_elements=return_elements)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\util\deprecation.py"", line 488, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\framework\importer.py"", line 442, in import_graph_def
    _ProcessNewOps(graph)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\framework\importer.py"", line 234, in _ProcessNewOps
    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\framework\ops.py"", line 3440, in _add_new_tf_operations
    for c_op in c_api_util.new_tf_operations(self)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\framework\ops.py"", line 3440, in <listcomp>
    for c_op in c_api_util.new_tf_operations(self)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\framework\ops.py"", line 3299, in _create_op_from_tf_operation
    ret = Operation(c_op, self)
  File ""C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\python\framework\ops.py"", line 1770, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): output dimensions must be positive
	 [[node map/while/resize_image_with_pad/resize_images/ResizeBilinear (defined at C:\Users\r.beckmann\AppData\Local\conda\conda\envs\babenv\lib\site-packages\tensorflow\contrib\predictor\saved_model_predictor.py:153)  = ResizeBilinear[T=DT_FLOAT, align_corners=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](map/while/resize_image_with_pad/control_dependency, map/while/resize_image_with_pad/resize_images/size)]]
	 [[{{node add_19/_165}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_561_add_19"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

"
28917,"libtensorflowlite.so crash when load model, just crash on SessionOption destructor","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28915,No module named 'tensorflow_hub',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.13.1
- Python version: 3.6.4
- Installed using virtualenv? pip? conda?: pip3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

It's on a Google Cloud Platform machine. 

**Describe the problem**
In jupyter-notebook python3 
Got the following error
ModuleNotFoundError: No module named 'tensorflow_hub'

When executed import tensorflow_hub as hub

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Many commands that I can't remember, but basically I installed tensorflow_hub using pip3 install tensorflow-hub

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28912,Unexpected behaviour of tf.keras.Model.predict using tf.data.Dataset as input,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code: _Yes_
- OS Platform and Distribution: _MacOS X, Ubuntu 16.04_
- Mobile device: _None_
- TensorFlow installed from (source or binary): _from source_
- TensorFlow version (use command below): _v1.13.1-0-g6612da8951_
- Python version: _3.7.3 (MacOS) and 3.6.7 (Ubuntu)_
- Bazel version: _0.20.0-homebrew (MacOS) and 0.20.0 (Ubuntu)_
- GCC/Compiler version: _clang-1000.11.45.5 (MacOS) and 7.3.0 (Ubuntu)_
- CUDA/cuDNN version: _None (MacOS) and 10.0 (Ubuntu)_
- GPU model and memory: _None (MacOS) and GeForce GTX 1080 Ti (Ubuntu) 11178 MiB memory_

**Describe the current behavior**
Calling `model.predict(x, steps=N)` on a `tf.keras.Model` instance with two inputs fails with many errors:
1. If the model is not compiled, I get a RuntimeError as follows:
```
RuntimeError: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.
```
2. If I do compile the model (even though this is not necessary, since `predict` should not compute any losses), I get a ValueError (see `ds1` below):
```
ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [<tf.Tensor 'IteratorGetNext_2:0' shape=(?, 28, 28, 1) dtype=float32>]...
```
3. If I further provide a target in the dataset (see `ds2` below), the predict method works and produces an output of the correct shape.
 
**Describe the expected behavior**
Calling `model.predict(x, steps=N)` on both an uncompiled (1) and compiled (2)`tf.keras.Model` should produce a list of numpy arrays corresponding to the outputs of the model without any errors.

**Code to reproduce the issue**
This test case is modified from #23702 to include multiple model inputs. The issue described there seems to be related, but not identical to this one. In particular, the fixes introduced in `tf-nightly-1.13.0-dev20190213`, that were mentioned, do not resolve the issue for this test case.
```python
import numpy as np
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_test = x_test.reshape((10000, 28, 28, 1)).astype(np.float32)
y_test = tf.keras.utils.to_categorical(y=y_test)

x1 = tf.keras.layers.Input((28, 28, 1), dtype=tf.float32)
conv1 = tf.keras.layers.Conv2D(8, kernel_size=3, activation='relu')
flat1 = tf.keras.layers.Flatten()

x2 = tf.keras.layers.Input((28, 28, 1), dtype=tf.float32)
conv2 = tf.keras.layers.Conv2D(8, kernel_size=3, activation='relu')
flat2 = tf.keras.layers.Flatten()

concat = tf.keras.layers.Concatenate()
proj = tf.keras.layers.Dense(10, activation='softmax')

m = tf.keras.models.Model([x1, x2], proj(concat([flat1(conv1(x1)), flat2(conv2(x2))])))
m.compile('adam', 'mse')

ds = tf.data.Dataset.from_tensor_slices(x_test)
ds1 = tf.data.Dataset.zip((ds, ds))
ds2 = tf.data.Dataset.zip((ds1, tf.data.Dataset.from_tensor_slices(y_test)))
output = m.predict(x=ds1.batch(batch_size=10), steps=1000, verbose=True)  # fails with ValueError
output = m.predict(x=ds2.batch(batch_size=10), steps=1000, verbose=True)  # works
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-e5c6dc2477e5> in <module>
     23 ds = ds.batch(batch_size=10)
     24 data = ds.make_one_shot_iterator()
---> 25 output = m.predict(x=data, steps=1000, verbose=True)

~/.virtualenvs/python3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)
   1094       # batch size.
   1095       x, _, _ = self._standardize_user_data(
-> 1096           x, check_steps=True, steps_name='steps', steps=steps)
   1097
   1098     if (self.run_eagerly or (isinstance(x, iterator_ops.EagerIterator) and

~/.virtualenvs/python3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)
   2380         feed_input_shapes,
   2381         check_batch_axis=False,  # Don't enforce the batch size.
-> 2382         exception_prefix='input')
   2383
   2384     if y is not None:

~/.virtualenvs/python3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
    321                        'Expected to see ' + str(len(names)) + ' array(s), '
    322                        'but instead got the following list of ' +
--> 323                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')
    324     elif len(names) > 1:
    325       raise ValueError(

ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [<tf.Tensor 'IteratorGetNext:0' shape=(?, 28, 28, 1) dtype=float32>]...```"
28903,Receiving InvalidArgument error when feeding inputs of uneven length,"**System information**
- I have written custom, albeit straightforward code using keras.Sequential.
- Platform: Google Colab, CPU runtime, Python 3
- TensorFlow installed using _pip install -q tensorflow==2.0.0-alpha0_

**Current behavior**
InvalidArgument error occurs.

**Expected behavior**
I should be able to train the network using inputs of uneven length.

**Code to reproduce the issue**
```
!pip install tensorflow==2.0.0-alpha0 

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.optimizers import Adam
import numpy as np
import pickle

model = keras.Sequential([
    layers.Embedding(input_dim=48191, output_dim=300),
    layers.LSTM(300),
    layers.Dense(1, activation='sigmoid')
])

model.compile(
    loss='binary_crossentropy', 
    optimizer=Adam(), 
    metrics=['accuracy']
    )

dataset = pickle.load(open(""dataset.pkl"", ""rb""))
data_generator = ((np.asarray([x]), np.asarray([y])) for x, y in dataset)
model.fit_generator(data_generator, steps_per_epoch=len(dataset))
```
**Error message**
```
/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Tried to stack elements of an empty list with non-fully-defined element_shape: [?,300]
	 [[{{node unified_lstm_2/TensorArrayV2Stack/TensorListStack}}]] [Op:__inference_keras_scratch_graph_6215]
```

[The dataset is required to reproduce the issue.](https://github.com/tensorflow/tensorflow/files/3203395/dataset.zip)"
28902,INTERNAL ERROR reported while trying to apply GpuDelegate to tflite,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code: Yes, I am using my own training model based on MobileNetV2. 
- OS Platform and Distribution: Ubuntu 18.04
- Mobile device: XiaoMe 8, Android 9
- tflite installed from (source or binary): nightly AAR (org.tensorflow:tensorflow-lite:0.0.0-nightly)
- tflite-gpu installed from (source or binary): nightly AAR (org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly)
- GPU model and memory: 

**Describe the current behavior**
When I attempt to load my .tflite model on the Android (after applying the GpuDelegate), it fails saying ""INTERNAL ERROR"" (see traceback below). What does it mean for this error? And what shall I do? Thanks!

**Describe the expected behavior**
The model should be loaded correctly and then run the Inference.

**Code to reproduce the issue**
I just modify the downloaded [TensorFlow Lite Android image classification example](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android), and add one more class extended from class Classifier to load my own trained model which is based on MobileNetV2. The model loads and runs fine if with CPU, i.e. I do not attempt to apply the GPU delegate before the attempting to load it. The only difference in the code is the following lines:

`tfliteOptions = new Interpreter.Options();`
`gpuDelegate = new GpuDelegate();`
`tfliteOptions.addDelegate(gpuDelegate);`

**Other info / logs**

    --------- beginning of crash
2019-05-21 08:27:02.183 13748-13769/org.tensorflow.lite.examples.classification E/AndroidRuntime: FATAL EXCEPTION: inference
    Process: org.tensorflow.lite.examples.classification, PID: 13748
    java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Prepare: Shader compilation failed: ERROR: 0:6: 'data' : Syntax error:  syntax error
    INTERNAL ERROR: no main() function!
    ERROR: 1 compilation errors.  No code generated.
    
    Node number 73 (TfLiteGpuDelegate) failed to prepare.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:83)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:60)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:224)
        at org.tensorflow.lite.examples.classification.tflite.Classifier.<init>(Classifier.java:195)
        at org.tensorflow.lite.examples.classification.tflite.ClassifierNote.<init>(ClassifierNote.java:41)
        at org.tensorflow.lite.examples.classification.tflite.Classifier.create(Classifier.java:107)
        at org.tensorflow.lite.examples.classification.ClassifierActivity.recreateClassifier(ClassifierActivity.java:167)
        at org.tensorflow.lite.examples.classification.ClassifierActivity.lambda$onInferenceConfigurationChanged$0$ClassifierActivity(ClassifierActivity.java:146)
        at org.tensorflow.lite.examples.classification.-$$Lambda$ClassifierActivity$83lGy2TUjuj0M5n4BhMB9qlLgSY.run(Unknown Source:8)
        at android.os.Handler.handleCallback(Handler.java:873)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at android.os.Looper.loop(Looper.java:201)
        at android.os.HandlerThread.run(HandlerThread.java:65)
"
28901,[TF 2.0] Model not converging when trained with custom training loop,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.02 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary from Pypi
- TensorFlow version (use command below): 2.0 alpha0
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: GTX1070 8GB

**Describe the current behavior**

I have created a simple regression model and trained it using keras and also using a custom training loop. What I noticed is that the model only converges when using the keras fit function. If I use the custom training loop, which manually computes gradients and applies them via an optimizer, the model does not converge. The same problem occurred not only on this very simple regression task but also on a model trained on the UTK Faces data set for age regression.

**Describe the expected behavior**

I would expect both, the model trained with keras fit and the model trained with a custom training loop, to converge.

**Code to reproduce the issue**


```
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

# Define constants
N_train_samples = 600
N_validation_samples = 100
N_evaluation_samples = 100
noise_sig = 0.1
N_epochs = 100
random_seed = 100
batch_size = 16
learning_rate = 0.1

# Create target signal
x = np.linspace(0.0, 3.0, N_train_samples+N_validation_samples+N_evaluation_samples, dtype=np.float32)
y = np.sin(1 + x*x) + noise_sig*np.random.randn(N_train_samples+N_validation_samples+N_evaluation_samples).astype(np.float32)
y_true = np.sin(1 + x*x)


# Define model
class MyModel(object):
    def __init__(self):
        # Create model variables
        self.W0 = tf.Variable(tf.random.normal([1, 10]), name=""W0"")
        self.b0 = tf.Variable(tf.zeros(10), name=""b0"")
        self.W1 = tf.Variable(tf.random.normal([10, 1]), name=""W1"")
        self.b1 = tf.Variable(tf.zeros(1), name=""b1"")
        self.trainable_variables = [self.W0, self.b0, self.W1, self.b1]

    def __call__(self, inputs):
        output = tf.reshape(inputs, [-1, 1])
        output = tf.nn.sigmoid(tf.add(tf.matmul(output, self.W0), self.b0))
        return tf.add(tf.matmul(output, self.W1), self.b1)


class MyKerasModel(tf.keras.Model):
    def __init__(self):
        super(MyKerasModel, self).__init__()
        # Create model variables
        self.dense0 = tf.keras.layers.Dense(10, activation=""sigmoid"")
        self.dense1 = tf.keras.layers.Dense(1, activation=""linear"")

    def call(self, inputs):
        output = tf.reshape(inputs, [-1, 1])
        output = self.dense0(output)
        return self.dense1(output)



# Define training step
@tf.function
def train_step(model, optimizer, x, y):
    with tf.GradientTape() as tape:
        tape.watch(model.trainable_variables)
        y_pred = model(x)
        loss_val = tf.reduce_mean(tf.square(y-y_pred))
    grads = tape.gradient(loss_val, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    return loss_val


# Shuffle and partition data set
shuffle_idx = np.arange(0, N_train_samples+N_validation_samples+N_evaluation_samples)
np.random.shuffle(shuffle_idx)
x_shuffled = x[shuffle_idx]
y_shuffled = y[shuffle_idx]
x_train = x_shuffled[0:N_train_samples]
y_train = y_shuffled[0:N_train_samples]
x_validation = x_shuffled[N_train_samples:N_train_samples+N_validation_samples]
y_validation = y_shuffled[N_train_samples:N_train_samples+N_validation_samples]
x_evaluation = x_shuffled[N_train_samples+N_validation_samples:N_train_samples+N_validation_samples+N_evaluation_samples]
y_evaluation = y_shuffled[N_train_samples+N_validation_samples:N_train_samples+N_validation_samples+N_evaluation_samples]

# Create data sets
train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(N_train_samples).batch(batch_size).repeat()
validation_ds = tf.data.Dataset.from_tensor_slices((x_validation, y_validation)).batch(N_validation_samples)
evaluation_ds = tf.data.Dataset.from_tensor_slices((x_evaluation, y_evaluation)).batch(N_evaluation_samples)

# Create model and optimizer
mdl = MyModel()
opt = tf.optimizers.Adam(learning_rate)

keras_mdl = MyKerasModel()
keras_mdl.compile(optimizer=tf.optimizers.Adam(learning_rate), loss=""mse"", metrics=[""mae""])

# Train model
epoch = 0
train_iters = 0
train_loss = 0.0
for x_feed, y_feed in train_ds:
    train_loss += train_step(mdl, opt, x_feed, y_feed)
    train_iters += 1
    if (train_iters >= int(N_train_samples/batch_size)):
        for x_feed, y_feed in validation_ds:
            y_pred = mdl(x_feed)
            validation_loss = tf.reduce_mean(tf.square(y-y_pred))
        print(""Epoch: {} Train loss: {:.5} Validation loss: {:.5}"".format(epoch, train_loss/train_iters, validation_loss))
        train_iters = 0
        train_loss = 0.0
        epoch += 1
    if (epoch == N_epochs):
        break

keras_mdl.fit_generator(train_ds, epochs=N_epochs, steps_per_epoch=int(N_train_samples/batch_size),\
        validation_data=validation_ds, validation_steps=1)

# Predict with model and plot results
y_pred = mdl(x)
y_keras_pred = keras_mdl(x)
plt.plot(x, y)
plt.plot(x, y_true)
plt.plot(x, y_pred.numpy())

```"
28900,undefined symbol: _ZTVN6icu_639ErrorCodeE while building v1.12.2,"**System information**
- Debian 10.0
- TensorFlow installed from source
- TensorFlow version: v1.12.2
- Python version: 3.5.4
- Bazel version: 0.15.2
- GCC/Compiler version (if compiling from source): gcc 7.4.0
- CUDA 9.2, cuDNN 7
- GPU model and memory: GeForce 940MX, 2Go

The build fails with : 
```
ERROR: /opt/tensorflow/tensorflow/BUILD:533:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1): bash failed: error executing command 
  (cd /home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr \
    CUDNN_INSTALL_PATH=/usr/local/cuda/lib64 \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc-7 \
    NCCL_HDR_PATH=/usr/include \
    NCCL_INSTALL_PATH=/usr/lib/x86_64-linux-gnu \
    PATH=/home/yves/anaconda3/envs/digicampipe/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/yves/anaconda3/bin:/home/yves/coin/monero/monero/build/release/bin/ \
    PYTHON_BIN_PATH=/home/yves/anaconda3/envs/digicampipe/bin/python \
    PYTHON_LIB_PATH=/home/yves/anaconda3/envs/digicampipe/lib/python3.5/site-packages \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=7.0 \
    TF_CUDA_VERSION=9.2 \
    TF_CUDNN_VERSION=7 \
    TF_NCCL_VERSION=2 \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL_SYCL=0 \
    TF_NEED_ROCM=0 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1 --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/k8-opt/genfiles/tensorflow_api/v1/ --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow._api.v1 bazel-out/k8-opt/genfiles/tensorflow/_api/v1/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/app/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/bitwise/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/compat/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/data/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/data/experimental/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/debugging/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/distributions/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/dtypes/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/errors/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/feature_column/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/gfile/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/graph_util/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/image/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/io/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/initializers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/activations/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/densenet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_v3/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/nasnet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/resnet50/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg16/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg19/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/xception/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/backend/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/callbacks/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/constraints/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/boston_housing/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar10/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar100/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/imdb/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/mnist/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/reuters/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/estimator/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/initializers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/layers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/losses/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/metrics/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/models/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/optimizers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/image/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/sequence/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/text/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/regularizers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/wrappers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/layers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/linalg/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/logging/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/losses/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/manip/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/math/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/metrics/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/nn/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/nn/rnn_cell/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/profiler/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/python_io/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/quantization/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/random/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/resource_loader/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/strings/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/builder/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/loader/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/main_op/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/signature_constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/signature_def_utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/tag_constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sets/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sparse/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/spectral/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/summary/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sysconfig/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/test/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/train/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/train/queue_runner/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/user_ops/__init__.py')
Traceback (most recent call last):
  File ""/home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/yves/anaconda3/envs/digicampipe/lib/python3.5/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/yves/anaconda3/envs/digicampipe/lib/python3.5/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: /home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZTVN6icu_639ErrorCodeE
 During handling of the above exception, another exception occurred:
 Traceback (most recent call last):
  File ""/home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/yves/anaconda3/envs/digicampipe/lib/python3.5/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/yves/anaconda3/envs/digicampipe/lib/python3.5/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: /home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZTVN6icu_639ErrorCodeE
 Failed to load the native TensorFlow runtime.
```

**Provide the exact sequence of commands / steps that you executed before running into the problem** :
```
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures
```

**Any other info / logs**
```
$ldd /home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so
	linux-vdso.so.1 (0x00007ffe132c4000)
	libtensorflow_framework.so => /home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/libtensorflow_framework.so (0x00007f3a9c170000)
	libcublas.so.9.2 => /home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib/libcublas.so.9.2 (0x00007f3a983a0000)
	libcusolver.so.9.2 => /home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccusolver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib/libcusolver.so.9.2 (0x00007f3a90f5f000)
	libcudart.so.9.2 => /home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib/libcudart.so.9.2 (0x00007f3a90cf5000)
	libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f3a90cc0000)
	libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f3a90c9f000)
	libgomp.so.1 => /usr/lib/x86_64-linux-gnu/libgomp.so.1 (0x00007f3a90c6c000)
	libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f3a90ae9000)
	librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f3a90adf000)
	libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f3a9095b000)
	libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f3a90941000)
	libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f3a90780000)
	/lib64/ld-linux-x86-64.so.2 (0x00007f3aaa5db000)
	libcuda.so.1 => /usr/lib/x86_64-linux-gnu/libcuda.so.1 (0x00007f3a8f625000)
	libcudnn.so.7 => /usr/local/cuda/lib64/libcudnn.so.7 (0x00007f3a7e694000)
	libcufft.so.9.2 => /usr/lib/x86_64-linux-gnu/libcufft.so.9.2 (0x00007f3a7903a000)
	libcurand.so.9.2 => /usr/lib/x86_64-linux-gnu/libcurand.so.9.2 (0x00007f3a750fc000)
	libnvidia-fatbinaryloader.so.418.56 => /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.418.56 (0x00007f3a74eae000)
```

```
$nm -A /usr/lib/x86_64-linux-gnu/libicu*.a | grep _ZTVN6icu_639ErrorCodeE
/usr/lib/x86_64-linux-gnu/libicui18n.a:decimfmt.ao:                 U _ZTVN6icu_639ErrorCodeE
nm: wintzimpl.ao: no symbols
nm: windtfmt.ao: no symbols
nm: winnmfmt.ao: no symbols
/usr/lib/x86_64-linux-gnu/libicui18n.a:number_mapper.ao:                 U _ZTVN6icu_639ErrorCodeE
/usr/lib/x86_64-linux-gnu/libicuuc.a:errorcode.ao:0000000000000000 V _ZTVN6icu_639ErrorCodeE
nm: cwchar.ao: no symbols
nm: wintz.ao: no symbols
nm: icuplug.ao: no symbols
```

```
nm /home/yves/.cache/bazel/_bazel_yves/fbc06f9baef46cade6e35d9e4137e37c/execroot/org_tensorflow/bazel-out/host/bin/external/icu/libicuuc.pic.a | grep _ZTVN6icu_ | grep ErrorCode
0000000000000000 V _ZTVN6icu_629ErrorCodeE
```"
28899, Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_attempt_count ,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
28898,Analysis of target '//tensorflow/contrib/tensor_forest:model_ops_test' failed; build aborted: for tensorflow/contrib/tensor_forest/libutils.so,"env:
OS: windows 10
bazel version: 0.24.1
tensorflow version:r1.14
python:3.6.4
CUDA:9.0
cuDNN: 7.4

----------------------------------

send under command in gitBash could complete successfully
```
$ bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package
```

----------------------------------

but send bazel test command encounter error, details as following.:
command(in gitBash):

```
$ bazel test tensorflow/contrib/tensor_forest:model_ops_test

Starting local Bazel server and connecting to it...
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
Loading:
Loading: 0 packages loaded
Analyzing: target //tensorflow/contrib/tensor_forest:model_ops_test (1 packages loaded, 0 targets configured)
Analyzing: target //tensorflow/contrib/tensor_forest:model_ops_test (33 packages loaded, 352 targets configured)
Analyzing: target //tensorflow/contrib/tensor_forest:model_ops_test (58 packages loaded, 2552 targets configured)
Analyzing: target //tensorflow/contrib/tensor_forest:model_ops_test (82 packages loaded, 4125 targets configured)
Analyzing: target //tensorflow/contrib/tensor_forest:model_ops_test (83 packages loaded, 4154 targets configured)
ERROR: file 'tensorflow/contrib/tensor_forest/libutils.so' is generated by these conflicting actions:
Label: //tensorflow/contrib/tensor_forest:model_ops_test
RuleClass: cc_test rule
Configuration: c9dc3b2a2ac77c2e5a3c9175e9c4aa9e
Mnemonic: Symlink
Action key: 0ac20b0e60679a64dc9111fddc500670
Progress message: Copying Execution Dynamic Library
PrimaryInput: File:[[<execution_root>]bazel-out/x64_windows-opt/bin]tensorflow/core/grappler/clusters/libutils.so, File:[[<execution_root>]bazel-out/x64_windows-opt/bin]tensorflow/core/grappler/costs/libutils.so
PrimaryOutput: File:[[<execution_root>]bazel-out/x64_windows-opt/bin]tensorflow/contrib/tensor_forest/libutils.so
ERROR: Analysis of target '//tensorflow/contrib/tensor_forest:model_ops_test' failed; build aborted: for tensorflow/contrib/tensor_forest/libutils.so, previous action: action 'Copying Execution Dynamic Library', attempted action: action 'Copying Execution Dynamic Library'
INFO: Elapsed time: 10.421s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (84 packages loaded, 4219 targets configured)
ERROR: Couldn't start the build. Unable to run tests
FAILED: Build did NOT complete successfully (84 packages loaded, 4219 targets configured)
```"
28897, Undefined symbol: tflite::InterpreterBuilder::~InterpreterBuilder() for tensorflow r1.14,"hello, I meet a problem:
when I use tensorflow1 r1.9 to build a IOS app using xcode,  it is OK. But when I use tensorflow r1.14，when building, it show error:

`:-1: Undefined symbol: tflite::InterpreterBuilder::~InterpreterBuilder()`

What causes it?  How to fix it? 
Anyone can give some advises? Thank you very much~
 
env: xcode10.2.1  iphone7  arm64"
28895,ImportError: DLL load failed: The specified module could not be found.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version:1.3.1
- Python version:3.7.3
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.5
- GPU model and memory: GeForce RTX 2080 / 24GB



**Describe the problem**
I can't see to run any file using tensorflow-gpu
**Provide the exact sequence of commands / steps that you executed before running into the problem**
After writing the code, running the file results in the following logs

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/user/Dropbox/2019 Spring Semester/Advanced Intelligence/TAsession1/TA1-1_student.py"", line 5, in <module>
    import tensorflow as tf
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\user\Anaconda3\envs\Projects\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
28894,deployment of isolation Forest with TensorFlow serving,"Hi All,

I have developed anomaly detection model using sklearn Isolation Forest Algorithm, now would like to go for live inference.
can i use tensorflow service for live inference, if it possible , can you please provide me an example for same.

"
28893,Installation Error,"**System information**
- Windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version: Alpha 2.0
- Python version: 3.7.3
- Installed using: pip
- GPU model and memory: GTX 1060, 16GB ram



My import tensorflow statement is not working. Here is the entire stack trace:

```
(base) D:\Project>python tf.py
Traceback (most recent call last):
  File ""C:\Users\Joshua\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Joshua\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Joshua\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Joshua\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Joshua\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""tf.py"", line 13, in <module>
    import tensorflow as tf
  File ""C:\Users\Joshua\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\Joshua\Anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Joshua\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Joshua\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Joshua\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Joshua\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Joshua\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Joshua\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.
```"
28892,Possible ODR violations for eigen's scalar_cast_op,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): debian stretch
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: v.1.13.1
- Python version: N/A
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 0.19.0
- GCC/Compiler version (if compiling from source): clang 3.7
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I have the following target:
```python
tf_cc_binary(
    name = ""tf_sample"",
    srcs = [
        ""tf_sample.cc""
    ],
    deps = [
        ""@org_tensorflow//tensorflow/core:tensorflow"",
    ],
)
```
with the following contents:
```cpp
#include <stdio.h>
#include ""tensorflow/core/platform/env.h""
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/core/public/session_options.h""

int main(int argc, char **argv) {
  ::tensorflow::Session *session;
  ::tensorflow::Status status = NewSession(tensorflow::SessionOptions(), &session);
  ::std::cout << ""Used TF! "" << status.ToString() << ::std::endl;
  return 0;
}
```
and it gives me the following linker error:
```console
$ bazel build //vehicle/vision:tf_sample 
INFO: Analysed target //vehicle/vision:tf_sample (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
INFO: Writing explanation of rebuilds to '/tmp/bazel_explain_phil.log'
INFO: From Linking vehicle/vision/tf_sample:
external/amd64_compilers_repo/usr/bin/ld.gold: warning: while linking bazel-out/k8-fastbuild/bin/vehicle/vision/tf_sample: symbol 'Eigen::internal::scalar_cast_op<int, std::complex<float> >::operator()(int const&) const' defined in multiple places (possible ODR violation):
  external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/functors/UnaryFunctors.h:155 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/tile_ops/tile_ops_cpu_impl_1.pic.o
  external/org_tensorflow/tensorflow/core/kernels/cast_op.h:251 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/cast_op/cast_op_impl_int32.pic.o
external/amd64_compilers_repo/usr/bin/ld.gold: warning: while linking bazel-out/k8-fastbuild/bin/vehicle/vision/tf_sample: symbol 'Eigen::internal::scalar_cast_op<double, std::complex<double> >::operator()(double const&) const' defined in multiple places (possible ODR violation):
  external/eigen_archive/Eigen/src/Core/functors/UnaryFunctors.h:155 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/matrix_square_root_op/matrix_square_root_op.pic.o
  external/org_tensorflow/tensorflow/core/kernels/cast_op.h:251 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/cast_op/cast_op_impl_double.pic.o
external/amd64_compilers_repo/usr/bin/ld.gold: warning: while linking bazel-out/k8-fastbuild/bin/vehicle/vision/tf_sample: symbol 'Eigen::internal::scalar_cast_op<float, std::complex<float> >::operator()(float const&) const' defined in multiple places (possible ODR violation):
  external/org_tensorflow/tensorflow/core/kernels/cast_op.h:251 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/cast_op/cast_op_impl_float.pic.o
  external/eigen_archive/Eigen/src/Core/functors/UnaryFunctors.h:155 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/matrix_square_root_op/matrix_square_root_op.pic.o
external/amd64_compilers_repo/usr/bin/ld.gold: warning: while linking bazel-out/k8-fastbuild/bin/vehicle/vision/tf_sample: symbol 'Eigen::internal::scalar_cast_op<std::complex<double>, std::complex<double> >::operator()(std::complex<double> const&) const' defined in multiple places (possible ODR violation):
  external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/functors/UnaryFunctors.h:155 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/save_restore_tensor/save_restore_tensor.pic.o
  external/org_tensorflow/tensorflow/core/kernels/cast_op.h:260 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/cast_op/cast_op_impl_complex128.pic.o
external/amd64_compilers_repo/usr/bin/ld.gold: warning: while linking bazel-out/k8-fastbuild/bin/vehicle/vision/tf_sample: symbol 'Eigen::internal::scalar_cast_op<tensorflow::bfloat16, float>::operator()(tensorflow::bfloat16 const&) const' defined in multiple places (possible ODR violation):
  external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/functors/UnaryFunctors.h:155 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/resize_bilinear_op/resize_bilinear_op.pic.o
  external/org_tensorflow/tensorflow/core/kernels/cast_op.h:288 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/cast_op/cast_op_impl_bfloat.pic.o
external/amd64_compilers_repo/usr/bin/ld.gold: warning: while linking bazel-out/k8-fastbuild/bin/vehicle/vision/tf_sample: symbol 'Eigen::internal::scalar_cast_op<int, std::complex<double> >::operator()(int const&) const' defined in multiple places (possible ODR violation):
  external/org_tensorflow/tensorflow/core/kernels/cast_op.h:251 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/cast_op/cast_op_impl_int32.pic.o
  external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/functors/UnaryFunctors.h:155 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/tile_ops/tile_ops_cpu_impl_1.pic.o
external/amd64_compilers_repo/usr/bin/ld.gold: warning: while linking bazel-out/k8-fastbuild/bin/vehicle/vision/tf_sample: symbol 'Eigen::internal::scalar_cast_op<std::complex<float>, std::complex<float> >::operator()(std::complex<float> const&) const' defined in multiple places (possible ODR violation):
  external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/functors/UnaryFunctors.h:155 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/save_restore_tensor/save_restore_tensor.pic.o
  external/org_tensorflow/tensorflow/core/kernels/cast_op.h:260 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/cast_op/cast_op_impl_complex64.pic.o
Target //vehicle/vision:tf_sample up-to-date:
  bazel-bin/vehicle/vision/tf_sample
INFO: Elapsed time: 81.008s, Critical Path: 80.69s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]
INFO: 17 processes: 17 linux-sandbox.
INFO: Build completed successfully, 18 total actions
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I already fixed another linker error:
```console
external/amd64_compilers_repo/usr/bin/ld.gold: warning: while linking bazel-out/k8-fastbuild/bin/vehicle/vision/tf_sample: symbol 'Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<unsigned short, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<unsigned short>, Eigen::TensorMap<Eigen::Tensor<unsigned short, 1, 1, long>, 1
6, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice, false, false>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<unsigned short, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<unsigned short>, Eigen::TensorMap<Eigen::Tensor<unsigned short, 1, 1, long>, 16, Eigen::MakePointer> const> const> const&, Eigen::ThreadPoolDevice const&)' defined i
n multiple places (possible ODR violation):
  external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:43 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/data/_objs/optional_ops/optional_ops.pic.o
  external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:227 from bazel-out/k8-fastbuild/bin/external/org_tensorflow/tensorflow/core/kernels/_objs/broadcast_to_op/broadcast_to_op.pic.o
```

by applying the following patch:
```patch
diff --git a/third_party/tensorflow/tensorflow/core/kernels/data/optional_ops.cc b/third_party/tensorflow/tensorflow/core/kernels/data/optional_ops.cc
index a406f74..56f3316 100644
--- a/third_party/tensorflow/tensorflow/core/kernels/data/optional_ops.cc
+++ b/third_party/tensorflow/tensorflow/core/kernels/data/optional_ops.cc
@@ -12,6 +12,9 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
 ==============================================================================*/
+
+#define EIGEN_USE_THREADS
+
 #include ""tensorflow/core/kernels/data/optional_ops.h""
 
 #include ""tensorflow/core/common_runtime/dma_helper.h""
```

Any thoughts? I'm not very good with partial template specializations."
28891,tf.contrib.distribute.CollectiveAllReduceStrategy always failed for OS error or socket closed,"When using tf.contrib.distribute.CollectiveAllReduceStrategy to distribute train on 16 workers with 2 GPU each, my job always failed with OS error or socket closed after running for several thousands of steps. I also tried 8 workers and different batch size, the failure always reproduce. And when using parameter server strategy, all my jobs can run successfully and I believe this was not caused by my cluster.

Thank you so much for helping investigating this problem.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
  using estimator and train_and_evaluate
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
  Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
  when training
- TensorFlow installed from (source or binary):
   source
- TensorFlow version (use command below):
   tf 1.13
- Python version:
  python 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
   CUDA 10
- GPU model and memory:
  P100, 16G


**Describe the current behavior**
When using tf.contrib.distribute.CollectiveAllReduceStrategy to distribute train on 16 workers with 2 GPU each, my job always failed with OS error or socket closed after running for several thousands of steps. I also tried 8 workers and different batch size, the failure always reproduce.

**Describe the expected behavior**
The job should keep training without failure

**Code to reproduce the issue**

**Other info / logs**

> 

2019-05-19T15:07:45.079Z: [1,13]<stderr>:INFO:tensorflow:loss = 3.7297182, step = 10300 (50.597 sec)
2019-05-19T15:07:45.080Z: [1,14]<stderr>:INFO:tensorflow:loss = 3.7297182, step = 10300 (50.608 sec)
2019-05-19T15:07:45.081Z: [1,14]<stderr>:INFO:tensorflow:global_step/sec: 1.97598
2019-05-19T15:08:13.129Z: [1,4]<stderr>:2019-05-19 15:08:13.128241: E tensorflow/core/common_runtime/ring_reducer.cc:369] Aborting RingReduce with Unavailable: Socket closed
2019-05-19T15:08:13.129Z: [1,4]<stderr>:2019-05-19 15:08:13.128323: W tensorflow/core/common_runtime/base_collective_executor.cc:203] BaseCollectiveExecutor::StartAbort Unavailable: Socket closed
2019-05-19T15:08:14.047Z: [1,1]<stderr>:Segmentation fault (core dumped)

or os error

2019-05-20T12:05:35.816Z: [1,12]<stderr>:INFO:tensorflow:loss = 5.7242765, step = 3400 (57.129 sec)
2019-05-20T12:05:35.817Z: [1,14]<stderr>:INFO:tensorflow:loss = 5.7242765, step = 3400 (57.107 sec)
2019-05-20T12:05:41.291Z: [1,7]<stderr>:2019-05-20 12:05:41.289749: E tensorflow/core/common_runtime/ring_reducer.cc:369] Aborting RingReduce with Unavailable: OS Error
2019-05-20T12:05:41.291Z: [1,7]<stderr>:2019-05-20 12:05:41.289831: W tensorflow/core/common_runtime/base_collective_executor.cc:203] BaseCollectiveExecutor::StartAbort Unavailable: OS Error
2019-05-20T12:05:41.774Z: [1,1]<stderr>:Segmentation fault (core dumped)

"
28890,XLA_GPU_JIT Slows Down GNMT (when large clusters are formed),"**System information**
- Have I written custom code: Use models from NVIDIA [OpenSeq2Seq](https://github.com/NVIDIA/OpenSeq2Seq)
- OS Platform and Distribution:  Ubuntu 16.04
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): upstream-base-779-g83909d2 1.13.1
- Python version: 3.5.2
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 5.4.0 20160609
- CUDA/cuDNN version: 10.0
- GPU model and memory: NVIDIA GV100

**Code to reproduce the issue**
Note that let's assume a context where the deadness analysis is disabled for forming large clusters. In such scenarios, XLA_GPU_JIT slows down this reported GNMT implementation by around 30%.

Reproduction steps:

1. Download the training dataset from the following link. Assuming putting it under /wmt16/
https://drive.google.com/open?id=1ooQiWhmzmYsk2qMOfaunjTlx_z6lcUyO
2. `git clone https://github.com/NVIDIA/OpenSeq2Seq.git`
3. `cd OpenSeq2Seq`
4. `git apply gnmt_config.txt` ([file here](https://github.com/tensorflow/tensorflow/files/3200298/gnmt_config.txt)). Assuming the dataset is placed under /wmt16/.
5. Run command:
`TF_XLA_FLAGS=""--tf_xla_disable_deadness_safety_checks_for_debugging=true "" CUDA_VISIBLE_DEVICES=0 python run.py --config_file=example_configs/text2text/en-de/en-de-gnmt-like-4GPUs.py --benchmark --bench_start 50 --bench_steps 100 --use_xla_jit`
6. Remove `--use_xla_jit` to run with native Tensorflow.

**Observed slowdown**
The performance measured on my GV100 (1 GPU):
With XLA_JIT:
    Avg time per step: 1.000s
With native Tensorflow:
    Avg time per step: 0.760s

This is around 30% slowdown, comparing XLA_JIT to native TF.

**A Theory of why such a slowdown**
My theory of why XLA slows down is as follows. Ideally, the TF runtime (host) should be able to run ahead of the device, so that the host overhead can be hidden. To achieve that, the TF runtime usually executes the dataflow ops in parallel on multiple CPUs to feed computation to one GPU stream. For example, when ops related to an LSTM cell are executed, the tf.while ops (e.g., Merge/Switch, etc.) could be executed in parallel, so that the loop related latencies are hidden. This, however, is not the case observed in XLA_JIT on the forward path of the GNMT.

A possible explanation of why the host does not run ahead is a result of interaction between host-device synchronization needed by tf.while and long-latency _XlaRun ops. The tf.while ops involve synchronization between host and device as they need to copy some computation results back to the host to make decisions about when to exit the loop. For example, a typical op sequence of tf.while is Add, Less, LoopCond, and Switch; the result of Add is on device but TF computes Less, LoopCond, and Switch on host. These synchronization latencies are better hidden in pure TF executions, as there are more parallel ops and each op is of lower latency. In contrast, scheduling a long-latency op such as _XlaRun along with the op sequence of tf.while on the same GPU stream can introduce extra dependency (established through the runtime scheduling order on the single GPU stream) and force the host to wait for the completion of this long-latency op even if they have no dependencies in the dataflow graph. Often, this is the case observed.

**Other info**
Further reference for script options:
https://nvidia.github.io/OpenSeq2Seq/html/machine-translation.html


"
28877,"Opening bug #27833 again, since not able to compile tensorflow on debian 9","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): debian 9
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.0, 1.14
- Python version: 3.6.5 (pyenv)
- Installed using virtualenv? pip? conda?: virtualenv (python -m venv)
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source):  gcc (Debian 6.3.0-18+deb9u1) 6.3.0 20170516
- CUDA/cuDNN version: No
- GPU model and memory: No


**Describe the problem**

Not able to compile tensorflow 2.0, 1.12, ... with bazel on debian system.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

activate a virtualenv with:
Keras-Applications==1.0.6
mock==3.0.5
numpy==1.16.3
six==1.12.0

git co r1.14
./configure
bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --config=mkl -k //tensorflow/tools/pip_package:build_pip_package --verbose_failures


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


```
tensorflow/core/kernels/BUILD:4615:1: Couldn't build file tensorflow/core/kernels/_objs/sparse_reduce_op/sparse_reduce_op.pic.o: C++ compilation of rule '//tensorflow/core/kernels:sparse_reduce_op' failed (Exit 1): gcc failed: error executing command
  (cd /home/f43995/.cache/bazel/_bazel_f43995/3010ddbda2b99362ce3481040aa5c4dc/execroot/org_tensorflow && \
  exec env - \
    PATH=/opt/py_envs/tfopt/bin:/home/f43995/.pyenv/shims:/home/f43995/.pyenv/bin:/home/f43995/.pyenv/shims:/home/f43995/.pyenv/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/f43995/.dotnet/tools:/opt/mssql-tools/bin:/opt/mssql-tools/bin:/home/f43995/bin \
    PWD=/proc/self/cwd \
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/host/bin/tensorflow/core/kernels/_objs/sparse_reduce_op/sparse_reduce_op.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/core/kernels/_objs/sparse_reduce_op/sparse_reduce_op.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -iquote . -iquote bazel-out/host/genfiles -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/genfiles/external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/host/genfiles/external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/genfiles/external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/nsync -iquote bazel-out/host/genfiles/external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/gif_archive -iquote bazel-out/host/genfiles/external/gif_archive -iquote bazel-out/host/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/genfiles/external/jpeg -iquote bazel-out/host/bin/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/host/genfiles/external/protobuf_archive -iquote bazel-out/host/bin/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/genfiles/external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/genfiles/external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/genfiles/external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/genfiles/external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/host/genfiles/external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -isystem third_party/eigen3/mkl_include -isystem bazel-out/host/genfiles/third_party/eigen3/mkl_include -isystem bazel-out/host/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/host/genfiles/external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/genfiles/external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem external/gif_archive/lib -isystem bazel-out/host/genfiles/external/gif_archive/lib -isystem bazel-out/host/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/host/genfiles/external/protobuf_archive/src -isystem bazel-out/host/bin/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/host/genfiles/external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/host/genfiles/external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive -g0 -g0 -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' '-DINTEL_MKL=1' -DEIGEN_USE_VML -DENABLE_MKL -fopenmp -msse3 -pthread '-DINTEL_MKL=1' -DENABLE_MKL -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/kernels/sparse_reduce_op.cc -o bazel-out/host/bin/tensorflow/core/kernels/_objs/sparse_reduce_op/sparse_reduce_op.pic.o)
Execution platform: @bazel_tools//platforms:host_platform
```

"
28871, Error parsing ApiDef file tensorflow/core/api_def/base_api/api_def_RefEnter.pbtxt,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu16.04
- TensorFlow installed from (source or binary):source
- TensorFlow version:2.0
- Python version:2.7
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):23.0 
- GCC/Compiler version (if compiling from source):5.4
- CUDA/cuDNN version:10.0/7.4
- GPU model and memory:GPU

**Describe the problem**

bazel create bazel-out/k8- pt/genfiles/tensorflow/python/parsing_ops_pygenrule.genrule_script.sh
however, this shell file could not be run correctly.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build --config=opt --config=cuda --config=monolithic //tensorflow/python:parsing_ops_pygenrule --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0""

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

ERROR: /home/xiesiyuan/Desktop/tensorflow2.0/tensorflow/tensorflow/python/BUILD:1933:1: Executing genrule //tensorflow/python:parsing_ops_pygenrule failed (Aborted): **bash failed: error executing command /bin/bash bazel-out/k8- opt/genfiles/tensorflow/python/parsing_ops_pygenrule.genrule_script.sh**
2019-05-21 01:11:26.706445: F tensorflow/python/framework/python_op_gen_main.cc:123] Non-OK-status: api_def_map.LoadFileList(env, api_files) status: Invalid argument: Error parsing ApiDef file tensorflow/core/api_def/base_api/api_def_RefEnter.pbtxt: 5(4): Expected identifier, got:

bazel-out/k8-opt/genfiles/tensorflow/python/parsing_ops_pygenrule.genrule_script.sh: line 2: 16961 Aborted  "
28868,tf.summary.image does not work with keras layers in tf 2.0 due to EagerExecution issues,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Official tf docker 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):No
- TensorFlow version (use command below):2.0.0-alpha0
- Python version: 3.5
- CUDA/cuDNN version: 10.1
- GPU model and memory:Titan V

I use tf.keras subclassing, but when I want to track the some images in my network, the error at the bottom of the post occurs. Initially,  I think the reason for the error is, that `tf.summary.image` becomes a normal Tensor as input, but needs an eagerTensor. If I create a random tensor in the summary function and evaluate the type it is an eagerTensor, but if I use a Tensor from a `keras.layers.Layer` class it evaluates to a normal Tensor and throws the error (you can try it in your code). 

First I thought that the `tf.dataset` returns a non-eager tensor, but if I use a numpy array as input, the same error occurs as well. So the error might be caused by the `keras.layer.Layer` class.

The error occurs on GPU and CPU.


**Working example**
```
import tensorflow as tf
import numpy as np

inp_arr_without_ds = np.random.rand(2, 200, 200, 3)

inp_arr_4_ds = np.random.rand(2, 2, 200, 200, 3)
tf_ds = tf.data.Dataset.from_tensor_slices((inp_arr_4_ds, inp_arr_4_ds))
tf_ds = tf_ds.map(lambda x, y: (x, y)).repeat(10).shuffle(10)

class random_model(tf.keras.Model):
    
    def __init__(self, name):
        super(random_model, self).__init__(name=name)
        self.conv_1 = tf.keras.layers.Conv2D(3, [3, 3], padding=""same"")
        self.tf_board_writer = tf.summary.create_file_writer(""test"")
        self.img_callback = [tf.keras.callbacks.LambdaCallback(on_epoch_end=self.save_img)]
        
    def call(self, inputs):
        self.initialized_layer = self.conv_1(inputs)
        return self.initialized_layer
    
    def save_img(self, epochs, logs):
        with self.tf_board_writer.as_default():
            # Does not work: type: class 'tensorflow.python.framework.ops.Tensor' 
            tf.summary.image(""image"", self.initialized_layer, step=epochs)
            
            # Does work type: class 'tensorflow.python.framework.ops.EagerTensor'
            #tf.summary.image(""image"", tf.random.uniform([2, 200, 200, 3]), step=epochs) 
            
    def compile_model(self):
        self.compile(tf.optimizers.Adam(0.001), tf.losses.mean_absolute_error)
    
    def fit_model_with_ds(self, ds):
        self.fit(ds, callbacks=self.img_callback)
        
    def fit_model_with_array(self, x, y):
        self.fit(x, y, callbacks=self.img_callback)

print(tf.__version__)        

# Both do not work
non_ds_model = random_model(""non_ds"") 
non_ds_model.compile_model()
non_ds_model.fit_model_with_array(inp_arr_without_ds, inp_arr_without_ds)
            
tf_ds_model = random_model(""tf_ds"")
tf_ds_model.compile_model()
tf_ds_model.fit_model_with_ds(tf_ds)
```


    
    


> **Error Message**
```
> 2.0.0-alpha0
> 
> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> <ipython-input-25-0b5a4b30a43a> in <module>
>      39 non_ds_model = random_model(""non_ds"")
>      40 non_ds_model.compile_model()
> ---> 41 non_ds_model.fit_model_with_array(inp_arr_without_ds, inp_arr_without_ds)
>      42 
>      43 tf_ds_model = random_model(""tf_ds"")
> 
> <ipython-input-25-0b5a4b30a43a> in fit_model_with_array(self, x, y)
>      32 
>      33     def fit_model_with_array(self, x, y):
> ---> 34         self.fit(x, y, callbacks=self.img_callback)
>      35 
>      36 print(tf.__version__)
> 
> /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
>     871           validation_steps=validation_steps,
>     872           validation_freq=validation_freq,
> --> 873           steps_name='steps_per_epoch')
>     874 
>     875   def evaluate(self,
> 
> /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)
>     406     if mode == ModeKeys.TRAIN:
>     407       # Epochs only apply to `fit`.
> --> 408       callbacks.on_epoch_end(epoch, epoch_logs)
>     409     progbar.on_epoch_end(epoch, epoch_logs)
>     410 
> 
> /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/callbacks.py in on_epoch_end(self, epoch, logs)
>     288     logs = logs or {}
>     289     for callback in self.callbacks:
> --> 290       callback.on_epoch_end(epoch, logs)
>     291 
>     292   def on_train_batch_begin(self, batch, logs=None):
> 
> <ipython-input-25-0b5a4b30a43a> in save_img(self, epochs, logs)
>      20         with self.tf_board_writer.as_default():
>      21             # Does not work: type: class 'tensorflow.python.framework.ops.Tensor'
> ---> 22             tf.summary.image(""image"", self.initialized_layer, step=epochs)
>      23 
>      24             # Does work type: class 'tensorflow.python.framework.ops.EagerTensor'
> 
> /usr/local/lib/python3.5/dist-packages/tensorboard/plugins/image/summary_v2.py in image(name, data, step, max_outputs, description)
>      71     encoded_images = tf.map_fn(tf.image.encode_png, limited_images,
>      72                                dtype=tf.string,
> ---> 73                                name='encode_each_image')
>      74     # Workaround for map_fn returning float dtype for an empty elems input.
>      75     encoded_images = tf.cond(
> 
> /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/map_fn.py in map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)
>     226                                      dynamic_size=False,
>     227                                      infer_shape=True)
> --> 228         for elem in elems_flat]
>     229     # Unpack elements
>     230     elems_ta = [
> 
> /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/map_fn.py in <listcomp>(.0)
>     226                                      dynamic_size=False,
>     227                                      infer_shape=True)
> --> 228         for elem in elems_flat]
>     229     # Unpack elements
>     230     elems_ta = [
> 
> /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/tensor_array_ops.py in __init__(self, dtype, size, dynamic_size, clear_after_read, tensor_array_name, handle, flow, infer_shape, element_shape, colocate_with_first_write_call, name)
>    1036         element_shape=element_shape,
>    1037         colocate_with_first_write_call=colocate_with_first_write_call,
> -> 1038         name=name)
>    1039 
>    1040     self._implementation.parent = weakref.ref(self)
> 
> /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/tensor_array_ops.py in __init__(***failed resolving arguments***)
>     742     if isinstance(size, ops.EagerTensor):
>     743       size = size.numpy()
> --> 744     self._tensor_array = [None for _ in range(size)]
>     745 
>     746   @property
> 
> TypeError: 'Tensor' object cannot be interpreted as an integer
> 

```
"
28865,"TF1.14 compile still fails with CUDA 10.1 (""Could not find any cublas_api.h"")","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: r1.14 tag
- Python version: 3.6
- Installed using virtualenv? pip? conda?: venv
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 8.2.1
- CUDA/cuDNN version: 10.1/7.5.1
- GPU model and memory: V100



**Describe the problem**

CUDA build fails because cublas_api.h is now under /usr/include and not /usr/local/cuda/include. (And the r1.14 find_cuda_config.py script ignores TF_CUDA_PATHS when searching for cublas.)

This problem is fixed on master. Someone just needs to bring third_party/gpu/find_cuda_config.py to the r1.14 branch.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

env TF_CUDA_PATHS=/usr/local/cuda,/usr ./configure
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**

Cuda Configuration Error: Failed to run find_cuda_config.py: Could not find any cublas_api.h matching version '' in any subdirectory:
        ''
        'include'
        'include/cuda'
        'include/*-linux-gnu'
        'extras/CUPTI/include'
        'include/cuda/CUPTI'
of:
        '/usr/local/cuda'

INFO: Elapsed time: 0.468s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)

"
28863,Build Tensorflow Lite from source on Yocto Linux,"I have built a custom 32 bit Linux with [Yocto project](https://www.yoctoproject.org/), now i have a gcc toolchain that full support on c and c++ standard library, can i build Tensorflow Lite from source? Which dependencies will i have to install for a succesful build?
"
28861,module 'tensorflow._api.v1.keras.layers' has no attribute 'Lamdba',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
`classifier_layer = layers.Lamdba(classifier_layer, input_shape = IMAGE_SIZE*[3]) 
classifier_model = tf.keras.Sequential([classifier_layer]) classifier_mode.summary()`
- OS Platform and 
Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro, 64bit, build number 17763.503
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7
- Using Visual studios as a compiler
- CUDA/cuDNN version: cant find my CUDA/cuDNN version.
- GPU model and memory: GTX 1060 6GB

**Describe the current behavior**
Giving ma a attribute error.

**Describe the expected behavior**
Not getting the attribute error

**Code to reproduce the issue**
`classifier_layer = layers.Lamdba(classifier_layer, input_shape = IMAGE_SIZE*[3]) classifier_model = tf.keras.Sequential([classifier_layer]) classifier_mode.summary()`

Provide a reproducible test case that is the bare minimum necessary to generate the problem.
just compile it.

**Other info / logs**
`classifier_layer = layers.Lamdba(classifier_layer, input_shape = IMAGE_SIZE*[3]) 
classifier_model = tf.keras.Sequential([classifier_layer]) classifier_mode.summary()`
module 'tensorflow._api.v1.keras.layers' has no attribute 'Lamdba'
"
28860,tf.data.Dataset::cache files are twice the size compared to original records,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1 / 1.14.1-dev / 2.0.0-nightly
- Python version: 3.7.3
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**

Files generated by `tf.data.Dataset::cache` consume considerably more disk space than the original TFRecord files. E.g. MNIST from `tensorflow_datasets` uses 21MB split into 10 files.  `tf.data.Dataset::cache` generates a single file with size 45MB.
Is there a specific reason why `tf.data.Dataset::cache` files use a lot more disk space and don't split the files into chunks?
This might be acceptable for MNIST size datasets but when using ImageNet `tf.data.Dataset::cache` will create a single cache file with well above 350GB vs 144GB of original TFRecords.

**Describe the expected behavior**
`tf.data.Dataset::cache` should produce a similar file compared to the input TFRecord files.

**Code to reproduce the issue**
```python
import tensorflow as tf 
import tensorflow_datasets as tfds 

tf.enable_eager_execution() # if version 1.x

data = tfds.load(""mnist"", split=tfds.Split.TRAIN) 
cached = data.cache(""cache/mnist"").shuffle(100).repeat().batch(128) 
 
for feat in cached: 
    print(""iterating"")
```

**Other info / logs**
Original TFRecords:
```console
$ ll tensorflow_datasets/mnist/1.0.0/
total 50008
drwxr-xr-x  15 lukasgeiger  staff   480B Mar 26 00:23 .
drwxr-xr-x   3 lukasgeiger  staff    96B Mar 26 00:23 ..
-rw-r--r--@  1 lukasgeiger  staff   2.0K Mar 26 00:23 dataset_info.json
-rw-r--r--   1 lukasgeiger  staff    48B Mar 26 00:23 image.image.json
-rw-r--r--   1 lukasgeiger  staff   3.2M Mar 26 00:23 mnist-test.tfrecord-00000-of-00001
-rw-r--r--   1 lukasgeiger  staff   1.9M Mar 26 00:23 mnist-train.tfrecord-00000-of-00010
-rw-r--r--   1 lukasgeiger  staff   1.9M Mar 26 00:23 mnist-train.tfrecord-00001-of-00010
-rw-r--r--   1 lukasgeiger  staff   1.9M Mar 26 00:23 mnist-train.tfrecord-00002-of-00010
-rw-r--r--   1 lukasgeiger  staff   1.9M Mar 26 00:23 mnist-train.tfrecord-00003-of-00010
-rw-r--r--   1 lukasgeiger  staff   1.9M Mar 26 00:23 mnist-train.tfrecord-00004-of-00010
-rw-r--r--   1 lukasgeiger  staff   1.9M Mar 26 00:23 mnist-train.tfrecord-00005-of-00010
-rw-r--r--   1 lukasgeiger  staff   1.9M Mar 26 00:23 mnist-train.tfrecord-00006-of-00010
-rw-r--r--   1 lukasgeiger  staff   1.9M Mar 26 00:23 mnist-train.tfrecord-00007-of-00010
-rw-r--r--   1 lukasgeiger  staff   1.9M Mar 26 00:23 mnist-train.tfrecord-00008-of-00010
-rw-r--r--   1 lukasgeiger  staff   1.9M Mar 26 00:23 mnist-train.tfrecord-00009-of-00010
```
Cached TFRecords:
```console
$ ll cache/
total 100960
drwxr-xr-x    4 lukasgeiger  staff   128B May 20 09:45 .
drwxr-xr-x@ 113 lukasgeiger  staff   3.5K May 20 10:14 ..
-rw-r--r--    1 lukasgeiger  staff    45M May 20 09:45 mnist.data-00000-of-00001
-rw-r--r--    1 lukasgeiger  staff   3.2M May 20 09:45 mnist.index
```"
28859,"TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(""Placeholder:0"", shape=(7, 7, 3, 64), dtype=float32) is not an element of this graph.","**### This is my code in python** 

from flask import Flask
from flask_restful import Api, Resource, reqparse

app = Flask(__name__)
api = Api(app)

import os
import json
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import logging
import tensorflow as tf
from keras import backend as K 

from collections import Counter

import pandas as pd
import numpy as np

from keras.models import load_model

from keras.preprocessing.image import array_to_img, img_to_array, load_img
from scipy.misc import imresize

from PIL import Image


users = [
    {
        ""name"": ""Nicholas"",
        ""age"": 42,
        ""occupation"": ""Network Engineer"",
       
    },
    {
        ""name"": ""Elvin"",
        ""age"": 32,
        ""occupation"": ""Doctor""
       
    },
    {
        ""name"": ""Jass"",
        ""age"": 22,
        ""occupation"": ""Web Developer""
      
    }
]

class User(Resource):
    def get(self, name):
        for user in users:
            if(name == user[""name""]):
                return user, 200
        return ""User not found"", 404

    def post(self, name):
        K.clear_session()
        parser = reqparse.RequestParser()
        parser.add_argument(""image"")
        #get the image
        model = load_model('C:/Users/ASUS/Downloads/mse-04-0.0877.h5')
        img_height, img_width, channels = 350, 350, 3

        img = load_img('C:/xampp/htdocs/faceD/image/logo.png')

        img = imresize(img, size=(img_height, img_width))	  
        test_x = img_to_array(img).reshape(img_height, img_width, channels) 
        test_x = test_x / 255.
        test_x = test_x.reshape((1,) + test_x.shape)
        predicted = model.predict(test_x)

        return{
            ""name"": ""Nicholas"",
            ""age"": 42,
            ""occupation"": ""Network Engineer"",
            ""prediction"": str(predicted[0][0])

    }, 201


    def put(self, name):
        parser = reqparse.RequestParser()
        parser.add_argument(""age"")
        parser.add_argument(""occupation"")
        args = parser.parse_args()

        for user in users:
            if(name == user[""name""]):
                user[""age""] = args[""age""]
                user[""occupation""] = args[""occupation""]
                user[""prediction""] = args[""str(predicted[0][0])""]
                return user, 200
        
        user = {
            ""name"": name,
            ""age"": args[""age""],
            ""occupation"": args[""occupation""],
            ""prediction"": args[""str(predicted[0][0])""]
        }
        users.append(user)
        return user, 201

    def delete(self, name):
        global users
        users = [user for user in users if user[""name""] != name]
        return ""{} is deleted."".format(name), 200
      
api.add_resource(User, ""/user/<string:name>"")

app.run(debug=True)



**### _All the error_**



Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 2309, in __call__
    return self.wsgi_app(environ, start_response)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 2295, in wsgi_app
    response = self.handle_exception(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 269, in error_router
    return original_handler(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1741, in handle_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\_compat.py"", line 34, in reraise
    raise value.with_traceback(tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 2292, in wsgi_app
    response = self.full_dispatch_request()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1815, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 269, in error_router
    return original_handler(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1718, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\_compat.py"", line 34, in reraise
    raise value.with_traceback(tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1813, in full_dispatch_request
    rv = self.dispatch_request()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1799, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 458, in wrapper
    resp = resource(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\views.py"", line 88, in view
    return self.dispatch_request(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 573, in dispatch_request
    resp = meth(*args, **kwargs)
  File ""C:\xampp\htdocs\faceD\app.py"", line 61, in post
    model = load_model('C:/Users/ASUS/Downloads/mse-04-0.0877.h5')
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\saving.py"", line 419, in load_model
    model = _deserialize_model(f, custom_objects, compile)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\saving.py"", line 287, in _deserialize_model
    K.batch_set_value(weight_value_tuples)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2470, in batch_set_value
    get_session().run(assign_ops, feed_dict=feed_dict)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 929, in run
    run_metadata_ptr)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1095, in _run
    'Cannot interpret feed_dict key as Tensor: ' + e.args[0])
TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(""Placeholder:0"", shape=(7, 7, 3, 64), dtype=float32) is not an element of this graph.
127.0.0.1 - - [20/May/2019 21:21:32] ""[1m[35mPOST /user/Nicholas HTTP/1.1[0m"" 500 -
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 2309, in __call__
    return self.wsgi_app(environ, start_response)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 2295, in wsgi_app
    response = self.handle_exception(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 269, in error_router
    return original_handler(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1741, in handle_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\_compat.py"", line 34, in reraise
    raise value.with_traceback(tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 2292, in wsgi_app
    response = self.full_dispatch_request()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1815, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 269, in error_router
    return original_handler(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1718, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\_compat.py"", line 34, in reraise
    raise value.with_traceback(tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1813, in full_dispatch_request
    rv = self.dispatch_request()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1799, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 458, in wrapper
    resp = resource(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\views.py"", line 88, in view
    return self.dispatch_request(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 573, in dispatch_request
    resp = meth(*args, **kwargs)
  File ""C:\xampp\htdocs\faceD\app.py"", line 70, in post
    predicted = model.predict(test_x)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py"", line 1169, in predict
    steps=steps)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training_arrays.py"", line 294, in predict_loop
    batch_outs = f(ins_batch)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2715, in __call__
    return self._call(inputs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1439, in __call__
    run_metadata_ptr)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value dense_1/bias
         [[{{node dense_1/bias/read}}]]
127.0.0.1 - - [20/May/2019 21:21:33] ""[1m[35mPOST /user/Nicholas HTTP/1.1[0m"" 500 -
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 2309, in __call__
    return self.wsgi_app(environ, start_response)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 2295, in wsgi_app
    response = self.handle_exception(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 269, in error_router
    return original_handler(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1741, in handle_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\_compat.py"", line 34, in reraise
    raise value.with_traceback(tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 2292, in wsgi_app
    response = self.full_dispatch_request()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1815, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 269, in error_router
    return original_handler(e)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1718, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\_compat.py"", line 34, in reraise
    raise value.with_traceback(tb)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1813, in full_dispatch_request
    rv = self.dispatch_request()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\app.py"", line 1799, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 458, in wrapper
    resp = resource(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask\views.py"", line 88, in view
    return self.dispatch_request(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\flask_restful\__init__.py"", line 573, in dispatch_request
    resp = meth(*args, **kwargs)
  File ""C:\xampp\htdocs\faceD\app.py"", line 61, in post
    model = load_model('C:/Users/ASUS/Downloads/mse-04-0.0877.h5')
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\saving.py"", line 419, in load_model
    model = _deserialize_model(f, custom_objects, compile)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\saving.py"", line 287, in _deserialize_model
    K.batch_set_value(weight_value_tuples)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2470, in batch_set_value
    get_session().run(assign_ops, feed_dict=feed_dict)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 929, in run
    run_metadata_ptr)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1095, in _run
    'Cannot interpret feed_dict key as Tensor: ' + e.args[0])
TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(""Placeholder:0"", shape=(7, 7, 3, 64), dtype=float32) is not an element of this graph."
28858,How to set up TensorFlow in GPU machine only using CPU By Java code？,"


tensorflow version: 1.8.0 Java

```
        System.out.println(""setting config"");
        ConfigProto.Builder configBuilder=ConfigProto.newBuilder()
                .setAllowSoftPlacement(true)
                .setLogDevicePlacement(true)
                .clearLogDevicePlacement()
                //.setInterOpParallelismThreads(1)
        ;
        ConfigProto config;
        string visibleDevices=""-1"";

        config=configBuilder.setGpuOptions(GPUOptions.newBuilder()
                .clearVisibleDeviceList()
                .setVisibleDeviceList(visibleDevices)
                .setAllowGrowth(true)
        )
        .build();
        System.out.println(""setting session"");
        this.sess=new Session( this.graph, config.toByteArray() );
```
this visibleDevices=""-1"" throw a error:
```
2019-05-20 20:01:08.472129: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-05-20 20:01:10.441081: E tensorflow/core/common_runtime/direct_session.cc:154] Invalid argument: 'visible_device_list' listed an invalid GPU id '-1' but visible device count is 3
Exception in thread ""main"" org.tensorflow.TensorFlowException: Failed to create session.
        at org.tensorflow.Session.allocate2(Native Method)
        at org.tensorflow.Session.<init>(Session.java:70)
```


this visibleDevices=""0"" Indicates that the 0th GPU is used, but my GPU is full and I want to use the CPU to make predictions.

"
28857,How can I use same tf.Session() in another function as opened session??,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
28856,TFLiteConverterV2 has no attribute 'from_saved_model',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 16.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): **v1.12.0-9492-g2c319fb415 2.0.0-alpha0**
- Python version: **3.6**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: **9.0/7.1.4**
- GPU model and memory:

**Describe the current behavior**
When running `tf.lite.TFLiteConverter.from_saved_model(saved_model_path)`, an error occurs as described in the title.

**Describe the expected behavior**
The TF lite converter should work properly.

**Code to reproduce the issue**
Just follow the sample code in [here](https://www.tensorflow.org/lite/r2/convert/python_api)
```
import tensorflow as tf
root = tf.train.Checkpoint()
root.v1 = tf.Variable(3.)
root.v2 = tf.Variable(2.)
root.f = tf.function(lambda x: root.v1 * root.v2 * x)

export_dir = '/tmp/test_saved_model'
input_data = tf.constant(1., shape=[1, 1])
to_save = root.f.get_concrete_function(input_data)
tf.saved_model.save(root, export_dir, to_save)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
```"
28855,Low performance and detection on Google Coral DevBoard,"<em>Just started working on google coral devboard. As I seen in blogs and official doc I need to convert FLOAT 32 bit neural network to QUANTIZED_UNIT8 i.e. 8bit neural network. </em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 19.04):
- Google Dev Board:
- TensorFlow installed from (source or binary):
- Edge TPU
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

As I run the official demo of the google dev board getting very low accuracy while fps is quite good, But the accuracy is no furthur than 50-60 %. 
The model is official and included into dev board itself. 
Can any one have any idea to improve accuracy or it will be same because of 8 bit neural network."
28854,Error loading a TensorRT optimised graph,"I was able to convert a frozen model using the tensorRT API on a Nvidia Tesla P100 on Debian 9 using the command

```
trt_graph = trt.create_inference_graph(
    input_graph_def=saved_graph,
    outputs=output_names[0:1],
    max_batch_size=1,
    max_workspace_size_bytes=5000000000,
    precision_mode='FP16',
    is_dynamic_op=True
)
```

I am able to load the graph on the same system. However, when I try to load the graph on my local system which has an Nvidia GeForce GTX 1050M I get the following error.

```
  File ""/home/fuzzybatman/.local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/fuzzybatman/.local/lib/python3.7/site-packages/tensorflow/python/framework/importer.py"", line 426, in import_graph_def
    graph._c_graph, serialized, options)  # pylint: disable=protected-access

tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'TRTEngineOp' in binary running on ceph. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
```

Is it because my GPU lacks support for TensorRT?"
28852,"after quantization aware training, add operation of resdural block lack min/max value, why? anyone can help?","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.12/1.13
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:9.2
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
after quantization aware training, when convert to tflite, Array slim_mobilenetv2/Add, which is an input to the Conv operator producing the output array slim_mobilenetv2/Conv_6/Relu6, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.
Fatal Python error: Aborted

**Describe the expected behavior**
can't convert to tflite?There should have min/max value?


**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28851,Keras Custom Conv2D layer does not work (`None` gradient issue),"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

```python
class CustomConv2D(Conv2D):
    def __init__(self,
                 filters,
                 kernel_size,
                 strides=(1, 1),
                 padding='valid',
                 dilation_rate=(1, 1),
                 activation=None,
                 use_bias=True,
                 kernel_initializer=tf.keras.initializers.TruncatedNormal(0.0, 0.01),
                 bias_initializer='zeros',
                 kernel_regularizer=None,
                 bias_regularizer=None,
                 activity_regularizer=None,
                 kernel_constraint=None,
                 bias_constraint=None,
                 **kwargs):
        
        self.pad_type = padding.lower()
        super(CustomConv2D, self).__init__(filters,
                                           kernel_size,
                                           strides,
                                           self.pad_type if self.pad_type in ['valid', 'same'] else 'valid',
                                           'channels_last',
                                           dilation_rate,
                                           activation,
                                           use_bias,
                                           kernel_initializer,
                                           bias_initializer,
                                           activity_regularizer,
                                           kernel_constraint,
                                           bias_constraint,
                                           **kwargs)
    
    def call(self, input):
        if self.pad_type in ['symmetric', 'reflect']:
            input_rows = tf.shape(input)[2]
            filter_rows = self.kernel_size[0]
            out_rows = (input_rows + self.strides[0] - 1) // self.strides[0]
            padding_rows = tf.maximum(0, (out_rows - 1) * self.strides[0] +
                                      (filter_rows - 1) * self.dilation_rate[0] + 1 - input_rows)
            rows_odd = tf.mod(padding_rows, 2)

            input_cols = tf.shape(input)[3]
            filter_cols = self.kernel_size[1]
            out_cols = (input_cols + self.strides[1] - 1) // self.strides[1]
            padding_cols = tf.maximum(0, (out_cols - 1) * self.strides[1] +
                                      (filter_cols - 1) * self.dilation_rate[1] + 1 - input_cols)
            cols_odd = tf.mod(padding_cols, 2)

            output = tf.pad(input, [[0, 0], [padding_rows // 2, padding_rows // 2 + rows_odd],
                            [padding_cols // 2, padding_cols // 2 + cols_odd], [0, 0]], mode=self.pad_type)

            return K.conv2d(output,
                            self.kernel,
                            strides=self.strides,
                            padding='valid',
                            data_format=self.data_format,
                            dilation_rate=self.dilation_rate)

        elif self.pad_type in ['same', 'valid']:
            return K.conv2d(input,
                            self.kernel,
                            strides=self.strides,
                            padding=self.padding,
                            data_format=self.data_format,
                            dilation_rate=self.dilation_rate)
```
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
  - Windows 10 & Linux Ubuntu 16.04 LTS
- TensorFlow installed from (source or binary):
  - pip install tensorflow (cpu version)
- TensorFlow version (use command below):
- Python version: 3.7.3
- Bazel version (if compiling from source): Not related
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: Not related
- GPU model and memory: Not related

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
My custom conv2d layer shows the following error message.
```bash
ValueError: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.
```
I'm not using any common ops (K.argmax, Kround, etc.) explicitly in 
```python
elif self.pad_type in ['same', 'valid']:
            return K.conv2d(input,
                            self.kernel,
                            strides=self.strides,
                            padding=self.padding,
                            data_format=self.data_format,
                            dilation_rate=self.dilation_rate)
```
What am I missing?

**Describe the expected behavior**
Just working

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```python
inputs = Input(shape=(None, None, 1))
x = inputs
x = CustomConv2D(filters=1, kernel_size=(k, k), padding='same')(x)
model = Model(inputs=inputs, outputs=x)
optimizer = Adam(config.learning_rate, config.momentum)
model.compile(loss='mean_squared_error',
                         optimizer=optimizer)
model.fit_generator(batch_gen, epochs=100, steps_per_epoch=10)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28849,Python3 type annotation does not work with @tf.function + for loop -> tf.while_loop conversion,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0 alpha
- Python version: 3.6.7
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
If you use python3 type annotation such as x:tf.Tensor = tf.constant(0) (I aliased tf.Tensor for various shape to keep my sanity for reinforcement learning problems) in a @tf.function and the function contains a for loop to be translated to tf.while_loop (that doesn't even have to use the tensor that's annotated), the code will fail as if you did not turn on eager execution.

**Describe the expected behavior**
Python3 type hinting should not fail the code.

**Code to reproduce the issue**
```
@tf.function
def tf_for_tf_break():
    x: tf.Tensor = tf.constant(0)
    for i in tf.range(5):
        x += i
    return x

print(tf_for_tf_break())
```

**Other info / logs**
WARNING: Logging before flag parsing goes to stderr.
W0519 21:35:32.992043 140297958307648 tf_logging.py:161] Entity <function tf_for_tf_break at 0x7f99a9edde18> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: AttributeError during conversion: 'NoneType' object has no attribute '_fields'
Traceback (most recent call last):
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py"", line 393, in function_to_graph
    node = node_to_graph(node, context)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py"", line 436, in node_to_graph
    node = converter.standard_analysis(node, context, is_initial=True)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/core/converter.py"", line 493, in standard_analysis
    graphs = cfg.build(node)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/cfg.py"", line 813, in build
    visitor.visit(node)
  File ""/usr/lib/python3.6/ast.py"", line 253, in visit
    return visitor(node)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/cfg.py"", line 672, in visit_FunctionDef
    self.visit(stmt)
  File ""/usr/lib/python3.6/ast.py"", line 253, in visit
    return visitor(node)
  File ""/usr/lib/python3.6/ast.py"", line 257, in generic_visit
    for field, value in iter_fields(node):
  File ""/usr/lib/python3.6/ast.py"", line 171, in iter_fields
    for field in node._fields:
AttributeError: 'NoneType' object has no attribute '_fields'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 369, in converted_call
    experimental_partial_types=partial_types)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 513, in to_graph
    arg_values, arg_types)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py"", line 190, in entity_to_graph
    node, name, ns = function_to_graph(o, program_ctx, arg_values, arg_types)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py"", line 396, in function_to_graph
    raise errors.InternalError('conversion', e)
tensorflow.python.autograph.pyct.errors.InternalError: AttributeError during conversion: 'NoneType' object has no attribute '_fields'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/jackshi/MagneticAccelerator/descrete_optimization/tf_scratch.py"", line 12, in <module>
    print(tf_for_tf_break())
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 426, in __call__
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 370, in _initialize
    *args, **kwds))
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1313, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1580, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1512, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 694, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 317, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 686, in wrapper
    ), args, kwargs)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 390, in converted_call
    return _call_unconverted(f, args, kwargs)
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 188, in _call_unconverted
    return f(*args, **kwargs)
  File ""/home/jackshi/MagneticAccelerator/descrete_optimization/tf_scratch.py"", line 7, in tf_for_tf_break
    for i in tf.range(5):
  File ""/home/jackshi/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 449, in __iter__
    ""Tensor objects are only iterable when eager execution is ""
TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.
"
28848,ImportError: DLL load failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.13
- Python version: 3.6.7
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.21.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0/7.5.1
- GPU model and memory:RTX2070



**Describe the problem**
I'm installing tf from source using bazel and I'm trying to use CUDA, when I build pip package by using: bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package 
**Provide the exact sequence of commands / steps that you executed before running into the problem**

bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package 

**Any other info / logs**

ERROR: E:/tensorflow/tensorflow/BUILD:573:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1): bash.exe failed: error executing command
  cd C:/users/dylan/_bazel_dylan/4ejpfwyr/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0
    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0
    SET PATH=C:\msys64\usr\bin;C:\msys64\bin
    SET PYTHON_BIN_PATH=C:/Users/dylan/AppData/Local/Programs/Python/Python36/python.exe
    SET PYTHON_LIB_PATH=C:/Users/dylan/AppData/Local/Programs/Python/Python36/lib/site-packages
    SET TF_CUDA_CLANG=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=5.0
    SET TF_CUDA_VERSION=10.0
    SET TF_CUDNN_VERSION=7
    SET TF_NEED_CUDA=1
    SET TF_NEED_OPENCL_SYCL=0
    SET TF_NEED_ROCM=0
  C:/msys64/usr/bin/bash.exe bazel-out/x64_windows-opt/genfiles/tensorflow/tf_python_api_gen_v1.genrule_script.sh
Execution platform: @bazel_tools//platforms:host_platform
Traceback (most recent call last):
  File ""\\?\C:\Users\dylan\AppData\Local\Temp\Bazel.runfiles_gllyv2tm\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""\\?\C:\Users\dylan\AppData\Local\Temp\Bazel.runfiles_gllyv2tm\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""\\?\C:\Users\dylan\AppData\Local\Temp\Bazel.runfiles_gllyv2tm\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\dylan\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\dylan\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""\\?\C:\Users\dylan\AppData\Local\Temp\Bazel.runfiles_gllyv2tm\runfiles\org_tensorflow\tensorflow\python\tools\api\generator\create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""\\?\C:\Users\dylan\AppData\Local\Temp\Bazel.runfiles_gllyv2tm\runfiles\org_tensorflow\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""\\?\C:\Users\dylan\AppData\Local\Temp\Bazel.runfiles_gllyv2tm\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""\\?\C:\Users\dylan\AppData\Local\Temp\Bazel.runfiles_gllyv2tm\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""\\?\C:\Users\dylan\AppData\Local\Temp\Bazel.runfiles_gllyv2tm\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""\\?\C:\Users\dylan\AppData\Local\Temp\Bazel.runfiles_gllyv2tm\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\dylan\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\dylan\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 2207.386s, Critical Path: 378.51s
INFO: 4635 processes: 4635 local.
FAILED: Build did NOT complete successfully
"
28847,how to use tf.contrib.image.rotate in tensorflow 1.1,"Here, we want to use  **tensorflow.contrib.image.rotate** function in our code, it works well in the tensorflow 1.8 version, but does not works well in the tensorflow 1.1 version. Also, if we remove  the **tensorflow.contrib.image.rotate** function , it also works well in the 1.1 tensorflow.  So how can I use the tensorflow.contrib.image.rotate in tensorflow 1.1 version.

The tensorflow.contrib.image.rotate has changed with the tensorflow library. In 1.1 version, Click [tf.contrib.image.rotate](https://github.com/tensorflow/docs/blob/r1.1/site/en/api_docs/python/tf/contrib/image/rotate.md) 
```
rotate(
    images,
    angles
)

```
and in 1.8 version, click [tf.contrib.image.rotate](https://github.com/tensorflow/docs/blob/r1.8/site/en/api_docs/python/tf/contrib/image/rotate.md). 
```
tf.contrib.image.rotate(
    images,
    angles,
    interpolation='NEAREST',
    name=None
)
```
So we remove the **interpolation='BILINEAR** parameters.  

Here is some of my code:
```
# coding=utf-8

import os
import numpy as np

import tensorflow as tf
from tensorflow.contrib.image import rotate as images_rotate

slim = tf.contrib.slim

def image_rotation(x):
  rands = tf.truncated_normal([tf.shape(x)[0]], stddev=0.05)
  return images_rotate(x, rands)

def graph(x, y, i, x_max, x_min, grad):
    eps = 2.0 * 32 / 255.0
    num_iter = 15
    alpha = eps / num_iter
    momentum = 1
    num_classes = 110

    with slim.arg_scope(inception_v1.inception_v1_arg_scope()):
        logits_v1, end_points_v1 = inception_v1.inception_v1(
            image_rotation(x), num_classes=num_classes, is_training=False)

    one_hot = tf.one_hot(y, num_classes)
    logits = logits_v1

    cross_entropy = tf.losses.softmax_cross_entropy(one_hot,
                                                    logits,
                                                    label_smoothing=0.0,
                                                    weights=1.0)
    noise = tf.gradients(cross_entropy, x)[0]

    kernel = gkern(7, 4).astype(np.float32)
    stack_kernel = np.stack([kernel, kernel, kernel]).swapaxes(2, 0)
    stack_kernel = np.expand_dims(stack_kernel, 3)

    noise = tf.nn.depthwise_conv2d(noise, stack_kernel, strides=[1, 1, 1, 1], padding='SAME')

    x = x + 2 * tf.sign(noise)
    return x, y, i, x_max, x_min, noise


def stop(x, y, i, x_max, x_min, grad):
  num_iter = FLAGS.num_iter
  return tf.less(i, num_iter)


def main(input_dir, output_dir):

    eps = 2 * 32 / 255.0
    batch_shape = [1, 224, 224, 3]

    with tf.Graph().as_default():
        # Prepare graph
        x_input = tf.placeholder(tf.float32, shape=batch_shape)
        x_max = tf.clip_by_value(x_input + eps, -1.0, 1.0)
        x_min = tf.clip_by_value(x_input - eps, -1.0, 1.0)

        y = tf.constant(np.zeros([FLAGS.batch_size]), tf.int64)
        i = tf.cast(tf.constant(0), tf.float32)

        grad = tf.zeros(shape=batch_shape)

        x_adv, _, _, _, _, _ = tf.while_loop(stop, graph, [x_input, y, i, x_max, x_min, grad])

```

Our environment is：
> 1. cuda8.0 
> 2. tensorflow1.1

And the problems is attached here:
```
Traceback (most recent call last):
  File ""attack_iter_notarge_attack_Grad_Rand.py"", line 352, in <module>
    tf.app.run()
  File ""/home/xuchao/anaconda3/envs/tensorflow1.1/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""attack_iter_notarge_attack_Grad_Rand.py"", line 343, in main
    notarget_grad_rand_attack(FLAGS.input_dir, FLAGS.output_dir)
  File ""attack_iter_notarge_attack_Grad_Rand.py"", line 303, in notarget_grad_rand_attack
    x_adv, _, _, _, _, _ = tf.while_loop(stop, caad18_grad_rand_notarget_graph, [x_input, y, i, x_max, x_min, grad])
  File ""/home/xuchao/anaconda3/envs/tensorflow1.1/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2623, in while_loop
    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/home/xuchao/anaconda3/envs/tensorflow1.1/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2456, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/home/xuchao/anaconda3/envs/tensorflow1.1/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2406, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""attack_iter_notarge_attack_Grad_Rand.py"", line 258, in caad18_grad_rand_notarget_graph
    noise = tf.nn.depthwise_conv2d(noise, stack_kernel, strides=[1, 1, 1, 1], padding='SAME')
  File ""/home/xuchao/anaconda3/envs/tensorflow1.1/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py"", line 372, in depthwise_conv2d
    input = ops.convert_to_tensor(input, name=""tensor_in"")
  File ""/home/xuchao/anaconda3/envs/tensorflow1.1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 639, in convert_to_tensor
    as_ref=False)
  File ""/home/xuchao/anaconda3/envs/tensorflow1.1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 704, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/xuchao/anaconda3/envs/tensorflow1.1/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 113, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/xuchao/anaconda3/envs/tensorflow1.1/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 102, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/home/xuchao/anaconda3/envs/tensorflow1.1/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 360, in make_tensor_proto
    raise ValueError(""None values not supported."")
ValueError: None values not supported.
```

I have searched for the problems on the website, and someones say it caused by the tf.contrib.image.rotate function can't work in the GPU environment in the tensorflow 1.1 version, so, I modify the image_rotation with:
```
def image_rotation(x):
  rands = tf.truncated_normal([tf.shape(x)[0]], stddev=0.05)
  with tf.device('/cpu:0'):
        input_tensor = tf.contrib.image.rotate(x, rands)
  return input_tensor
```
But it doesn't work well for me, look forward to your help. Thank you!"
28846,TF 2.0 crossed_column  on Windows fails with SystemError: <built-in function TFE_Py_FastPathExecute> returned a result with an error set,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.0-9492-g2c319fb415 2.0.0-alpha0
- Python version: 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The code snippets works fine on Colab but gives the following error on Windows:

```
OverflowError: Python int too large to convert to C long
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\IPython\core\interactiveshell.py"", line 3296, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-6-6cfdea12e863>"", line 44, in <module>
    demo(feature_column.indicator_column(crossed_feature))
  File ""<ipython-input-6-6cfdea12e863>"", line 36, in demo
    print(feature_layer(example_batch))
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 660, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 473, in call
    self._state_manager)
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 4391, in get_dense_tensor
    return transformation_cache.get(self, state_manager)
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 2573, in get
    transformed = column.transform_feature(self, state_manager)
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 4330, in transform_feature
    transformation_cache, state_manager)
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 4184, in get_sparse_tensors
    transformation_cache.get(self, state_manager), None)
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 2573, in get
    transformed = column.transform_feature(self, state_manager)
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py"", line 4145, in transform_feature
    hash_key=self.hash_key)
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\ops\sparse_ops.py"", line 564, in sparse_cross_hashed
    name=name)
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\ops\sparse_ops.py"", line 617, in _sparse_cross_internal
    name=name)
  File ""C:\Users\user\Anaconda3\envs\tf2\lib\site-packages\tensorflow\python\ops\gen_sparse_ops.py"", line 1372, in sparse_cross
    ""internal_type"", internal_type)
SystemError: <built-in function TFE_Py_FastPathExecute> returned a result with an error set
```
Executing:
```
import sys
sys.maxsize
```

gives:
`9223372036854775807`

**Describe the expected behavior**
Same output as running on Colab:

![image](https://user-images.githubusercontent.com/2398765/57988793-d5c2c180-7ac4-11e9-8b33-02f3cdb22abc.png)


**Code to reproduce the issue**
```
import tensorflow as tf
import pandas as pd

from tensorflow import feature_column
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split

URL = 'https://storage.googleapis.com/applied-dl/heart.csv'
dataframe = pd.read_csv(URL)
dataframe.head()

train, test = train_test_split(dataframe, test_size=0.2)
train, val = train_test_split(train, test_size=0.2)

def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  labels = dataframe.pop('target')
  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  return ds


batch_size = 5 # A small batch sized is used for demonstration purposes
train_ds = df_to_dataset(train, batch_size=batch_size)
val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)
test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)

example_batch = next(iter(train_ds))[0]

# A utility method to create a feature column
# and to transform a batch of data
def demo(feature_column):
  feature_layer = layers.DenseFeatures(feature_column)
  print(feature_layer(example_batch))

age = feature_column.numeric_column(""age"")
age_buckets = feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])
thal = feature_column.categorical_column_with_vocabulary_list(
      'thal', ['fixed', 'normal', 'reversible'])

crossed_feature = feature_column.crossed_column([age_buckets, thal], hash_bucket_size=3)
demo(feature_column.indicator_column(crossed_feature))
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28845,GPU visible device selection causes segfault in tf-nightly-gpu,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): tf-nightly-gpu==1.14.1.dev20190519
- Python version: 2.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The following code causes a segfault:
```python
import tensorflow as tf

config = tf.ConfigProto()
config.gpu_options.visible_device_list = '0'
sess = tf.Session(config=config)
print(sess)
```

**Describe the expected behavior**
No segfault.  GPU pinning should work.

cc @jaingaurav"
28844,TF2.0 leaking memory when input_shape is specified in keras layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): there is a custom MWE code snippet included in the issue
- OS Platform and Distribution: Linux Elementary Loki (Ubuntu 16.04)
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0.0-alpha0
- Python version: 3.7.1

**Describe the current behavior**
Generating several models with no input shape specified results in normal memory occupancy:

```python
import time

from tensorflow import keras


for _ in range(100):
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(120, activation='relu'))
    model.compile(loss='binary_crossentropy',
                  optimizer=keras.optimizers.SGD())
    time.sleep(0.1)
```
![no_shape](https://user-images.githubusercontent.com/472900/57986674-e39a2780-7a6f-11e9-909f-ac244abbcc4b.png)

This is the behavior expected when the input shape is specified. However, when multiple models are generated within the same program life cycle, the specification of an input shape seems to produce a memory leak.

If the input shape is specified when the models are created, they pile up in memory, without being destroyed. Also the execution time seems to increase quite a lot.

```python
import time

from tensorflow import keras


for _ in range(100):
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(120, activation='relu', input_shape=(10, 10)))
    model.compile(loss='binary_crossentropy',
                  optimizer=keras.optimizers.SGD())
    time.sleep(0.1)
```

![shape](https://user-images.githubusercontent.com/472900/57986711-67541400-7a70-11e9-9743-5528ece4417b.png)

**Describe the expected behavior**
Model generation should behave the same from a memory point of view regardless of whether the input shape is specified or not.

**Code to reproduce the issue**
It is enough to execute the code snippets included in the issue. In order to generate the memory occupancy, the `memory_profiler` package can be used. Assuming the code snippet is pasted in a file called `test.py`, run:

```
$ mprof run --include-children python test.py
$ mprof plot
```

**Other info / logs**
I generated a list of all the objects for the 2 code snippets, using `Pympler`.

```python
from pympler import muppy
from pympler import summary

...

all_objects = muppy.get_objects()
occupancy = summary.summarize(all_objects)
summary.print_(occupancy)
```

For the models generated without input shape, here is the result:

```
                                                                   types |   # objects |   total size
======================================================================== | =========== | ============
                                                             <class 'str |       79278 |     14.02 MB
                                                            <class 'dict |       14468 |      6.93 MB
                                                            <class 'code |       25252 |      3.49 MB
                                                            <class 'type |        2582 |      2.57 MB
                                                            <class 'list |        8573 |    944.06 KB
                                                           <class 'tuple |       12079 |    796.21 KB
                                                             <class 'set |         732 |    466.12 KB
                                                         <class 'weakref |        4475 |    349.61 KB
                                                     <class 'abc.ABCMeta |         341 |    346.27 KB
                     <class 'tensorflow.core.framework.op_def_pb2.ArgDef |        3822 |    328.45 KB
  <class 'google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType |         369 |    320.16 KB
                                                            <class 'cell |        5921 |    277.55 KB
                                                     function (__init__) |        1694 |    224.98 KB
                                                        <class 'property |        2466 |    192.66 KB
                                              <class 'wrapper_descriptor |        2353 |    183.83 KB
```

And here is the snapshot for the models generated with the input shape.

```
                                                           types |   # objects |   total size
================================================================ | =========== | ============
                                                   <class 'tuple |      296304 |     26.77 MB
                                                    <class 'dict |       71296 |     16.14 MB
                                                     <class 'str |       84828 |     14.54 MB
                                                     <class 'int |      395032 |     10.55 MB
                                                    <class 'list |       98027 |      9.89 MB
                                                    <class 'code |       25281 |      3.49 MB
                                                    <class 'type |        2587 |      2.58 MB
                                                     <class 'set |        2944 |    975.00 KB
               <class 'tensorflow.python.framework.ops.Operation |       14100 |    771.09 KB
    <class 'tensorflow.python.framework.ops.Operation._InputList |       14100 |    771.09 KB
                  <class 'tensorflow.python.framework.ops.Tensor |       14100 |    771.09 KB
  <class 'tensorflow.python.pywrap_tensorflow_internal.TF_Output |       13200 |    721.88 KB
                                            <class 'SwigPyObject |       14100 |    660.94 KB
                                 <class 'collections.OrderedDict |        1262 |    622.22 KB
                                                 <class 'weakref |        6127 |    478.67 KB
```

Edit: typo in `keras.models`
Edit: typo in `keras.layers`"
28843,TF2.0 DocSprint Prep - Error with Dataset Example,"## URL(s) with the issue:

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset

## Description of issue (what needs changing):

The Example for ""from_generator"" fails.

### Clear description

This example uses tf.enable_eager_execution() which gives the following error
AttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'

If you remove this line of code the example runs but identifies this code is deprecated in TF V2.

### Correct links

I do not see a link to the source.

### Parameters defined

The parameters are defined but the example only uses three of the four parameters.  The last parameter is optional but not shown how to be used.

### Returns defined

The return code is defined correctly as a dataset.

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

There is a usage example.  This PR is regarding the example.

### Request visuals, if applicable

There are not example.

### Submit a pull request?
yes
https://github.com/tensorflow/tensorflow/pull/28842

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
yes
https://github.com/tensorflow/tensorflow/pull/28842
"
28841, tf.Dataset.map() only processes one example in my dataset,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.12.2
- Python version: 3.5
- CUDA/cuDNN version: V8.0.61
- GPU model and memory: Tesla P100-PCIE, 12193MiB

**Describe the current behavior**
I have a dataset containing 592 examples, but `tf.Dataset.map` only processes one of those, as evidenced by a global counter, which I increment in the function given to `map()`. Why is it not processing all examples in the dataset? I run in eager execution, but code inside `.map()` is not executed eagerly.

**Describe the expected behavior**
All 592 examples in my dataset should be processed (with the counter being 592 afterwards).

**Code to reproduce the issue**
My dataset: https://we.tl/t-rZYNJ6I9oU

```
from __future__ import absolute_import, division, print_function
import tensorflow as tf
import numpy as np
import sys
import utilities

counter = 0

def decode_png_mask(image_buffer):
    """"""
    Takes string of bytes encoding a PNG and produces a tensor image
    """"""
    image = tf.squeeze(tf.image.decode_image(image_buffer, channels=1), axis=2)
    image.set_shape([None, None])
    image = tf.greater(image, 0)
    image = tf.cast(image, dtype=tf.uint8)
    return image

def masks_to_onehots(tag_masks, tag_class_indices, num_classes):
    def onehotify(pixel_tag_masks):
        tag_mask_sizes_suppressed = tf.where(tf.not_equal(tag_mask_sizes, 0), tag_mask_sizes, tag_mask_sizes + 9999999)
        smallest_mask_index = tf.argmin(tag_mask_sizes_suppressed)
        onehot = tf.one_hot(smallest_mask_index
                            , depth=num_classes, dtype=tf.uint8)
        return onehot
    tag_mask_sizes = tf.reduce_sum(tag_masks, axis=[1, 2])
    image_masks = tf.transpose(tag_masks, perm=[1, 2, 0])
    onehots = tf.map_fn(lambda x: tf.map_fn(onehotify, x), image_masks)
    return onehots

def parse_example(example_proto, width, height, num_classes):
    features = {
        'image/encoded': tf.FixedLenFeature((), tf.string),
        'image/height': tf.FixedLenFeature((), tf.int64),
        'image/width': tf.FixedLenFeature((), tf.int64),
        'image/filename': tf.FixedLenFeature((), tf.string),
        'image/object/bbox/xmin': tf.VarLenFeature(tf.float32),
        'image/object/bbox/xmax': tf.VarLenFeature(tf.float32),
        'image/object/bbox/ymin': tf.VarLenFeature(tf.float32),
        'image/object/bbox/ymax': tf.VarLenFeature(tf.float32),
        'image/object/class/label': tf.VarLenFeature(tf.int64),
        'image/object/class/text': tf.VarLenFeature(tf.string),
        'image/object/mask': tf.VarLenFeature(tf.string),
        'image/depth': tf.FixedLenFeature((), tf.string)
    }

    global counter
    counter = counter + 1

    parsed_example = tf.parse_single_example(example_proto, features)

    # Decode image
    image = tf.image.decode_jpeg(parsed_example['image/encoded'])
    parsed_example['image/encoded'] = image

    tag_masks = tf.sparse.to_dense(parsed_example['image/object/mask'], default_value="""")
    tag_masks = tf.map_fn(decode_png_mask, tag_masks, dtype=tf.uint8)
    tag_masks = tf.reshape(tag_masks, shape=tf.stack([-1, height, width]), name='tag_masks')

    # All segmentation now have their mask in mask, their labelmap index in classes_indices and their tagname in classes_text
    tag_class_indices = tf.sparse.to_dense(parsed_example['image/object/class/label'])
    tag_class_names = tf.sparse.to_dense(parsed_example['image/object/class/text'], default_value="""")
    onehots = masks_to_onehots(tag_masks, tag_class_indices, num_classes)
    parsed_example['image/labels'] = onehots

    return parsed_example

tf.enable_eager_execution()

NUM_CLASSES = 21

tfrecord_train = ""/path/to/tf.record""
dataset_train = tf.data.TFRecordDataset(tfrecord_train)

# Read image widht/height from the TFRecord file
iterator = dataset_train.make_one_shot_iterator()
next_element = iterator.get_next()
parsed_element = np.fromstring(next_element.numpy(), dtype=np.uint8)
example = tf.train.Example.FromString(parsed_element)
height = example.features.feature['image/height'].int64_list.value[0]
width = example.features.feature['image/width'].int64_list.value[0]

dataset_train = dataset_train.map(lambda x: parse_example(x, width, height, NUM_CLASSES))
print(counter)
```
"
28840,tf.make_ndarray() throws an AttributeError: 'Tensor' object has no attribute 'tensor_shape',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.12.2
- Python version: 3.5
- CUDA/cuDNN version: V8.0.61
- GPU model and memory: Tesla P100-PCIE, 12193MiB

**Describe the current behavior**
When calling `tf.make_ndarray()` on a tensor (`<class 'tensorflow.python.framework.ops.Tensor'>`, dtype `uint8`, shape `(?, 1000, 1500)`), I get the following error:

`File ""/home/.../python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 563, in MakeNdarray
    shape = [d.size for d in tensor.tensor_shape.dim]
AttributeError: 'Tensor' object has no attribute 'tensor_shape'`

I call the function inside a function given to `tf.Dataset.map()`, which is not executing eagerly. However, the error also occurs when using eager execution (as tested by using a for-loop on the dataset instead of `.map()`).

**Describe the expected behavior**
I expect `tf.make_ndarray()` to return a NumPy array as advertised :)

**Code to reproduce the issue**
My dataset: https://we.tl/t-rZYNJ6I9oU

```
from __future__ import absolute_import, division, print_function
import tensorflow as tf
import numpy as np
import os
import sys

def decode_png_mask(image_buffer):

    """"""
    Takes string of bytes encoding a PNG and produces a tensor image
    """"""
    image = tf.squeeze(tf.image.decode_image(image_buffer, channels=1), axis=2)
    image.set_shape([None, None])
    image = tf.greater(image, 0)
    image = tf.cast(image, dtype=tf.uint8)
    return image

def masks_to_onehots(tag_masks, tag_class_indices, num_classes):

    def onehotify(pixel_tag_masks):
        nonzero_indices = np.flatnonzero(pixel_tag_masks)
        tag_mask_sizes_suppressed = [tag_mask_sizes[i] if i in nonzero_indices else 9999999 for i in range(len(tag_mask_sizes))]
        smallest_mask_index = np.argmin(tag_mask_sizes_suppressed)
        class_index = tag_class_indices[smallest_mask_index]
        onehot = eye[class_index]
        return onehot

    eye = np.eye(num_classes)
    tag_masks = tf.make_ndarray(tag_masks) #tag_masks = tag_masks.numpy()
    tag_class_indices = tf.make_ndarray(tag_class_indices) #tag_class_indices = tag_class_indices.numpy()
    tag_mask_sizes = np.sum(tag_masks, axis=(1, 2))
    image_masks = np.transpose(tag_masks, axes=[1, 2, 0])
    onehots = np.apply_along_axis(onehotify, axis=2, arr=image_masks)
    #onehots = np.array([[eye[tag_class_indices[np.argmin([tag_mask_sizes[i] if i in np.flatnonzero(pixel_tag_masks) else 9999999 for i in range(len(tag_mask_sizes))])]] for pixel_tag_masks in image_masks[height]] for height in range(image_masks.shape[0])])
    return tf.convert_to_tensor(onehots)

def parse_example(example_proto, width, height, num_classes):
    features = {
        'image/encoded': tf.FixedLenFeature((), tf.string),
        'image/height': tf.FixedLenFeature((), tf.int64),
        'image/width': tf.FixedLenFeature((), tf.int64),
        'image/filename': tf.FixedLenFeature((), tf.string),
        'image/object/bbox/xmin': tf.VarLenFeature(tf.float32),
        'image/object/bbox/xmax': tf.VarLenFeature(tf.float32),
        'image/object/bbox/ymin': tf.VarLenFeature(tf.float32),
        'image/object/bbox/ymax': tf.VarLenFeature(tf.float32),
        'image/object/class/label': tf.VarLenFeature(tf.int64),
        'image/object/class/text': tf.VarLenFeature(tf.string),
        'image/object/mask': tf.VarLenFeature(tf.string),
        'image/depth': tf.FixedLenFeature((), tf.string)
    }

    parsed_example = tf.parse_single_example(example_proto, features)

    # Decode image
    image = tf.image.decode_jpeg(parsed_example['image/encoded'])
    parsed_example['image/encoded'] = image

    tag_masks = tf.sparse.to_dense(parsed_example['image/object/mask'], default_value="""")
    tag_masks = tf.map_fn(decode_png_mask, tag_masks, dtype=tf.uint8)
    tag_masks = tf.reshape(tag_masks, shape=tf.stack([-1, height, width]), name='tag_masks')

    # All segmentation now have their mask in mask, their labelmap index in classes_indices and their tagname in classes_text
    tag_class_indices = tf.sparse.to_dense(parsed_example['image/object/class/label'])
    tag_class_names = tf.sparse.to_dense(parsed_example['image/object/class/text'], default_value="""")
    onehots = masks_to_onehots(tag_masks, tag_class_indices, num_classes)
    parsed_example['image/labels'] = onehots

    return parsed_example

tf.enable_eager_execution()

NUM_CLASSES = 21

tfrecord_train = ""/path/to/tf.record""
dataset_train = tf.data.TFRecordDataset(tfrecord_train)

# Read image widht/height from the TFRecord file
iterator = dataset_train.make_one_shot_iterator()
next_element = iterator.get_next()
parsed_element = np.fromstring(next_element.numpy(), dtype=np.uint8)
example = tf.train.Example.FromString(parsed_element)
height = example.features.feature['image/height'].int64_list.value[0]
width = example.features.feature['image/width'].int64_list.value[0]

dataset_train = dataset_train.map(lambda x: parse_example(x, width, height, NUM_CLASSES))
```

**Other info / logs**
Full traceback:

`Traceback (most recent call last):
  File ""/home/local/CYCLOMEDIA001/ebos/Workspace/all_cf/src/experimental/cityfusion/tasks/material_segmentation/semantic_fpn.py"", line 114, in <module>
    dataset_train = dataset_train.map(lambda x: parse_example(x, width, height, NUM_CLASSES))
  File ""/home/.../python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1038, in map
    return MapDataset(self, map_func)
  File ""/home/.../python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 2611, in __init__
    map_func, ""Dataset.map()"", input_dataset)
  File ""/home/.../python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1860, in __init__
    self._function.add_to_graph(ops.get_default_graph())
  File ""/home/.../python3.5/site-packages/tensorflow/python/framework/function.py"", line 479, in add_to_graph
    self._create_definition_if_needed()
  File ""/home/.../python3.5/site-packages/tensorflow/python/framework/function.py"", line 335, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""/home/.../python3.5/site-packages/tensorflow/python/framework/function.py"", line 344, in _create_definition_if_needed_impl
    self._capture_by_value, self._caller_device)
  File ""/home/.../python3.5/site-packages/tensorflow/python/framework/function.py"", line 864, in func_graph_from_py_func
    outputs = func(*func_graph.inputs)
  File ""/home/.../python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1794, in tf_data_structured_function_wrapper
    ret = func(*nested_args)
  File ""/path/to/script.py"", line 114, in <lambda>
    dataset_train = dataset_train.map(lambda x: parse_example(x, width, height, NUM_CLASSES))
  File ""path/to/script.py"", line 86, in parse_example
    onehots = masks_to_onehots(tag_masks, tag_class_indices, num_classes)
  File ""/path/to/script.py"", line 25, in masks_to_onehots
    tag_masks = tf.make_ndarray(tag_masks) #tag_masks = tag_masks.numpy()
  File ""/home/.../python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 563, in MakeNdarray
    shape = [d.size for d in tensor.tensor_shape.dim]
AttributeError: 'Tensor' object has no attribute 'tensor_shape'`
"
28839,error: default initialization of an object of const type 'const Subgraph::Identity' without a user-provided default constructor,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
OS X 10.11.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
Source
- TensorFlow version:
13.1
- Python version:
3.6.7
- Installed using virtualenv? pip? conda?:
Conda
- Bazel version (if compiling from source):
bazel 18.1 & 0.21.1
- GCC/Compiler version (if compiling from source):
$ g++ --version
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin15.6.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
MacBook-Pro:tensorflow davidlaxer$ c++ --version
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin15.6.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
MacBook-Pro:tensorflow davidlaxer$ clang --version
clang version 5.0.0 (tags/RELEASE_500/final)
Target: x86_64-apple-darwin15.6.0
Thread model: posix
InstalledDir: /Users/davidlaxer/anaconda/bin
MacBook-Pro:tensorflow davidlaxer$ which clang
/Users/davidlaxer/anaconda/bin/clang
MacBook-Pro:tensorflow davidlaxer$ /Users/davidlaxer/anaconda/bin/clang --version
clang version 5.0.0 (tags/RELEASE_500/final)
Target: x86_64-apple-darwin15.6.0
Thread model: posix

- CUDA/cuDNN version:
CPU Only
- GPU model and memory:



**Describe the problem**
ERROR: /Users/davidlaxer/tensorflow/tensorflow/core/grappler/graph_analyzer/BUILD:5:1: C++ compilation of rule '//tensorflow/core/grappler/graph_analyzer:graph_analyzer_lib' failed (Exit 1)
tensorflow/core/grappler/graph_analyzer/graph_analyzer.cc:75:28: error: default initialization of an object of const type 'const Subgraph::Identity' without a user-provided default constructor
  const Subgraph::Identity empty_parent;
                           ^
                                       {}
1 error generated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28838,TFLite GPU support for C++,"**System information**
- TensorFlow version (you are using): 0.0.1-gpu-experimental
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Anyone know if Tensorflow Lite has GPU support for C++ (or Python)? I've seen guides for Android and iOS, but I haven't come across anything about C++ (or Python).

**Who will benefit with this feature?**

C++ and Python developers.
"
28837,Support Stateful LSTM on TPU,"<em>Cannot use LSTM model with tf.keras if Stateful = True on TPU</em>

**System information**
- TensorFlow version (you are using): 1.13

**Describe the feature and the current behavior/state.**
if I build tf.keras model and then try to convert to TPU model it gives: 

`WARNING:tensorflow:Model replication does not currently support stateful models.  Degrading to a single core.`

**Will this change the current api? How?**
unlikely

**Who will benefit with this feature?**
anyone to research time-series prediction

**Any Other info.**
"
28836,"No gradients provided for any variable: ['cnn_model_14/conv2d_42/kernel:0', 'cnn_model_14/conv2d_42/bias:0', 'cnn_model_14/conv2d_43/kernel:0', 'cnn_model_14/conv2d_43/bias:0', 'cnn_model_14/dense_28/kernel:0', 'cnn_model_14/dense_28/bias:0', 'cnn_model_14/dense_29/kernel:0', 'cnn_model_14/dense_29/bias:0'].","> ---------------------------------------------------------------------------
> ValueError                                Traceback (most recent call last)
> <timed eval> in <module>()
> 
> <ipython-input-92-4e8fa0eeafe4> in train(train_dataset, train_labels_dataset, epochs)
>       8             labels = label_batch
>       9             print('logits->',logits.shape , 'labels->',labels.shape)
> ---> 10             train_step(logits,labels)
>      11 
>      12         if (epoch + 1) % 15 == 0:
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
>     424     # This is the first call of __call__, so we have to initialize.
>     425     initializer_map = {}
> --> 426     self._initialize(args, kwds, add_initializers_to=initializer_map)
>     427     if self._created_variables:
>     428       try:
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
>     368     self._concrete_stateful_fn = (
>     369         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
> --> 370             *args, **kwds))
>     371 
>     372     def invalid_creator_scope(*unused_args, **unused_kwds):
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
>    1311     if self._input_signature:
>    1312       args, kwargs = None, None
> -> 1313     graph_function, _, _ = self._maybe_define_function(args, kwargs)
>    1314     return graph_function
>    1315 
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
>    1578           or call_context_key not in self._function_cache.missed):
>    1579         self._function_cache.missed.add(call_context_key)
> -> 1580         graph_function = self._create_graph_function(args, kwargs)
>    1581         self._function_cache.primary[cache_key] = graph_function
>    1582         return graph_function, args, kwargs
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
>    1510             arg_names=arg_names,
>    1511             override_flat_arg_shapes=override_flat_arg_shapes,
> -> 1512             capture_by_value=self._capture_by_value),
>    1513         self._function_attributes)
>    1514 
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
>     692                                           converted_func)
>     693 
> --> 694       func_outputs = python_func(*func_args, **func_kwargs)
>     695 
>     696       # invariant: `func_outputs` contains only Tensors, IndexedSlices,
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
>     315         # __wrapped__ allows AutoGraph to swap in a converted function. We give
>     316         # the function a weak reference to itself to avoid a reference cycle.
> --> 317         return weak_wrapped_fn().__wrapped__(*args, **kwds)
>     318     weak_wrapped_fn = weakref.ref(wrapped_fn)
>     319 
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
>     684                   optional_features=autograph_options,
>     685                   force_conversion=True,
> --> 686               ), args, kwargs)
>     687 
>     688         # Wrapping around a decorator allows checks like tf_inspect.getargspec
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, args, kwargs)
>     390     return _call_unconverted(f, args, kwargs)
>     391 
> --> 392   result = converted_f(*effective_args, **kwargs)
>     393 
>     394   # The converted function's closure is simply inserted into the function's
> 
> /tmp/tmplz2l0k7l.py in tf__train_step(logits, labels)
>       5     loss = ag__.converted_call('mean_squared_error', tf.losses, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (labels, logits), {})
>       6     gradient_of_cnn = ag__.converted_call('gradient', cnn_tape, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (loss, model.trainable_variables), {})
> ----> 7     ag__.converted_call('apply_gradients', cnn_optimizer, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_2, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (zip(gradient_of_cnn, model.trainable_variables),), {})
>       8 
>       9 
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in converted_call(f, owner, options, args, kwargs)
>     265 
>     266   if not options.force_conversion and conversion.is_whitelisted_for_graph(f):
> --> 267     return _call_unconverted(f, args, kwargs)
>     268 
>     269   # internal_convert_user_code is for example turned off when issuing a dynamic
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in _call_unconverted(f, args, kwargs)
>     186     return f.__self__.call(args, kwargs)
>     187 
> --> 188   return f(*args, **kwargs)
>     189 
>     190 
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in apply_gradients(self, grads_and_vars, name)
>     394       ValueError: If none of the variables have gradients.
>     395     """"""
> --> 396     grads_and_vars = _filter_grads(grads_and_vars)
>     397     var_list = [v for (_, v) in grads_and_vars]
>     398 
> 
> ~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in _filter_grads(grads_and_vars)
>     922   if not filtered:
>     923     raise ValueError(""No gradients provided for any variable: %s."" %
> --> 924                      ([v.name for _, v in grads_and_vars],))
>     925   if vars_with_empty_grads:
>     926     logging.warning(
> 
> ValueError: No gradients provided for any variable: ['cnn_model_14/conv2d_42/kernel:0', 'cnn_model_14/conv2d_42/bias:0', 'cnn_model_14/conv2d_43/kernel:0', 'cnn_model_14/conv2d_43/bias:0', 'cnn_model_14/dense_28/kernel:0', 'cnn_model_14/dense_28/bias:0', 'cnn_model_14/dense_29/kernel:0', 'cnn_model_14/dense_29/bias:0'].
> 
> 



====================================================================

```

from __future__ import absolute_import, division, print_function, unicode_literals

#!pip install tensorflow-gpu==2.0.0-alpha0
import tensorflow as tf

from tensorflow.keras import datasets, layers, models
print(tf.__version__)
import os
import time
import numpy as np


(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

train_images = train_images.reshape((60000, 28, 28, 1))
test_images = test_images.reshape((10000, 28, 28, 1))

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

# Load training and eval data
((train_data, train_labels),
 (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()
train_data = train_data.reshape((60000,28,28,1))
eval_data = eval_data.reshape((10000,28,28,1))

train_data = train_data/np.float32(255)
train_labels = train_labels.astype(np.int32)  # not required

eval_data = eval_data/np.float32(255)
eval_labels = eval_labels.astype(np.int32)  # not required

EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 16
BUFFER_SIZE = 60000
BATCH_SIZE = 256

# We will reuse this seed overtime (so it's easier)
# to visualize progress in the animated GIF)
seed = tf.random.normal([num_examples_to_generate, noise_dim])


# Batch and shuffle the data
train_dataset = tf.data.Dataset.from_tensor_slices(train_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
train_labels_dataset =  tf.data.Dataset.from_tensor_slices(train_labels).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)


input_shape = (28,28.1)
class cnn_model(tf.keras.Model):
    def __init__(self):
        super(cnn_model,self).__init__()
        
        #self.conv1 = layers.Conv2D(32,(3,3),activation='relu',input_shape= input_shape)
        self.conv1 = layers.Conv2D(32, 3, 3, padding='same', activation='relu')
        self.maxpool = layers.MaxPool2D((2,2))
        self.conv2 = layers.Conv2D(64,(3,3),activation ='relu')
        self.conv3 = layers.Conv2D(128,(3,3),activation='relu')
        self.flatten = layers.Flatten()
        self.dense64 = layers.Dense(64,activation='relu')
        self.dense10 = layers.Dense(10,activation='relu')
        self.dropout = layers.Dropout(0.25)
    def call(self,inputs):
        x = self.conv1(inputs)
        x = self.conv2(x)
        x = self.maxpool(x)
        x = self.dropout(x)
        x = self.flatten(x)
        x = self.dense64(x)
        x = self.dense10(x)
        return x



model = cnn_model()
#result=tf.argmax(model(train_data[:10]))
labels = train_labels[:50]
logits = tf.argmax(model(train_data[:50]),axis=1)
#print(labelss.shape)
print(logits.shape , ':', labels.shape)
print('logits->',logits)
print(""======="")
print('labels->',labels[1])
#print(train_labels[:10])


cnn_optimizer = tf.optimizers.Adam(1e-4)


checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, ""ckpt"")
checkpoint = tf.train.Checkpoint(cnn_optimizer=cnn_optimizer)



# Notice the use of `tf.function`
# This annotation causes the function to be ""compiled"".
@tf.function
def train_step(logits,labels):    
    with tf.GradientTape() as cnn_tape:
        print(""train_step"")
        loss = tf.losses.mean_squared_error(labels,logits)
        #print(""loss"",loss)
        gradient_of_cnn = cnn_tape.gradient(loss,model.trainable_variables)
        
        cnn_optimizer.apply_gradients(zip(gradient_of_cnn,model.trainable_variables))
        
        #cnn_optimizer.minimize(loss,var_list=model.trainable_variables)


def train(train_dataset,train_labels_dataset,epochs):
    for epoch in range(epochs):
        start = time.time()
        
        for train_batch,label_batch in zip(train_dataset,train_labels_dataset):
            print(train_batch.shape,label_batch.shape)
            logits = tf.argmax(model(train_batch),axis=1)
            labels = label_batch
            print('logits->',logits.shape , 'labels->',labels.shape)
            train_step(logits,labels)
            
        if (epoch + 1) % 15 == 0:
            checkpoint.save(file_prefix = checkpoint_prefix)
        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))


%%time
train(train_dataset,train_labels_dataset, EPOCHS)
```"
28835,"No gradients provided for any variable: ['cnn_model_14/conv2d_42/kernel:0', 'cnn_model_14/conv2d_42/bias:0', 'cnn_model_14/conv2d_43/kernel:0', 'cnn_model_14/conv2d_43/bias:0', 'cnn_model_14/dense_28/kernel:0', 'cnn_model_14/dense_28/bias:0', 'cnn_model_14/dense_29/kernel:0', 'cnn_model_14/dense_29/bias:0'].","This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
28833,TypeError: cannot unpack non-iterable NoneType object,"loss = tf.losses.mean_squared_error(labels,logits)
cnn_optimizer = tf.keras.optimizers.Adam(1e-4)

# Notice the use of `tf.function`
# This annotation causes the function to be ""compiled"".
#@tf.function
def train_step(logits,labels):    
    with tf.GradientTape() as cnn_tape:
        print(""train_step"")
        loss = tf.losses.mean_squared_error(labels,logits)
        #print(""loss"",loss)
        gradient_of_cnn = cnn_tape.gradient(loss,model.trainable_variables)
        cnn_optimizer.apply_gradients(gradient_of_cnn)

def train(train_dataset,train_labels_dataset,epochs):
    for epoch in range(epochs):
        start = time.time()
        
        for train_batch,label_batch in zip(train_dataset,train_labels_dataset):
            print(train_batch.shape,label_batch.shape)
            logits = tf.argmax(train_batch)
            labels = label_batch
            train_step(logits,labels)
            
        if (epoch + 1) % 15 == 0:
            checkpoint.save(file_prefix = checkpoint_prefix)
        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

%%time
train(train_dataset,train_labels_dataset, EPOCHS)



(256, 28, 28, 1) (256,)
train_step
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<timed eval> in <module>()

<ipython-input-16-6e197a4fd13b> in train(train_dataset, train_labels_dataset, epochs)
      7             logits = tf.argmax(train_batch)
      8             labels = label_batch
----> 9             train_step(logits,labels)
     10 
     11         if (epoch + 1) % 15 == 0:

<ipython-input-15-c1d555ba6f91> in train_step(logits, labels)
      8         #print(""loss"",loss)
      9         gradient_of_cnn = cnn_tape.gradient(loss,model.trainable_variables)
---> 10         cnn_optimizer.apply_gradients(gradient_of_cnn)

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in apply_gradients(self, grads_and_vars, name)
    394       ValueError: If none of the variables have gradients.
    395     """"""
--> 396     grads_and_vars = _filter_grads(grads_and_vars)
    397     var_list = [v for (_, v) in grads_and_vars]
    398 

~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in _filter_grads(grads_and_vars)
    914   filtered = []
    915   vars_with_empty_grads = []
--> 916   for grad, var in grads_and_vars:
    917     if grad is None:
    918       vars_with_empty_grads.append(var)

TypeError: cannot unpack non-iterable NoneType object

"
28832,bazel still report error: name 'http_archive' is not defined,"I'm experiencing the same error described in issue #27189, when I try to build TF v1.12.2 using Bazel 0.25.2 on a Jetson TX2
```
$ export TF_NEED_CUDA=1
$ export TF_CUDA_VERSION=9.0
$ export CUDA_TOOLKIT_PATH=/usr/local/cuda
$ export TF_CUDNN_VERSION=7.1.5
$ export CUDNN_INSTALL_PATH=/usr/lib/aarch64-linux-gnu/
$ export TF_CUDA_COMPUTE_CAPABILITIES=6.2

$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
ERROR: /home/nvidia/git/tensorflow/WORKSPACE:3:1: name 'http_archive' is not defined
ERROR: Error evaluating WORKSPACE file
ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': error loading package 'external': Could not load //external package
ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': error loading package 'external': Could not load //external package
INFO: Elapsed time: 0.222s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```"
28831,tf-nightly-gpu 2.0 very slow on tape.gradient(),"While migrating to tensorflow 2.0 I found a big performance issue.

```
@tf.function
def onTrainStep(self, data, training=True):

    images, labels = data

    with tf.GradientTape() as tape:
        loss, predictions = self.seq2seq(images, labels, training)

    # Calculate the total probability of the output string.
    probability = tf.nn.softmax(predictions)

    ggn = 0
    if training:
        params = self.seq2seq.trainable_variables

        gradients = tape.gradient(loss, params)
        gradients, _ = tf.clip_by_global_norm(gradients, 5.0)
        ggn = tf.linalg.global_norm(gradients)

        # update op - apply gradients
        self.optimizer.apply_gradients(zip(gradients, params))

    return loss, predictions, probability, ggn

```
### tensorflow-gpu 1.13.1: 
takes 0.7 seconds
### tensorflow-gpu 2.0 nightly
takes 2.4 seconds

### removing `gradients = tape.gradient(loss, params)` and `ggn = tf.linalg.global_norm(gradients)`:
takes 0.3 seconds

That means `gradients = tape.gradient(loss, params)` is consuming most of the time

"
28830,Add Tensorflow Lite GPU Delegates for the desktop,"**System information**
- TensorFlow version (you are using): Tensorflow2.0alpha
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Tensorflow lite only has GPU delegates for iOS and Android devices.

In theory, Tensorflow lite should be able to use desktop Opengles apis through GLAD.

**Will this change the current api? How?**

This will use the existing interfaces for gpu delegates.

**Who will benefit with this feature?**

1. Tensorflow lite will be able to be gpu accelerated on desktops
1. Users of Tensorflow lite can have the same acceleration on the desktop and the mobile devices for ease of development.
1. Nvidia Tegra kits are a desktop-like platform that isn't an Android or iOS device but is able to run compute shaders.
1. Inference on the GPU may now run fast enough and now become suitable for real-time applications compared to the CPU."
28829,FAILED: Build did NOT complete successfully,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04.2**
- TensorFlow installed from (source or binary): source 
- TensorFlow version: git master, should be version 1.13.1
- Python version: 3.6.7
- Installed using virtualenv? pip? conda?: pip 
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: 10.0/7.5.1
- GPU model and memory: Geforce 980M



```console
INFO: From Compiling tensorflow/core/grappler/utils/functions.cc [for host]:
In file included from tensorflow/core/grappler/utils/functions.cc:33:0:
./tensorflow/core/grappler/utils.h: In function 'int tensorflow::grappler::NodePositionIfSameNode(const string&, const string&)':
./tensorflow/core/grappler/utils.h:134:49: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
       std::distance(input_it, input_name.end()) < node_name.size()) {
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~
tensorflow/core/grappler/utils/functions.cc: In function 'tensorflow::Status tensorflow::grappler::ReplaceInputWithConst(const tensorflow::NodeDef&, int, tensorflow::grappler::GrapplerFunctionItem*)':
tensorflow/core/grappler/utils/functions.cc:304:38: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   if (input_index < 0 || input_index >= item->input_size()) {
                          ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~
tensorflow/core/grappler/utils/functions.cc: In function 'tensorflow::Status tensorflow::grappler::RemoveFunctionOutputs(const absl::flat_hash_set<int>&, tensorflow::grappler::GrapplerFunctionItem*, std::vector<std::pair<int, int> >*)':
tensorflow/core/grappler/utils/functions.cc:344:44: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     if (remove_output < 0 || remove_output >= item->output_size()) {
                              ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~
tensorflow/core/grappler/utils/functions.cc:356:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < item->output_size(); ++i) {
                   ~~^~~~~~~~~~~~~~~~~~~~~
In file included from ./tensorflow/core/platform/default/logging.h:24:0,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/core/status.h:25,
                 from ./tensorflow/core/lib/core/errors.h:21,
                 from ./tensorflow/core/framework/tensor_shape.h:23,
                 from ./tensorflow/core/framework/partial_tensor_shape.h:20,
                 from ./tensorflow/core/framework/attr_value_util.h:23,
                 from ./tensorflow/core/framework/function.h:22,
                 from ./tensorflow/core/grappler/utils/functions.h:26,
                 from tensorflow/core/grappler/utils/functions.cc:15:
./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':
./tensorflow/core/util/tensor_format.h:470:54:   required from here
./tensorflow/core/util/tensor_format.h:444:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   CHECK(index >= 0 && index < dimension_attribute.size())
./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))
                                               ^
./tensorflow/core/util/tensor_format.h:444:3: note: in expansion of macro 'CHECK'
   CHECK(index >= 0 && index < dimension_attribute.size())
   ^
ERROR: ....../tensorflow/tensorflow/core/BUILD:3467:1: C++ compilation of rule '//tensorflow/core:gpu_runtime_impl' failed (Exit 1)
In file included from tensorflow/core/common_runtime/gpu/gpu_device.cc:81:0:
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/cuda_config.h:19:44: error: expected '}' before numeric constant
 #define TF_CUDA_CAPABILITIES ""CudaVersion(""5.2"")""
                                            ^
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/cuda_config.h:19:44: note: in definition of macro 'TF_CUDA_CAPABILITIES'
 #define TF_CUDA_CAPABILITIES ""CudaVersion(""5.2"")""
                                            ^~~
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/cuda_config.h:19:44: error: could not convert '{""CudaVersion(""}' from '<brace-enclosed initializer list>' to 'std::vector<tensorflow::{anonymous}::CudaVersion>'
 #define TF_CUDA_CAPABILITIES ""CudaVersion(""5.2"")""
                                            ^
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/cuda_config.h:19:44: note: in definition of macro 'TF_CUDA_CAPABILITIES'
 #define TF_CUDA_CAPABILITIES ""CudaVersion(""5.2"")""
                                            ^~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1575:1: error: 'Status' does not name a type; did you mean 'static'?
 Status BaseGPUDeviceFactory::EnablePeerAccess(
 ^~~~~~
 static
tensorflow/core/common_runtime/gpu/gpu_device.cc:1619:1: error: 'Status' does not name a type; did you mean 'static'?
 Status BaseGPUDeviceFactory::GetValidDeviceIds(
 ^~~~~~
 static
tensorflow/core/common_runtime/gpu/gpu_device.cc:1759:1: error: 'uint64' does not name a type; did you mean 'uint4'?
 uint64 BaseGPUDevice::SafeAllocFrontier(uint64 old_value) {
 ^~~~~~
 uint4
tensorflow/core/common_runtime/gpu/gpu_device.cc:1767:5: error: 'BaseGPUDevice' has not been declared
 int BaseGPUDevice::PendingKernels() {
     ^~~~~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc: In function 'int PendingKernels()':
tensorflow/core/common_runtime/gpu/gpu_device.cc:1768:7: error: 'kernel_tracker_' was not declared in this scope
   if (kernel_tracker_) {
       ^~~~~~~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc: At global scope:
tensorflow/core/common_runtime/gpu/gpu_device.cc:1774:1: error: 'uint64' does not name a type; did you mean 'uint4'?
 uint64 GPUKernelTracker::MaybeQueue(OpKernelContext* ctx) {
 ^~~~~~
 uint4
tensorflow/core/common_runtime/gpu/gpu_device.cc:1800:6: error: 'GPUKernelTracker' has not been declared
 void GPUKernelTracker::RecordQueued(uint64 queued_count, int weight) {
      ^~~~~~~~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1800:37: error: variable or field 'RecordQueued' declared void
 void GPUKernelTracker::RecordQueued(uint64 queued_count, int weight) {
                                     ^~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1800:37: error: 'uint64' was not declared in this scope
tensorflow/core/common_runtime/gpu/gpu_device.cc:1800:37: note: suggested alternatives:
In file included from external/protobuf_archive/src/google/protobuf/stubs/common.h:46:0,
                 from external/protobuf_archive/src/google/protobuf/io/coded_stream.h:135,
                 from bazel-out/host/genfiles/tensorflow/core/lib/core/error_codes.pb.h:23,
                 from ./tensorflow/core/lib/core/status.h:23,
                 from ./tensorflow/core/common_runtime/device_factory.h:22,
                 from tensorflow/core/common_runtime/gpu/gpu_device.cc:37:
external/protobuf_archive/src/google/protobuf/stubs/port.h:156:18: note:   'google::protobuf::uint64'
 typedef uint64_t uint64;
                  ^~~~~~
In file included from ./tensorflow/core/platform/types.h:29:0,
                 from ./tensorflow/core/platform/default/logging.h:25,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/core/status.h:25,
                 from ./tensorflow/core/common_runtime/device_factory.h:22,
                 from tensorflow/core/common_runtime/gpu/gpu_device.cc:37:
./tensorflow/core/platform/default/integral_types.h:32:28: note:   'tensorflow::uint64'
 typedef unsigned long long uint64;
                            ^~~~~~
./tensorflow/core/platform/default/integral_types.h:32:28: note:   'tensorflow::uint64'
./tensorflow/core/platform/default/integral_types.h:32:28: note:   'tensorflow::uint64'
tensorflow/core/common_runtime/gpu/gpu_device.cc:1800:58: error: expected primary-expression before 'int'
 void GPUKernelTracker::RecordQueued(uint64 queued_count, int weight) {
                                                          ^~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1847:6: error: 'GPUKernelTracker' has not been declared
 void GPUKernelTracker::MaybeQueueProgressEvent() {
      ^~~~~~~~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc: In function 'void MaybeQueueProgressEvent()':
tensorflow/core/common_runtime/gpu/gpu_device.cc:1848:3: error: 'mutex_lock' was not declared in this scope
   mutex_lock l(mu_);
   ^~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1848:3: note: suggested alternative:
In file included from ./tensorflow/core/platform/mutex.h:31:0,
                 from ./tensorflow/core/platform/default/notification.h:24,
                 from ./tensorflow/core/platform/notification.h:26,
                 from ./tensorflow/core/lib/core/notification.h:21,
                 from ./tensorflow/core/common_runtime/gpu/gpu_event_mgr.h:24,
                 from ./tensorflow/core/common_runtime/gpu/gpu_device.h:30,
                 from tensorflow/core/common_runtime/gpu/gpu_device.cc:38:
./tensorflow/core/platform/default/mutex.h:63:23: note:   'tensorflow::mutex_lock'
 class SCOPED_LOCKABLE mutex_lock {
                       ^~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1849:7: error: 'num_pending_' was not declared in this scope
   if (num_pending_ == 0) {
       ^~~~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1849:7: note: suggested alternative: 'sigpending'
   if (num_pending_ == 0) {
       ^~~~~~~~~~~~
       sigpending
tensorflow/core/common_runtime/gpu/gpu_device.cc:1850:5: error: 'uint64' was not declared in this scope
     uint64 new_count = timing_counter_->next();
     ^~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1850:5: note: suggested alternatives:
In file included from external/protobuf_archive/src/google/protobuf/stubs/common.h:46:0,
                 from external/protobuf_archive/src/google/protobuf/io/coded_stream.h:135,
                 from bazel-out/host/genfiles/tensorflow/core/lib/core/error_codes.pb.h:23,
                 from ./tensorflow/core/lib/core/status.h:23,
                 from ./tensorflow/core/common_runtime/device_factory.h:22,
                 from tensorflow/core/common_runtime/gpu/gpu_device.cc:37:
external/protobuf_archive/src/google/protobuf/stubs/port.h:156:18: note:   'google::protobuf::uint64'
 typedef uint64_t uint64;
                  ^~~~~~
In file included from ./tensorflow/core/platform/types.h:29:0,
                 from ./tensorflow/core/platform/default/logging.h:25,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/core/status.h:25,
                 from ./tensorflow/core/common_runtime/device_factory.h:22,
                 from tensorflow/core/common_runtime/gpu/gpu_device.cc:37:
./tensorflow/core/platform/default/integral_types.h:32:28: note:   'tensorflow::uint64'
 typedef unsigned long long uint64;
                            ^~~~~~
./tensorflow/core/platform/default/integral_types.h:32:28: note:   'tensorflow::uint64'
./tensorflow/core/platform/default/integral_types.h:32:28: note:   'tensorflow::uint64'
tensorflow/core/common_runtime/gpu/gpu_device.cc:1851:18: error: 'new_count' was not declared in this scope
     RecordQueued(new_count, 1);
                  ^~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1851:5: error: 'RecordQueued' was not declared in this scope
     RecordQueued(new_count, 1);
     ^~~~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1852:5: error: 'em_' was not declared in this scope
     em_->ThenExecute(stream_,
     ^~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1852:22: error: 'stream_' was not declared in this scope
     em_->ThenExecute(stream_,
                      ^~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1852:22: note: suggested alternative: 'strncmp'
     em_->ThenExecute(stream_,
                      ^~~~~~~
                      strncmp
tensorflow/core/common_runtime/gpu/gpu_device.cc:1853:23: error: invalid use of 'this' in non-member function
                      [this, new_count]() { RecordTerminated(new_count); });
                       ^~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc: In lambda function:
tensorflow/core/common_runtime/gpu/gpu_device.cc:1853:61: error: 'new_count' is not captured
                      [this, new_count]() { RecordTerminated(new_count); });
                                                             ^~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1853:38: note: the lambda has no capture-default
                      [this, new_count]() { RecordTerminated(new_count); });
                                      ^
tensorflow/core/common_runtime/gpu/gpu_device.cc:1851:18: note: '<typeprefixerror>new_count' declared here
     RecordQueued(new_count, 1);
                  ^~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1853:44: error: 'RecordTerminated' was not declared in this scope
                      [this, new_count]() { RecordTerminated(new_count); });
                                            ^~~~~~~~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc: At global scope:
tensorflow/core/common_runtime/gpu/gpu_device.cc:1857:6: error: 'GPUKernelTracker' has not been declared
 void GPUKernelTracker::RecordTerminated(uint64 queued_count) {
      ^~~~~~~~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1857:41: error: variable or field 'RecordTerminated' declared void
 void GPUKernelTracker::RecordTerminated(uint64 queued_count) {
                                         ^~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1857:41: error: 'uint64' was not declared in this scope
tensorflow/core/common_runtime/gpu/gpu_device.cc:1857:41: note: suggested alternatives:
In file included from external/protobuf_archive/src/google/protobuf/stubs/common.h:46:0,
                 from external/protobuf_archive/src/google/protobuf/io/coded_stream.h:135,
                 from bazel-out/host/genfiles/tensorflow/core/lib/core/error_codes.pb.h:23,
                 from ./tensorflow/core/lib/core/status.h:23,
                 from ./tensorflow/core/common_runtime/device_factory.h:22,
                 from tensorflow/core/common_runtime/gpu/gpu_device.cc:37:
external/protobuf_archive/src/google/protobuf/stubs/port.h:156:18: note:   'google::protobuf::uint64'
 typedef uint64_t uint64;
                  ^~~~~~
In file included from ./tensorflow/core/platform/types.h:29:0,
                 from ./tensorflow/core/platform/default/logging.h:25,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/core/status.h:25,
                 from ./tensorflow/core/common_runtime/device_factory.h:22,
                 from tensorflow/core/common_runtime/gpu/gpu_device.cc:37:
./tensorflow/core/platform/default/integral_types.h:32:28: note:   'tensorflow::uint64'
 typedef unsigned long long uint64;
                            ^~~~~~
./tensorflow/core/platform/default/integral_types.h:32:28: note:   'tensorflow::uint64'
./tensorflow/core/platform/default/integral_types.h:32:28: note:   'tensorflow::uint64'
tensorflow/core/common_runtime/gpu/gpu_device.cc:1917:1: error: expected declaration before '}' token
 }  // namespace tensorflow
 ^
tensorflow/core/common_runtime/gpu/gpu_device.cc:1544:26: warning: 'std::vector<tensorflow::{anonymous}::CudaVersion> tensorflow::GetSupportedCudaComputeCapabilities()' defined but not used [-Wunused-function]
 std::vector<CudaVersion> GetSupportedCudaComputeCapabilities() {
                          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/core/common_runtime/gpu/gpu_device.cc:1484:12: warning: 'int tensorflow::GetMinGPUMultiprocessorCount(stream_executor::Platform*, const std::vector<tensorflow::gtl::IntType<tensorflow::PlatformGpuId_tag_, int> >&)' defined but not used [-Wunused-function]
 static int GetMinGPUMultiprocessorCount(
            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1118.884s, Critical Path: 99.33s
INFO: 3435 processes: 3435 local.
FAILED: Build did NOT complete successfully
```

Did anybody meet the same issue?

Cheers
Pei"
28828,module 'tensorflow._api.v1.keras.layers' has no attribute 'Lamdba',"Cannot build my code due to ""module 'tensorflow._api.v1.keras.layers' has no attribute 'Lamdba'"" heres the code thats related to it:

`classifier_layer = layers.Lamdba(classifier_layer, input_shape = IMAGE_SIZE*[3])
classifier_model = tf.keras.Sequential([classifier_layer])
classifier_mode.summary()`

Im currently just ""Copy pasting"" / writing it from the Tensorflow tutorial 
(https://www.tensorflow.org/tutorials/images/hub_with_keras) to understand how it works, im very unsure why its not working for me since i used every import they used on the page aswell, looked up if i need to install another package (had to do that some times already) but unfortunally i didnt found anything."
28827,WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.,"I'm working on a text analytics project and encountered this issue. I don't have much experience with this. Please assist. 

![image](https://user-images.githubusercontent.com/17949213/57971131-863aa380-79a7-11e9-90b8-ef8f2969aa1a.png)
"
28825,plzz help,"Use standard file APIs to check for files with this prefix.

```
WARNING:tensorflow:From C:\Users\HP\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\tools\freeze_graph.py:232: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.convert_variables_to_constants
WARNING:tensorflow:From C:\Users\HP\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.extract_sub_graph
Traceback (most recent call last):
  File ""export_inference_graph.py"", line 156, in <module>
    tf.app.run()
  File ""C:\Users\HP\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""export_inference_graph.py"", line 152, in main
    write_inference_graph=FLAGS.write_inference_graph)
  File ""C:\Users\HP\Desktop\RE\models\research\object_detection\exporter.py"", line 465, in export_inference_graph
    write_inference_graph=write_inference_graph)
  File ""C:\Users\HP\Desktop\RE\models\research\object_detection\exporter.py"", line 421, in _export_inference_graph
    placeholder_tensor, outputs)
  File ""C:\Users\HP\Desktop\RE\models\research\object_detection\exporter.py"", line 264, in write_saved_model
    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_path)
  File ""C:\Users\HP\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\saved_model\builder_impl.py"", line 425, in __init__
    super(SavedModelBuilder, self).__init__(export_dir=export_dir)
  File ""C:\Users\HP\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\saved_model\builder_impl.py"", line 100, in __init__
    ""directory: %s"" % export_dir)
AssertionError: Export directory already exists. Please specify a different export directory: inference_graph\saved_model
```"
28824,Error Loading Package @io_bazel_rules_docker when building Tensorflow,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 1.12.2 / master branch
- Python version: Python 3.6.8 :: Anaconda, Inc.
- Installed using virtualenv? pip? conda?: Conda
- Bazel version (if compiling from source): 0.25.2
- GCC/Compiler version (if compiling from source): gcc version 8.2.0 (Rev3, Built by MSYS2 project)
- CUDA/cuDNN version: Cuda v10.1 - cudnn-9.2-windows10-x64-v7.5.1.10
- GPU model and memory: NVidia 1060


**Describe the problem**
Build failing when running `bazel build --config=opt //tools/pip_package:build_pip_package`
with error:
```
ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories'
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I followed the tutorial here: https://medium.com/@amsokol.com/how-to-build-and-install-tensorflow-gpu-cpu-for-windows-from-source-code-using-bazel-d047d9342b44

```
> python configure.py
Python Location (default): C:\Users\Arise\Miniconda3\envs\tensorflow-v1.10\python.exe
Python Libraries Path (default): C:\Users\Arise\Miniconda3\envs\tensorflow-v1.10\lib\site-packages
XLA JIT support: No
ROCm support: No
CUDA support: Yes
CUDA compute capabilities (default): 3.5,7.0
Optimization Flags Bazel (default): --config=opt
Override Eigen Strong Inline (default): Yes
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
(tensorflow-v1.10) C:\Users\Arise\tensorflow-build\tensorflow>bazel build
Starting local Bazel server and connecting to it...
WARNING: Usage: bazel build <options> <targets>.
Invoke `bazel help build` for full description of usage and options.
Your request is correct, but requested an empty set of targets. Nothing will be built.
INFO: An error occurred during the fetch of repository 'io_bazel_rules_docker'
INFO: Call stack for the definition of repository 'io_bazel_rules_docker':
 - C:/users/arise/_bazel_arise/ji3ak47x/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - C:/users/arise/tensorflow-build/tensorflow/WORKSPACE:29:1
ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):
        File ""C:/users/arise/_bazel_arise/ji3ak47x/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 234
                _clone_or_update(ctx)
        File ""C:/users/arise/_bazel_arise/ji3ak47x/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 74, in _clone_or_update
                fail((""error cloning %s:\n%s"" % (ctx....)))
error cloning io_bazel_rules_docker:
+ cd C:/users/arise/_bazel_arise/ji3ak47x/external
+ rm -rf C:/users/arise/_bazel_arise/ji3ak47x/external/io_bazel_rules_docker C:/users/arise/_bazel_arise/ji3ak47x/external/io_bazel_rules_docker
/usr/bin/bash: line 5: rm: command not found
ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': Traceback (most recent call last):
        File ""C:/users/arise/_bazel_arise/ji3ak47x/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 234
                _clone_or_update(ctx)
        File ""C:/users/arise/_bazel_arise/ji3ak47x/external/bazel_tools/tools/build_defs/repo/git.bzl"", line 74, in _clone_or_update
                fail((""error cloning %s:\n%s"" % (ctx....)))
error cloning io_bazel_rules_docker:
+ cd C:/users/arise/_bazel_arise/ji3ak47x/external
+ rm -rf C:/users/arise/_bazel_arise/ji3ak47x/external/io_bazel_rules_docker C:/users/arise/_bazel_arise/ji3ak47x/external/io_bazel_rules_docker
/usr/bin/bash: line 5: rm: command not found
INFO: Elapsed time: 2.642s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```
"
28823,"[TF 2.0 alpha] Tutorial ""Using TFRecords and tf.Example"" can't run on tensorflow2.0 α0 gpu","Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

TensorFlow version: Tensorflow 2.0 alpha
Doc Link: Using TFRecords and tf.Example https://www.tensorflow.org/alpha/tutorials/load_data/tf_records
Windows 10 LTSC x64 Python3.6 Cuda 10.0 Cudnn 7.5

## Description of issue (what needs changing):

If I run the example code, I will have an error in the cell:
tf_serialize_example(f0,f1,f2,f3)

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

`UnknownError           Traceback (most recent call last)
<ipython-input-21-406ee79a7f52> in <module>
----> 1 tf_serialize_example(f0,f1,f2,f3)

<ipython-input-20-3f3d0d83f6b2> in tf_serialize_example(f0, f1, f2, f3)
      3     serialize_example,
      4     (f0,f1,f2,f3),  # pass these args to the above function.
----> 5     tf.string)      # the return type is `tf.string`.
      6   return tf.reshape(tf_string, ()) # The result is a scalar

F:\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\ops\script_ops.py in eager_py_func(func, inp, Tout, name)
    387     if `func` returns None.
    388   """"""
--> 389   return _internal_py_func(func=func, inp=inp, Tout=Tout, eager=True, name=name)
    390 
    391 

F:\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\ops\script_ops.py in _internal_py_func(func, inp, Tout, stateful, eager, is_grad_func, name)
    276   if eager:
    277     result = gen_script_ops.eager_py_func(
--> 278         input=inp, token=token, Tout=Tout, name=name)
    279   else:
    280     if stateful:

F:\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\ops\gen_script_ops.py in eager_py_func(input, token, Tout, name)
     64       else:
     65         message = e.message
---> 66       _six.raise_from(_core._status_to_exception(e.code, message), None)
     67   # Add nodes to the TensorFlow graph.
     68   token = _execute.make_str(token, ""token"")

F:\Anaconda3\envs\TF2\lib\site-packages\six.py in raise_from(value, from_value)

UnknownError: RuntimeError: Error copying tensor to device: CPU:0. Can't copy 35 bytes of a tensor into another with 32 bytes buffer.
Traceback (most recent call last):

  File ""F:\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 205, in __call__
    return func(device, token, args)

  File ""F:\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 107, in __call__
    ret = self._func(*args)

  File ""<ipython-input-5-a40a581f0687>"", line 10, in serialize_example
    'feature2': _bytes_feature(feature2),

  File ""<ipython-input-1-0ab605f55efd>"", line 8, in _bytes_feature
    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.

  File ""F:\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\framework\ops.py"", line 732, in numpy
    return self._cpu_nograd()._numpy()  # pylint: disable=protected-access

  File ""F:\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\framework\ops.py"", line 899, in _cpu_nograd
    return self._copy_nograd(context.context(), ""CPU:0"")

  File ""F:\Anaconda3\envs\TF2\lib\site-packages\tensorflow\python\framework\ops.py"", line 847, in _copy_nograd
    new_tensor = self._copy_to_device(context=ctx._handle, device=device_name)

RuntimeError: Error copying tensor to device: CPU:0. Can't copy 35 bytes of a tensor into another with 32 bytes buffer.

 [Op:EagerPyFunc]
`

"
28822,Tensorflow loss increase during the training,"I cloned a github project that using tensorflow :
+ https://github.com/yinguobing/cnn-facial-landmark

and i tried to training ibug dataset (300VW , 300W , Helen...) to get a trained tensorflow model 
but when training starting , the result is good and the loss decreasing during training , but after 1000 steps , the loss value increase and decrease during the training , I don't have any idea about this changing of loss value is a problem or bug or not , 
How can i fix that?

![image](https://user-images.githubusercontent.com/19480228/57968022-700bf380-7965-11e9-8256-e130e12c5d97.png)


**System information**
- The source code : https://github.com/yinguobing/cnn-facial-landmark/blob/master/landmark.py
- OS Platform and Distribution : Windows 10 x64
- TensorFlow installed from : binary
- TensorFlow version : 13.1.1 ( GPU )
- Python version: 3.6
- CUDA/cuDNN version:10.0/7.4
- GPU model and memory:Nvidia Geforce 840m 4 Go


"
28821,Large virtual memory usage for TF Lite 2.0,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04 and 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.0 and 1.10
- Python version: 3.5.2 and 3.6.7
- Bazel version (if compiling from source): 19.0 and 16.0
- GCC/Compiler version (if compiling from source): 7.4 and 7.3
- CUDA/cuDNN version: 10.1 and 9.1
- GPU model and memory: Nvidia RTX 2080ti(11 GB) and Nvidia GTX 1050ti(4 GB)


**Describe the current behavior**
When using valgrind massif on label_image TF Lite example, it reports 400 MB of virtual memory,
even though the model's size is only 14 MB and I do not understand where this overhead is coming from.
Here is the profiling information at peak:
100.00% (413,081,600B) (page allocation syscalls) mmap/mremap/brk, --alloc-fns, etc.
->89.83% (371,077,120B) 0x6B8E6B9: mmap (mmap.c:34)
| ->48.74% (201,330,688B) 0x6B0A3CF: new_heap (arena.c:438)
| | ->48.74% (201,330,688B) 0x6B0AC1F: arena_get2.part.3 (arena.c:646)
| |   ->48.74% (201,330,688B) 0x6B11248: malloc (malloc.c:2911)
| |     ->48.74% (201,330,688B) 0x657C1E6: operator new(unsigned long) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.25)
| |       ->32.49% (134,221,824B) 0x4BDD65: ??? (in /home/paul/.cache/bazel/_bazel_paul/3c9cebfe1f000a90a0a2bd1f5b50e543/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/examples/label_image/label_image)
| |       | ->32.49% (134,221,824B) 0x4EE3B1: ??? (in /home/paul/.cache/bazel/_bazel_paul/3c9cebfe1f000a90a0a2bd1f5b50e543/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/examples/label_image/label_image)
| |       |   ->32.49% (134,221,824B) 0x65A657D: ??? (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.25)
| |       |     ->32.49% (134,221,824B) 0x5BBE6B8: start_thread (pthread_create.c:333)
| |       |       ->32.49% (134,221,824B) 0x6B9441B: clone (clone.S:109)

**Describe the expected behavior**
I expected less memory usage from this lite tool.

**Code to reproduce the issue**
Just run label_image TF example and with this:
`valgrind --tool=massif --pages-as-heap=yes --massif-out-file=massif.out bazel-bin/tensorflow/lite/examples/label_image/label_image -m mobilenet_v2
_1.0_224.tflite -i grace_hopper.bmp; grep mem_heap_B massif.out | sed -e 's/mem_heap_B=\(.*\)/\1/' | sort -g | tail -n 1`

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

LE:
By running with debugging symbols, it seems that EigenForTFLite is the culprit; is this really a wanted behavior?"
28820,"Converting keras model file to tflite, got this error.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 x64
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): 1.13.1


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: EXPAND_DIMS, FILL, FULLY_CONNECTED, PACK, RESHAPE, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: CudnnRNN.
2019-05-17 23:06:18.042831: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: CudnnRNN
2019-05-17 23:06:18.042831: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-05-17 23:06:18.042831: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-05-17 23:06:18.042831: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-05-17 23:06:18.042831: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-05-17 23:06:18.042831: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: CudnnRNN
2019-05-17 23:06:18.043831: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: CudnnRNN
2019-05-17 23:06:18.043831: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: CudnnRNN
2019-05-17 23:06:18.045831: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 134 operators, 271 arrays (0 quantized)
2019-05-17 23:06:18.046831: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 134 operators, 271 arrays (0 quantized)
2019-05-17 23:06:18.054832: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 17 operators, 43 arrays (0 quantized)
2019-05-17 23:06:18.054832: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 17 operators, 43 arrays (0 quantized)
2019-05-17 23:06:18.055832: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 1856 bytes, theoretical optimal value: 1856 bytes.
2019-05-17 23:06:18.055832: E tensorflow/lite/toco/toco_tooling.cc:421] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: EXPAND_DIMS, FILL, FULLY_CONNECTED, PACK, RESHAPE, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: CudnnRNN.
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28819,"Object detection: when training, GPU utilization started high, and became low/idle later on.","**System information**
- Have I written custom code: No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows Server 2016
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7.3
- CUDA/cuDNN version: 10/7.1
- GPU model and memory: Tesla V100 - 16 GB

**Describe the current behavior**
I am trying to train a face detector by using the Object Detection API. Specifically, I am using 4000 images from the Wider Faces data set for training/validation, and using faster_rcnn_resnet101_coco for fine-tuning. I split the train set images into 5 shards, and in the .config file, I changed the `min_dimension` and `max_dimension` to 300 and 512, respectively, in hopes of faster training.

After I kicked off training, I noticed that the GPU memory usage was about 95%. GPU volatile-utilization and CPU utilization on the other hand were behaving oddly. Specifically, during the very first ~3k steps, GPU volatile-utilization was between 60%  and 95%, and the CPU utilization was only around 8%. Global_step/sec essentially plateaued around 8 steps/sec within the first 3k steps. 

From ~3k steps and onward, CPU utilization increased to 80-100% whereas GPU volatile utilization oscillated between 0% to 30% and **for the most part, it was idle (0%)**. GPU memory usage continued to be high.

**Describe the expected behavior**
Given the initial high GPU volatile utilization rate, I was expecting the high util-rate to persist, so it was a bit strange to see that after the initial 3k steps, the training process only occasionally used the GPU, and mostly relied on the CPU.

Any pointers/help would be much appreciated. Thanks!




"
28818,RW4YQ2T67I2,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
28815,ArrayIndexOutOfBoundsException: length=1; index=1,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, Android Studio 3.4.1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
OnePlus 6

**Describe the problem**

I am using the tensorflow example object_detection app, it's working fine. But when I try plugging in my own model ""tiny-yolo-obj.lite"" (created with Tiny YOLO) and ""labelmap2.txt"" (first line being ???, other 36 lines my objects) it throws the following error:

```
Process: org.tensorflow.lite.examples.detection, PID: 31738
    java.lang.ArrayIndexOutOfBoundsException: length=1; index=1
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

**My model meta:**

`{""net"": {""type"": ""[net]"", ""batch"": 64, ""subdivisions"": 8, ""width"": 416, ""height"": 416, ""channels"": 3, ""momentum"": 0.9, ""decay"": 0.0005, ""angle"": 0, ""saturation"": 1.5, ""exposure"": 1.5, ""hue"": 0.1, ""learning_rate"": 0.001, ""max_batches"": 40200, ""policy"": ""steps"", ""steps"": ""-1,100,20000,30000"", ""scales"": "".1,10,.1,.1""}, ""type"": ""[region]"", ""anchors"": [1.08, 1.19, 3.42, 4.41, 6.63, 11.38, 9.42, 5.11, 16.62, 10.52], ""bias_match"": 1, ""classes"": 36, ""coords"": 4, ""num"": 5, ""softmax"": 1, ""jitter"": 0.2, ""rescore"": 1, ""object_scale"": 5, ""noobject_scale"": 1, ""class_scale"": 1, ""coord_scale"": 1, ""absolute"": 1, ""thresh"": 0.6, ""random"": 1, ""model"": ""cfg/tiny-yolo-obj.cfg"", ""inp_size"": [416, 416, 3], ""out_size"": [13, 13, 205], ""name"": ""tiny-yolo-obj"", ""labels"": [""Rosen 6"", ""Rosen 7"", ""Rosen 8"", ""Rosen 9"", ""Rosen 10"", ""Rosen Under"", ""Rosen Ober"", ""Rosen K\u00f6nig"", ""Rosen Ass"", ""Eichel 6"", ""Eichel 7"", ""Eichel 8"", ""Eichel 9"", ""Eichel 10"", ""Eichel Under"", ""Eichel Ober"", ""Eichel K\u00f6nig"", ""Eichel Ass"", ""Schellen 6"", ""Schellen 7"", ""Schellen 8"", ""Schellen 9"", ""Schellen 10"", ""Schellen Under"", ""Schellen Ober"", ""Schellen K\u00f6nig"", ""Schellen Ass"", ""Schilten 6"", ""Schilten 7"", ""Schilten 8"", ""Schilten 9"", ""Schilten 10"", ""Schilten Under"", ""Schilten Ober"", ""Schilten K\u00f6nig"", ""Schilten Ass""], ""colors"": [[254.0, 254.0, 254], [246.0625, 222.25, 127], [238.125, 190.5, 0], [230.1875, 158.75, -127], [222.25, 127.0, 254], [214.3125, 95.25, 127], [206.375, 63.5, 0], [198.4375, 31.75, -127], [190.5, 0.0, 254], [182.5625, -31.75, 127], [174.625, -63.5, 0], [166.6875, -95.25, -127], [158.75, -127.0, 254], [150.8125, -158.75, 127], [142.875, -190.5, 0], [134.9375, -222.25, -127], [127.0, 254.0, 254], [119.0625, 222.25, 127], [111.125, 190.5, 0], [103.1875, 158.75, -127], [95.25, 127.0, 254], [87.3125, 95.25, 127], [79.375, 63.5, 0], [71.4375, 31.75, -127], [63.5, 0.0, 254], [55.5625, -31.75, 127], [47.625, -63.5, 0], [39.6875, -95.25, -127], [31.75, -127.0, 254], [23.8125, -158.75, 127], [15.875, -190.5, 0], [7.9375, -222.25, -127], [0.0, 254.0, 254], [-7.9375, 222.25, 127], [-15.875, 190.5, 0], [-23.8125, 158.75, -127]]}`

**My code in DetectorActivity**

```
  // Configuration values for the prepackaged SSD model.
  private static final int TF_OD_API_INPUT_SIZE = 300;
  private static final boolean TF_OD_API_IS_QUANTIZED = false; // maybe also true, dunno yet
  private static final String TF_OD_API_MODEL_FILE = ""tiny-yolo-obj.lite"";
  private static final String TF_OD_API_LABELS_FILE = ""labelmap2.txt"";
  private static final DetectorMode MODE = DetectorMode.TF_OD_API;
  // Minimum detection confidence to track a detection.
  private static final float MINIMUM_CONFIDENCE_TF_OD_API = 0.5f;
  private static final boolean MAINTAIN_ASPECT = false;
  private static final Size DESIRED_PREVIEW_SIZE = new Size(640, 480);
  private static final boolean SAVE_PREVIEW_BITMAP = false;
  private static final float TEXT_SIZE_DIP = 10;
```

Any help would be greatly appreciated! Thanks in advance."
28812,Signature defs lost when calling saved_model_cli convert,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
```
Yes.  Using saved_model_cli tool.
```
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
```
cat /etc/os-release 
NAME=""Red Hat Enterprise Linux Server""
VERSION=""7.6 (Maipo)""
ID=""rhel""
ID_LIKE=""fedora""
VARIANT=""Server""
VARIANT_ID=""server""
VERSION_ID=""7.6""
PRETTY_NAME=""Red Hat Enterprise Linux Server 7.6 (Maipo)""
ANSI_COLOR=""0;31""
CPE_NAME=""cpe:/o:redhat:enterprise_linux:7.6:GA:server""
HOME_URL=""https://www.redhat.com/""
BUG_REPORT_URL=""https://bugzilla.redhat.com/""

REDHAT_BUGZILLA_PRODUCT=""Red Hat Enterprise Linux 7""
REDHAT_BUGZILLA_PRODUCT_VERSION=7.6
REDHAT_SUPPORT_PRODUCT=""Red Hat Enterprise Linux""
REDHAT_SUPPORT_PRODUCT_VERSION=""7.6""
```
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
```
Source
```
- TensorFlow version (use command below):
```
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
2019-05-17 20:37:38.121490: I tensorflow/stream_executor/platform/default/dso_loader.cc:43] Successfully opened dynamic library libcudart.so.10.1
v1.12.1-142-gcd15418 1.14.0-rc0
```
- Python version:
```
python --version
Python 3.6.8 :: Anaconda, Inc.
```
- Bazel version (if compiling from source):
```
0.24.1
```
- GCC/Compiler version (if compiling from source):
```
7.3.0
```
- CUDA/cuDNN version:
```
cudatoolkit               10.1.152 
cudnn                     7.5.1_10.1 
```
- GPU model and memory:
```
Tesla V100-SXM2
16130MiB
```
You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
```
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
2019-05-17 20:37:38.121490: I tensorflow/stream_executor/platform/default/dso_loader.cc:43] Successfully opened dynamic library libcudart.so.10.1
v1.12.1-142-gcd15418 1.14.0-rc0
```

**Describe the current behavior**

The ""predict"" signature definition is lost when running the `saved_model_cli convert` command against a resnet model.

**Describe the expected behavior**
Both the ""predict"" signature, and the ""serving_default"" signature definitions should be in the saved_model.

Code was removed near these lines in trt_convert.py when the code was restructured in the r1.14 branch:
https://github.com/tensorflow/tensorflow/blob/6b657e327cc9ca6e2906ade3e4877e3303065d70/tensorflow/python/compiler/tensorrt/trt_convert.py#L254

The original code in the v1.13.1 tagged version looped through all of the signature definitions:
https://github.com/tensorflow/tensorflow/blob/6612da89516247503f03ef76e974b51a434fb52e/tensorflow/contrib/tensorrt/python/trt_convert.py#L292

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

The following steps will show the issue with the converted graph:
```
mkdir -p $HOME/saved-models
cd $HOME/saved-models
wget http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NCHW.tar.gz
tar --no-same-owner -xzvf resnet_v1_fp16_savedmodel_NCHW.tar.gz

cd $HOME
mkdir -p $HOME/inference-models/resnet_v1_50_fp16

saved_model_cli convert --dir $HOME/saved-models/resnet_v1_fp16_savedmodel_NCHW/1538686290 --output_dir $HOME/inference-models/resnet_v1_50_fp16/cli --tag_set serve tensorrt --precision_mode FP16 --max_batch_size 1 --is_dynamic_op False

saved_model_cli show --dir $HOME/saved-models/resnet_v1_fp16_savedmodel_NCHW/1538686290 --all # Will show ""predict"" saved model signature definition

saved_model_cli show --dir $HOME/inference-models/resnet_v1_50_fp16/cli --all # The ""predict"" signature definition does not exist in the converted model
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28811,Tensorflow matmul of float64's behaves like numpy float32 matmul,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): 1.13.1
- Python version: 3.6.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10
- GPU model and memory: Titan Xp


**Describe the current behavior**
Multiplying two tf.float64s together is giving me a substantial error over multiplying two np.float64s together. 

**Describe the expected behavior**
np.matmul(a, b) should be very close to tf.matmul(a, b) when a, b are both float64s. This issue is compounding over a spectrogram preprocessing pipeline making tensorflow unusable for pushing my signal preprocessing from numpy into tensorflow. 

**Code to reproduce the issue**
```
a = tf.placeholder(tf.float64, [None, None])
b = tf.placeholder(tf.float64, [None, None])

res_tf = tf.matmul(a, b)

in1 = np.random.uniform(size=(998, 257))
in2 = np.random.uniform(size=(257, 80))

print(in1.dtype)
print(in2.dtype)

numpy_result_f64 = np.matmul(in1, in2)
numpy_result_f32 = np.matmul(in1.astype(np.float32), in2.astype(np.float32))

with tf.Session() as sess:
    tensorflow_result = sess.run(res_tf, feed_dict={a: in1, b: in2})
    
print(((numpy_result_f64 - tensorflow_result) / numpy_result_f64).max())
print(((numpy_result_f32 - tensorflow_result) / numpy_result_f32).max())
```
Out:
```
float64
float64
0.16405904009391822
9.08087494225598e-07
```
This has the same issue whether the code is run on GPU or CPU. 

This issue does not appear on tf 1.12. "
28807,TensorFlow Lite InterpreterBuilder::ParseTensors incorrect for big-endian machines,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-45-generic s390x)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.13.0
- Python version: Python 2.7.15rc1 (default, Nov 12 2018, 14:31:15)
- Bazel version (if compiling from source): N/A (tflite build via lite/tools/make/Makefile)
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Any attempt to run one of the TF Lite utilities (e.g. label_image, benchmark_model) or use the interpreter via an import in Python will generate error messages at time of loading a FlatBuffers tflite model file.

**Describe the expected behavior**
TensorFlow Lite should correctly read a FlatBuffers tflite file and build an internal model structure for its interpreter without any errors.

**Code to reproduce the issue**
A mere inspection of the model.cc source code (in directory tensorflow/lite) will show that the InterpreterBuilder::ParseTensors function assigns a FlatBuffers buffer pointer directly to the TF Lite tensor's object data field. (See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/model.cc line 350).
This will cause any multi-byte element of a tensor to be incorrectly interpreted since FlatBuffers use strictly little-endian for all numeric values.

**Other info / logs**
The offending source line is line 390:
*buffer_data = reinterpret_cast<const char*>(array->data());

A tentative solution needs a two-fold change:
1. The tensor type must be used to learn how to interpret the char data and this data must be byte swapped accordingly. FlatBuffers already provides a utility function for that:
flatbuffers::EndianScalar(). Unfortunately this requires a loop over all data in strides of the size of a tensor element. But need only be done once during model build.

Example of correctly handling 32-bit integers:
<pre>
            *buffer_size = size;                                                                
            *buffer_data = reinterpret_cast&lt;const char*&gt;(array->data());                                                                   
            switch (type) {                                                                     
            case kTfLiteInt32: {                                                                
              int32_t *p = reinterpret_cast&lt;int32_t*&gt;(const_cast&lt;uint8_t*&gt;(array->data()));     
              for (size_t i = 0; i &lt; size; i+=4, ++p)                                           
                *p = flatbuffers::EndianScalar(*p);                                             
              break;                                                                            
            }                                                                                   
</pre>

2. The FlatBuffers buffer must be writable. One must drop the const specifier and moreover since the tflite file is memory-mapped the mapping options must include PROT_WRITE and the mode must be MAP_PRIVATE in mmap_allocation.cc.

Example of new mmap call:
<pre>
   mmap(nullptr, buffer_size_bytes_, PROT_READ|PROT_WRITE, MAP_PRIVATE, mmap_fd_, 0);
</pre>

There is also a minor issue in the label_image example where a BMP file is read and its header which has some little-endian integers that are not converted on a big-endian machine.

A simple solution for this (in lite/examples/label_image/bitmap_helpers.cc):
<pre>
 header_size = flatbuffers::EndianScalar(header_size);
 *width = flatbuffers::EndianScalar(*width);
 *height = flatbuffers::EndianScalar(*height);
 bpp = flatbuffers::EndianScalar(bpp);
</pre>
"
28804,tf.signal.stft supports only float32 inputs ,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.13
- Are you willing to contribute it (Yes/No): maybe but not much experience



**Describe the feature and the current behavior/state.**
tf.signal.stft allows computing the short-time fourier transform over an input signal. Right now, the op only supports float32 inputs. I'm getting significant differences between a numpy and TF implementation because of this. The RFFT implementation in tensorflow supports float64 inputs and none of the other functions called require float32 so I can't see too many obstacles to fixing. 

https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/ops/signal/spectral_ops.py

**Will this change the current api? How?**
No
**Who will benefit with this feature?**
People moving their frequency-domain processing into tensorflow. 
**Any Other info.**
Would also be good to allow rfft to work on complex128. 
"
28801,Linux: No module named tensorflow_estimator.python.estimator.tpu,"I successfully developed and run a model using Tensorflow Probability with Pruning in a Windows machine, but I get the following error in Linux (Ubuntu 16.04):

```
  File ""<ipython-input-3-622d85983aea>"", line 4, in <module>
    import tensorflow_probability as tfp

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow_probability/__init__.py"", line 78, in <module>
    from tensorflow_probability.python import *  # pylint: disable=wildcard-import

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow_probability/python/__init__.py"", line 21, in <module>
    from tensorflow_probability.python import bijectors

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/__init__.py"", line 23, in <module>
    from tensorflow_probability.python.bijectors.absolute_value import AbsoluteValue

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/absolute_value.py"", line 22, in <module>
    from tensorflow_probability.python.bijectors import bijector

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/bijector.py"", line 31, in <module>
    from tensorflow_probability.python.internal import distribution_util

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow_probability/python/internal/distribution_util.py"", line 26, in <module>
    from tensorflow_probability.python.internal import dtype_util

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow_probability/python/internal/dtype_util.py"", line 24, in <module>
    from tensorflow.contrib import framework as contrib_framework

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/__init__.py"", line 41, in <module>
    from tensorflow.contrib import distributions

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/distributions/__init__.py"", line 44, in <module>
    from tensorflow.contrib.distributions.python.ops.estimator import *

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/estimator.py"", line 21, in <module>
    from tensorflow.contrib.learn.python.learn.estimators.head import _compute_weighted_loss

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/__init__.py"", line 93, in <module>
    from tensorflow.contrib.learn.python.learn import *

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/__init__.py"", line 28, in <module>
    from tensorflow.contrib.learn.python.learn import *

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/__init__.py"", line 40, in <module>
    from tensorflow.contrib.learn.python.learn.experiment import Experiment

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py"", line 39, in <module>
    from tensorflow.contrib.tpu.python.tpu import tpu_estimator

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/tpu/__init__.py"", line 77, in <module>
    from tensorflow.contrib.tpu.python.tpu.tpu_config import *

  File ""/home/rubens/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_config.py"", line 22, in <module>
    from tensorflow_estimator.python.estimator.tpu.tpu_config import *

ModuleNotFoundError: No module named 'tensorflow_estimator.python.estimator.tpu'
```
All the packages involved are up-to-date, including pandas, matplotlib and numpy. Pip / conda reinstalling is not solving this issue. I'm running Python 3.6.8 64bits, Qt 5.11.2, PyQt5 5.11.3 on Linux, Spyder 3.3.1."
28800,kjj,
28799,TypeError: 'Not JSON Serializable' while doing tf.keras.Model.save and using keras variable in loss_weights in tf.keras.Model.compile,"**System information**
- Have I written custom code: NA
- OS Platform and Distribution: Ubuntu 16.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.12.0
- Python version: 3.5.2
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: release 9.0, V9.0.176
- GPU model and memory: Tesla K80, 12 GB

**Describe the current behavior**
When I try to save my model using model.save() where model is a tf.keras.Model instance, it throws a _TypeError: ('Not JSON Serializable:', <tf.Variable 'Variable:0' shape=() dtype=float32>)_ .
I am using a tf.keras.backend.variable() in loss_weights in model.compile.
Optimizer: tf.keras.optimizers.Adam
Interestingly, when I try to save my model weights only using model.save_weights where model is a tf.keras.Model instance, it works fine, NO ERROR.

**Describe the expected behavior**
It should not throw any type of error during training.

**Code to reproduce the issue**
`import tensorflow as tf`
`import numpy as np`
`import os`
`import sys`

`input_layer = tf.keras.layers.Input(shape=([4,3]), batch_size=1)`
`layer1 = tf.keras.layers.Dense(20)(input_layer)`
`layer2 = tf.keras.layers.Dense(1,name=""output1"")(layer1)`
`layer3 = tf.keras.layers.Dense(1,name=""output2"")(layer1)`
`model = tf.keras.Model(inputs=input_layer, outputs=[layer2,layer3])`
`alpha = tf.keras.backend.variable(0.25)`
`model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss={""output1"":tf.keras.metrics.binary_crossentropy,""output2"":tf.keras.metrics.binary_crossentropy},loss_weights=[1.0,alpha])`

`# model.fit() is skipped just to get straight to error.`
`model.save(""./weights.h5"")`

Just execute this code as it is, It will throw same error!!

**Other info / logs**
Traceback (most recent call last):
  File ""main_latest.py"", line 45, in <module>
    max_queue_size=10)
  File ""/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py"", line 2177, in fit_generator
    initial_epoch=initial_epoch)
  File ""/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py"", line 216, in fit_generator
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py"", line 214, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py"", line 601, in on_epoch_end
    self.model.save(filepath, overwrite=True)
  File ""/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py"", line 1363, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File ""/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/saving.py"", line 134, in save_model
    default=serialization.get_json_type).encode('utf8')
  File ""/usr/lib/python3.5/json/__init__.py"", line 237, in dumps
    **kw).encode(obj)
  File ""/usr/lib/python3.5/json/encoder.py"", line 198, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File ""/usr/lib/python3.5/json/encoder.py"", line 256, in iterencode
    return _iterencode(o, 0)
  File ""/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/util/serialization.py"", line 64, in get_json_type
    raise TypeError('Not JSON Serializable:', obj)
TypeError: ('Not JSON Serializable:', <tf.Variable 'Variable:0' shape=() dtype=float32>)

![TypeError](https://user-images.githubusercontent.com/14198246/57926377-b8290880-78c8-11e9-92fa-d03803a27123.PNG)
"
28798,tf.data.Dataset::cache doesn't cleanup unused lock and tmp files ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13.1 / 1.14.dev / 2.0.0-alpha0
- Python version: 3.7.3
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**
`tf.data.Dataset::cache` doesn't cleanup unused `lock` and `tmp` files if the iterator doesn't complete a pass over the whole dataset or if the process exits before cache has been completed. This means subsequent runs of the same code with an incomplete cache will fail with:
```python traceback
tensorflow.python.framework.errors_impl.AlreadyExistsError: There appears to be a concurrent caching iterator running - cache lockfile already exists ('cache/mnist_0.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1558092594 [Op:IteratorGetNextSync]
```

**Describe the expected behavior**
The iterator should cleanup incomplete cache files if finished or if the process exits. This would be really handy when running multiple runs on the machine and if processes might error or finish before the cache has been complete.

**Code to reproduce the issue**
```python
import tensorflow as tf 
import tensorflow_datasets as tfds 

tf.enable_eager_execution() # if version 1.x

data = tfds.load(""mnist"", split=tfds.Split.TRAIN) 
cached = data.cache(""cache/mnist"").shuffle(100).repeat().batch(128) 
 
for feat in cached: 
    print(""iterating"")
```
"
28797,[TF2.0] Can't use keras validation data with distribution strategy ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): pip tf-nightly-gpu-2.0-preview
- TensorFlow version (use command below): 2.0.0.dev20190517
- Python version: 3.7.3
- CUDA/cuDNN version: 10 / 7.4.2.24
- GPU model and memory: 4 x V100

**Describe the current behavior**
Using keras validation data and `tf.distribute.MirroredStrategy()` will fail with `'BatchDataset' object is not subscriptable` in TF 2.0 nightly.

**Describe the expected behavior**
Without distribution strategy everything works fine.

**Code to reproduce the issue**
```python
import tensorflow as tf
import tensorflow_datasets as tfds

mnist_train, mnist_test = tfds.load(name='mnist', split=[tfds.Split.TRAIN, tfds.Split.TEST], as_supervised=True)

strategy = tf.distribute.MirroredStrategy()

def scale(image, label):
  image = tf.cast(image, tf.float32)
  image /= 255

  return image, label

train_dataset = mnist_train.map(scale).shuffle(1000).batch(256)
test_dataset = mnist_test.map(scale).batch(256)

with strategy.scope():
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(10, activation='softmax')
  ])

  model.compile(loss='sparse_categorical_crossentropy',
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])

model.fit(train_dataset, validation_data=test_dataset, epochs=10)
```

**Other info / logs**
```python traceback
  File ""tf_bug.py"", line 30, in <module>
    model.fit(train_dataset, validation_data=test_dataset, epochs=10)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 649, in fit
    validation_freq=validation_freq)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_distributed.py"", line 143, in fit_distributed
    steps_name='steps_per_epoch')
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_arrays.py"", line 145, in model_iteration
    _print_train_info(inputs, val_inputs, steps_per_epoch, verbose)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_arrays.py"", line 450, in _print_train_info
    hasattr(inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):
TypeError: 'BatchDataset' object is not subscriptable
```
"
28796,reduction_ops_gpu_complex128.cu.pic.o was not created,"**System information**
- Ubuntu 18.04.2
- https://github.com/VLOGroup/tensorflow-icg
- CUDA 10
- cudNN 7
- Python 3.6.8 |Anaconda, Inc.|
- GCC 7.3.0
- Bazel version 0.11.1


While building Tensorflow-icg (https://github.com/VLOGroup/tensorflow-icg) on a Slurm Cluster occurred the error 

```
 #warning ""host_defines.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.""
  ^~~~~~~
./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(271): error: initializer not allowed for __shared__ variable

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(320): error: initializer not allowed for __shared__ variable

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(271): error: initializer not allowed for __shared__ variable

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(320): error: initializer not allowed for __shared__ variable

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(271): error: initializer not allowed for __shared__ variable

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(320): error: initializer not allowed for __shared__ variable

6 errors detected in the compilation of ""/tmp/tmpxft_00005f84_00000000-7_reduction_ops_gpu_complex128.cu.compute_52.cpp1.ii"".
ERROR: /cluster/ty00gyna/tensorflow-icg/tensorflow/core/kernels/BUILD:2709:1: output 'tensorflow/core/kernels/_objs/reduction_ops_gpu/tensorflow/core/kernels/reduction_ops_gpu_complex128.cu.pic.o' was not created

ERROR: /cluster/ty00gyna/tensorflow-icg/tensorflow/core/kernels/BUILD:2709:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build

```


"
28792,"No gradients provided for any variable, check your graph for ops that do not support gradients while optimization","ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [""<tf.Variable 'Variable:0' shape=(784, 500) dtype=float32_ref>""


this is coming up on using -  

optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)

"
28791,RandomStandardNormal not supported by TensorFlow Lite runtime,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, 64 bit
- TensorFlow installed from (source or binary): binary (conda install tensorflow for python 3.7)
- TensorFlow version (or github SHA if from source): 1.13.0


**Provide the text output from tflite_convert**

```
--------------------------------------------------------------------------
ConverterError                           Traceback (most recent call last)
<ipython-input-36-c548bab089a8> in <module>
----> 1 tflite_model = converter.convert()

~\AppData\Local\Continuum\anaconda3\envs\diec\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
    454           input_tensors=self._input_tensors,
    455           output_tensors=self._output_tensors,
--> 456           **converter_kwargs)
    457     else:
    458       result = _toco_convert_graph_def(

~\AppData\Local\Continuum\anaconda3\envs\diec\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs)
    440   data = toco_convert_protos(model_flags.SerializeToString(),
    441                              toco_flags.SerializeToString(),
--> 442                              input_data.SerializeToString())
    443   return data
    444 

~\AppData\Local\Continuum\anaconda3\envs\diec\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str)
    203       stderr = _try_convert_to_unicode(stderr)
    204       raise ConverterError(
--> 205           ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
    206   finally:
    207     # Must manually cleanup files.

ConverterError: TOCO failed. See console for info.
2019-05-17 14:44:52.027648: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: RandomStandardNormal
2019-05-17 14:44:52.029852: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-05-17 14:44:52.030246: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-05-17 14:44:52.030690: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-05-17 14:44:52.031017: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-05-17 14:44:52.031571: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: RandomStandardNormal
2019-05-17 14:44:52.034015: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 43 operators, 65 arrays (0 quantized)
2019-05-17 14:44:52.035043: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 43 operators, 65 arrays (0 quantized)
2019-05-17 14:44:52.040937: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 14 operators, 32 arrays (0 quantized)
2019-05-17 14:44:52.041523: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 14 operators, 32 arrays (0 quantized)
2019-05-17 14:44:52.042039: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 256 bytes, theoretical optimal value: 256 bytes.
2019-05-17 14:44:52.044822: E tensorflow/lite/toco/toco_tooling.cc:421] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, EXP, FULLY_CONNECTED, LOGISTIC, MUL. Here is a list of operators for which you will need custom implementations: RandomStandardNormal.
Traceback (most recent call last):
  File ""C:\Users\issohl\AppData\Local\Continuum\anaconda3\envs\diec\Scripts\toco_from_protos-script.py"", line 10, in <module>
    sys.exit(main())
  File ""C:\Users\issohl\AppData\Local\Continuum\anaconda3\envs\diec\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\issohl\AppData\Local\Continuum\anaconda3\envs\diec\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""C:\Users\issohl\AppData\Local\Continuum\anaconda3\envs\diec\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, EXP, FULLY_CONNECTED, LOGISTIC, MUL. Here is a list of operators for which you will need custom implementations: RandomStandardNormal.

```

Also, please include a link to a GraphDef or the model if possible.

Basically this boils down to the usage of this on the model:

 epsilon = K.random_normal(shape=(batch, dim))


```
# This model is based heavily on VAE example from Keras
# https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py

from keras.layers import Lambda, Input, Dense
from keras.models import Model
from keras.utils import plot_model
from keras import backend as K
from keras.losses import mse

class VAE:
    def __init__(self, original_dim, intermediate_dim, latent_dim):
        """"""Creates a variational autoencoder for continuous values
        """"""
        self.original_dim = original_dim
        input_shape = (original_dim,)
        
        # VAE model = encoder + decoder
        # build encoder model
        inputs = Input(shape=input_shape, name='encoder_input')
        x = Dense(intermediate_dim, activation='relu')(inputs)
        x = Dense(intermediate_dim, activation='relu')(x)
        self.z_mean = Dense(latent_dim, name='z_mean')(x)
        self.z_log_var = Dense(latent_dim, name='z_log_var')(x)
        
        # use reparameterization trick to push the sampling out as input
        # note that ""output_shape"" isn't necessary with the TensorFlow backend
        z = Lambda(VAE.sampling, output_shape=(latent_dim,), name='z')([self.z_mean, self.z_log_var])
        
        # instantiate encoder model
        self.encoder = Model(inputs, [self.z_mean, self.z_log_var, z], name='encoder')
        
        # build decoder model
        latent_inputs = Input(shape=(latent_dim,), name='z_sampling')
        x = Dense(intermediate_dim, activation='relu')(latent_inputs)
        x = Dense(intermediate_dim, activation='relu')(x)
        outputs = Dense(original_dim, activation='sigmoid')(x)

        # instantiate decoder model
        self.decoder = Model(latent_inputs, outputs, name='decoder')

        # instantiate VAE model
        outputs = self.decoder(self.encoder(inputs)[2])
        self.vae = Model(inputs, outputs, name='vae_mlp')
                         
    def describe(self):
        """"""Display model summaries and saves the architectures to PNG""""""
        self.encoder.summary()
        plot_model(self.encoder, to_file='vae_mlp_encoder.png', show_shapes=True)
        self.decoder.summary()
        plot_model(self.decoder, to_file='vae_mlp_decoder.png', show_shapes=True)
        self.vae.summary()
        plot_model(self.vae, to_file='vae_mlp.png', show_shapes=True)
    
    def fit(self, X, optimizer='adam', **kwargs):
        """"""Fits the model""""""
        
        def vae_loss_func(x, x_true):
            reconstruction_loss = mse(x, x_true)
            reconstruction_loss *= self.original_dim
            kl_loss = 1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var)
            kl_loss = K.sum(kl_loss, axis=-1)
            kl_loss *= -0.5
            return K.mean(reconstruction_loss + kl_loss)
        
        self.vae.compile(optimizer=optimizer, loss=vae_loss_func)
        return self.vae.fit(X, X, **kwargs)
    
    def evaluate(self, X, **kwargs):
        """"""Evaluate the model""""""
        return self.vae.evaluate(x=X, y=X, **kwargs)
        
    # reparameterization trick
    # instead of sampling from Q(z|X), sample epsilon = N(0,I)
    # z = z_mean + sqrt(var) * epsilon
    def sampling(args):
        """"""Reparameterization trick by sampling from an isotropic unit Gaussian.
        # Arguments
            args (tensor): mean and log of variance of Q(z|X)
        # Returns
            z (tensor): sampled latent vector
        """"""
        z_mean, z_log_var = args
        batch = K.shape(z_mean)[0]
        dim = K.int_shape(z_mean)[1]

        # by default, random_normal has mean = 0 and std = 1.0
        epsilon = K.random_normal(shape=(batch, dim))
        return z_mean + K.exp(0.5 * z_log_var) * epsilon
```

Command used to reproduce:

See Jupyter Notebook: https://github.com/lisaong/diec/blob/tflite-mcu/day3/Anomaly_detection_VAE.ipynb


**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached."
28790,Build issue running build from source in Docker container,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 - docker image nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.12
- Python version: 2.7.15
- Installed using virtualenv? pip? conda?: installed using combo pip + bazel as described in installation
- Bazel version (if compiling from source): 0.18
- GCC/Compiler version (if compiling from source): 7.3.0
- CUDA/cuDNN version: CUDA 9.0 CUDNN 7.0
- GPU model and memory: Titan X - 12 GB

**Describe the problem**

When running a previously building docker container, we notice that the tensorflow build halts at the following line 

```
ERROR: /tensorflow/tensorflow/contrib/tensor_forest/hybrid/BUILD:49:1: Linking of rule '//tensorflow/contrib/tensor_forest/hybrid:gen_training_ops_py_wrappers_cc' failed (Exit 1)
/usr/bin/ld: warning: libcuda.so.1, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Stensor_Uforest_Shybrid_Cgen_Utraining_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)
```

However the docker container follows the suggested installation approach through Docker.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

The following Docker container is being used

```
ROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04

#--------------------------------------------------------------------------------------------------------------------------------
# Update and install pre-requisites
#--------------------------------------------------------------------------------------------------------------------------------
# Start with updating the existing container
RUN apt update -y && apt upgrade -y 
RUN apt install -y gedit octave python-pip python-dev python-virtualenv python-scipy git vim pkg-config zip g++ zlib1g-dev unzip wget python-enum34
RUN pip install pyyaml six numpy wheel mock keras_applications==1.0.6 keras_preprocessing==1.0.5

RUN wget https://github.com/bazelbuild/bazel/releases/download/0.18.0/bazel-0.18.0-installer-linux-x86_64.sh
RUN chmod +x bazel-0.18.0-installer-linux-x86_64.sh
RUN ./bazel-0.18.0-installer-linux-x86_64.sh

#--------------------------------------------------------------------------------------------------------------------------------
# Install TensorFlow 1.12 --> If you change anything below
#--------------------------------------------------------------------------------------------------------------------------------
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64
WORKDIR /
RUN git clone https://github.com/tensorflow/tensorflow.git
WORKDIR /tensorflow/
RUN git checkout r1.12

#--------------------------------------------------------------------------------------------------------------------------------
# Configure environment variables and system specific properties
#--------------------------------------------------------------------------------------------------------------------------------
ENV CI_BUILD_PYTHON=python
ENV TF_NEED_CUDA=1
ENV TF_CUDA_VERSION=9.0
ENV TF_CUDNN_VERSION=7
# TensorRT was checked, but challenge of getting the ScanComplete code to work on this was to large for the remaining project time - - > could be a future approach
ENV TF_NEED_TENSORRT=0
# Compute capability - TitanX 6.1 - V100 7.0 - Quadro m2000m 5.0 - Quadro m2200 5.2 - else look up on https://developer.nvidia.com/cuda-gpus
ENV TF_CUDA_COMPUTE_CAPABILITIES=6.1

#--------------------------------------------------------------------------------------------------------------------------------
# Install TensorFlow 1.12 --> If you change anything below
#--------------------------------------------------------------------------------------------------------------------------------

RUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1
RUN LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs:${LD_LIBRARY_PATH}
RUN tensorflow/tools/ci_build/builds/configured GPU

# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# EXPLICITLY SELECT WHICH OPTIONS YOU WANT BELOW
# Rule 1 - confirmed for DGX-1 system
# Rule 2 - expected values for Google cloud - should be confirmed
# Rule 3 - confirmed for TitanX, GTX1080 + Intel(R) Xeon(R) CPU E5-2630 v2
# If an optimization is not selected, and your system supports it
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 

#RUN bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-msse4.1 --copt=-msse4.2 --config=cuda --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" tensorflow/tools/pip_package:build_pip_package
#RUN bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-msse4.1 --copt=-msse4.2 --config=cuda --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" tensorflow/tools/pip_package:build_pip_package
RUN bazel build -c opt --copt=-mavx --copt=-msse4.1 --copt=-msse4.2 --config=cuda --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" tensorflow/tools/pip_package:build_pip_package

RUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip
RUN pip --no-cache-dir install --upgrade /tmp/pip/tensorflow-*.whl
RUN rm -rf /tmp/pip
RUN rm -rf /root/.cache

#--------------------------------------------------------------------------------------------------------------------------------
# Initialize the docker
#--------------------------------------------------------------------------------------------------------------------------------
# Configure the working directory inside the docker
# Set it to the default path to run all the scripts for 3frog
WORKDIR /scancomplete/

```

**Any other info / logs**

We noticed this bug only last week, since the docker container build just fine before. It might be due to the base container from nvidia having a change, but we are unable to skip this issue. 

Any help appreciated.
"
28789,ExtractImagePatches Op Request,"**System information**
- Ubuntu 14.04
- Tensorflow Installed from Binary:
- TensorFlow version 1.13:


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, MAXIMUM, MAX_POOL_2D, MUL, PAD. Here is a list of operators for which you will need custom implementations: ExtractImagePatches.
```

Also, please include a link to a GraphDef or the model if possible.
This is the onedrive link for the file
[Google Drive Link](https://drive.google.com/open?id=1pu_IAj2b9GoU4HCDd___MLg_20ikB8DZ)

**Any other info / logs**

I was trying to convert Tiny YOLO model to the tflite format when i encountered this error.
"
28788,"Bug in tf,keras.layers.Conv2D when use dilation_rate","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

```python
import tensorflow as tf # TF2

class Conv2D_BN_ReLU(tf.keras.Model):
    """"""Conv2D + BN + ReLU""""""
    def __init__(self,
            filters,
            kernel_size,
            strides=1,
            padding=""SAME"",
            dilation_rate=1,
            use_bias=False,
            kernel_initializer=""he_normal"",
            kernel_regularizer=None,
            **bn_params):
        super(Conv2D_BN_ReLU, self).__init__()

        self.conv = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides,
                padding=padding, dilation_rate=dilation_rate, use_bias=use_bias,
                kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)
        self.bn = tf.keras.layers.BatchNormalization(**bn_params)

    def call(self, x, training=None):
        x = self.conv(x)
        x = tf.nn.relu(self.bn(x, training=training))
        return x

if __name__ == ""__main__"":
    import os
    os.environ[""CUDA_VISIBLE_DEVICES""] = ""6""

    net = Conv2D_BN_ReLU(64, 1, 1, dilation_rate=6)
    x = tf.ones((1, 32, 32, 64))
    y = net(x)

    x = tf.ones((1, 64, 64, 64))
    y = net(x)
```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

tensorflow.python.framework.errors_impl.InvalidArgumentError: padded_shape[0]=68 is not divisible by block_shape[0]=6 [Op:SpaceToBatchND]

**Describe the expected behavior**

I think the second evaluation should also work, because I use padding=""SAME""

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28787,Unable to run native XLA AOT tests,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: r1.12
- Python version: python 3.6.3
- Bazel version (if compiling from source): 0.18.1
- GCC/Compiler version (if compiling from source): Apple LLVM version 10.0.1 (clang-1001.0.46.4)
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the problem**
There is a set of native tests in tensorflow/compiler/aot/tests. I am not able to run them using bazel because of a linking error while building the rule `tfcompile_test` in .../tests/BUILD. Specifically, `tfcompile_test` depends upon `test_graph_tfmatmulandadd_with_profiling` and `test_graph_tfmatmulandadd` which fail to link.

**Code to reproduce the issue**
In an untouched Tensorflow repo with r1.12 checkout and bazel 0.18.1 installed, run
`bazel build //tensorflow/compiler/aot/tests:tfcompile_test`

**Describe the current behavior**
Error message is as follows:
`/Users/willxujun/code/tensorflow/tensorflow/compiler/aot/tests/BUILD:225:1: Linking of rule '//tensorflow/compiler/aot/tests:tfcompile_test' failed (Exit 1)
Undefined symbols for architecture x86_64:
 ""___tfcompile_MatMulAndAddCompWithProfiling_HloProfilePrinterData_protobuf_array_contents"", referenced from:
      MatMulAndAddCompWithProfiling::StaticData()::'lambda'()::operator()() const in tfcompile_test.o
  ""___tfcompile_MatMulAndAddComp_ProgramShape_protobuf_array_contents"", referenced from:
      MatMulAndAddComp::StaticData()::'lambda'()::operator()() const in tfcompile_test.o
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/compiler/aot/tests:tfcompile_test failed to build`

The problem seems to stem from constructing MatMulAndAddCompWithProfiling or MatMulAndAddComp objects in `tfcompile_test.cc`. These two classes are graphs compiled by XLA. 
Disabling the relevant tests in `tfcompile_test.cc` makes the issue go away.
Alternatively, in .../aot/tests/BUILD, removing tfcompile_flags from test_graph_tfmatmulandadd, and setting enable_xla_hlo_profiling to False in test_graph_tfmatmulandadd_with_profiling makes the issue go away.
This problem seems to happen to only macOS. I could run the same command without issues in Ubuntu 16.04.
This problem seems to be related to the linking of dependencies. I could successfully run the individual `tf_library`s and get the compiled graph classes in bazel_genfiles/, and both undefined symbols are ""extern C"" variables found in the graphs' header files, and it seems the root definition is not found somehow. As a result, the graph objects cannot be constructed.

**Describe the expected behavior**
In Ubuntu 16.04, build succeeds with the following:
`INFO: Build completed successfully, 3560 total actions`
Then a tfcompile_test executable would be produced in bazel_bin/tensorflow/compiler/aot/tests, which can be run successfully.

**Other info / logs**
N/A"
28786,catch keyboard interrupt in tf.function,"**System information**
- TensorFlow version (you are using): 2.0.0-alpha
- Are you willing to contribute it (Yes/No): Maybe depends on workload



**Describe the feature and the current behavior/state.** keyboard interrupt in tf.function. Currently I cannot keyboard interrupt or break the loop in tf.function made training function.

**Will this change the current api? How?** Depends on how tf 2.0 works. Might need to change the way c++ and python interface so that we can kill the threads.

**Who will benefit with this feature?** Developers. We don't need to pkill a training process, restarts it, load checkpoint and do inference. "
28785,Can't install Tensorflow 1.14.0 ,"When i import tensorflow_model_optimization as tfmot like document, i got error:
`Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/lees/Library/Python/3.6/lib/python/site-packages/tensorflow_model_optimization/__init__.py"", line 69, in <module>
    _ensure_tf_install()
  File ""/Users/lees/Library/Python/3.6/lib/python/site-packages/tensorflow_model_optimization/__init__.py"", line 66, in _ensure_tf_install
    required=required_tensorflow_version, present=tf.__version__))
ImportError: This version of TensorFlow Model Optimization requires TensorFlow version >= 1.14.0; Detected an installation of version 1.13.1. Please upgrade TensorFlow to proceed.`

But I can't upgrade tensorflow to 1.14.0, even cannot find Tensorflow 1.14.0 by pip3 install --upgrade tensorflow==1.14.0.
So, is it a bug?"
28783,TF Lite select tf ops example linker error: libtensorflow-lite.a missing tflite subgraph,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone 7
- TensorFlow installed from (source or binary): source
- TensorFlow version: r1.13
- Python version: 2.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.19.2
- GCC/Compiler version (if compiling from source): 4.2.1
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Followed guide on [Select TensorFlow operators to use in TensorFlow Lite](https://www.tensorflow.org/lite/guide/ops_select)

Then tried to run example project `tensorflow/lite/examples/ios/camera/tflite_camera_example_with_select_tf_ops.xcodeproj`

Gave linker errors as below

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Errors as below:

> Undefined symbol: tflite::Subgraph::ModifyGraphWithDelegate(_TfLiteDelegate*)
> 
> Undefined symbol: tflite::Subgraph::AddTensors(int, int*)
> 
> Undefined symbol: tflite::Subgraph::SetTensorParametersReadOnly(int, TfLiteType, char const*, unsigned long, int const*, TfLiteQuantizationParams, char const*, unsigned long, tflite::Allocation const*)
> 
> Undefined symbol: tflite::Subgraph::ResetVariableTensors()
> 
> Undefined symbol: tflite::Subgraph::Invoke()
> 
> Undefined symbol: tflite::Subgraph::ResizeInputTensor(int, std::__1::vector<int, std::__1::allocator<int> > const&)
> 
> Undefined symbol: tflite::Subgraph::SetExecutionPlan(std::__1::vector<int, std::__1::allocator<int> > const&)
> 
> Undefined symbol: tflite::Subgraph::SetTensorParametersReadWrite(int, TfLiteType, char const*, unsigned long, int const*, TfLiteQuantizationParams, bool)
> 
> Undefined symbol: tflite::Subgraph::SetVariables(std::__1::vector<int, std::__1::allocator<int> >)
> 
> Undefined symbol: tflite::Subgraph::AddNodeWithParameters(std::__1::vector<int, std::__1::allocator<int> > const&, std::__1::vector<int, std::__1::allocator<int> > const&, char const*, unsigned long, void*, _TfLiteRegistration const*, int*)
> 
> Undefined symbol: tflite::Subgraph::AllocateTensors()
> 
> Undefined symbol: tflite::Subgraph::SetInputs(std::__1::vector<int, std::__1::allocator<int> >)
> 
> Undefined symbol: tflite::Subgraph::UseNNAPI(bool)
> 
> Undefined symbol: tflite::Subgraph::SetExternalContext(TfLiteExternalContextType, TfLiteExternalContext*)
> 
> Undefined symbol: tflite::Subgraph::SetOutputs(std::__1::vector<int, std::__1::allocator<int> >)
> 
> Undefined symbol: tflite::Subgraph::Subgraph(tflite::ErrorReporter*, TfLiteExternalContext**, std::__1::vector<std::__1::unique_ptr<tflite::Subgraph, std::__1::default_delete<tflite::Subgraph> >, std::__1::allocator<std::__1::unique_ptr<tflite::Subgraph, std::__1::default_delete<tflite::Subgraph> > > >*)
"
28782,[TF2.0] Can't use tf.data.Dataset::cache with distribution strategy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): pip tf-nightly-gpu-2.0-preview
- TensorFlow version (use command below): 2.0.0.dev20190514
- Python version: 3.7.3
- CUDA/cuDNN version: 10 / 7.4.2.24
- GPU model and memory: V100

**Describe the current behavior**
Using `tf.data.Dataset::cache` and `tf.distribute.MirroredStrategy()` will fail with `Cache should only be read after it has been completed. [Op:MultiDeviceIteratorInit]` in TF 2.0 nightly.

**Describe the expected behavior**
Using `tf-nightly-gpu==1.14.1.dev20190514` graph mode `tf.data` caching works using distribution strategy and doesn't throw an error.

**Code to reproduce the issue**
```python
import tensorflow as tf
import tensorflow_datasets as tfds

mnist_train, mnist_test = tfds.load(name='mnist', split=[tfds.Split.TRAIN, tfds.Split.TEST], as_supervised=True, data_dir=""gs://plumerai/data"")

strategy = tf.distribute.MirroredStrategy()

def scale(image, label):
  image = tf.cast(image, tf.float32)
  image /= 255

  return image, label

train_dataset = mnist_train.cache().repeat().map(scale).shuffle(1000).batch(256)
test_dataset = mnist_test.cache().repeat().map(scale).batch(256)

with strategy.scope():
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(10, activation='softmax')
  ])

  model.compile(loss='sparse_categorical_crossentropy',
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])

model.fit(train_dataset, validation_data=test_dataset, steps_per_epoch=100, validation_steps=10, epochs=10)
```

**Other info / logs**
```python
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py"", line 646, in fit validation_freq=validation_freq)
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_distributed.py"", line 143, in fit_distributed steps_name='steps_per_epoch')
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_arrays.py"", line 194, in model_iteration val_iterator = _get_iterator(val_inputs, model._distribution_strategy)
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_arrays.py"", line 512, in _get_iterator inputs, distribution_strategy)
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py"", line 529, in get_iterator initialize_iterator(iterator, distribution_strategy)
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py"", line 535, in initialize_iterator init_op = control_flow_ops.group(iterator.initialize())
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py"", line 274, in initialize return super(DistributedIteratorV1, self)._initializer
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py"", line 259, in _initializer init_ops.extend(it.initialize())
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py"", line 660, in initialize self._iterator._eager_reset() # pylint: disable=protected-access
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py"", line 333, in _eager_reset max_buffer_size=self._max_buffer_size)
File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 3118, in multi_device_iterator_init _six.raise_from(_core._status_to_exception(e.code, message), None)
File ""<string>"", line 3, in raise_from tensorflow.python.framework.errors_impl.InternalError: Cache should only be read after it has been completed. [Op:MultiDeviceIteratorInit]
```"
28779,cannot really use eager execution to see tensors inside of a layer.,"i am using tf-nightly-gpu-2.0-preview dev20190516 on ubuntu 18.04.

whenever I try to convert a tensor into a numpy array from inside the ""call"" function of a custom keras layer i get the following stack trace when I start execution:

  File ""<stdin>"", line 1, in <module>
  File ""/home/zadeck/learning/tfkeras/interrow/trainPlant.py"", line 101, in main
    modelObj.add (recLayer)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py"", line 192, in add
    output_tensor = layer(self.outputs[0])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 629, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 90, in wrapper
    ), args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 377, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File ""/tmp/tmp1ojmi3gq.py"", line 9, in tf__call
    ag__.converted_call('plotPicture', viewImage, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (ag__.converted_call('numpy', x, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None), 0), None)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 219, in converted_call
    f = getattr(owner, f)
AttributeError: 'Tensor' object has no attribute 'numpy'

This happens very early in my eager execution as if someone behind the scenes is calling the compiler on each layer before execution begins.   If i try to use the numpy attribute outside of the keras layers i have no problem.   

I do not explicitly call the ""compile"" function for my model.

I am able to trick the system into making this work hiding the access to the numpy call inside of an indirect function call.

code within keras layer that works properly:

def build (self, input_shape):
    ...
    self.indirect = self.nothing

def call (self, x):
    self.indirect (x)
    self.indirect = self.useXnumpy

def nothing (self, x):
    y = 1

def useXnumpy (self, x):
    ... =  x.numpy ()


what does not work is either have the call to x.numpy () directly in the ""call"" function for a keras layer or to directly call the useXnumpy routine from the ""call"" function of a keras layer.   Having the indirect call fools the compiler or preprocessor sufficiently to allow the values to be executed.   

I do not know if the real bug is that the preprocessing step should not be executed on the layer when in eager mode or if it simply needs to be told that calling numpy() is ok on tensors.     

I do know that i am in eager mode because i have no problem accessing the numpy function on tensors inside the loss function.    it is simply trying to do that from within a keras layer that causes problems."
28778,TF Lite can't run example project of select tensorflow operators on iOS,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: r1.13
- Python version: 2.7
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 0.19.2
- GCC/Compiler version (if compiling from source): 4.2.1
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Following guide: [Select TensorFlow operators to use in TensorFlow Lite](https://www.tensorflow.org/lite/guide/ops_select)

Built with command
`tensorflow/contrib/makefile/build_all_ios_with_tflite.sh -a arm64`

Ran example project in XCode
`tensorflow/lite/examples/ios/camera/tflite_camera_example_with_select_tf_ops.xcodeproj`

Got a list of 20 errors in cstring that look like
`No member named 'memcpy' in the global namespace`
`No member named 'memmove' in the global namespace; did you mean 'remove'?`
`No member named 'strcpy' in the global namespace`
`No member named 'strncpy' in the global namespace`


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28777,Conv2D breaking when used with keras Model subclassing,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.0 alpha gpu 
- Python version: 3.6
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
I am trying to use `tf.keras.Model` subclassing to define my model but it is failing on the first conv layer. Here is the code I am using:

```python

class CustomModel(tf.keras.Model):
  def __init__(self, **kwargs):
    super(CustomModel, self).__init__(**kwargs)
    self.conv1   = Conv2D(32, (3, 3), padding='same')
    self.conv2   = Conv2D(64, (3, 3), padding='same')
    self.pool    = MaxPooling2D(pool_size=(2, 2))
    self.bn      = BatchNormalization()
    self.relu    = Activation(""relu"")
    self.softmax = Activation(""softmax"")
    self.drop1   = Dropout(0.25)
    self.drop2   = Dropout(0.5)
    self.dense1  = Dense(512)
    self.dense2  = Dense(10)
    self.flat    = Flatten()
    
  
  
  def call(self, inputs, train):
    z = self.conv1(inputs)
    z = self.bn(z, training=train)
    z = self.relu(z)
    
    z = self.conv1(z)
    z = self.bn(z, training=train)
    z = self.relu(z)
    z = self.pool(z)
    z = self.drop1(z, training=train)
    
    z = self.conv2(z)
    z = self.bn(z, training=train)
    z = self.relu(z)
    
    z = self.conv2(z)
    z = self.bn(z, training=train)
    z = self.relu(z)
    z = self.pool(z)
    z = self.drop1(z, training=train)
    
    z = self.flat(z)
    z = self.dense1(z)
    z = self.relu(z)
    z = self.drop2(z, training=train)
    z = self.dense2(z)
    z = self.softmax(z)
    
    return z
```
In order to check if the model is working fine, I am passing a random input to the model in this way:

```
random_input = np.random.rand(32,32, 3).astype(np.float32)
random_input = np.expand_dims(random_input, axis=0)
preds = model(random_input, train=False)
```

But this throws the following error: `InvalidArgumentError: input depth must be evenly divisible by filter depth: 32 vs 3 [Op:Conv2D]`

The same model works fine with `Sequential/Functional` API. So either I am missing out on something or there is something wrong with the subclassing. Can you please look into it?"
28775,"batch_util CopySliceToElement does not support uint32, uint64 dtypes","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): master
- Python version: 3.6
- Bazel version (if compiling from source): 0.25.1
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

When batch_util::CopySliceToElement gets a dtype of uint32 or uint64, it fails with error:
`Unimplemented: CopySliceToElement Unhandled data type: 22`  (this is uint32)

This is an issue for using tensor_slice_dataset_op, which can calls this function and should also support these dtypes.

**Describe the expected behavior**
This function should handle these primitive types

**Code to reproduce the issue**
Unit tests in tensor_slice_dataset_op_test.cc fail when these dtypes are added

**Other info / logs**
NA
"
28773,TensorFlow 1.14 changes Keras callback order relative to model build,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): r1.14 branch built  from source
- TensorFlow version (use command below): r1.14
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
TensorFlow 1.14 changes the relative call order of building the model and the set_model callback in the tf.keras fit_generator path. (As of commit cd701ec in the r1.14 branch).

The keras/engine/training.py `_make_train_function` adds the optimizer update ops / aka, the backward prop phase, and fills out the model's graph. Callbacks that need full graph visibility need their `set_model` function called after the full graph is created.

The order of the operations are as follows:

tf.keras fit():  1. `_make_train_function`  2. `set_model`
tf.keras fit_generator():  1. `set_model` 2. `_make_train_function`
keras_team Keras fit():  1. `_make_train_function`  2. `set_model`
keras_team Keras fit_generator():  1. `_make_train_function`  2. `set_model`

The tf.keras fit_generator() path stands out as being different from the rest.

Commit https://github.com/tensorflow/tensorflow/commit/a332fea0be8def4aa5985499ad807ef78d029142 fixed this for the non-eager mode case and added a test case to help prevent future regression.  Commit https://github.com/tensorflow/tensorflow/commit/615182adb3d01fd8357e574bd8920c0995c6bbb8#diff-6561418ac6882a842d78dad52731895b regressed this order, and also removed the test case that was intended to catch regressions.

Another side effect of the current code is that the `_make_train_function` is called from `model.train_on_batch` so in the fit_generator path this is now being called on every iteration. While the majority of the `_make_train_function` is guarded by a check that won't do actual work, there are somethings in that method that will run and waste cycles on every iteration.

**Describe the expected behavior**
The Keras callback `set_model` method should be called after the whole model is populated. 

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
28767,tf.keras.callbacks.Tensorboard: write_images does not visualize Conv2D weights,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- TensorFlow version (use command below): v1.12.2-0-gcf74798993 1.12.2
- Python version: 3.6.5

**Describe the current behavior**
When I want to have a look at the weights of Conv2D filters in TensorBoard, only their biases get logged (see attached image). I looked for the corresponding source code and found the following snippet:
https://github.com/tensorflow/tensorflow/blob/6612da89516247503f03ef76e974b51a434fb52e/tensorflow/python/keras/callbacks.py#L951-L983
The problem seems to be that Conv2D weights have a 4d shape [H_kernel, W_kernel, C_in, C_out], which is not intended as convolutional layers case in the above code.


**Describe the expected behavior**
I would expect that the convolutional weights are visualized. I know this would be a huge amount of images (C_in * C_out), but I think the current behaviour is confusing.

**Code to reproduce the issue**
```python
import tensorflow as tf

cifar10 = tf.keras.datasets.cifar10

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
print(type(x_train))
model = tf.keras.models.Sequential([
    tf.keras.layers.InputLayer(input_shape=(32, 32, 3)),
    tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])
model.summary()

tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f""../../../logs"", histogram_freq=1,
                                             write_images=True, write_grads=True)
csvlogger = tf.keras.callbacks.CSVLogger('train.log')
model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5, callbacks=[tensorboard, csvlogger], validation_data=(x_test, y_test))
```
**Other info / logs**
![image](https://user-images.githubusercontent.com/34747372/57854395-6f9a1e00-77e8-11e9-9223-bdd8845ac478.png)

"
28766,Statefulness in Text generation using a RNN with eager execution,"## URL(s) with the issue:

https://www.tensorflow.org/tutorials/sequences/text_generation

## Description of issue (what needs changing):

### Clear description

* Two questions regarding the `stateful` defined in the tutorial. 
* The input data was originally a long text. It got cut into sequences with length 100, shuffled, and packed into batches of size 64. However, according to the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN) for the `statefulness`
> You can set RNN layers to be 'stateful', which means that the states
computed for the samples in one batch will be reused as initial states
for the samples in the next batch. This assumes a one-to-one mapping
between samples in different successive batches.

After pre-processing the data as discussed above, there is no such one-to-one mapping is not there, i.e. the samples in different batches are independent instead of related. This is confirmed by running the following code after the code for create training batches, which print out the successive samples with index `0` in the first two batches. 
```Python
for input_example, target_example in  dataset.take(2):
  print ('Input data: ', repr(''.join(idx2char[input_example[0, :].numpy()])))
```
outputs
```Python
Input data:  'n that perished vessel the dowry of his\nsister. But mark how heavily this befell to the\npoor gentlew'
Input data:  ""y enrich'd\nWith politic grave counsel; then the king\nHad virtuous uncles to protect his grace.\n\nFirs""
```
---
* In addition, if `stateful=True`, it is suggested to set `shuffle=False` in the `model.fit()`, which is also missing in the tutorial. 
> specify `shuffle=False` when calling fit().

* The problems above are really confusing and any discussions are welcome. "
28765,import issue tensorflow v2 and v1 ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Windows Server 2016 Standard:
- CPU Xeon (R) CPU E5-2698 v4
- AVX2
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0.0-alpha0 
- Python version: 3.6.8
- Installed using: Tried with: virtualenv, pip and  conda




**Describe the problem**
Installation works fine but  import tensorlfow does not work
**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow as tf

**Any other info / logs**
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\ProgramData\Anaconda3\envs\testtf\lib\site-packages\tensorflow\__init__.py"", line 27, in <module>
    from tensorflow._api.v2 import audio
  File ""C:\ProgramData\Anaconda3\envs\testtf\lib\site-packages\tensorflow\_api\v2\audio\__init__.py"", line 8, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\ProgramData\Anaconda3\envs\testtf\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\envs\testtf\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\envs\testtf\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\envs\testtf\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\envs\testtf\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\envs\testtf\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\envs\testtf\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.
```
See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
28763,Name of losses.Reduction.SUM_BY_NONZERO_WEIGHTS is misleading,"**Describe the current behavior**
`losses.Reduction.SUM_BY_NONZERO_WEIGHTS` calculates the mean, not the sum. (The behavior is in sync with the [docs](https://www.tensorflow.org/api_docs/python/tf/losses/Reduction).)
**Describe the expected behavior**
I would expect `losses.Reduction.SUM_BY_NONZERO_WEIGHTS` to calculate the sum, not the mean.
"
28762,[tensorflow/docs]Translate variables.md from English to Chinese.,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
28761,Can't set an initial state for the Bidirectional LSTM Layer of tf.keras 2.0 under eager execution mode,"**System information**
- Have I written custom code: No
- OS Platform and Distribution: MacOS 10.14.4 
- TensorFlow installed from: pip install tensorflow==2.0.0-alpha0 
- TensorFlow version: v1.12.0-9492-g2c319fb415 2.0.0-alpha0
- Python version: 3.7.3

**Describe the current behavior**
- Get an Error when setting an initial state for the Bidirectional LSTM Layer of tf.keras 2.0 under eager execution mode

**Describe the expected behavior**
- The code should work with eager execution mode.

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np


hidden_units = 64
time_step = 50
vocab_size = 100
embed_size = 64
batch_size = 10

embedding = tf.keras.layers.Embedding( vocab_size, embed_size, input_length=time_step, trainable=False )
lstm =  tf.keras.layers.LSTM(hidden_units, return_sequences=False, return_state=True )
bilstm_1 =  tf.keras.layers.Bidirectional(lstm, name='bilstm1')
bilstm_2 =  tf.keras.layers.Bidirectional(lstm, name='bilstm2')
concat =  tf.keras.layers.Concatenate()
dense = tf.keras.layers.Dense(vocab_size, activation='softmax')

def mod(input_1,input_2):
    
    input_1 = embedding(input_1)
    input_2 = embedding(input_2)
    output_1, forward_h, forward_c, backward_h, backward_c = bilstm_1(input_1)
    output_2, _,_,_,_ = bilstm_2(input_2, initial_state=(forward_h, forward_c, backward_h, backward_c))
    output = dense(concat([output_1,output_2]))
    return output

input_1=np.random.randint(0,99,size=[batch_size, time_step])
input_2=np.random.randint(0,99,size=[batch_size, time_step])
target = np.random.randint(2,size=[batch_size])

#test the model
mod(input_1,input_2)

```

**Other info / logs**
The Error detail：
`InvalidArgumentError: Incompatible shapes: [2,256] vs. [50,256] [Op:Add] name: bilstm2/add/`"
28760,TF2.0 custom dynamic rnn with autograph and tensorflow datasets fails to run,"When I followed the effective tensorflow2 instructions to try custom dynamic loop optimized with autograph, I encountered the following errors. It seems the sequence length used in dynamic rnn became None. Everything is fine if I disable tf.function and replace DynamicRNN with DynamicRNNV2, which uses eager execution.
```python
# model.py
import tensorflow as tf
from tensorflow.keras import layers


class Model(tf.keras.Model):
  def __init__(self, vocab_size, emb_size, rnn_size):
    super(Model, self).__init__()
    self.embedding = layers.Embedding(vocab_size, emb_size)
    self.rnn = DynamicRNN(rnn_size)

  def call(self, x):
    x = self.embedding(x)
    x, _ = self.rnn(x)
    return x

class DynamicRNN(layers.Layer):
  def __init__(self, rnn_size):
    super(DynamicRNNV1, self).__init__()
    self.rnn_size = rnn_size
    self.cell = layers.GRU(rnn_size, return_state=True)

  @tf.function
  def call(self, input_data):
    outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)
    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)
    for i in tf.range(input_data.shape[1]):
      print(input_data)
      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)
      outputs = outputs.write(i, output)
    return tf.transpose(outputs.stack(), [1, 0, 2]), state

class DynamicRNNV2(layers.Layer):
  def __init__(self, rnn_size):
    super(DynamicRNNV2, self).__init__()
    self.rnn_size = rnn_size
    self.cell = layers.GRU(rnn_size, return_state=True)

  def call(self, input_data):
    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)
    outputs = []
    for i in range(input_data.shape[1]):
      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)
      outputs.append(tf.expand_dims(output, 1))
    return tf.concat(outputs, axis=1), state
```

```
2019-05-16 08:15:39.248597: I tensorflow/stream_executor/platform/default/dso_loader.cc:43] Successfully opened dynamic library libcublas.so.10.0
I0516 08:15:39.560903 140231802230528 train.py:55] (256, 120, 16)
Tensor(""input_data:0"", shape=(256, 160, 16), dtype=float32)
I0516 08:15:40.161331 140231802230528 train.py:55] (256, 160, 16)
Tensor(""input_data:0"", shape=(256, None, 16), dtype=float32)
Traceback (most recent call last):
  File ""train.py"", line 59, in <module>
    app.run(main)
  File ""/opt/conda/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/opt/conda/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""train.py"", line 54, in main
    output = model(question)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 678, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/workspace/code/tf_workspace/dataset_test/model.py"", line 36, in call
    x, _ = self.rnn(x)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 678, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 424, in __call__
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1305, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1625, in _maybe_define_function
    args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1527, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 713, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 329, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2126, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 705, in wrapper
    ), args, kwargs)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 360, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File ""/tmp/tmppfaea7ty.py"", line 20, in tf__call
    outputs, state = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (input_data.shape[1],), None), None, loop_body, (outputs, state))
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 264, in converted_call
    return _call_unconverted(f, args, kwargs)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 173, in _call_unconverted
    return f(*args)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py"", line 1305, in range
    limit = ops.convert_to_tensor(limit, dtype=dtype, name=""limit"")
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1086, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1144, in convert_to_tensor_v2
    as_ref=False)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1223, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 305, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 246, in constant
    allow_broadcast=True)
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 284, in _constant_impl
    allow_broadcast=allow_broadcast))
  File ""/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 455, in make_tensor_proto
    raise ValueError(""None values not supported."")
ValueError: None values not supported.
```

```python
# train.py
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import sys

from absl import app
from absl import flags
from absl import logging
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.python.ops import control_flow_util

from model import Model

sys.path.append(os.path.dirname(os.path.dirname(sys.path[0])))

control_flow_util.ENABLE_CONTROL_FLOW_V2 = True

FLAGS = flags.FLAGS

flags.DEFINE_integer(""batch_size"", 256, ""Batch size."")


def main(_):
  dataset_train, info = tfds.load(name=""squad/bytes"",
                                  split=tfds.Split.TRAIN, with_info=True,
                                  data_dir=""tensorflow_datasets"",
                                  batch_size=FLAGS.batch_size)

  vocab_size = info.features[""question""].encoder.vocab_size
  model = Model(vocab_size=vocab_size, emb_size=16, rnn_size=16)

  for i in range(1):
    for features in dataset_train:
      question = features[""question""]
      output = model(question)
      logging.info(output.shape)


if __name__ == ""__main__"":
  app.run(main)
```
"
28759,Tf.dataset shuffle buffer cannot release,"**System information**
- TensorFlow version (you are using): 2.0 alpha gpu

**Describe the feature and the current behavior/state.**
- When using shuffle op of tf.dataset, the buffer cannot release when the dataset instance is deleted. 
For example, i train my model with 2 datasets in sequence.
dataset1.shuffle(buffer_size = 1000)
model.fit(dataset1)   memory consumption: 50%
del dataset1
dataset2.shuffle(buffer_size = 1000) memory consumption: 80%
model.fit(dataset2)

This is not a matter when shuffle filenames, but serious for img dataset comes form a tfrecord file.
For instance in my case, 1000 imgs(600 X 600 X 3, FP32) in the buffer consumed 30% resource of machine which is really a big matter for automatic train process



"
28757,voice activity detection implementation,"I found that voice activity detection is implemented in the paper ""Small-Footprint Keyword Spotting Using Deep Neural Networks"". But I did not find anything related to voice activity detection in the paper ""Convolutional Neural Networks for Small-footprint Keyword Spotting"".
My question is that is voice activity detection implemented in this code or not?
"
28753,Tflite metal gpu ios model reload,"My target is ios device ,Target backend is metal gpu , Durining our test ,I found that 'memory leak'  occured when switch different models  about 100 times ,so  how to release last neural models ?like below:
interpreter=nullptr
DeleteGpuDelegate(delegate)
is it right ?"
28752,"""ValueError: Unknown layer: name"" when creating deep copy of model","I created a custom layer, which looks as follows:

```
class NoisyLayer(keras.layers.Layer):

    def __init__(self, in_shape=(1,2592), out_units=256, activation=tf.identity): 
        super(NoisyLayer, self).__init__()
        self.in_shape = in_shape
        self.out_units = out_units
        self.mu_interval = 1.0/np.sqrt(float(self.out_units))
        self.sig_0 = 0.5
        self.activation = activation
        self.assign_resampling()

    def build(self, input_shape):
        # Initializer
        self.mu_initializer = tf.initializers.random_uniform(minval=-self.mu_interval, maxval=self.mu_interval)
        self.si_initializer = tf.initializers.constant(self.sig_0/np.sqrt(float(self.out_units)))

        # Weights
        self.w_mu = tf.Variable(initial_value=self.mu_initializer(shape=(self.in_shape[-1], self.out_units), dtype='float32'), trainable=True)
        self.w_si = tf.Variable(initial_value=self.si_initializer(shape=(self.in_shape[-1], self.out_units), dtype='float32'), trainable=True)

        # Biases
        self.b_mu = tf.Variable(initial_value=self.mu_initializer(shape=(self.in_shape[0], self.out_units), dtype='float32'), trainable=True)
        self.b_si = tf.Variable(initial_value=self.si_initializer(shape=(self.in_shape[0], self.out_units), dtype='float32'), trainable=True)

        super(NoisyLayer, self).build(input_shape)

    def call(self, inputs, resample_noise_flag):
        if resample_noise_flag:
            self.assign_resampling()

        # Putting it all together
        self.w = tf.math.add(self.w_mu, tf.math.multiply(self.w_si, self.w_eps))
        self.b = tf.math.add(self.b_mu, tf.math.multiply(self.b_si, self.q_eps))

        return self.activation(tf.linalg.matmul(inputs, self.w) + self.b)

    def compute_output_shape(self, input_shape):
        return (input_shape[0], self.out_units)

.......
```

The layer itself seems to work. However, the error arises when working with the following model, which makes use of the layer :

```
class Network:
    def __init__(self, actionspace_size, learning_rate, gradient_momentum, gradient_min):
        frames_input = keras.layers.Input((84, 84, 4))
        actions_input = keras.layers.Input((actionspace_size,))

        conv1 = keras.layers.Conv2D(16, (8, 8), strides=(4, 4), activation=""relu"")(frames_input)
        conv2 = keras.layers.Conv2D(32, (4, 4), strides=(2, 2), activation=""relu"")(conv1)

        flattened = keras.layers.Flatten()(conv2)

        # NoisyNet        
        hidden = NoisyLayer(activation=tf.nn.relu)(inputs=flattened, resample_noise_flag=True)
        output = NoisyLayer(in_shape=(1,256), out_units=actionspace_size)(inputs=hidden, resample_noise_flag=True)
        
        filtered_output = keras.layers.merge.Multiply()([output, actions_input])

        self.model = keras.models.Model(inputs=[frames_input, actions_input], outputs=filtered_output)

        self.model.compile(loss='mse', optimizer=keras.optimizers.RMSprop(lr=learning_rate, rho=gradient_momentum, epsilon=gradient_min))
```

Particularly, the error occurs when I try to make a deepcopy of the network, which looks as follows:

```
import copy
q_net = Network(actionspace_size, learning_rate, gradient_momentum, gradient_min).model
target_net = copy.deepcopy(q_net)
```

The error raised looks as follows:

```
2019-05-16 00:35:37.698461: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Traceback (most recent call last):
  File ""DQN_tf_NoisyNet.py"", line 318, in <module>
    main()
  File ""DQN_tf_NoisyNet.py"", line 255, in main
    target_net = copy.deepcopy(q_net)
  File ""/usr/lib/python3.5/copy.py"", line 182, in deepcopy
    y = _reconstruct(x, rv, 1, memo)
  File ""/usr/lib/python3.5/copy.py"", line 299, in _reconstruct
    y.__setstate__(state)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/network.py"", line 1266, in __setstate__
    model = saving.unpickle_model(state)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py"", line 435, in unpickle_model
    return _deserialize_model(f)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py"", line 225, in _deserialize_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py"", line 458, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/usr/local/lib/python3.5/dist-packages/keras/layers/__init__.py"", line 55, in deserialize
    printable_module_name='layer')
  File ""/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py"", line 145, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/network.py"", line 1022, in from_config
    process_layer(layer_data)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/network.py"", line 1008, in process_layer
    custom_objects=custom_objects)
  File ""/usr/local/lib/python3.5/dist-packages/keras/layers/__init__.py"", line 55, in deserialize
    printable_module_name='layer')
  File ""/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py"", line 138, in deserialize_keras_object
    ': ' + class_name)
ValueError: Unknown layer: NoisyLayer
```

Apparently, Tensorflow seems to be incapable of making a deepcopy of the custom layer, since, as soon as I replace the two instances of the custom layer by dense layers, the code works again. 

So, I was  wondering whether there is some way to tell Tensorflow how to interpret the custom layer when executing the deepcopy command.

I am using Tensorflow 1.12.0 in Python3.5.2 on Ubuntu 16.04. Thanks in advance!"
28751,Error then try to feed sparse data to tensorflow dataset api,"Tensorflow 1.13.1

I have a sparse numpy array and trying to feed it to dataset api and dynamically pad in every batch.

```
import tensorflow as tf
import numpy as np

X = np.array([np.ones((np.random.randint(5, 10), 1)) for i in range(10)])
y = np.ones(10).reshape(-1, 1)


data = tf.data.Dataset.from_tensor_slices((X, y))
data = data.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=2))
data = data.padded_batch(10, padded_shapes=([None, 1], []))
iterator = tf.data.Iterator.from_structure(data.output_types, data.output_shapes)
batch = iterator.get_next()
init_op = iterator.make_initializer(data)

with tf.Session() as sess:
    sess.run(init_op)
    batch_out = sess.run(batch)
    print(batch_out)
```

But get error
```
Expected binary or unicode string, got array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]])
```"
28748,Counting parameters from Keras model doesn't work correctly with list of layers,"Below is an example that keras model is not able to count correctly the number of parameters when custom keras layers are inside a list that is defined in an another custom layer. 

```
import tensorflow as tf

class TestLayer2(tf.keras.layers.Layer):
    def __init__(self, dim):
        super(TestLayer2, self).__init__()
        self.dense1 = tf.keras.layers.Dense(dim)
        
    def call(self, x):
        x = self.dense1(x)
        return x

class TestLayer1(tf.keras.layers.Layer):
    def __init__(self, dim):
        super(TestLayer1, self).__init__()
        self.list_of_dense = [TestLayer2(dim) for _ in range(2)]
        
    def call(self, x):
        for i in range(len(self.list_of_dense)):
            x = self.list_of_dense[i](x)
        return x
    
class TestModel(tf.keras.Model):
    def __init__(self, dim):
        super(TestModel, self).__init__()
        self.dense1 = tf.keras.layers.Dense(dim)
        self.layer = TestLayer1(dim*2)
        
    def call(self, x):
        x = self.dense1(x)
        x = self.layer(x)
        return x

t_model = TestModel(512)

tmp = tf.random.normal([64,512])

t_model(tmp)

t_model.summary()
```

returns 

```_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4728 (Dense)           multiple                  262656    
_________________________________________________________________
test_layer1_13 (TestLayer1)  multiple                  0         
=================================================================
Total params: 262,656
Trainable params: 262,656
Non-trainable params: 0
```
which is not correct. If the nested layers were outside a list then are counted correctly.

```
import tensorflow as tf

class TestLayer2(tf.keras.layers.Layer):
    def __init__(self, dim):
        super(TestLayer2, self).__init__()
        self.dense1 = tf.keras.layers.Dense(dim)
        
    def call(self, x):
        x = self.dense1(x)
        return x

class TestLayer1(tf.keras.layers.Layer):
    def __init__(self, dim):
        super(TestLayer1, self).__init__()
        self.dense1 = TestLayer2(dim)
        self.dense2 = TestLayer2(dim)
        
    def call(self, x):
        x = self.dense1(x)
        x = self.dense2(x)
        return x

class TestModel(tf.keras.Model):
    def __init__(self, dim):
        super(TestModel, self).__init__()
        self.dense1 = tf.keras.layers.Dense(dim)
        self.layer = TestLayer1(dim*2)
        
    def call(self, x):
        x = self.dense1(x)
        x = self.layer(x)
        return x

t_model = TestModel(512)

tmp = tf.random.normal([64,512])

t_model(tmp)

t_model.summary()
```

which gives 

```
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4731 (Dense)           multiple                  262656    
_________________________________________________________________
test_layer1_14 (TestLayer1)  multiple                  1574912   
=================================================================
Total params: 1,837,568
Trainable params: 1,837,568
Non-trainable params: 0
```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.13
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.0/CuDNN 7.3.1
- GPU model and memory: Nvidia Titan V
"
28742,TFLite only slightly faster with GPU on Helio P22,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): n/a
- Mobile device: **Xiaomi Redmi 6**
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): r1.13
- Python version: n/a
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: **PowerVR GE8320**

**Describe the current behavior**

Running the [TFLite Demo](https://github.com/tensorflow/tensorflow/tree/6d28416/tensorflow/lite/java/demo), average inference time for 1 thread is **480ms**, but it's just **370ms** with GPU. With 4 threads, it's **360ms**.

**Describe the expected behavior**

I'd expect GPU performance to be (significantly) better than 4-thread CPU. Granted it's not a great GPU, but I'd expect it to be substantially faster than the CPU.

**Other info / logs**

Xiaomi Redmi 6:
- OS | Android 8.1 (Oreo), planned upgrade to Android 9.0 (Pie)
- Chipset | Mediatek MT6762 Helio P22 (12 nm)
- CPU | Octa-core 2.0 GHz Cortex-A53
- GPU | PowerVR GE8320
"
28741,Add tf.normalize to provide a clean interface for tensor normalization,"**System information**
- TensorFlow version (you are using): 1.3+ or 2.0a
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Currently there are two ""ways"" to normalize vectors, matrices, and tensors.
1. `tf.math.l2_normalize`
2. `tf.norm`

The first one directly normalizes the input tensor and returns it.
The latter only computes the norm and the user has to do the division to obtain a normalized tensor.

I propose to add a function called `tf.math.normalize` which has the same/similar `args` as `tf.norm`. It computes the normalized tensor as `tf.math.l2_normalize` does but supports all the normalizations that `tf.norm` supports.

**Will this change the current api? How?**
No, it just adds a cleaner interface to do normalization.
In the long run `tf.math.l2_normalize` would be obsolete, though. It's implementation could be removed and it could use `tf.normalize` internally.

**Who will benefit with this feature?**
When looking for a way to perform l1 normalization I only found `l2_normalize` and `tf.norm`. I then expected there to exist a `l1_normalize` function as well which is not the case.
From my point of view this is an inconsistency that people will encounter from time to time.

I would propose to only add this to tensorflow 2.0 and maybe also remove `tf.math.l2_normalize` in that case."
28740,Parallel 2 conv layer but got the same time consumption as serial,"Hi,
I'm trying to study the parallelization of static graphs, so I realize tensorflow codes with 2 convolution layers taking the same input.
Here's my code with tensorflow 1.12.0.
```
import os
import time
import math
import numpy as np
import tensorflow as tf

os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""
os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""

def test(m, session, feed_dict, t):
    for i in range(t):
        session.run([m.y, m.z], feed_dict=feed_dict)

def main():
    m = Model()
    session = tf.Session()
    session.run(m.init_op)
    feed_dict = {
        m.x: np.zeros([4, 56, 56, 32]),
    }
    print('hot')
    test(m, session, feed_dict, 100)
    print('start')
    start = time.time()
    test(m, session, feed_dict, 10000)
    print((time.time()-start) / 10000 * 1000)

class Model:
    def _conv_layer(self, name, input_var, stride, in_channels, out_channels):
        KERNEL_SIZE = 3
        with tf.variable_scope(name) as scope:
            filter_shape = [KERNEL_SIZE, KERNEL_SIZE, out_channels, in_channels]
            kernel = tf.get_variable(
                'weights',
                shape=filter_shape,
                initializer=tf.truncated_normal_initializer(stddev=math.sqrt(2.0 / KERNEL_SIZE / KERNEL_SIZE / in_channels)),
                dtype=tf.float32
            )
            biases = tf.get_variable(
                'biases',
                shape=[out_channels],
                initializer=tf.constant_initializer(0.0),
                dtype=tf.float32
            )
            output = tf.nn.bias_add(
                tf.nn.conv2d(
                    input_var,
                    kernel,
                    [1, stride, stride, 1],
                    padding='SAME'
                ),
                biases
            )
            return output

    def __init__(self):
        tf.reset_default_graph()
        self.x = tf.placeholder(tf.float32, [None, 56, 56, 32])

        self.y = self._conv_layer('layer', self.x, 1, 32, 32)
        self.z = self._conv_layer('layer2', self.x, 1, 32, 32)

        self.init_op = tf.initialize_all_variables()

if __name__ == '__main__':
    main()
```
The time consumption is the same as `self.z = self._conv_layer('layer2', self.y, 1, 32, 32)` (note the `self.y`), so that confuse me about the parallel performance of tensorflow, can any body help to explain that or realize the true parallel way of 2 conv layers (in a single gpu) ?"
